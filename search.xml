<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CMD和ENTRYPOINT区别</title>
    <url>/2021/07/18/CMD%E5%92%8CENTRYPOINT%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>title: CMD和ENTRYPOINT区别<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: CMD和ENTRYPOINT区别<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. ENTRYPOINT 简介       ENTRYPOINT 容器启动后执行的命令,让容器执行表现的像一个可执行程序一样,与CMD 的 区 别 是 不 可 以 被 docker run 覆 盖 , 会 把 docker run 后 面 的 参 数 当 作 传 递 给 ENTRYPOINT 指令的参数。       Dockerfile 中只能指定一个 ENTRYPOINT,如果指定了很多,只 有 最 后 一 个 有 效 。 docker run 命 令 的 -entrypoint 参 数 可 以 把 指 定 的 参 数 继 续 传 递 给ENTRYPOINT<img alt="clipboard.png" src="https://img-blog.csdnimg.cn/img_convert/97399bfd3dcf7c555383392f8a860e95.png">1. CMD简介<img alt="clipboard.png" src="https://img-blog.csdnimg.cn/img_convert/238b9202658310be9fead467bbd5225d.png"><li>案例（下面基于centos这个基础镜像构建一个镜像测试CMD命令） 1)在/opt/dockerfile目录下创建一个Dockerfile文件         <img alt="" height="252" src="https://img-blog.csdnimg.cn/20201226125025104.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="640">       <pre><code class="language-bash">#基于我们从阿里云下载下来的centos基础镜像<br>FROM centos</p>
<p>CMD [“/bin/echo”,”this is test cmd”]</code></pre>        2)使用dockerfile构建镜像        命令：docker build -f /opt/dockerfile/mydockerfile-test -t cmdtest:v1.0 .<img alt="" height="294" src="https://img-blog.csdnimg.cn/20201226125501906.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1016"> 3)启动刚刚创建的镜像       命令：docker run -it 镜像id      <img alt="" height="310" src="https://img-blog.csdnimg.cn/20201226132049861.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="811">        可以看到，/bin/echo This is test cmd 这条命令成功执行.        直接进入container里面，而不执行echo指令，可以在docker run 后面直接加上/bin/bash命令，/bin/bash命令会覆盖掉cmd后面的命令。        <img alt="" height="67" src="https://img-blog.csdnimg.cn/20201226132816526.png" width="710">        /bin/bash 命令覆盖掉了dockerfile中的cmd命令，直接进入到了container中。</li><li>案例（下面基于centos这个基础镜像构建一个镜像测试ENTRYPOINT命令） 1)在/opt/dockerfile目录下创建一个Dockerfile文件     <img alt="" height="256" src="https://img-blog.csdnimg.cn/20201226133307368.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="660">     <pre><code class="language-bash">#基于我们从阿里云下载下来的centos基础镜像<br>FROM centos</p>
<p>ENTRYPOINT [“/bin/echo”,”this is test entrypoint”]</code></pre>  2)使用dockerfile构建镜像       <img alt="" height="191" src="https://img-blog.csdnimg.cn/20201226133444798.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="884"> 3)启动刚刚创建的镜像       a: 直接在docker run 后面加参数/bin/bash，entrypoint会把/bin/bash当成一个echo的字符串参数，不会进入到容器中。            <img alt="" height="331" src="https://img-blog.csdnimg.cn/20201226133622564.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="938">       b: 如果想覆盖dockerfile中entrypoint指令，可以在docker run命令中加–entrypoint参数来指定。          <img alt="" height="54" src="https://img-blog.csdnimg.cn/20201226133856718.png" width="934">           可以发现不打印上面的内容了，直接进入容器       c：直接启动容器          <img alt="" height="92" src="https://img-blog.csdnimg.cn/20201226134031861.png" width="738"></li></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>CSS3 新增圆角以及盒子阴影</title>
    <url>/2021/07/18/CSS3%20%E6%96%B0%E5%A2%9E%E5%9C%86%E8%A7%92%E4%BB%A5%E5%8F%8A%E7%9B%92%E5%AD%90%E9%98%B4%E5%BD%B1/</url>
    <content><![CDATA[<p>title: CSS3 新增圆角以及盒子阴影<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—1.圆角边框</p>
<blockquote>
 <pre><code class="language-css">border-radius:length;
</blockquote>
<p>border-top-left-radius   定义了左上角的弧度<br>border-top-right-radius   定义了右上角的弧度<br>border-bottom-right-radius   定义了右下角的弧度<br>border-bottom-left-radius   定义了左下角的弧度<br></code></pre> </p>
<ul>
<li>其中每一个值可以为 数值或百分比的形式。 -  技巧：让一个正方形 变成圆圈 <pre><code class="language-css">border-radius: 50%;
</code></pre> 
<img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/cd90d25bf757638154c28d92250dac7c.png">如果要在四个角上一一指定，可以使用以下规则👇👇： <pre><code class="language-css">border-radius: 左上角 右上角  右下角  左下角;
</code></pre> </li>
<li> 四个值: 第一个值为左上角，第二个值为右上角，第三个值为右下角，第四个值为左下角。 -  三个值: 第一个值为左上角, 第二个值为右上角和左下角，第三个值为右下角 -  两个值: 第一个值为左上角与右下角，第二个值为右上角与左下角 -  一个值：四个圆角值相同 </li>
</ul>
<p>2.盒子阴影(box-shadow)</p>
<blockquote>
 <pre><code class="language-css">box-shadow: offset-x offset-y [blur [spread]] [color] [inset]
</code></pre> 
 <table><thead>|值|描述
</blockquote>
</thead><tbody>|offset-x|阴影的水平偏移量。正数向右偏移，负数向左偏移。
|offset-y|阴影的垂直偏移量。正数向下偏移，负数向上偏移。
|blur|可选。阴影模糊距离，不能取负数。
|spread|可选。阴影大小
|color|可选。阴影的颜色
|inset|可选。表示添加内阴影，默认为外阴影
</tbody></table>
 <pre><code class="language-css">div &#123;
   width: 200px;
   height: 200px;
   border: 10px solid red;
   /* box-shadow: 5px 5px 3px 4px rgba(0, 0, 0, .4);  */
   /* box-shadow:水平位置 垂直位置 模糊距离 阴影尺寸（影子大小） 阴影颜色  内/外阴影； */
   box-shadow: 0 15px 30px  rgba(0, 0, 0, .4);   
&#125;</code></pre> 


<p> </p>
]]></content>
      <categories>
        <category>Css</category>
      </categories>
  </entry>
  <entry>
    <title>CSS三大特性：继承性,层叠性,优先级</title>
    <url>/2021/07/18/CSS%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7%EF%BC%9A%E7%BB%A7%E6%89%BF%E6%80%A7,%E5%B1%82%E5%8F%A0%E6%80%A7,%E4%BC%98%E5%85%88%E7%BA%A7/</url>
    <content><![CDATA[<p>title: CSS三大特性：继承性,层叠性,优先级<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—1.CSS 层叠性</p>
<blockquote>
 <img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/b344df10be0a874a08eb3facfe676d9f.png"> 
 -`概念`： 
</blockquote>
<ul>
<li> 所谓层叠性是指多种CSS样式的叠加 -  是浏览器处理冲突的一个能力,如果一个属性通过两个相同选择器设置到同一个元素上，那么这个时候一个属性就会将另一个属性层叠掉 </li>
<li><code>原则</code>： </li>
<li> 样式冲突，遵循的原则是就近原则。 那个样式离着结构近，就执行那个样式。 -  样式不冲突，不会层叠。 </li>
</ul>
<p>2.CSS 继承性</p>
<blockquote>
 <img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/9d2cc036b8878879f807166ec03fb36f.png"> 
 -`概念`： 
</blockquote>
<ul>
<li> 子标签会继承父标签的某些样式，如文本颜色和字号。 -  想要设置一个可继承的属性，只需将它应用于父元素即可。 </li>
<li><code>注意</code>： </li>
<li>恰当地使用继承可以简化代码，降低CSS样式的复杂性。比如有很多子级孩子都需要某个样式，可以给父级指定一个，这些孩子继承过来就好了。 -  子元素可以继承父元素的样式（<strong>text-，font-，line-这些元素开头的可以继承，以及color属性</strong>）<br>行高的继承： <pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
 &lt;meta charset="UTF-8"&gt;
 &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
 &lt;title&gt;CSS行高的继承&lt;/title&gt;
&lt;style&gt;
body&#123;
color:cyan;
font:12px/1.5 bold;
&#125;</li>
</ul>
<p>div&#123;<br>  font-size:40px;//有指定文字大小，则为40x1.5px;<br>&#125;</p>
<p>  &lt;/style&gt;<br>&lt;/head&gt;</p>
<p>&lt;body&gt;<br>  &lt;div&gt;zzf1&lt;/div&gt;<br>  &lt;p&gt;我没有指定文字大小&lt;/p&gt;//没有指定文字大小，则为12px;<br>&lt;/body&gt;<br>&lt;/html&gt;</p>
<p></code></pre><br>  <img alt="在这里插入图片描述" height="337" src="https://img-blog.csdnimg.cn/20200815161259653.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2NzQ0NjM1,size_16,color_FFFFFF,t_70#pic_center" width="885"> 
   </p>
<p>3.优先级</p>
<blockquote>
<p>        <img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/58c1cbcf6ab954ad9b8d66e766f1c7d1.png"><br> -<code>概念</code>：定义CSS样式时，经常出现两个或更多规则应用在同一元素上，此时， </p>
</blockquote>
<ul>
<li> 选择器相同，则执行层叠性 -  选择器不同，就会出现优先级的问题。 </li>
<li><code>权重计算公式</code>： <table><thead>|标签选择器|计算权重公式
</thead><tbody>|继承或者 *|0,0,0,0
|每个元素（标签选择器）|0,0,0,1
|每个类，伪类|0,0,1,0
|每个ID|0,1,0,0
|每个行内样式 style=""|1,0,0,0
|每个!important  最重要的|∞ 无穷大
</tbody></table></li>
<li> 值从左到右，左面的最大，一级大于一级，数位之间没有进制，级别之间不可超越。 -  关于CSS权重，我们需要一套计算公式来去计算，这个就是 CSS Specificity（特殊性） -  div { color: pink !important; } </li>
<li><code>权重叠加</code>： <pre><code class="language-css"> div ul  li   ------&gt;      0,0,0,3
 .nav ul li   ------&gt;      0,0,1,2
 a:hover      -----—&gt;      0,0,1,1
 .nav a       ------&gt;      0,0,1,1
</code></pre> </li>
<li><code>继承的权重是0</code>： </li>
<li> 我们修改样式，一定要看该标签有没有被选中 -  如果选中了，那么以上面的公式来计权重。谁大听谁的。 -  如果没有选中，那么权重是0，因为继承的权重为0. </li>
</ul>
]]></content>
      <categories>
        <category>Css</category>
      </categories>
  </entry>
  <entry>
    <title>CSS元素显示模式的存在(块级元素，行内元素，行内块元素）</title>
    <url>/2021/07/18/CSS%E5%85%83%E7%B4%A0%E6%98%BE%E7%A4%BA%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%AD%98%E5%9C%A8(%E5%9D%97%E7%BA%A7%E5%85%83%E7%B4%A0%EF%BC%8C%E8%A1%8C%E5%86%85%E5%85%83%E7%B4%A0%EF%BC%8C%E8%A1%8C%E5%86%85%E5%9D%97%E5%85%83%E7%B4%A0%EF%BC%89/</url>
    <content><![CDATA[<p>title: CSS元素显示模式的存在(块级元素，行内元素，行内块元素）<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—### CSS元素显示模式</p>
<li> 
  <ul>- - - - 
 

<h2 id="元素显示模式的存在"><a href="#元素显示模式的存在" class="headerlink" title="元素显示模式的存在"></a>元素显示模式的存在</h2><p>HTML中有各种各样的标签，如 &lt; img/&gt; &lt; h1&gt;~&lt; h6&gt;,&lt; span&gt;及 &lt; div&gt;等等。这些标签代表不同的HTML元素，有各自的含义和特定使用环境。同时，这些标签在其“本质”上就有着不同的分类。<strong>即元素可被分作 block(块级元素），inline(行内元素或内联元素）和inline-block(行内块元素）</strong></p>
<h2 id="block-块级元素"><a href="#block-块级元素" class="headerlink" title="block 块级元素"></a>block 块级元素</h2><p>首先，了解block元素，需要知道常见的block块级元素有哪些：**&lt; h1&gt;~&lt; h6&gt;，&lt; p&gt;,&lt; ul&gt;，&lt; li&gt;, &lt; ol&gt;,和&lt; div&gt;标签。**<strong>最常见的是 &lt; div&gt;标签</strong>，也是写代码中经常用到的。 再者，需要了解block元素的特点：</p>
<ol>
<li>独占一行，排斥其它元素与其在同一行1. 可以定义宽度width,高度height，但默认宽度就是100%1. 可以定义四个方向上的margin及padding1. 内部可容纳其它块元素或行内元素<br>关于独占一行，有以下简单demo来体现：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&amp;lt;div class=&quot;div1&quot;&amp;gt;aaaa&amp;lt;/div&amp;gt;&amp;lt;div class=&quot;div2&quot;&amp;gt;bbbb&amp;lt;/div&amp;gt;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.div1&#123;</span><br><span class="line">    background-color: red;</span><br><span class="line">&#125;</span><br><span class="line">.div2&#123;</span><br><span class="line">    background-color: yellow;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>将两个div标签即块级元素写在同一行，并设置一定的背景颜色。 最终结果<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200814101853819.png#pic_center"> 可见两个块级元素并没有办法在同一行，都是各占一行 可以尝试换成别的元素，也会发现，块级元素都会排斥其它元素与其在同一行，是<strong>独占一行</strong>的。‘ 这是块级元素的第一个特点：<strong>独占一行</strong></p>
<p>由上我们也可发现，若不指定width宽度，那么块级元素的宽度属性是100%（与浏览器同宽）。即默认宽度为100%。我们可以设置对其设置宽度，高度。如将CSS代码修改成：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.div1&#123;</span><br><span class="line">    background-color: red;</span><br><span class="line">    width: 100px;</span><br><span class="line">    height: 100px;</span><br><span class="line">&#125;</span><br><span class="line">.div2&#123;</span><br><span class="line">    background-color: yellow;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>效果：<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200814102314382.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjYzMzIw,size_16,color_FFFFFF,t_70#pic_center"> 可见，块级元素block的第二个特点：<strong>可以设置宽度和高度，并且默认宽度为100%。</strong></p>
<p>关于四个方向的margin和padding值设置： 我们从以上代码继续添加属性如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.div1&#123;</span><br><span class="line">    background-color: red;</span><br><span class="line">    width: 100px;</span><br><span class="line">    height: 100px;</span><br><span class="line">    margin: 50px 50px 50px 50px;</span><br><span class="line">&#125;</span><br><span class="line">.div2&#123;</span><br><span class="line">    background-color: yellow;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>效果<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200814102912675.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjYzMzIw,size_16,color_FFFFFF,t_70#pic_center"> 设置padding也是一样的，四个方向都可以设置 即块级元素的第三个特点，不仅可以设置宽度和高度，<strong>还可以设置四个方向上的margin和padding值</strong>。</p>
<p>关于第四点，内部可容纳其它块元素和行内元素，修改一下html</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&amp;lt;div class=&quot;div1&quot;&amp;gt;aaaa</span><br><span class="line">    &amp;lt;div class=&quot;inside&quot;&amp;gt;ccc&amp;lt;/div&amp;gt;</span><br><span class="line">&amp;lt;/div&amp;gt;  </span><br><span class="line">&amp;lt;div class=&quot;div2&quot;&amp;gt;bbbb&amp;lt;/div&amp;gt;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.div1&#123;</span><br><span class="line">    background-color: red;</span><br><span class="line">    width: 100px;</span><br><span class="line">    height: 100px;</span><br><span class="line">    margin: 50px 50px 50px 50px;</span><br><span class="line">&#125;</span><br><span class="line">.div2&#123;</span><br><span class="line">    background-color: yellow;</span><br><span class="line">&#125;</span><br><span class="line">.inside&#123;</span><br><span class="line">    background-color: green;</span><br><span class="line">    width: 30px;</span><br><span class="line">    height: 30px;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>效果<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200814103428153.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjYzMzIw,size_16,color_FFFFFF,t_70#pic_center"> 也可以尝试在块级元素中插入行内元素。最后一个特点：<strong>块级元素内可以容纳其它块级元素或行内元素</strong></p>
<h2 id="inline-行内元素"><a href="#inline-行内元素" class="headerlink" title="inline 行内元素"></a>inline 行内元素</h2><p>按照同样的思路，了解学习行内元素，也是先了解行内元素有什么，再了解其特点。 首先，常见的inline元素有，&lt; a&gt; ，&lt; strong&gt; ， &lt; b&gt;，&lt; em&gt;，&lt; i&gt;，&lt; del&gt;，&lt; s&gt;，&lt; ins&gt;，&lt; u&gt;，&lt; span&gt;。<strong>其中a标签是超链接标签，span标签是最典型常见的行内元素。</strong> 再者，inline行内元素的特点有：</p>
<ol>
<li>可以与其它相邻行内元素在同一行1. 无法定义width，height，默认宽度为content内容本身宽度1. 只有margin-left,margin-right,padding-left,padding-right有效1. 行内元素内只能容纳文本或其它行内元素<br>关于第一点，可以与其它行内元素在第一行，可看</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&amp;lt;span class=&#x27;span1&#x27;&amp;gt;aaaa&amp;lt;/span&amp;gt;&amp;lt;span class=&#x27;span2&#x27;&amp;gt;bbbb&amp;lt;/span&amp;gt;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.span1&#123;</span><br><span class="line">    background-color: pink;</span><br><span class="line">&#125;</span><br><span class="line">.span2&#123;</span><br><span class="line">    background-color:green;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200814104801992.png#pic_center"> 可以看到，<strong>一行确实可容纳多个行内元素，不独占一行</strong>。并且，<strong>默认宽度确实是content内容本身宽度</strong>。 对于宽度和高度的设置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.span1&#123;</span><br><span class="line">    background-color: pink;</span><br><span class="line">    width: 100px;</span><br><span class="line">    height: 100px;  </span><br><span class="line">&#125;</span><br><span class="line">.span2&#123;</span><br><span class="line">    background-color:green;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>添加了宽度和高度属性<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200814105111926.png?x-oss-process=image/watermark,ype_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjYzMzIw,size_16,color_FFFFFF,t_70#pic_center"> 发现并没有像块级元素一样可以设置宽度和高度，<strong>即行内元素设置宽度高度是无效的</strong></p>
<p>关于margin值和padding值的设置，<strong>只有设置left和right是有效的，top和button是无效的</strong>。 可以从以下片段看出:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&amp;lt;span class=&#x27;span1&#x27;&amp;gt;aaaa&amp;lt;/span&amp;gt;&amp;lt;span class=&#x27;span2&#x27;&amp;gt;bbbb&amp;lt;/span&amp;gt;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.span1&#123;</span><br><span class="line">    background-color: pink;</span><br><span class="line">    margin-top: 50px;</span><br><span class="line">    margin-left: 50px;</span><br><span class="line">&#125;</span><br><span class="line">.span2&#123;</span><br><span class="line">    background-color:green;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>为第一个span元素添加了margin-top和margin-left，效果如下图：<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200814105520304.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjYzMzIw,size_16,color_FFFFFF,t_70#pic_center"><strong>margin-top并没有出效果，但margin-left有效果，同理，margin-button也没有效果，margin-right有效果。****padding值也是一样的特点</strong>，只是展示效果会略有不同，这是由于padding和margin属性内涵的区别导致。<strong>详情可看关于盒子模型属性的详细介绍。****第四点，行内元素内可容纳其它文本内容和行内元素</strong>，可自行佐证测试。</p>
<h2 id="inline-block-行内块元素"><a href="#inline-block-行内块元素" class="headerlink" title="inline-block 行内块元素"></a>inline-block 行内块元素</h2><p>行内块元素有 &lt; img/&gt; &lt; input/&gt; &lt; td&gt; 。 行内块元素的特点：</p>
<ol>
<li>可与相邻多个行内元素/行内块元素，在同一行 （行内元素的特点）1. 可以设置宽度和高度，但默认宽度为content内容本身1. 可以设置四个方向的margin,padding<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&amp;lt;span class=&#x27;span1&#x27;&amp;gt;aaaa&amp;lt;/span&amp;gt;&amp;lt;span class=&#x27;span2&#x27;&amp;gt;bbbb&amp;lt;/span&amp;gt;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.span1&#123;</span><br><span class="line">    display:inline-block;</span><br><span class="line">    background-color: pink;</span><br><span class="line">&#125;</span><br><span class="line">.span2&#123;</span><br><span class="line">    display:inline-block;</span><br><span class="line">    background-color:green;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可以加 display: inline-block，将元素转化为行内块元素。<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200814110544582.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjYzMzIw,size_16,color_FFFFFF,t_70#pic_center"> 可见，行内块元素，<strong>一行能同时占有多个，不独占一行</strong> <strong>并且默认宽度为内容本身</strong></p>
<p>稍作修改，添加宽度高度和margin</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.span1&#123;</span><br><span class="line">    display:inline-block;</span><br><span class="line">    background-color: pink;</span><br><span class="line">    width: 100px;</span><br><span class="line">    height: 100px;</span><br><span class="line">    margin: 100px;</span><br><span class="line">&#125;</span><br><span class="line">.span2&#123;</span><br><span class="line">    display:inline-block;</span><br><span class="line">    background-color:green;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200814110825641.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjYzMzIw,size_16,color_FFFFFF,t_70#pic_center"> 可见，可以设置margin，也可以设置宽度高度，同样也可设置padding。</p>
]]></content>
      <categories>
        <category>Css</category>
      </categories>
  </entry>
  <entry>
    <title>CSS复合选择器</title>
    <url>/2021/07/18/CSS%E5%A4%8D%E5%90%88%E9%80%89%E6%8B%A9%E5%99%A8/</url>
    <content><![CDATA[<p>title: CSS复合选择器<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—1.简介</p>
<blockquote>
<p> 复合选择器是由两个或多个基础选择器，通过不同的方式组合而成的 </p>
</blockquote>
<p>2.后代选择器<strong>，</strong>又称为包含选择器</p>
<blockquote>
</blockquote>
<ul>
<li>用来选择元素或元素组的子孙后代 -  其写法就是把外层标签写在前面，内层标签写在后面，中间用<strong>「空格」</strong>分隔，先写父亲爷爷，再写儿子孙子。 -  子孙后代都可以这么选择。或者说，它能选择任何包含在内 的标签。 <pre><code class="language-css">父级 子级&#123;属性:属性值;属性:属性值;&#125;</li>
</ul>
<p>.class h3 &#123;color:red;font-size:16px;&#125;</code></pre><br>  <img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/7e6e06c06f873c73d1ed952c23adbad4.png"><img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/7e6e06c06f873c73d1ed952c23adbad4.png"> </p>
<ul>
<li> 当标签发生嵌套时，内层标签就成为外层标签的后代。 -  子孙后代都可以这么选择。或者说，它能选择任何包含在内的标签。 </li>
</ul>
<p>3.子元素选择器</p>
<blockquote>
</blockquote>
<ul>
<li>子元素选择器只能选择作为某元素子元素(亲儿子)的元素。 -  其写法就是把父级标签写在前面，子级标签写在后面，中间跟一个 <code>&amp;gt;</code> 进行连接 -  这里的子,指的是亲儿子。不包含孙子 重孙子之类。 <pre>`.class&gt;h3 {color:red;font-size:14px;}`</pre> </li>
</ul>
<p>4.并集选择器</p>
<blockquote>
<p> 如果某些选择器定义的相同样式，就可以利用并集选择器，可以让代码更简洁。并集选择器（CSS选择器分组）是各个选择器通过<code>,</code>连接而成的，通常用于集体声明。 </p>
</blockquote>
<ul>
<li>任何形式的选择器（包括标签选择器、class类选择器 id选择器等），都可以作为并集选择器的一部分。 -  并集选择器通常用于集体声明  ，逗号隔开的，所有选择器都会执行后面样式，逗号可以理解为和的意思。 <pre><code class="language-css">比如  
.one, 
p , 
#test &#123;color: #F00;&#125;  
表示   .one 和 p  和 #test 这三个选择器都会执行颜色为红色。 
通常用于集体声明。  </code></pre> </li>
</ul>
<p>5.链接伪类选择器</p>
<blockquote>
<p> 用于向某些选择器添加特殊的效果。写的时候，他们的顺序尽量不要颠倒,按照lvha的顺序。否则可能引起错误。<br> 链接伪类，是利用交集选择器. </p>
</blockquote>
<ul>
<li><code>a:link</code>  未访问的链接 -  <code>a:visited</code>  已访问的链接 -  <code>a:hover</code>  鼠标移动到链接上 -  <code>a:active</code>  选定的链接<br>实际工作中，很少写全四个状态，一般写法如下： <pre><code class="language-css">a &#123;   /* a是标签选择器  所有的链接 */
   font-weight: 700;
   font-size: 16px;
   color: gray;
      text-decoration: none; /* 清除链接默认的下划线*/
&#125;
a:hover &#123;   /* :hover 是链接伪类选择器 鼠标经过 */
   color: red; /*  鼠标经过的时候，由原来的 灰色 变成了红色 */
&#125;</code></pre> </li>
</ul>
<p>6.focus伪类选择器</p>
<blockquote>
<p>  :focus 伪类选择器用于选取获得焦点的表单元素。<br> 焦点就是光标，一般情况下是&lt;input&gt;类表单元素才能获取，因此这个选择器也主要针对于表单元素来使用<br> <strong>W3C定义：接收键盘事件或其他用户输入的元素都允许 :focus 选择器。</strong><br> 简单来说就是支持input标签。可以在CSS中采用input:focus{}进行操作。<br> 如下是简单例子<br> &lt;div class=”outer”&gt;&lt;input type=”text” name=”” id=”” value=”” /&gt;&lt;/div&gt;<br> &lt;style&gt;    .outer{<!-- -->     width: 200px;     height: 200px;     background-color: red;    }    input:focus{<!-- -->     background-color: green;    } &lt;/style&gt;<br> <img alt="" src="https://img-blog.csdn.net/20180705113102315?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Fub2RkZ3V5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"><img alt="" src="https://img-blog.csdn.net/2018070511311843?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Fub2RkZ3V5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"><br>                 点击前                                    选中后 </p>
</blockquote>
<p>7.复合选择器总结</p>
<blockquote>
 <table><thead>|选择器|作用|特征|使用情况|隔开符号及用法
</blockquote>
</thead><tbody>|后代选择器|用来选择元素后代|是选择所有的子孙后代|较多|符号是`空格` .nav a
|子代选择器|选择 最近一级元素|只选亲儿子|较少|符号是`&gt;`   .nav&gt;p
|交集选择器|选择两个标签交集的部分|既是 又是|较少|`没有符号`  p.one
|并集选择器|选择某些相同样式的选择器|可以用于集体声明|较多|符号是`逗号` .nav, .header
|链接伪类选择器|给链接更改状态| |较多|重点记住 a{} 和 a:hover  实际开发的写法
</tbody></table>

]]></content>
      <categories>
        <category>Css</category>
      </categories>
  </entry>
  <entry>
    <title>CSS外观属性</title>
    <url>/2021/07/18/CSS%E5%A4%96%E8%A7%82%E5%B1%9E%E6%80%A7/</url>
    <content><![CDATA[<p>title: CSS外观属性<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—1.color</p>
<blockquote>
<p> color属性用于定义文本的颜色 其取值方式有以下3种： </p>
</blockquote>
<ul>
<li>实际工作中，用16进制的写法是最多的，且我们更喜欢简写方式比如#f0代表红色。 <table><thead>|表示表示|属性值
</thead><tbody>|预定义的颜色值|red，green，blue，pink
|十六进制|#FF0000，#FF6600，#29D794
|RGB代码|rgb(255,0,0)或rgb(100%,0%,0%)
</tbody></table></li>
</ul>
<p>2.text-align</p>
<blockquote>
<p> text-align属性用于设置文本内容的水平对齐方式，相当于html中的align对齐属性。 </p>
</blockquote>
<ul>
<li>注意：是让盒子里面的文本内容水平居中， 而不是让盒子居中对齐<br>其可用属性值如下： <table><thead>|属性|解释
</thead><tbody>|left|左对齐（默认值）
|right|右对齐
|center|居中对齐
</tbody></table></li>
</ul>
<p>3.text-decoration</p>
<blockquote>
<p> text-decoration,通常我们用于给链接修改装饰效果<br> <table><thead>|值|描述</p>
</blockquote>
</thead><tbody>|none|默认。定义标准的文本。取消下划线（最常用）
|underline|定义文本下的一条线。下划线 也是我们链接自带的（常用）
|overline|定义文本上的一条线。（不用）
|line-through|定义穿过文本下的一条线。（不常用）
</tbody></table>


<p>4.text-indent</p>
<blockquote>
<p> text-indent属性用于设置首行文本的缩进 </p>
</blockquote>
<ul>
<li>其属性值可为不同单位的数值、em字符宽度的倍数、或相对于浏览器窗口宽度的百分比%，允许使用负值。 -  建议使用em作为设置单位。 -  1em 就是一个字的宽度。如果是汉字的段落，1em 就是一个汉字的宽度 <pre><code class="language-css">p &#123;
      /*行间距*/
      line-height: 25px;
      /*首行缩进2个字  em  1个em 就是1个字的大小*/
      text-indent: 2em;  
 &#125;</code></pre> </li>
</ul>
<p>5.line-height</p>
<blockquote>
<p> line-height属性用于设置行间距，就是行与行之间的距离，即字符的垂直间距，一般称为行高。 </p>
</blockquote>
<ul>
<li>line-height常用的属性值单位有三种，分别为像素px，相对值em和百分比%，实际工作中使用最多的是像素px <pre><code>一般情况下，行距比字号大7--8像素左右就可以了。
line-height: 24px;
</code></pre> 
行高测量<br>行高测量方法：<img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/8031634f470e114b1bae4f21548e4354.png"><br><img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/3a214e8842ac7786729909abd1b5d5d2.png"><code>行高测量方法</code>行高我们利用最多的一个地方是：可以让单行文本在盒子中垂直居中对齐。 <blockquote> </li>
</ul>
<p>  <strong>文字的行高等于盒子的高度。</strong>行高   =  上距离 +  内容高度  + 下距离 上距离和下距离总是相等的，因此文字看上去是垂直居中的。 </p>
<img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/4cd41b5c8794db770924ea51b88bb32f.png">

<p>行高与高度的三种关系</p>
<ul>
<li> 如果 行高 等 高度  文字会 垂直居中 -  如果行高 大于 高度   文字会 偏下 -  如果行高小于高度   文字会  偏上 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  /*line-height 要设置在font属性下面，否则无效，例如：*/</span><br><span class="line">  height: 80px;</span><br><span class="line">  text-align: center;</span><br><span class="line">  font: normal bold 30px &quot;宋体&quot;;</span><br><span class="line">  line-height: 80px;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<p>可以使用display:flex;布局方式让文字水平垂直居中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  display: flex;</span><br><span class="line">  align-items: center;     /* 侧轴对齐方式*/</span><br><span class="line">  justify-content: center; /* 主轴对齐方式 */</span><br></pre></td></tr></table></figure>

<p>6.CSS外观属性总结</p>
<blockquote>
 <table><thead>|属性|表示|注意点
</blockquote>
</thead><tbody>|color|颜色|我们通常用  十六进制   比如 而且是简写形式 #fff
|line-height|行高|控制行与行之间的距离
|text-align|水平对齐|可以设定文字水平的对齐方式
|text-indent|首行缩进|通常我们用于段落首行缩进2个字的距离   text-indent: 2em;
|text-decoration|文本修饰|记住 添加 下划线  underline  取消下划线  none
</tbody></table>

]]></content>
      <categories>
        <category>Css</category>
      </categories>
  </entry>
  <entry>
    <title>CSS学习之小米的侧边栏</title>
    <url>/2021/07/18/CSS%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B0%8F%E7%B1%B3%E7%9A%84%E4%BE%A7%E8%BE%B9%E6%A0%8F/</url>
    <content><![CDATA[<p>title: CSS学习之小米的侧边栏<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—title: CSS学习之小米的侧边栏<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—<li>代码 <pre><code class="language-html">&lt;!DOCTYPE html&gt;<br>&lt;html lang="en"&gt;<br>&lt;head&gt;<br>    &lt;meta charset="UTF-8"&gt;<br>    &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;<br>    &lt;title&gt;小米侧边栏&lt;/title&gt;<br>    &lt;style&gt;<br>        a &#123;<br>            /* 将行级元素变为块级元素 <em>/<br>            display: block;<br>            background-color: rgb(83, 87, 88);<br>            width: 278px;<br>            height: 45px;<br>            /</em> 首行缩进两格 <em>/<br>            text-indent: 2em;<br>            font-size: 14px;<br>            color: #fff;<br>            /</em> 链接的底部下划线去掉 <em>/<br>            text-decoration: none;<br>            /</em> 设置文字垂直居中 <em>/<br>            line-height: 45px;<br>        &#125;<br>        /</em> 将鼠标浮上去的时候背景颜色 */<br>        a:hover &#123;<br>           background-color: rgb(254, 103, 0);<br>        &#125;<br>    &lt;/style&gt;<br>&lt;/head&gt;<br>&lt;body&gt;<br>    &lt;a href="#"&gt;手机 电话卡&lt;/a&gt;<br>    &lt;a href="#"&gt;电视 盒子&lt;/a&gt;<br>    &lt;a href="#"&gt;笔记本 平板&lt;/a&gt;<br>    &lt;a href="#"&gt;出行 穿戴&lt;/a&gt;<br>    &lt;a href="#"&gt;智能 路由器&lt;/a&gt;<br>    &lt;a href="#"&gt;健康 儿童&lt;/a&gt;<br>    &lt;a href="#"&gt;耳机 音响&lt;/a&gt;<br>&lt;/body&gt;<br>&lt;/html&gt;</code></pre>   </li>1. 效果<img alt="" height="344" src="https://img-blog.csdnimg.cn/20210201221154919.png" width="284">1. 单行文字垂直居中的原理<img alt="" height="326" src="https://img-blog.csdnimg.cn/20210201221258269.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="686"></p>
]]></content>
      <categories>
        <category>Css</category>
      </categories>
  </entry>
  <entry>
    <title>CSS字体样式</title>
    <url>/2021/07/18/CSS%E5%AD%97%E4%BD%93%E6%A0%B7%E5%BC%8F/</url>
    <content><![CDATA[<p>title: CSS字体样式<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—1.font-size</p>
<blockquote>
</blockquote>
<ul>
<li>font-size属性用于设置字号(字体大小) -  <code>谷歌浏览器</code>默认的文字大小为16px -  不同浏览器可能默认显示的字号大小不一致，我们尽量给一个明确值大小，不要默认大小。一般给body指定整个页面文字的大小。 <pre><code class="language-css">p &#123; font-size:20px; &#125;
</code></pre> 
单位 </li>
<li>相对长度单位、绝对长度单位 <img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/c85ad388913be4f7e4118a073317d213.png"> </li>
</ul>
<p>2.font-family</p>
<blockquote>
</blockquote>
<ul>
<li>font-family属性用于设置哪一种字体。 <pre><code class="language-css">p &#123; font-family:"微软雅黑";&#125;
</code></pre> </li>
<li>指定多个字体，如果浏览器不支持第一个字体就会尝试下一个直到找到合适的字体，如果都没有，以电脑默认字体为准。 <pre><code class="language-css">p &#123;font-family: Arial,"Microsoft Yahei", "微软雅黑";&#125;
</code></pre> 
<ul><li> CSS Unicode字体 </li>
<li>在 CSS 中设置字体名称，直接写中文是可以的。但是在文件编码（GB2312、UTF-8 等）不匹配时会产生乱码的错误。 -  xp 系统不支持 类似微软雅黑的中文。 -  解决方案：英文来替代。比如<code>font-family:&quot;Microsoft Yahei&quot;</code>。在 CSS 直接使用 Unicode 编码来写字体名称可以避免这些错误。使用 Unicode 写中文字体名称，浏览器是可以正确的解析的。 </li></ul><pre>`font-family: "\5FAE\8F6F\96C5\9ED1";   表示设置字体为“微软雅黑”。`</pre> </li>
</ul>
<p>3.font-weight</p>
<blockquote>
 <table><thead>|属性值|描述
</blockquote>
</thead><tbody>|normal|默认值（不加粗的）
|bold|定义粗体（加粗的）
|100~900|400 等同于 normal，而 700 等同于 bold  (数字表示粗细用的多)
</tbody></table>


<p>4.font-style</p>
<blockquote>
<p> font-style属性用于定义字体风格，如设置斜体、倾斜或正常字体，其可用属性值如下：<br> <table><thead>|属性|作用</p>
</blockquote>
</thead><tbody>|normal|默认值，浏览器会显示标准的字体样式  font-style: normal;
|italic|浏览器会显示斜体的字体样式。
</tbody></table>


<p>5.font:综合设置字体样式</p>
<blockquote>
 <pre><code>选择器 &#123; font: font-style  font-weight  font-size/line-height  font-family;&#125;
</code></pre> 
 <ul><li> 注意：使用font属性时，必须按上面语法格式中的顺序书写，不能更换顺序，各个属性以`空格`隔开 
</blockquote>
<ul>
<li>其中不需要设置的属性可以省略(取默认值),但必须保留<code>font-size</code>和<code>font-family</code>属性，否则font属性将不起作用。 </li></ul><img alt="" height="464" src="https://img-blog.csdnimg.cn/20210129212733617.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1071"> </li>
</ul>
<p>6.font总结</p>
<blockquote>
 <table><thead>|属性|表示|注意点
</blockquote>
</thead><tbody>|font-size|字号|我们通常用的单位是px 像素，一定要跟上单位
|font-family|字体|实际工作中按照团队约定来写字体
|font-weight|字体粗细|记住加粗是 700 或者 bold  不加粗 是 normal 或者  400  记住数字不要跟单位
|font-style|字体样式|记住倾斜是 italic     不倾斜 是 normal  工作中我们最常用 normal
|font|字体连写|1. 字体连写是有顺序的  不能随意换位置 2. 其中字号 和 字体 必须同时出现
</tbody></table>

]]></content>
      <categories>
        <category>Css</category>
      </categories>
  </entry>
  <entry>
    <title>CSS背景(background)</title>
    <url>/2021/07/18/CSS%E8%83%8C%E6%99%AF(background)/</url>
    <content><![CDATA[<p>title: CSS背景(background)<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—1.背景颜色</p>
<blockquote>
<p> background-color: 颜色值;   默认的值是 **transparent  **透明的 </p>
</blockquote>
<p>2.背景图片(image)</p>
<blockquote>
<p> 语法： background-image : none | url (url) ; 例如: background-image: url(images/1.png); </p>
</blockquote>
<p>3.背景平铺（repeat）</p>
<blockquote>
 <pre><code class="language-css">background-repeat : repeat | no-repeat | repeat-x | repeat-y 
</code></pre> 
 <table><thead>|参数|作用
</blockquote>
</thead><tbody>|repeat|背景图像在纵向和横向上平铺（默认的）
|no-repeat|背景图像不平铺
|repeat-x|背景图像在横向上平铺
|repeat-y| 背景图像在纵向平铺   
</tbody></table> 什么是repeat？
          
 <img alt="" height="380" src="https://img-blog.csdnimg.cn/20210202210607583.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="582">
  什么是repeat-x？
          
 <img alt="" height="248" src="https://img-blog.csdnimg.cn/20210202210750597.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="483">
  什么是repeat-y？
          
 <img alt="" height="369" src="https://img-blog.csdnimg.cn/20210202210842685.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="451">


<p>4.背景位置(position)</p>
<blockquote>
 <pre><code class="language-css">background-position : length || length
background-position : position || position 
</code></pre> 
 <table><thead>|参数|值
</blockquote>
</thead><tbody>|length|百分数 | 由浮点数字和单位标识符组成的长度值
|position|top | center | bottom | left | center | right   方位名词
</tbody></table>
 注意： 
 -  必须先指定background-image属性 -  position 后面是x坐标和y坐标。可以使用方位名词或者 精确单位。 -  如果指定两个值，两个值都是方位名字，则两个值前后顺序无关，比如left  top和top  left效果一致 -  如果只指定了一个方位名词，另一个值默认居中对齐。 -  如果position 后面是精确坐标， 那么第一个，肯定是 x 第二个一定是y -  如果只指定一个数值,那该数值一定是x坐标，另一个默认垂直居中 -  如果指定的两个值是 精确单位和方位名字混合使用，则第一个值是x坐标，第二个值是y坐标 
 背景简写： 
 -  background：属性的值的书写顺序官方没有强制的标准。为了可读性，建议如下写： -  background: 背景颜色 背景图片地址 背景平铺 背景滚动 背景位置; 
 <pre><code>/* 有背景图片背景颜色可以不用写*/
background: transparent url(image.jpg) repeat-y  scroll center top ;</code></pre> 


<p>5.背景图像固定background-attachment</p>
<blockquote>
<p> 背景是否跟着滚动而滚动<br> <img alt="" height="456" src="https://img-blog.csdnimg.cn/20210202214748899.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1105"> </p>
</blockquote>
<p>6.背景半透明(CSS3)</p>
<blockquote>
 <pre><code class="language-css">background: rgba(0, 0, 0, 0.3);
background: rgba(0, 0, 0, .3);
</code></pre> 
</blockquote>
<ul>
<li>等同于background-color: rgba(0, 0, 0, .3) -  最后一个参数是alpha 透明度  取值范围 0~1之间 -  我们习惯把0.3 的 0 省略掉  这样写 background: rgba(0, 0, 0, .3); -  注意：背景半透明是指盒子背景半透明，盒子里面的内容不受影响 -  低于IE 9的版本不支持<br>盒子半透明 opacity </li>
<li>设置opacity元素的所有后代元素会随着一起具有透明性，一般用于调整图片或者模块的整体不透明度 <pre>`opacity: .2;`</pre> </li>
</ul>
<p>7.背景总结</p>
<blockquote>
 <table><thead>|属性|作用|值
</blockquote>
</thead><tbody>|background-color|背景颜色|预定义的颜色值/十六进制/RGB代码
|background-image|背景图片|url(图片路径)
|background-repeat|是否平铺|repeat/no-repeat/repeat-x/repeat-y
|background-position|背景位置|length/position    分别是x  和 y坐标， 切记 如果有 精确数值单位，则必须按照先X 后Y 的写法
|background-attachment|背景固定还是滚动|scroll/fixed
|背景简写|更简单|背景颜色 背景图片地址 背景平铺 背景滚动 背景位置;  他们没有顺序
|背景透明|让盒子半透明|background: rgba(0,0,0,0.3);   后面必须是 4个值
</tbody></table>

]]></content>
      <categories>
        <category>Css</category>
      </categories>
  </entry>
  <entry>
    <title>ClickHouse函数整理（详细）</title>
    <url>/2021/07/18/ClickHouse%E5%87%BD%E6%95%B0%E6%95%B4%E7%90%86%EF%BC%88%E8%AF%A6%E7%BB%86%EF%BC%89/</url>
    <content><![CDATA[<p>title: ClickHouse函数整理（详细）<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—<strong>1、日期类函数</strong></p>
<p>1.1 时间或日期截取函数（to）—— 返回非日期</p>
<img alt="" height="712" src="https://img-blog.csdnimg.cn/20210428220216155.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<h3 id="1-2-时间或日期截取函数（toStartOf）——-返回日期"><a href="#1-2-时间或日期截取函数（toStartOf）——-返回日期" class="headerlink" title="1.2 时间或日期截取函数（toStartOf）—— 返回日期"></a>1.2 时间或日期截取函数（toStartOf）—— 返回日期</h3><img alt="" height="819" src="https://img-blog.csdnimg.cn/2021042822051175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<h3 id="1-3-日期或时间日期生成函数"><a href="#1-3-日期或时间日期生成函数" class="headerlink" title="1.3 日期或时间日期生成函数"></a>1.3 日期或时间日期生成函数</h3><img alt="" height="215" src="https://img-blog.csdnimg.cn/20210428220633454.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<h2 id="2、类型转化类函数"><a href="#2、类型转化类函数" class="headerlink" title="2、类型转化类函数"></a><strong>2、类型转化类函数</strong></h2><p>2.1 精度保留（非四舍五入）</p>
<img alt="" height="303" src="https://img-blog.csdnimg.cn/20210428220711501.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<h3 id="2-2-字符串转化为整数（非整数的字符串返回0）"><a href="#2-2-字符串转化为整数（非整数的字符串返回0）" class="headerlink" title="2.2 字符串转化为整数（非整数的字符串返回0）"></a>2.2 字符串转化为整数（非整数的字符串返回0）</h3><img alt="" height="424" src="https://img-blog.csdnimg.cn/20210428221013726.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<h3 id="2-3-日期与时间日期转化"><a href="#2-3-日期与时间日期转化" class="headerlink" title="2.3 日期与时间日期转化"></a>2.3 日期与时间日期转化</h3><img alt="" height="168" src="https://img-blog.csdnimg.cn/20210428221149986.png" width="1200">

<h3 id="2-4-转化为字符型"><a href="#2-4-转化为字符型" class="headerlink" title="2.4 转化为字符型"></a>2.4 转化为字符型</h3><img alt="" height="110" src="https://img-blog.csdnimg.cn/2021042822121547.png" width="1200">

<h3 id="2-5-查看数据类型"><a href="#2-5-查看数据类型" class="headerlink" title="2.5 查看数据类型"></a>2.5 查看数据类型</h3><img alt="" height="122" src="https://img-blog.csdnimg.cn/2021042822123799.png" width="1200">

<h2 id="3、字符串操作"><a href="#3、字符串操作" class="headerlink" title="3、字符串操作"></a><strong>3、字符串操作</strong></h2><h3 id="3-1-基本字符串操作"><a href="#3-1-基本字符串操作" class="headerlink" title="3.1 基本字符串操作"></a>3.1 基本字符串操作</h3><img alt="" height="512" src="https://img-blog.csdnimg.cn/20210428221303145.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<h3 id="3-2-字符串查找"><a href="#3-2-字符串查找" class="headerlink" title="3.2 字符串查找"></a>3.2 字符串查找</h3><img alt="" height="323" src="https://img-blog.csdnimg.cn/20210428221405249.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<h3 id="3-3-字符串替换"><a href="#3-3-字符串替换" class="headerlink" title="3.3 字符串替换"></a>3.3 字符串替换</h3><img alt="" height="390" src="https://img-blog.csdnimg.cn/20210428221552835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<h3 id="3-4-字符串分割"><a href="#3-4-字符串分割" class="headerlink" title="3.4 字符串分割"></a>3.4 字符串分割</h3><img alt="" height="223" src="https://img-blog.csdnimg.cn/20210428221802201.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<h3 id="3-5-字符串拼接"><a href="#3-5-字符串拼接" class="headerlink" title="3.5 字符串拼接"></a>3.5 字符串拼接</h3><img alt="" height="117" src="https://img-blog.csdnimg.cn/20210428221914613.png" width="1200">

<h2 id="4、条件语句"><a href="#4、条件语句" class="headerlink" title="4、条件语句"></a><strong>4、条件语句</strong></h2><img alt="" height="168" src="https://img-blog.csdnimg.cn/2021042822200846.png" width="1200">

<h2 id="5、数学函数"><a href="#5、数学函数" class="headerlink" title="5、数学函数"></a><strong>5、数学函数</strong></h2><img alt="" height="642" src="https://img-blog.csdnimg.cn/20210428222026911.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<h2 id="6、舍入函数"><a href="#6、舍入函数" class="headerlink" title="6、舍入函数"></a><strong>6、舍入函数</strong></h2><img alt="" height="222" src="https://img-blog.csdnimg.cn/20210428222128986.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<h3 id="7、URL操作函数"><a href="#7、URL操作函数" class="headerlink" title="7、URL操作函数"></a><strong>7、URL操作函数</strong></h3><blockquote>
 <table align="left" cellspacing="0" style="width:448pt;"><tbody><td style="border-color:#dddddd;text-align:center;vertical-align:middle;width:112pt;">**函数**</td><td style="border-color:#dddddd;text-align:center;vertical-align:middle;width:112pt;">**用途**</td><td style="border-color:#dddddd;text-align:center;vertical-align:middle;width:112pt;">**举例**</td><td style="border-color:#dddddd;text-align:center;vertical-align:middle;width:112pt;">**结果**</td>
</blockquote>
<td style="border-color:#dddddd;vertical-align:middle;width:112pt;">protocol()</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回URL的协议类型</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">protocol(‘http://www.baidu.com.cn’)</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回 http</td>
<td style="border-color:#dddddd;vertical-align:middle;width:112pt;">domain()</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回URL的域名</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">domain(‘http://www.baidu.com.cn’)</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回 www.baidu.com.cn</td>
<td style="border-color:#dddddd;vertical-align:middle;width:112pt;">domainWithoutWWW()</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回URL不带www的域名</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">domainWithoutWWW(‘http://www.baidu.com.cn’)</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回 baidu.com.cn</td>
<td style="border-color:#dddddd;vertical-align:middle;width:112pt;">topLevelDomain()</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回顶级域名</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">topLevelDomain(‘http://www.baidu.com.cn’)</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回 cn</td>
<td style="border-color:#dddddd;vertical-align:middle;width:112pt;">firstSignificantSubdomain()</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">Returns the “first significant subdomain”.</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">firstSignificantSubdomain(‘http://www.baidu.com.cn’)</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回 baidu</td>
<td style="border-color:#dddddd;vertical-align:middle;width:112pt;">cutToFirstSignificantSubdomain()</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">Returns the part of the domain that includes top-level subdomains up to the “first significant subdomain” (see the explanation above).</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">cutToFirstSignificantSubdomain(‘http://www.baidu.com.cn’)</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回 baidu.com.cn</td>
<td style="border-color:#dddddd;vertical-align:middle;width:112pt;">path()</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回URL的路径</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">path(‘https://www.baidu.com/s?wd=SQL%E4%B8%AD%E7%9A%84split’)</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回 /s</td>
<td style="border-color:#dddddd;vertical-align:middle;width:112pt;">pathFull()</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回URL的完整路径</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">pathFull(‘https://www.baidu.com/s?wd=SQL%E4%B8%AD%E7%9A%84split’)</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回 /s?wd=SQL%E4%B8%AD%E7%9A%84split</td>
<td style="border-color:#dddddd;vertical-align:middle;width:112pt;">queryString()</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回URL的参数（查询字符串）</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">queryString(‘https://www.baidu.com/s?wd=SQL%E4%B8%AD%E7%9A%84split’)</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回 wd=SQL%E4%B8%AD%E7%9A%84split</td>
<td style="border-color:#dddddd;vertical-align:middle;width:112pt;">extractURLParameters()</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">以列表的形式返回URL的参数</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">extractURLParameters(‘https://www.baidu.com/s?wd=SQL%E4%B8%AD%E7%9A%84split&amp;ur=qwguq’)</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回 [‘wd=SQL%E4%B8%AD%E7%9A%84split’,‘ur=qwguq’]</td>
<td style="border-color:#dddddd;vertical-align:middle;width:112pt;">extractURLParameterNames()</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">以列表的形式返回URL的参数名</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">extractURLParameterNames(‘https://www.baidu.com/s?wd=SQL%E4%B8%AD%E7%9A%84split&amp;ur=qwguq’)</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回 [‘wd’,‘ur’]</td>
<td style="border-color:#dddddd;vertical-align:middle;width:112pt;">cutQueryString()</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回URL？（参数）前面的内容</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">cutQueryString(‘https://www.baidu.com/s?wd=SQL%E4%B8%AD%E7%9A%84split&amp;ur=qwguq’)</td><td style="border-color:#dddddd;vertical-align:middle;width:112pt;">返回 https://www.baidu.com/s</td>
</tbody></table>


<h3 id="8、IP操作函数"><a href="#8、IP操作函数" class="headerlink" title="8、IP操作函数"></a><strong>8、IP操作函数</strong></h3><img alt="" height="304" src="https://img-blog.csdnimg.cn/20210428222623141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<h2 id="9、表操作"><a href="#9、表操作" class="headerlink" title="9、表操作"></a><strong>9、表操作</strong></h2><h3 id="9-1-表连接操作"><a href="#9-1-表连接操作" class="headerlink" title="9.1 表连接操作"></a>9.1 表连接操作</h3><img alt="" height="251" src="https://img-blog.csdnimg.cn/20210428222707498.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<h3 id="9-2-LIMIT操作"><a href="#9-2-LIMIT操作" class="headerlink" title="9.2 LIMIT操作"></a>9.2 LIMIT操作</h3><img alt="" height="233" src="https://img-blog.csdnimg.cn/20210428222743597.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>Clickhouse 字典表使用场景</title>
    <url>/2021/07/18/Clickhouse%20%E5%AD%97%E5%85%B8%E8%A1%A8%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
    <content><![CDATA[<p>title: Clickhouse 字典表使用场景<br>categories:</p>
<ul>
<li>clickhouse<br>tags:</li>
<li>clickhouse</li>
</ul>
<p>—# 一.字典创建和查询</p>
<h2 id="1-创建表和数据："><a href="#1-创建表和数据：" class="headerlink" title="1.创建表和数据："></a>1.创建表和数据：</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">drop table t_region;</span><br><span class="line">create table t_region(region_id UInt64, parent_region UInt64, region_name String) ENGINE=TinyLog;</span><br><span class="line">insert into t_region values</span><br><span class="line">(1, 0, &#x27;jiangsu&#x27;),(2, 1, &#x27;suzhou&#x27;),(3, 2, &#x27;huqiu&#x27;),(4, 0, &#x27;anhui&#x27;),(5, 4, &#x27;hefei&#x27;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">创建字典， 指定HIERARCHICAL字段：</span><br><span class="line">DROP DICTIONARY t_dict_region;</span><br><span class="line">CREATE DICTIONARY t_dict_region (</span><br><span class="line">    region_id UInt64,</span><br><span class="line">    parent_region UInt64  HIERARCHICAL,</span><br><span class="line">    region_name String </span><br><span class="line">)</span><br><span class="line">PRIMARY KEY region_id</span><br><span class="line">SOURCE(CLICKHOUSE(</span><br><span class="line">    host &#x27;localhost&#x27;</span><br><span class="line">    port 9001</span><br><span class="line">    user &#x27;default&#x27;</span><br><span class="line">    db &#x27;default&#x27;</span><br><span class="line">    password &#x27;&#x27;</span><br><span class="line">    table &#x27;t_region&#x27;</span><br><span class="line">))</span><br><span class="line">LAYOUT(HASHED())</span><br><span class="line">LIFETIME(30);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="2-字典的查询"><a href="#2-字典的查询" class="headerlink" title="2.字典的查询"></a>2.字典的查询</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT dictGetString(&#x27;default.t_dict_region&#x27;, &#x27;region_name&#x27;, toUInt64(2)) AS regionName;</span><br><span class="line"></span><br><span class="line">┌─regionName─┐</span><br><span class="line">│ suzhou     │</span><br><span class="line">└────────────┘</span><br><span class="line">SELECT dictGetHierarchy(&#x27;default.t_dict_region&#x27;, toUInt64(3));</span><br><span class="line"></span><br><span class="line">┌─dictGetHierarchy(&#x27;default.t_dict_region&#x27;, toUInt64(3))─┐</span><br><span class="line">│ [3,2,1]                                                │</span><br><span class="line">└────────────────────────────────────────────────────────┘</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="3-字典数据源之mysql表"><a href="#3-字典数据源之mysql表" class="headerlink" title="3.字典数据源之mysql表"></a>3.字典数据源之mysql表</h2><li>在mysql数据库创建表并插入数据： <pre><code class="language-sql">drop table test.test_dc;
create table test.test_dc(
  id bigint,
  name varchar(100),
  age int,
  PRIMARY KEY (id)
);

<p>insert into test.test_dc values(1, ‘flink’, 4);<br>insert into test.test_dc values(2, ‘spark’, 6);<br>insert into test.test_dc values(3, ‘clickhouse’, 5);</p>
<p>查看MySQL数据：<br>mysql&gt; select * from test.test_dc;<br>+—-+————+——+<br>| id | name       | age  |<br>+—-+————+——+<br>|  1 | flink      |    4 |<br>|  2 | spark      |    6 |<br>|  3 | clickhouse |    5 |<br>+—-+————+——+</p>
<p></code></pre>   </li></p>
<h3 id="4-字典的数据源之文件数据源"><a href="#4-字典的数据源之文件数据源" class="headerlink" title="4.字典的数据源之文件数据源"></a>4.字典的数据源之文件数据源</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TabSeparated格式</span><br><span class="line">文件示例：</span><br><span class="line"></span><br><span class="line">准备测试数据</span><br><span class="line">文件命名为person.tsv，存放在目录：/var/lib/clickhouse/user_files，字段之间使用制表符分隔，即格式为TabSeparated。数据如下：</span><br><span class="line">1	&#x27;id001&#x27;	&#x27;xiaohe&#x27;	23</span><br><span class="line">2	&#x27;id002&#x27;	&#x27;xiaoxue&#x27;	25</span><br><span class="line">3	&#x27;id003&#x27;	&#x27;xiaoyu&#x27;	26</span><br><span class="line">4	&#x27;id004&#x27;	&#x27;xiaoxi&#x27;	27</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">创建字典：</span><br><span class="line">DROP DICTIONARY t_dict_person_ddl;</span><br><span class="line">CREATE DICTIONARY t_dict_person_ddl</span><br><span class="line">(</span><br><span class="line">    id UInt64,</span><br><span class="line">    code String,</span><br><span class="line">    name String,</span><br><span class="line">    age UInt8</span><br><span class="line">)</span><br><span class="line">PRIMARY KEY id</span><br><span class="line">SOURCE(FILE(path &#x27;/var/lib/clickhouse/user_files/person.tsv&#x27; format &#x27;TabSeparated&#x27;))</span><br><span class="line">LAYOUT(FLAT())</span><br><span class="line">LIFETIME(30);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">SELECT dictGetString(&#x27;default.t_dict_person_ddl&#x27;, &#x27;name&#x27;, toUInt64(2)) AS regionName;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>当然,字典类型的数据也可以通过配置实现</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&amp;lt;yandex&amp;gt; </span><br><span class="line">  &amp;lt;dictionary&amp;gt; </span><br><span class="line">    &amp;lt;name&amp;gt;t_dict_executable&amp;lt;/name&amp;gt;  </span><br><span class="line"></span><br><span class="line">    &amp;lt;structure&amp;gt; </span><br><span class="line">      &amp;lt;id&amp;gt; </span><br><span class="line">        &amp;lt;name&amp;gt;id&amp;lt;/name&amp;gt; </span><br><span class="line">      &amp;lt;/id&amp;gt;  </span><br><span class="line">      &amp;lt;attribute&amp;gt; </span><br><span class="line">        &amp;lt;name&amp;gt;code&amp;lt;/name&amp;gt;  </span><br><span class="line">        &amp;lt;type&amp;gt;String&amp;lt;/type&amp;gt;  </span><br><span class="line">        &amp;lt;null_value/&amp;gt; </span><br><span class="line">      &amp;lt;/attribute&amp;gt;  </span><br><span class="line">      &amp;lt;attribute&amp;gt; </span><br><span class="line">        &amp;lt;name&amp;gt;name&amp;lt;/name&amp;gt;  </span><br><span class="line">        &amp;lt;type&amp;gt;String&amp;lt;/type&amp;gt;  </span><br><span class="line">        &amp;lt;null_value/&amp;gt; </span><br><span class="line">      &amp;lt;/attribute&amp;gt;  </span><br><span class="line">      &amp;lt;attribute&amp;gt; </span><br><span class="line">        &amp;lt;name&amp;gt;age&amp;lt;/name&amp;gt;  </span><br><span class="line">        &amp;lt;type&amp;gt;UInt8&amp;lt;/type&amp;gt;  </span><br><span class="line">        &amp;lt;null_value/&amp;gt; </span><br><span class="line">      &amp;lt;/attribute&amp;gt; </span><br><span class="line">    &amp;lt;/structure&amp;gt;  </span><br><span class="line">    &amp;lt;source&amp;gt; </span><br><span class="line">      &amp;lt;executable&amp;gt;</span><br><span class="line">        &amp;lt;command&amp;gt;cat /var/lib/clickhouse/user_files/person.tsv&amp;lt;/command&amp;gt;</span><br><span class="line">        &amp;lt;format&amp;gt;TabSeparated&amp;lt;/format&amp;gt;</span><br><span class="line">      &amp;lt;/executable&amp;gt;</span><br><span class="line">    &amp;lt;/source&amp;gt;  </span><br><span class="line">    &amp;lt;layout&amp;gt; </span><br><span class="line">      &amp;lt;hashed/&amp;gt; </span><br><span class="line">    &amp;lt;/layout&amp;gt;  </span><br><span class="line">    &amp;lt;lifetime&amp;gt;10&amp;lt;/lifetime&amp;gt; </span><br><span class="line">  &amp;lt;/dictionary&amp;gt; </span><br><span class="line">&amp;lt;/yandex&amp;gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="二-字典的存储方式"><a href="#二-字典的存储方式" class="headerlink" title="二.字典的存储方式"></a>二.字典的存储方式</h1><p>以下测试均在default数据库。</p>
<h2 id="1-flat-hash-sparse-hash-cache"><a href="#1-flat-hash-sparse-hash-cache" class="headerlink" title="1. flat/hash/sparse_hash/cache"></a>1. flat/hash/sparse_hash/cache</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">DROP DICTIONARY t_dict_person_ddl;</span><br><span class="line">CREATE DICTIONARY t_dict_person_ddl</span><br><span class="line">(</span><br><span class="line">    id UInt64,</span><br><span class="line">    code String,</span><br><span class="line">    name String,</span><br><span class="line">    age UInt8</span><br><span class="line">)</span><br><span class="line">PRIMARY KEY id</span><br><span class="line">SOURCE(CLICKHOUSE(</span><br><span class="line">    host &#x27;localhost&#x27;</span><br><span class="line">    port 9001</span><br><span class="line">    user &#x27;default&#x27;</span><br><span class="line">    db &#x27;default&#x27;</span><br><span class="line">    password &#x27;&#x27;</span><br><span class="line">    table &#x27;t_dic_ch&#x27;</span><br><span class="line">    where &#x27;id&amp;gt;0&#x27;</span><br><span class="line">))</span><br><span class="line">LAYOUT(CACHE(SIZE_IN_CELLS 10000))</span><br><span class="line">LIFETIME(30);</span><br><span class="line"></span><br><span class="line">SELECT dictGetString(&#x27;default.t_dict_person_ddl&#x27;, &#x27;name&#x27;, toUInt64(2)) AS regionName;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>FLAT()、HASHED()、SPARSE_HASHED()、CACHE(SIZE_IN_CELLS 10000)</strong></p>
<h2 id="2-complex-key-hashed-complex-key-cache"><a href="#2-complex-key-hashed-complex-key-cache" class="headerlink" title="2. complex_key_hashed/complex_key_cache"></a>2. complex_key_hashed/complex_key_cache</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">DROP DICTIONARY t_dict_person_ddl;</span><br><span class="line">CREATE DICTIONARY t_dict_person_ddl</span><br><span class="line">(</span><br><span class="line">    id UInt64,</span><br><span class="line">    code String,</span><br><span class="line">    name String,</span><br><span class="line">    age UInt8</span><br><span class="line">)</span><br><span class="line">PRIMARY KEY id,code</span><br><span class="line">SOURCE(CLICKHOUSE(</span><br><span class="line">    host &#x27;localhost&#x27;</span><br><span class="line">    port 9001</span><br><span class="line">    user &#x27;default&#x27;</span><br><span class="line">    db &#x27;default&#x27;</span><br><span class="line">    password &#x27;&#x27;</span><br><span class="line">    table &#x27;t_dic_ch&#x27;</span><br><span class="line">    where &#x27;id&amp;gt;0&#x27;</span><br><span class="line">))</span><br><span class="line">LAYOUT(COMPLEX_KEY_HASHED())</span><br><span class="line">LIFETIME(30);</span><br><span class="line"></span><br><span class="line">SELECT dictGet(&#x27;default.t_dict_person_ddl&#x27;, &#x27;name&#x27;, tuple(toUInt64(2), &#x27;id002&#x27;)) AS name;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>COMPLEX_KEY_HASHED()、COMPLEX_KEY_CACHE(SIZE_IN_CELLS 10000)</strong></p>
<h2 id="3-range-hashed"><a href="#3-range-hashed" class="headerlink" title="3. range_hashed"></a>3. range_hashed</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">drop table t_hash_range;</span><br><span class="line">create table t_hash_range(id UInt64, start Date, end Date, amount Float32) ENGINE=TinyLog;</span><br><span class="line">insert into t_hash_range values</span><br><span class="line">(123, &#x27;2020-03-20&#x27;, &#x27;2020-03-22&#x27;, 0.15)</span><br><span class="line">(123, &#x27;2020-03-23&#x27;, &#x27;2020-03-27&#x27;, 0.25)</span><br><span class="line">(456, &#x27;2020-04-20&#x27;, &#x27;2020-04-30&#x27;, 0.35)</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line">查看数据：</span><br><span class="line">SELECT * FROM t_hash_range;</span><br><span class="line"></span><br><span class="line">┌──id─┬──────start─┬────────end─┬─amount─┐</span><br><span class="line">│ 123 │ 2020-03-20 │ 2020-03-22 │   0.15 │</span><br><span class="line">│ 123 │ 2020-03-23 │ 2020-03-27 │   0.25 │</span><br><span class="line">│ 456 │ 2020-04-20 │ 2020-04-30 │   0.35 │</span><br><span class="line">└─────┴────────────┴────────────┴────────┘</span><br><span class="line"></span><br><span class="line">创建字典：</span><br><span class="line">DROP DICTIONARY t_dict_hash_range;</span><br><span class="line">CREATE DICTIONARY t_dict_hash_range (</span><br><span class="line">    id UInt64,</span><br><span class="line">    start Date,</span><br><span class="line">    end Date,</span><br><span class="line">    amount Float32</span><br><span class="line">)</span><br><span class="line">PRIMARY KEY id</span><br><span class="line">SOURCE(CLICKHOUSE(</span><br><span class="line">    host &#x27;localhost&#x27;</span><br><span class="line">    port 9001</span><br><span class="line">    user &#x27;default&#x27;</span><br><span class="line">    db &#x27;default&#x27;</span><br><span class="line">    password &#x27;&#x27;</span><br><span class="line">    table &#x27;t_hash_range&#x27;</span><br><span class="line">))</span><br><span class="line">LAYOUT(RANGE_HASHED())</span><br><span class="line">RANGE(MIN start MAX end)</span><br><span class="line">LIFETIME(30);</span><br><span class="line"></span><br><span class="line">查看id为123的记录，在日期2020-03-21日的amount：</span><br><span class="line">select dictGetFloat32(&#x27;default.t_dict_hash_range&#x27;, &#x27;amount&#x27;, toUInt64(123), toDate(&#x27;2020-03-21&#x27;)) as amount;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">查看id为123的记录，在日期2020-03-25日的amount：</span><br><span class="line">select dictGetFloat32(&#x27;default.t_dict_hash_range&#x27;, &#x27;amount&#x27;, toUInt64(123), toDate(&#x27;2020-03-25&#x27;)) as amount;</span><br><span class="line"></span><br><span class="line">日期之外的记录：</span><br><span class="line">SELECT dictGetFloat32(&#x27;default.t_dict_hash_range&#x27;, &#x27;amount&#x27;, toUInt64(123), toDate(&#x27;2020-03-29&#x27;)) AS amount;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="4-ip-tire"><a href="#4-ip-tire" class="headerlink" title="4. ip_tire"></a>4. ip_tire</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">创建表和测试数据：</span><br><span class="line">drop table t_ip_tire;</span><br><span class="line">create table t_ip_tire(prefix String, asn UInt32, ccode String) ENGINE=TinyLog;</span><br><span class="line">insert into t_ip_tire values</span><br><span class="line">(&#x27;202.79.32.0/20&#x27;, 17501, &#x27;NP&#x27;)</span><br><span class="line">(&#x27;2620:0:870::/48&#x27;, 3856, &#x27;US&#x27;)</span><br><span class="line">(&#x27;2a02:6b8:1::/48&#x27;, 13238, &#x27;RU&#x27;)</span><br><span class="line">(&#x27;2001:db8::/32&#x27;, 65536, &#x27;ZZ&#x27;)</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line">查看数据：</span><br><span class="line">SELECT * FROM t_ip_tire;</span><br><span class="line"></span><br><span class="line">┌─prefix──────────┬───asn─┬─ccode─┐</span><br><span class="line">│ 202.79.32.0/20  │ 17501 │ NP    │</span><br><span class="line">│ 2620:0:870::/48 │  3856 │ US    │</span><br><span class="line">│ 2a02:6b8:1::/48 │ 13238 │ RU    │</span><br><span class="line">│ 2001:db8::/32   │ 65536 │ ZZ    │</span><br><span class="line">└─────────────────┴───────┴───────┘</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">创建字典：</span><br><span class="line">DROP DICTIONARY t_dict_ip_tire;</span><br><span class="line">CREATE DICTIONARY t_dict_ip_tire (</span><br><span class="line">    prefix String,</span><br><span class="line">    asn UInt32,</span><br><span class="line">    ccode String</span><br><span class="line">)</span><br><span class="line">PRIMARY KEY prefix</span><br><span class="line">SOURCE(CLICKHOUSE(</span><br><span class="line">    host &#x27;localhost&#x27;</span><br><span class="line">    port 9001</span><br><span class="line">    user &#x27;default&#x27;</span><br><span class="line">    db &#x27;default&#x27;</span><br><span class="line">    password &#x27;&#x27;</span><br><span class="line">    table &#x27;t_ip_tire&#x27;</span><br><span class="line">))</span><br><span class="line">LAYOUT(IP_TRIE())</span><br><span class="line">LIFETIME(30);</span><br><span class="line"></span><br><span class="line">检索数据：</span><br><span class="line">select</span><br><span class="line">dictGetUInt32(&#x27;default.t_dict_ip_tire&#x27;, &#x27;asn&#x27;, tuple(IPv4StringToNum(&#x27;202.79.32.22&#x27;))) as asn,</span><br><span class="line">dictGetString(&#x27;default.t_dict_ip_tire&#x27;, &#x27;ccode&#x27;, tuple(IPv4StringToNum(&#x27;202.79.32.22&#x27;))) as ccode</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p> </p>
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
      <tags>
        <tag>Clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>DataNode的工作机制，多目录配置，服役新数据节点，退役旧数据节点，Hadoop  存档</title>
    <url>/2021/07/18/DataNode%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%A4%9A%E7%9B%AE%E5%BD%95%E9%85%8D%E7%BD%AE%EF%BC%8C%E6%9C%8D%E5%BD%B9%E6%96%B0%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9%EF%BC%8C%E9%80%80%E5%BD%B9%E6%97%A7%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9%EF%BC%8CHadoop%20%C2%A0%E5%AD%98%E6%A1%A3/</url>
    <content><![CDATA[<p>title: DataNode的工作机制，多目录配置，服役新数据节点，退役旧数据节点，Hadoop  存档<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—title: DataNode的工作机制，多目录配置，服役新数据节点，退役旧数据节点，Hadoop  存档<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—         rsync -rvl $pdir/$fname $user@hadoop$host:$pdir<br>done;</code></pre>   ⑸增加新增节点的ssh无密登录（102，103，104，105这几个节点上都要确保有所有节点的ssh免密登录）         注意：102的root用户也要配置对方的ssh免密登录   ⑹                  </li>1. 服役新节点具体步骤，在102服务器这个namenode节点上操作     ⑴在 102服务器namenode 的/opt/module/hadoop-2.7.2/etc/hadoop 目录下创建 dfs.hosts 文件           <img alt="" class="has" height="245" src="https://img-blog.csdnimg.cn/20190722220804852.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="474">      ⑵在 namenode 的 hdfs-site.xml 配置文件中增加 dfs.hosts 属性             <img alt="" class="has" height="262" src="https://img-blog.csdnimg.cn/20190722221210500.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="413">      ⑶刷新 namenode            <img alt="" class="has" height="219" src="https://img-blog.csdnimg.cn/20190722221330463.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="552">      ⑷更新 resourcemanager 节点             <img alt="" class="has" height="83" src="https://img-blog.csdnimg.cn/20190722221432616.png" width="659">      ⑸可以在浏览器上发现多了一个节点            <img alt="" class="has" height="369" src="https://img-blog.csdnimg.cn/20190722221540752.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="386">    ⑹在 namenode 的 slaves 文件中增加新主机名称            <img alt="" class="has" height="160" src="https://img-blog.csdnimg.cn/20190722221706325.png" width="227">    ⑺将修改的hdfs-site.xml,slaves文件同步到其它服务器          <img alt="" class="has" height="316" src="https://img-blog.csdnimg.cn/20190722221929771.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="365">   ⑻到105服务器上单独命令启动新的数据节点和节点管理器         a:启动datanode                  <img alt="" class="has" height="152" src="https://img-blog.csdnimg.cn/20190722222155289.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="465">         b：启动nodemanager               <img alt="" class="has" height="106" src="https://img-blog.csdnimg.cn/20190722222259780.png" width="575">    ⑼我们到浏览器看一下状态           <img alt="" class="has" height="362" src="https://img-blog.csdnimg.cn/20190722222355781.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="424">     ⑽如果数据不均衡，可以用命令实现集群的再平衡            <img alt="" class="has" height="165" src="https://img-blog.csdnimg.cn/2019072222273332.png" width="580">      </p>
<h1 id="四：退役旧数据节点"><a href="#四：退役旧数据节点" class="headerlink" title="四：退役旧数据节点"></a>四：退役旧数据节点</h1><ol>
<li>需求：        随着公司业务的减少，数据量变少了，原有的数据节点的容量有点多了， 需要在原有集群基础上动态减少一些数据节点。1. 环境准备    ⑴保持集群正在运行状态           <img alt="" class="has" height="372" src="https://img-blog.csdnimg.cn/2019072321450086.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="395">   ⑵要退的节点我们选择105   ⑶在 namenode 的/opt/module/hadoop-2.7.2/etc/hadoop 目录下创建 dfs.hosts.exclude 文件，       在文件中添加主机名称（要退役的节点）       <img alt="" class="has" height="168" src="https://img-blog.csdnimg.cn/20190723214828682.png" width="499">   ⑷在 namenode 的 hdfs-site.xml 配置文件中增加 dfs.hosts.exclude 属性       <img alt="" class="has" height="294" src="https://img-blog.csdnimg.cn/20190723215125482.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="527">  ⑸刷新 namenode、刷新 resourcemanager        <img alt="" class="has" height="144" src="https://img-blog.csdnimg.cn/20190723215254849.png" width="619">         <img alt="" class="has" height="77" src="https://img-blog.csdnimg.cn/20190723215344699.png" width="676">   ⑹检查 web 浏览器，退役节点的状态为 decommission in progress（退役中），说明数据节点正在复制块到其他节点        <img alt="" class="has" height="67" src="https://img-blog.csdnimg.cn/20190723215646506.png" width="763">    ⑺等待退役节点状态为 decommissioned（所有块已经复制完成），停止该节点及节点资源管理器。       注意：如果副本数是 3，服役的节点小于等于 3，是不能退役成功的，需要修改副本数后才能退役       <img alt="" class="has" height="320" src="https://img-blog.csdnimg.cn/20190723215747719.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="323">    ⑻到105节点上关闭指定的datanode和nodemanager         sbin/hadoop-daemon.sh stop datanode         sbin/yarn-daemon.sh stop nodemanager    ⑼后面还要进行下面操作          a:从 namenode 的 dfs.hosts 文件中删除退役节点 hadoop105               <img alt="" class="has" height="213" src="https://img-blog.csdnimg.cn/20190723221113495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="377">          b：刷新 namenode，刷新 resourcemanager                  hdfs dfsadmin -refreshNodes                  yarn rmadmin -refreshNodes          c：从 namenode 的 slave 文件中删除退役节点 hadoop105                <img alt="" class="has" height="194" src="https://img-blog.csdnimg.cn/20190723221406524.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="333">         d:同步各个服务器的配置文件               <img alt="" class="has" height="199" src="https://img-blog.csdnimg.cn/20190723221539134.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="313">     ⑽最后再次看浏览器，105已经没了          <img alt="" class="has" height="366" src="https://img-blog.csdnimg.cn/20190723221627586.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="391">
 </li>
</ol>
<h1 id="五：集群间数据拷贝"><a href="#五：集群间数据拷贝" class="headerlink" title="五：集群间数据拷贝"></a>五：集群间数据拷贝</h1><ol>
<li>采用 discp 命令实现两个 hadoop 集群之间的递归数据复制  <img alt="" class="has" height="86" src="https://img-blog.csdnimg.cn/20190723225029499.png" width="678">           1. scp 实现两个远程主机之间的文件复制（目前一直在用的）<h1 id="六：Hadoop-存档"><a href="#六：Hadoop-存档" class="headerlink" title="六：Hadoop  存档"></a>六：Hadoop  存档</h1></li>
<li>简介       每个文件均按块存储，每个块的元数据存储在 namenode 的内存中，因此 hadoop 存储小文件会非常低效。 因为大量的小文件会耗尽 namenode 中的大部分内存。但注意，存储小文件所需要的磁盘容量和存储这些文件 原始内容所需要的磁盘空间相比也不会增多。例如，一个 1MB 的文件以大小为 128MB 的块存储，使用的是 1MB 的磁盘空间，而不是 128MB。       Hadoop 存档文件或 HAR 文件，是一个更高效的文件存档工具，它将文件存入 HDFS块，在减少 namenode 内存使用的同时，允许对文件进行透明的访问。具体说来，Hadoop存档文件可以用作 MapReduce 的输入。        就是说hadoop会将许多的小文件看成一个整体，这样就不会存在一个小文件占用一个数据块了。是这个Har 文件整体占用一个数据块。1.  案例实操     ⑴首先我们在hdfs上创建一个目录           <img alt="" class="has" height="96" src="https://img-blog.csdnimg.cn/2019072322591116.png" width="542">     ⑵在这个目录下上传3个小文件          <img alt="" class="has" height="224" src="https://img-blog.csdnimg.cn/20190723230038141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="533">      ⑶归档文件：归档成一个叫做 xxx.har 的文件夹，该文件夹下有相应的数据文件。Xx.har 目录是                            一个整体，该目录看成是一个归档文件即可。                      下面这个命令表示，将/user/kgf/input目录下的锁文件归档到“/”根目录下，名称为myhar.har的归档文件           命令：hadoop archive -archiveName myhar.har -p /user/kgf/input /           效果：出现下面问题                 <img alt="" class="has" height="304" src="https://img-blog.csdnimg.cn/2019072323282198.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="775">         解决方法：发现集群重新启动一下就好了。             <img alt="" class="has" height="320" src="https://img-blog.csdnimg.cn/20190723234140806.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="479">        ⑷如何查看归档文件里面的文件呢？              <img alt="" class="has" height="138" src="https://img-blog.csdnimg.cn/20190723234325482.png" width="558">                   命令：hadoop fs -lsr har:///myhar.har              我们可以将这里面的文件拷贝到其它目录             <img alt="" class="has" height="177" src="https://img-blog.csdnimg.cn/20190723234526964.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="654">             <img alt="" class="has" height="299" src="https://img-blog.csdnimg.cn/20190723234549256.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="590"> </li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Docker Compose配置文件docker-compose.yml文件详解</title>
    <url>/2021/07/18/Docker%20Compose%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6docker-compose.yml%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p>title: Docker Compose配置文件docker-compose.yml文件详解<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—一份标准的docker-compose.yml文件应该包含version、services、networks三大部分，其中最关键的就是services和networks两个部分。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">version: &#x27;2&#x27;</span><br><span class="line">services:</span><br><span class="line">  web:</span><br><span class="line">    image: dockercloud/hello-world</span><br><span class="line">    ports:</span><br><span class="line">      - 8080</span><br><span class="line">    networks:</span><br><span class="line">      - front-tier</span><br><span class="line">      - back-tier</span><br><span class="line"> </span><br><span class="line">  redis:</span><br><span class="line">    image: redis</span><br><span class="line">    links:</span><br><span class="line">      - web</span><br><span class="line">    networks:</span><br><span class="line">      - back-tier</span><br><span class="line"> </span><br><span class="line">  lb:</span><br><span class="line">    image: dockercloud/haproxy</span><br><span class="line">    ports:</span><br><span class="line">      - 80:80</span><br><span class="line">    links:</span><br><span class="line">      - web</span><br><span class="line">    networks:</span><br><span class="line">      - front-tier</span><br><span class="line">      - back-tier</span><br><span class="line">    volumes:</span><br><span class="line">      - /var/run/docker.sock:/var/run/docker.sock </span><br><span class="line"> </span><br><span class="line">networks:</span><br><span class="line">  front-tier:</span><br><span class="line">    driver: bridge</span><br><span class="line">  back-tier:</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="services部分"><a href="#services部分" class="headerlink" title="services部分"></a>services部分</h1><p>1、image</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">services:</span><br><span class="line">  web:</span><br><span class="line">    image: hello-world</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在services标签下的第二级标签是web，这个名字是用户自己自定义的，它就是服务名称。 image 则是指定服务的镜像名称或镜像id。如果镜像在本地不存在，compose将会尝试拉取这个镜像。</p>
<p>2、build</p>
<p>服务除了可以基于指定的镜像，还可以基于一份Dockerfile，在使用up启动之时执行构建人物，这个构建标签就是build，它可以指定Dockerfile所在文件夹的路径。compose将会利用它自动构建这个镜像，然后使用这个镜像启动服务同期。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">build: /path/to/build/dir</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>也可以是想对路径，只要上下文确定就可以读取到Dockerfile</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">build: ./dir</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>设定上下文根目录，然后以该目录为准指定Dockerfike</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">build:</span><br><span class="line">  context: ../</span><br><span class="line">  dockerfile: path/of/Dockerfile</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意build都是一个目录，如果你指定Dockerfile文件需要在build标签的子级标签中使用dockerfile标签指定，如上面的例子。 如果你同事指定了 image和build 两个标签，那么compos会构建镜像并且把镜像命名为image后面的那个名字</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">build: ./dir</span><br><span class="line">image: webapp:tag</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>3、command</p>
<p>command命令可以覆盖容器启动后默认执行的命令。两种写法。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">command: bundle exec thin -p 3000</span><br><span class="line">command: [bundle, exec, thin, -p, 3000]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>4、container_name</p>
<p>前面说过 Compose 的容器名称格式是：&lt;项目名称&gt;&lt;服务名称&gt;&lt;序号&gt; 虽然可以自定义项目名称、服务名称，但是如果你想完全控制容器的命名，可以使用这个标签指定：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">container_name: app</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>5、depends_on</p>
<p>depends_on解决了容器的依赖、启动先后的问题。 例如下面容器会先启动redis和db两个服务，最后才启动web服务：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">version: &#x27;2&#x27;</span><br><span class="line">services:</span><br><span class="line">  web:</span><br><span class="line">    build: .</span><br><span class="line">    depends_on:</span><br><span class="line">      - db</span><br><span class="line">      - redis</span><br><span class="line">  redis:</span><br><span class="line">    image: redis</span><br><span class="line">  db:</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意的是，默认情况下使用 docker-compose up web 这样的方式启动 web 服务时，也会启动 redis 和 db 两个服务，因为在配置文件中定义了依赖关系。</p>
<p>6、dns</p>
<p>和 –dns参数一样的用途，格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dns: 8.8.8.8</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li> <br>也可以是一个列表：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dns:</span><br><span class="line">  - 8.8.8.8</span><br><span class="line">  - 9.9.9.9</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>此外dns_search的配置也类似：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dns_search: example.com</span><br><span class="line">dns_search:</span><br><span class="line">  - dc1.example.com</span><br><span class="line">  - dc2.example.com</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>7、tmpfs</p>
<p>挂载临时目录到容器内部，与run的参数一样效果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tmpfs: /run</span><br><span class="line">tmpfs:</span><br><span class="line">  - /run</span><br><span class="line">  - /tmp</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>8、environment</p>
<p>设置镜像变量，它可以保存变量到镜像里，也就是说启动的容器也会包含这些变量设置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">environment:</span><br><span class="line">  RACK_ENV: development</span><br><span class="line">  SHOW: &#x27;true&#x27;</span><br><span class="line">  SESSION_SECRET:</span><br><span class="line"> </span><br><span class="line">environment:</span><br><span class="line">  - RACK_ENV=development</span><br><span class="line">  - SHOW=true</span><br><span class="line">  - SESSION_SECRET</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>9、expose</p>
<p>用于指定暴露的端口，但是只是作为参考，端口映射的话还得ports标签</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">expose:</span><br><span class="line"> - &quot;3000&quot;</span><br><span class="line"> - &quot;8000&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>10、external_links</p>
<p>在使用Docker的过程中，我们会有许多单独使用docker run启动的容器，为了使Compose能够连接这些不在docker-compose.yml中定义的容器，我们需要一个特殊的标签，就是external_links，它可以让Compose项目里面的容器连接到那些项目配置外部的容器（前提是外部容器中必须至少有一个容器是连接到与项目内的服务的同一个网络里面）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">external_links:</span><br><span class="line"> - redis_1</span><br><span class="line"> - project_db_1:mysql</span><br><span class="line"> - project_db_1:postgresql</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>11、extra_hosts</p>
<p>添加主机名的标签，就是往容器内部/etc/hosts文件中添加一些记录，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">extra_hosts:</span><br><span class="line"> - &quot;somehost:162.242.195.82&quot;</span><br><span class="line"> - &quot;otherhost:50.31.209.229&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>12、labels</p>
<p>向容器添加元数据，和Dockerfile的lable指令一个意思</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">labels:</span><br><span class="line">  com.example.description: &quot;Accounting webapp&quot;</span><br><span class="line">  com.example.department: &quot;Finance&quot;</span><br><span class="line">  com.example.label-with-empty-value: &quot;&quot;</span><br><span class="line">labels:</span><br><span class="line">  - &quot;com.example.description=Accounting webapp&quot;</span><br><span class="line">  - &quot;com.example.department=Finance&quot;</span><br><span class="line">  - &quot;com.example.label-with-empty-value&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>13、links</p>
<p>解决容器连接问题，与docker的–link一样的效果，会连接到其他服务中的容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">links:</span><br><span class="line"> - db</span><br><span class="line"> - db:database</span><br><span class="line"> - redis</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>使用的别名将会自动在服务容器中的/etc/hosts里创建。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">172.12.2.186  db</span><br><span class="line">172.12.2.186  database</span><br><span class="line">172.12.2.187  redis</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>14、ports</p>
<p>用作端口映射 使用HOST:CONTAINER格式或者只是指定容器的端口，宿主机会随机映射端口</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ports:</span><br><span class="line"> - &quot;3000&quot;</span><br><span class="line"> - &quot;8000:8000&quot;</span><br><span class="line"> - &quot;49100:22&quot;</span><br><span class="line"> - &quot;127.0.0.1:8001:8001&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意：当使用HOST:CONTAINER格式来映射端口时，如果你使用的容器端口小于60你可能会得到错误得结果，因为YAML将会解析xx:yy这种数字格式为60进制。所以建议采用字符串格式。</p>
<p>15、security_opt</p>
<p>为每个容器覆盖默认的标签。简单说来就是管理全部服务的标签，比如设置全部服务的user标签值为USER</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">security_opt:</span><br><span class="line">  - label:user:USER</span><br><span class="line">  - label:role:ROLE</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>16、volumes</p>
<p>挂载一个目录或者一个已经存在的数据卷容器，可以直接使用[HOST:CONTAINER]这样的格式，或者使用[HOST:CONTAINER:ro]这样的格式，或者对于容器来说，数据卷是只读的，这样可以有效保护宿主机的文件系统。 compose的数据卷指定路径可以是相对路径，使用 . 或者 … 来指定性对目录 数据卷的格式可以是下面多种形式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">volumes:</span><br><span class="line">  // 只是指定一个路径，Docker 会自动在创建一个数据卷（这个路径是容器内部的）。</span><br><span class="line">  - /var/lib/mysql</span><br><span class="line"> </span><br><span class="line">  // 使用绝对路径挂载数据卷</span><br><span class="line">  - /opt/data:/var/lib/mysql</span><br><span class="line"> </span><br><span class="line">  // 以 Compose 配置文件为中心的相对路径作为数据卷挂载到容器。</span><br><span class="line">  - ./cache:/tmp/cache</span><br><span class="line"> </span><br><span class="line">  // 使用用户的相对路径（~/ 表示的目录是 /home/&amp;lt;用户目录&amp;gt;/ 或者 /root/）。</span><br><span class="line">  - ~/configs:/etc/configs/:ro</span><br><span class="line"> </span><br><span class="line">  // 已经存在的命名的数据卷。</span><br><span class="line">  - datavolume:/var/lib/mysql</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>如果你不使用宿主机的路径，你可以指定一个volume_driver。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">volume_driver: mydriver</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li> <br>17、volumes_from</li>
</ul>
<p>从其它容器或者服务挂载数据卷，可选的参数是:ro或者:rw，前者表示容器只读，后者表示容器对数据卷是可读可写的，默认是可读可写的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">volumes_from:</span><br><span class="line">  - service_name</span><br><span class="line">  - service_name:ro</span><br><span class="line">  - container:container_name</span><br><span class="line">  - container:container_name:rw</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>18、network_mode</p>
<p>网络模式，与docker client的–net参数类似，只是相对多了一个service:[sevice name]的格式。 例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">network_mode: &quot;bridge&quot;</span><br><span class="line">network_mode: &quot;host&quot;</span><br><span class="line">network_mode: &quot;none&quot;</span><br><span class="line">network_mode: &quot;service:[service name]&quot;</span><br><span class="line">network_mode: &quot;container:[container name/id]&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>19 networks</p>
<p>加入指定网络</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">services:</span><br><span class="line">  some-service:</span><br><span class="line">    networks:</span><br><span class="line">     - some-network</span><br><span class="line">     - other-network</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>关于这个标签还有一个特别的子标签aliases，这是一个用来设置服务别名的标签，例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">services:</span><br><span class="line">  some-service:</span><br><span class="line">    networks:</span><br><span class="line">      some-network:</span><br><span class="line">        aliases:</span><br><span class="line">         - alias1</span><br><span class="line">         - alias3</span><br><span class="line">      other-network:</span><br><span class="line">        aliases:</span><br><span class="line">         - alias2</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>docker-compose.yml还有很多其他命令，比如depends_on、pid、devices等，这里就不一一介绍了</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>DockerCompose简介</title>
    <url>/2021/07/18/DockerCompose%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>title: DockerCompose简介<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: DockerCompose简介<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—composetest_redis_1   docker-entrypoint.sh redis …   Up      6379/tcp<br>composetest_web_1     flask run                        Up      0.0.0.0:5000-&gt;5000/tcp</code></pre> 停止命令 <strong>docker-compose stop 或docker-compose down</strong> <pre><code class="language-bash">[root@web composetest]# docker-compose stop<br>Stopping composetest_web_1   ... done<br>Stopping composetest_redis_1 ... done</code></pre> 假设项目需要重新打包**  docker-compose up –build** </li><li>网络规则<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20201029112250681.png#pic_center"><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20201029113336750.png#pic_center"><pre><code class="language-bash">docker network inspect [networkid]<br></code></pre> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/2020102911344840.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzY5MTc3Mw==,size_16,color_FFFFFF,t_70#pic_center"><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20201029113548962.png#pic_center"><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/2020102911372757.png#pic_center"> </li></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>Dockerfile中的COPY和ADD指令详解与比较</title>
    <url>/2021/07/18/Dockerfile%E4%B8%AD%E7%9A%84COPY%E5%92%8CADD%E6%8C%87%E4%BB%A4%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83/</url>
    <content><![CDATA[<p>title: Dockerfile中的COPY和ADD指令详解与比较<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—Dockerfile中的COPY指令和ADD指令都可以将主机上的资源复制或加入到容器镜像中，都是在构建镜像的过程中完成的。</p>
<p>COPY指令和ADD指令的唯一区别在于是否支持从远程URL获取资源。COPY指令只能从执行docker build所在的主机上读取资源并复制到镜像中。而ADD指令还支持通过URL从远程服务器读取资源并复制到镜像中。</p>
<p>满足同等功能的情况下，推荐使用COPY指令。ADD指令更擅长读取本地tar文件并解压缩。</p>
<ol>
<li>COPY指令</li>
</ol>
<p>COPY指令能够将构建命令所在的主机本地的文件或目录，复制到镜像文件系统。</p>
<p>exec格式用法（推荐）： COPY [“&lt;src&gt;”,… “&lt;dest&gt;”]，推荐，特别适合路径中带有空格的情况</p>
<p>shell格式用法： COPY &lt;src&gt;… &lt;dest&gt;</p>
<p> </p>
<ol start="2">
<li>ADD指令 ADD指令不仅能够将构建命令所在的主机本地的文件或目录，而且能够将远程URL所对应的文件或目录，作为资源复制到镜像文件系统。 所以，可以认为ADD是增强版的COPY，支持将远程URL的资源加入到镜像的文件系统。  </li>
</ol>
<p>exec格式用法（推荐）： ADD [“&lt;src&gt;”,… “&lt;dest&gt;”]，特别适合路径中带有空格的情况</p>
<p>shell格式用法： ADD &lt;src&gt;… &lt;dest&gt;</p>
<p> 说明，对于从远程URL获取资源的情况，由于ADD指令不支持认证，如果从远程获取资源需要认证，则只能使用RUN wget或RUN curl替代。 另外，如果源路径的资源发生变化，则该ADD指令将使Docker Cache失效，Dockerfile中后续的所有指令都不能使用缓存。因此尽量将ADD指令放在Dockerfile的后面。</p>
<ol start="3">
<li>COPY指令和ADD指令的用法非常相似，具体注意事项如下：</li>
</ol>
<ul>
<li>源路径可以有多个- 源路径是相对于执行build的相对路径- 源路径如果是本地路径，必须是build上下文中的路径- 源路径如果是一个目录，则该目录下的所有内容都将被加入到容器，但是该目录本身不会- 目标路径必须是绝对路径，或相对于WORKDIR的相对路径- 目标路径如果不存在，则会创建相应的完整路径- 目标路径如果不是一个文件，则必须使用/结束- 路径中可以使用通配符</li>
</ul>
<ol start="4">
<li>读取URL远程资源</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">RUN mkdir -p /usr/src/things \</span><br><span class="line">    &amp;amp;&amp;amp; curl -SL http://example.com/big.tar.xz \</span><br><span class="line">    | tar -xJC /usr/src/things \</span><br><span class="line">    &amp;amp;&amp;amp; make -C /usr/src/things all</span><br></pre></td></tr></table></figure>

<p>事实上，当要读取URL远程资源的时候，并不推荐使用ADD指令，而是建议使用RUN指令，在RUN指令中执行wget或curl命令。</p>
<p>转载自：</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>Dockerfile简介</title>
    <url>/2021/07/18/Dockerfile%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>title: Dockerfile简介<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: Dockerfile简介<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. 什么是Dockerfile？ Dockerfile是用来构建docker镜像的构建文件，是由一系列命令和参数构成的脚本。1. 构建Dockerfile的三步骤：  a：编写Dockerfile文件  b：docker build去执行文件  c：docker run去运行生产的镜像1. Dockerfile的构建过程解析  a：每条保留字指令都必须为大写字母且后面要跟随至少一个参数  b：指令按照从上到下，顺序执行  c：#表示注释  d：每条指令都会创建一个新的镜像层，并对镜像进行提交<img alt="" height="347" src="https://img-blog.csdnimg.cn/20201226101923368.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="706">1. Docker执行Dockerfile的大致流程       a：dcoker从基础镜像运行一个容器       b：执行一条指令并对容器做出修改       c：执行类似docker commit的操作提交一个新的镜像层       d：docker再基于刚提交的镜像运行一个新容器       e：执行dockerfile中的下一条指令直到所有指令都执行完成1. dockerfile的体系结构（保留字指令） ①FROM：表示基础镜像，当前新镜像是基于哪个镜像的。              例如：FROM tomcat  —–》就是基于tomcat作为基础镜像的 ②MAINTAINER：表示镜像维护者的姓名和邮箱地址                  例如：MAINTAINER The Centos Project &lt;<a href="mailto:&#x63;&#x6c;&#x6f;&#117;&#x64;&#x2d;&#x6f;&#112;&#115;&#64;&#x63;&#101;&#110;&#116;&#111;&#115;&#46;&#x6f;&#x72;&#x67;">&#x63;&#x6c;&#x6f;&#117;&#x64;&#x2d;&#x6f;&#112;&#115;&#64;&#x63;&#101;&#110;&#116;&#111;&#115;&#46;&#x6f;&#x72;&#x67;</a>&gt; ③RUN：表示容器构建时需要运行的命令 ④EXPOSE：表示构建的容器启动后对外暴露的端口号              例如：EXPOSE 6379 ⑤WORKDIR：表示指定在容器创建后，终端默认登录进来的工作目录，一个落脚点                    例如：WORKDIR /data   表示当我们进入容器后默认就在/data这个目录下 ⑥ENV：用来在构建镜像过程中设置环境变量              例如：ENV MY_PATH /usr/mytest   表示我们设置一个环境变量名称为MY_PATH，                         值为/usr/mytest，那么我们后面就可以引用这个环境变量。比如我们在设置                         落脚点的时候，WORKDIR $MY_PATH，那么登录进来后直接就是在/usr/mytest                         目录下。 ⑦ADD： 将宿主机目录下的文件拷贝进镜像并且ADD命令会自动处理URL和解压tar压缩包                   例如：ADD centos-7-docker.tar.xz / ⑧COPY：类似ADD，拷贝文件和目录到镜像中。将从构建上下文目录中&lt;源路径&gt;的文件/目录                        复制到新的一层镜像内的&lt;目标路径&gt;位置。              例如：COPY src dest 或者 COPY [“src”,”dest”]  ⑨VOLUME：容器数据卷，用于数据保存和持久化工作  ⑩CMD           a：表示指定一个容器启动时要运行的命令                     <img alt="" height="159" src="https://img-blog.csdnimg.cn/20181103103647354.png" width="572">               b：Dockerfile中可以有多个CMD指令，但只有最后一个生效，CMD会被docker run 之后                     的参数替代。   ENTRYPOINT：表示指定一个容器启动时要运行的命令，ENTRYPOINT的目的和CMD一样，                                  都是在指定容器启动程序及参数。   ONBUILD：表示当构建一个被继承的Dockerfile时运行命令，父镜像在被子继承后父镜像的                           onbuild被触发。<li>案例之构建自己的centos镜像  ⑴Base镜像（scratch）        Docker Hub中99%的镜像都是通过在base镜像中安装和配置需要的软件构建出来的。  ⑵自定义镜像mycentos        ①我们现在可以看看我们从网上下载下载的centos镜像原本是什么样子的              <img alt="" height="323" src="https://img-blog.csdnimg.cn/20181103134447707.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="547"> ⑶在/opt/dockerfile目录下创建自己的dockerfile    <img alt="" height="668" src="https://img-blog.csdnimg.cn/20201226115505509.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="605">       <pre><code class="language-bash">#基于我们从阿里云下载下来的centos基础镜像<br>FROM centos</p>
<p>#定义作者信息<br>MAINTAINER kgf&lt;<a href="mailto:&#x6b;&#x67;&#102;&#x40;&#49;&#x36;&#51;&#x2e;&#99;&#111;&#x6d;">&#x6b;&#x67;&#102;&#x40;&#49;&#x36;&#51;&#x2e;&#99;&#111;&#x6d;</a>&gt;</p>
<p>#设置环境变量<br>ENV MY_PATH /usr/local</p>
<p>#定义进入容器后的工作目录就是/usr/local<br>WORKDIR $MY_PATH</p>
<p>#定义容器支持vim命令<br>RUN yum -y install vim</p>
<p>#定义容器支持ifconfig命令<br>RUN yum -y install net-tools</p>
<p>#定义容器暴露的端口号为80<br>EXPOSE 80</p>
<p>#输出构建完成信息<br>CMD echo “=============构建完成============”</p>
<p>#最后进入容器的/bin/bash路径下<br>CMD /bin/bash</code></pre>  ⑷使用dockerfile文件构建新的镜像       命令：docker build -f Dockerfile的绝对路径 -t 镜像名称:版本号 .           docker build -f /opt/dockerfile/mydockerfile-centos -t mycentos:v1.1 .    <img alt="" height="464" src="https://img-blog.csdnimg.cn/20201226120355247.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="849">     <img alt="" height="441" src="https://img-blog.csdnimg.cn/20201226120419220.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="704"> ⑸下面我们运行新建的镜像        命令：docker run -it mycentos:v1.1   <img alt="" height="617" src="https://img-blog.csdnimg.cn/20201226121353215.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="796">  <img alt="" height="174" src="https://img-blog.csdnimg.cn/20201226121504898.png" width="713"> ⑹使用docker history +镜像ID 查看镜像详细信息         <img alt="" height="385" src="https://img-blog.csdnimg.cn/2020122612205842.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="770"></li></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>Docker安装Oracle12c知识点总结</title>
    <url>/2021/07/18/Docker%E5%AE%89%E8%A3%85Oracle12c%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>title: Docker安装Oracle12c知识点总结<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: Docker安装Oracle12c知识点总结<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. <strong><strong><strong>拉取指定版本的镜像</strong></strong></strong> docker pull sath89/oracle-12c1. <strong>查看已经下载的镜像</strong><img alt="" height="96" src="https://img-blog.csdnimg.cn/20200820180202495.png" width="554">1. <strong><strong><strong>数据库设置和数据将保存到</strong></strong><strong><strong>/mydata/oracle12c</strong></strong><strong><strong>/ oradata文件夹</strong></strong></strong> 1) 首先需要创建/mydata/oracle12c/oracledata文件夹路径 2)赋予读写等权限(很重要)     chmod -R a+w /mydata/oracle12c/oracledata  3)执行下面的创建实例语句     docker run –shm-size=1024MB -p 1521:1521 \     –privileged \     -e ORACLE_ALLOW_REMOTE=true \     -v /mydata/oracle12c/oracledata:/u01/app/oracle \     –name oracle12c –restart=always -d sath89/oracle-12c 1. **<strong><strong>进入Oracle内部查看  1) **</strong></strong>进入容器内部       docker exec -it 容器ID/bin/bash  2)切换为oracle用户      su oracle  3)进入数据库      $ORACLE_HOME/bin/sqlplus / as sysdba  4)查看数据库状态      <img alt="" height="167" src="https://img-blog.csdnimg.cn/20200820180535952.png" width="370">  5)修改system用户密码       alter user system identified by iamp1234;  6)连接Oracle     hostname: ip地址     port:1521     sid:xe     username:system     password:iamp1234</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>Docker之阿里云镜像加速器配置</title>
    <url>/2021/07/18/Docker%E4%B9%8B%E9%98%BF%E9%87%8C%E4%BA%91%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F%E5%99%A8%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>title: Docker之阿里云镜像加速器配置<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—# 一：简介</p>
<p>         1：为什么使用阿里云镜像加速器?</p>
<p>               一般而言，我们使用Docker，是需要从Docker官网去拉取镜像的，但是官网是在国外的，                所以下载非常慢，或者都下载不了，总是报timeout连接失败错误，因此需要配置镜像的下载，               这个是docker操作首先要做的事情，通常使用以下两种方式。</p>
<h1 id="二：直接使用镜像仓库地址进行下载："><a href="#二：直接使用镜像仓库地址进行下载：" class="headerlink" title="二：直接使用镜像仓库地址进行下载："></a>二：直接使用镜像仓库地址进行下载：</h1><p>           比如：前往网易云蜂巢镜像中心：<img alt="" class="has" height="233" src="https://img-blog.csdn.net/2018102014523129?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="482">                        <img alt="" class="has" height="73" src="https://img-blog.csdn.net/20181020212635912?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="478">                       可以直接使用具体的镜像地址进行下载，docker pull hub.c.163.com/public/tomcat:latest                       不过这种方式就是每次都需要去指定具体的镜像地址，这个比较纠结，很多时候没记得具体的地址。</p>
<h1 id="三：使用加速器下载"><a href="#三：使用加速器下载" class="headerlink" title="三：使用加速器下载"></a>三：使用加速器下载</h1><p>         1：简介                第二种方式稍微就简单一些，不需要去记具体的镜像下载地址，                可以使用镜像加速器来实现，常用的加速有很多，比如阿里云、DaoCloud、、                以使用阿里云的为例：进入官网 <img alt="" class="has" height="294" src="https://img-blog.csdn.net/20181021134351291?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="615">:</p>
<p>        3：注册之后可以看到加速器地址               <img alt="" class="has" height="504" src="https://img-blog.csdn.net/20181021135224261?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="547">               根据上面的操作文档，选择对应的操作系统，进行相应的操作即可。               如下：                      <img alt="" class="has" height="132" src="https://img-blog.csdn.net/20181022095528915?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="528">                     后面执行下面两个命令：                            sudo systemctl daemon-reload，udo systemctl restart docker                最后使用docker info查看详细信息：                        <img alt="" class="has" height="178" src="https://img-blog.csdnimg.cn/20181028103116750.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="350">         4：网上看到的相关问题               <img alt="" class="has" height="410" src="https://img-blog.csdn.net/20181021140024471?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="639">    </p>
<p>               </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p>  </p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>Docker数据卷之具名挂载和匿名挂载</title>
    <url>/2021/07/18/Docker%E6%95%B0%E6%8D%AE%E5%8D%B7%E4%B9%8B%E5%85%B7%E5%90%8D%E6%8C%82%E8%BD%BD%E5%92%8C%E5%8C%BF%E5%90%8D%E6%8C%82%E8%BD%BD/</url>
    <content><![CDATA[<p>title: Docker数据卷之具名挂载和匿名挂载<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—### 1、匿名挂载</p>
<p>(1）启动容器</p>
<p>docker run -d -P –name nginx01 -v /etc/nginx nginx </p>
<p>-v 容器内路径</p>
<img alt="" height="54" src="https://img-blog.csdnimg.cn/20200706160620860.png" width="644">

<p>（2）查看所有卷的情况</p>
<p>docker volume ls<img alt="" height="71" src="https://img-blog.csdnimg.cn/20200706160710977.png" width="624"></p>
<p>注：</p>
<p>由上图可以看到，VOLUME NAME 有的是随机生成的字符串，对于这种就是匿名挂载，因为-v的时候只写了容器内的路径看，而没有写容器外的路径</p>
<h3 id="2、具名挂载"><a href="#2、具名挂载" class="headerlink" title="2、具名挂载"></a>2、具名挂载</h3><p>(1)  启动容器</p>
<p>docker run -d -P –name nginx02 -v juming-nginx:/etc/nginx nginx </p>
<p>语法： -v 卷名：容器内路径</p>
<img alt="" height="187" src="https://img-blog.csdnimg.cn/20200706160923588.png" width="1053">

<p>（2）查看一下这个卷</p>
<p>docker volumn inspect juming-nginx</p>
<img alt="" height="218" src="https://img-blog.csdnimg.cn/20200706161119579.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h5YWppYQ==,size_16,color_FFFFFF,t_70" width="510">

<p>注：</p>
<p>a、所有docker容器内的卷，没有指定目录的情况下都是在 /var/lib/docker/volumes/XXX</p>
<img alt="" height="53" src="https://img-blog.csdnimg.cn/20200706161228773.png" width="754">

<p>b、docker volumn ls 查看所有的卷都在这个位置/var/lib/docker/volumns</p>
<img alt="" height="128" src="https://img-blog.csdnimg.cn/20200706161232907.png" width="764">

<p>c、查看刚才添加的juming-nginx目录</p>
<img alt="" height="99" src="https://img-blog.csdnimg.cn/20200706161256139.png" width="807">

<h3 id="3、选择"><a href="#3、选择" class="headerlink" title="3、选择"></a>3、选择</h3><p>我们通过具名挂载可以方便的找到我们的一个卷，大多数情况在使用的，不建议大家使用匿名挂载</p>
<p>如何确定是匿名挂载还是具名挂载呢？</p>
<p>-v 容器内路径               #匿名挂载 -v 卷名：容器内路径         #具名挂载 -v /宿主机路径：容器内路径    #指定路径挂载</p>
<h3 id="4、拓展"><a href="#4、拓展" class="headerlink" title="4、拓展"></a>4、拓展</h3><p>（1）通过 -v 容器内路径:ro rw 改变读写权限</p>
<p>ro readonly  #只读 rw readwrite #可读可写</p>
<p>（2）一旦这个设定了容器权限，容器对我们挂载出来的内容就有限定了</p>
<p>docker run -d -P –name nginx02 -v juming-nginx:/etc/nginx:ro  nginx docker run -d -P –name nginx02 -v juming-nginx:/etc/nginx:rw  nginx</p>
<p>（3）ro</p>
<p>只要看到ro就说明这个路径只能通过宿主机来改变，容器内部是无法操作的</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>ELK知识点学习</title>
    <url>/2021/07/18/ELK%E7%9F%A5%E8%AF%86%E7%82%B9%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>title: ELK知识点学习<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—title: ELK知识点学习<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—1. </p>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>Docker网络详解之Overlay</title>
    <url>/2021/07/18/Docker%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B9%8BOverlay/</url>
    <content><![CDATA[<p>title: Docker网络详解之Overlay<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—我们在上篇文章说了Docker在单个Docker daemon(即是单主机)模式下面的时候网络默认为Bridge，既然提到了单个Docker daemon，那么多主机即是集群的模式的情况下呢？在这种模式下Docker默认使用Overlay网络来进行容器间的通信。</p>
<p>接下来我们看看我们在加入一个集群或者初始化一个集群的时候会发生什么事情，下面这段话来自官方文档：</p>
<ol>
<li>首先一个名<code>ingress</code>的overlay网络被创建，这样在你没有指定网络的情况下你的集群中的services（你可以理解为一个container，实际上它为多个重复的container，是集群中的一个概念）会自动连接到这个网络。这样集群中的services通过这个网络进行通信。1. 然后一个名叫<code>docker_gwbridge</code>的网桥被建立，这个网桥用来连接在这个网络中的Docker daemon<br>所以由以上可知，逻辑上我们都处于一个叫ingress的overlay网络上，实际上Docker daemon之间的通信还是通过一个叫docker_gwbridge的网桥进行的。每个services或者container同时能够加入很多个网络，但是它们只能和连接在同一个网络上的其他service或者container进行通信。</li>
</ol>
<h2 id="建立一个Overlay网络"><a href="#建立一个Overlay网络" class="headerlink" title="建立一个Overlay网络"></a>建立一个Overlay网络</h2><p>当我们要建立一个overlay网络的时候有几个前提：</p>
<ol>
<li>必须要打开必要的端口让网络能进行通信，比如必须打开2377端口的TCP、7946端口的TCP和UDP以及4789端口UDP，这都是进行通信必要的1. 在你创建你自己的overlay网络之前，你必须加入一个集群或者是初始化一个集群<br>准备工作做好后，我们用<code>$ docker network create -d overlay your-overlaynetwork-name</code>来创建你的overlay网络，如果你想自己配置关于网络的IP地址范围、子网、网关或者其他选项，你能通过添加<code>--attachable</code>来进行配置</li>
</ol>
<h2 id="Overlay网络的安全性"><a href="#Overlay网络的安全性" class="headerlink" title="Overlay网络的安全性"></a>Overlay网络的安全性</h2><p>在默认的情况，overlay网络中的services进行通信是通过<code>AES加密算法</code>过的，并且集群中的管理节点会<code>每12小时</code>对这个加密秘钥进行更改。当你想在你自己的overlay网络中应用加密算法，你能通过<code>--opt encrypted</code>命令来开启加密，但是注意，<code>windows上的Docker daemon不支持加密</code></p>
<p><code>转载自：</code></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>ES之词库的动态添加</title>
    <url>/2021/07/18/ES%E4%B9%8B%E8%AF%8D%E5%BA%93%E7%9A%84%E5%8A%A8%E6%80%81%E6%B7%BB%E5%8A%A0/</url>
    <content><![CDATA[<p>title: ES之词库的动态添加<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、环境准备</p>
<blockquote>
<p> 1）安装nginx1.18.0<br> 2)  安装好ES7.8.1和kibana7.8.1（提前准备好） </p>
</blockquote>
<h3 id="2、安装nginx"><a href="#2、安装nginx" class="headerlink" title="2、安装nginx"></a>2、安装nginx</h3><blockquote>
<p> 2.1）拉取nginx1.18.0镜像<br>         docker pull nginx:1.18.0<br> 2.2）创建挂载容器里面的界面的访问<br>          mkdir -p /mydata/nignx/html<br> 2.3）在/mydata/nignx/html/中创建hotwords.txt<br>          <img alt="" height="208" src="https://img-blog.csdnimg.cn/20210704142127275.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="464"><br> 2.4）docker命令启动nginx<br>          docker run -itd -p 80:80 -v /mydata/nignx/html:/usr/share/nginx/html nginx:1.18.0<br> <img alt="" height="156" src="https://img-blog.csdnimg.cn/20210704142706539.png" width="1200"><br> 2.5) 浏览器访问：<br>     <img alt="" height="131" src="https://img-blog.csdnimg.cn/20210704142903713.png" width="649"> </p>
</blockquote>
<h3 id="3、开始配置es"><a href="#3、开始配置es" class="headerlink" title="3、开始配置es"></a>3、开始配置es</h3><blockquote>
<p> 3.1) 进入/opt/es781/elasticsearch-7.8.1/plugins/ik/config目录下修改IKAnalyzer.cfg.xml<br> <img alt="" height="363" src="https://img-blog.csdnimg.cn/20210704143225821.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="925"><br> 3.2）重启es<br> 3.3）使用kibana查看<br>      <img alt="" height="136" src="https://img-blog.csdnimg.cn/20210704143626716.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="578"><br> 3.4）测试一个单词“就是我”<br>       <img alt="" height="190" src="https://img-blog.csdnimg.cn/20210704143741562.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="591"><br>      我们在nginx的hotwords.txt中添加这个单词<br>        <img alt="" height="130" src="https://img-blog.csdnimg.cn/20210704143923740.png" width="506"><br> 不重启es直接查询：<br> <img alt="" height="280" src="https://img-blog.csdnimg.cn/2021070414394629.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1053"> </p>
</blockquote>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>ElasticSearch简介以及单机安装</title>
    <url>/2021/07/18/ElasticSearch%E7%AE%80%E4%BB%8B%E4%BB%A5%E5%8F%8A%E5%8D%95%E6%9C%BA%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>title: ElasticSearch简介以及单机安装<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—title: ElasticSearch简介以及单机安装<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—1. 简介       Elasticsearch是一个基于的开源搜索引擎。无论在开源还是专有领域，Lucene可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。1. 特点：       a：分布式的实时文件存储，每个字段都被索引并可被搜索       b：分布式的实时分析搜索引擎–做不规则查询       c：可以扩展到上百台服务器，处理PB级结构化或非结构化数据  Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单1. 环境：    a：centos7    b：jdk1.81. 将安装包上传到/usr/local/module/目录下，并解压  <img alt="" class="has" height="157" src="https://img-blog.csdnimg.cn/20200102205146168.png" width="641">  <img alt="" class="has" height="163" src="https://img-blog.csdnimg.cn/20200102205531112.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="580">1. 启动，在/usr/local/module/elasticsearch-6.3.1/目录下   <img alt="" class="has" height="288" src="https://img-blog.csdnimg.cn/20200102210012570.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="650">   可以发现elasticsearch不能够以root用户启动1. 下面我们创建一个elk用户启动elasticsearch   <img alt="" class="has" height="119" src="https://img-blog.csdnimg.cn/20200102211743279.png" width="519">   <img alt="" class="has" height="144" src="https://img-blog.csdnimg.cn/20200102211807259.png" width="591">1. 再次启动  <img alt="" class="has" height="323" src="https://img-blog.csdnimg.cn/20200102212334646.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="682">1. 测试是否成功启动，重新打开一个窗口  <img alt="" class="has" height="399" src="https://img-blog.csdnimg.cn/20200102212553874.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="602">  出现上面的效果就代表启动成功。1. 下面我们需要外部机器访问es，那么我们需要修改配置文件/usr/local/module/elasticsearch-6.3.1/config/elasticsearch.yml  <img alt="" class="has" height="160" src="https://img-blog.csdnimg.cn/20200102213627273.png" width="441">1. 再次启动  <img alt="" class="has" height="255" src="https://img-blog.csdnimg.cn/20200102213812564.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="770">  可以发现出错了。1. 解决  a：vim /etc/security/limits.conf         <img alt="" class="has" height="224" src="https://img-blog.csdnimg.cn/20200102214043147.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="468">                  nofile - 打开文件的最大数目        noproc - 进程的最大数目        soft 指的是当前系统生效的设置值        hard 表明系统中所能设定的最大值   b： vim /etc/sysctl.conf          <img alt="" class="has" height="100" src="https://img-blog.csdnimg.cn/20200102214607863.png" width="421"> c：使用sysctl -p使其生效      <img alt="" class="has" height="125" src="https://img-blog.csdnimg.cn/20200102214715585.png" width="477">1. 再次启动  <img alt="" class="has" height="357" src="https://img-blog.csdnimg.cn/20200102215022459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="756">1. 效果：  <img alt="" class="has" height="362" src="https://img-blog.csdnimg.cn/20200102215055276.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="521"></p>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>Elasticseach之Linux单节点部署</title>
    <url>/2021/07/18/Elasticseach%E4%B9%8BLinux%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>title: Elasticseach之Linux单节点部署<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、将es的安装包上传到Linux服务器</p>
<blockquote>
 <img alt="" height="150" src="https://img-blog.csdnimg.cn/20210624175745621.png" width="886"> 
</blockquote>
<h3 id="2、解压软件"><a href="#2、解压软件" class="headerlink" title="2、解压软件"></a>2、解压软件</h3><blockquote>
<p> 2.1、解压命令<br>         tar -zxvf elasticsearch-7.8.0-linux-x86_64.tar.gz<br> <img alt="" height="140" src="https://img-blog.csdnimg.cn/20210624175940110.png" width="897"> </p>
</blockquote>
<h3 id="3、创建用户"><a href="#3、创建用户" class="headerlink" title="3、创建用户"></a>3、创建用户</h3><blockquote>
<p> 因为安全问题， Elasticsearch 不允许 root 用户直接运行，所以要创建新用户，在 root 用户中创建新用户。<br> useradd es #新增 es 用户 passwd es #为 es 用户设置密码 userdel -r es #如果错了，可以删除再加 chown -R es:es /opt/elasticsearch-7.8.0 #文件夹所有者 </p>
</blockquote>
<h3 id="4、修改配置文件"><a href="#4、修改配置文件" class="headerlink" title="4、修改配置文件"></a>4、修改配置文件</h3><blockquote>
<p> 修改/opt/elasticsearch-7.8.0/config/elasticsearch.yml文件。<br> <pre><code class="language-html"># 加入如下配置<br>cluster.name: elasticsearch<br>node.name: node-1<br>network.host: 0.0.0.0<br>http.port: 9200<br>cluster.initial_master_nodes: ["node-1"]<br></code></pre><br> 修改/etc/security/limits.conf<br> <pre><code class="language-bash"># 在文件末尾中增加下面内容</p>
</blockquote>
<h1 id="每个进程可以打开的文件数的限制"><a href="#每个进程可以打开的文件数的限制" class="headerlink" title="每个进程可以打开的文件数的限制"></a>每个进程可以打开的文件数的限制</h1><p>es soft nofile 65536<br>es hard nofile 65536<br></code></pre><br> 修改/etc/security/limits.d/20-nproc.conf<br> <pre><code class="language-bash"># 在文件末尾中增加下面内容</p>
<h1 id="每个进程可以打开的文件数的限制-1"><a href="#每个进程可以打开的文件数的限制-1" class="headerlink" title="每个进程可以打开的文件数的限制"></a>每个进程可以打开的文件数的限制</h1><p>es soft nofile 65536<br>es hard nofile 65536</p>
<h1 id="操作系统级别对每个用户创建的进程数的限制"><a href="#操作系统级别对每个用户创建的进程数的限制" class="headerlink" title="操作系统级别对每个用户创建的进程数的限制"></a>操作系统级别对每个用户创建的进程数的限制</h1><ul>
<li>hard nproc 4096<h1 id="注：-带表-Linux-所有用户名称"><a href="#注：-带表-Linux-所有用户名称" class="headerlink" title="注： * 带表 Linux 所有用户名称"></a>注： * 带表 Linux 所有用户名称</h1></code></pre><br>修改/etc/sysctl.conf <pre><code class="language-bash"># 在文件中增加下面内容
# 一个进程可以拥有的 VMA(虚拟内存区域)的数量,默认值为 65536
vm.max_map_count=655360
</code></pre> 
重新加载 <pre><code class="language-bash">sysctl -p
</code></pre> </li>
</ul>
<h3 id="5、启动软件"><a href="#5、启动软件" class="headerlink" title="5、启动软件"></a>5、启动软件</h3><blockquote>
<p> 使用 ES 用户启动<br> <pre><code>cd /opt/elasticsearch-7.8.0/<br>#启动<br>bin/elasticsearch<br>#后台启动<br>bin/elasticsearch -d<br></code></pre> </p>
</blockquote>
<h3 id="6、关闭防火墙"><a href="#6、关闭防火墙" class="headerlink" title="6、关闭防火墙"></a>6、关闭防火墙</h3><blockquote>
<p> #暂时关闭防火墙 systemctl stop firewalld #永久关闭防火墙 systemctl enable firewalld.service #打开防火墙永久性生效，重启后不会复原 systemctl disable firewalld.service #关闭防火墙，永久性生效，重启后不会复原   </p>
</blockquote>
<h3 id="7、测试软件"><a href="#7、测试软件" class="headerlink" title="7、测试软件"></a>7、测试软件</h3><blockquote>
<p> 浏览器中输入地址：<br> <img alt="" height="559" src="https://img-blog.csdnimg.cn/20210624181957612.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="894"> </p>
</blockquote>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>Elasticseach之Linux集群部署</title>
    <url>/2021/07/18/Elasticseach%E4%B9%8BLinux%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>title: Elasticseach之Linux集群部署<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、环境准备</p>
<blockquote>
<p> 安装Elasticsearch 7.8.0<br> 服务器：<br>     192.168.56.20 -es001（Master）<br>     192.168.56.21 -es002<br>     192.168.56.22 -es003 </p>
</blockquote>
<h3 id="2、将es的安装包上传到Linux服务器"><a href="#2、将es的安装包上传到Linux服务器" class="headerlink" title="2、将es的安装包上传到Linux服务器"></a>2、将es的安装包上传到Linux服务器</h3><blockquote>
 <img alt="" src="https://img-blog.csdnimg.cn/20210624175745621.png"> 
 将软件分发到其他节点： es002, es003 
</blockquote>
<h3 id="3、解压软件"><a href="#3、解压软件" class="headerlink" title="3、解压软件"></a>3、解压软件</h3><blockquote>
<p> 解压命令： tar -zxvf elasticsearch-7.8.0-linux-x86_64.tar.gz<br> <img alt="" height="690" src="https://img-blog.csdnimg.cn/20210624185309332.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"><br> 将软件改名：<br> mv elasticsearch-7.8.0 es-cluster<br> <img alt="" height="682" src="https://img-blog.csdnimg.cn/20210624185621133.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> </p>
</blockquote>
<h3 id="4、创建用户"><a href="#4、创建用户" class="headerlink" title="4、创建用户"></a>4、创建用户</h3><blockquote>
<p> 因为安全问题， Elasticsearch 不允许 root 用户直接运行，所以要创建新用户，在 root 用户中创建新用户。<br> useradd es #新增 es 用户 passwd es #为 es 用户设置密码 userdel -r es #如果错了，可以删除再加 chown -R es:es /opt/es-cluster #文件夹所有者 </p>
</blockquote>
<h3 id="5、修改配置文件"><a href="#5、修改配置文件" class="headerlink" title="5、修改配置文件"></a>5、修改配置文件</h3><blockquote>
<p> 修改es001节点的/opt/es-cluster/config/elasticsearch.yml 文件<br> <pre><code class="language-html"># 加入如下配置<br>#集群名称<br>cluster.name: cluster-es<br>#节点名称， 每个节点的名称不能重复<br>node.name: node-1<br>#ip 地址， 每个节点的地址不能重复<br>network.host: 192.168.56.20<br>#是不是有资格主节点<br>node.master: true<br>node.data: true<br>http.port: 9200</p>
</blockquote>
<h1 id="head-插件需要这打开这两个配置"><a href="#head-插件需要这打开这两个配置" class="headerlink" title="head 插件需要这打开这两个配置"></a>head 插件需要这打开这两个配置</h1><p>http.cors.allow-origin: “*”<br>http.cors.enabled: true<br>http.max_content_length: 200mb<br>#es7.x 之后新增的配置，初始化一个新的集群时需要此配置来选举 master<br>cluster.initial_master_nodes: [“node-1”]<br>#es7.x 之后新增的配置，节点发现<br>discovery.seed_hosts: [“192.168.56.20:9300”, “192.168.56.21:9300”, “192.168.56.22:300”]<br>gateway.recover_after_nodes: 2<br>network.tcp.keep_alive: true<br>network.tcp.no_delay: true<br>transport.tcp.compress: true<br>#集群内同时启动的数据任务个数，默认是 2 个<br>cluster.routing.allocation.cluster_concurrent_rebalance: 16<br>#添加或删除节点及负载均衡时并发恢复的线程个数，默认 4 个<br>cluster.routing.allocation.node_concurrent_recoveries: 16<br>#初始化数据恢复时，并发恢复线程的个数，默认 4 个<br>cluster.routing.allocation.node_initial_primaries_recoveries: 16<br></code></pre><br> 修改es002节点的/opt/es-cluster/config/elasticsearch.yml 文件<br> <pre><code class="language-html"># 加入如下配置<br>#集群名称<br>cluster.name: cluster-es<br>#节点名称， 每个节点的名称不能重复<br>node.name: node-2<br>#ip 地址， 每个节点的地址不能重复<br>network.host: 192.168.56.21<br>#是不是有资格主节点<br>node.master: true<br>node.data: true<br>http.port: 9200</p>
<h1 id="head-插件需要这打开这两个配置-1"><a href="#head-插件需要这打开这两个配置-1" class="headerlink" title="head 插件需要这打开这两个配置"></a>head 插件需要这打开这两个配置</h1><p>http.cors.allow-origin: “*”<br>http.cors.enabled: true<br>http.max_content_length: 200mb<br>#es7.x 之后新增的配置，初始化一个新的集群时需要此配置来选举 master<br>cluster.initial_master_nodes: [“node-1”]<br>#es7.x 之后新增的配置，节点发现<br>discovery.seed_hosts: [“192.168.56.20:9300”, “192.168.56.21:9300”, “192.168.56.22:300”]<br>gateway.recover_after_nodes: 2<br>network.tcp.keep_alive: true<br>network.tcp.no_delay: true<br>transport.tcp.compress: true<br>#集群内同时启动的数据任务个数，默认是 2 个<br>cluster.routing.allocation.cluster_concurrent_rebalance: 16<br>#添加或删除节点及负载均衡时并发恢复的线程个数，默认 4 个<br>cluster.routing.allocation.node_concurrent_recoveries: 16<br>#初始化数据恢复时，并发恢复线程的个数，默认 4 个<br>cluster.routing.allocation.node_initial_primaries_recoveries: 16<br></code></pre><br>  修改es003节点的/opt/es-cluster/config/elasticsearch.yml 文件<br> <pre><code class="language-html"># 加入如下配置<br>#集群名称<br>cluster.name: cluster-es<br>#节点名称， 每个节点的名称不能重复<br>node.name: node-3<br>#ip 地址， 每个节点的地址不能重复<br>network.host: 192.168.56.22<br>#是不是有资格主节点<br>node.master: true<br>node.data: true<br>http.port: 9200</p>
<h1 id="head-插件需要这打开这两个配置-2"><a href="#head-插件需要这打开这两个配置-2" class="headerlink" title="head 插件需要这打开这两个配置"></a>head 插件需要这打开这两个配置</h1><p>http.cors.allow-origin: “*”<br>http.cors.enabled: true<br>http.max_content_length: 200mb<br>#es7.x 之后新增的配置，初始化一个新的集群时需要此配置来选举 master<br>cluster.initial_master_nodes: [“node-1”]<br>#es7.x 之后新增的配置，节点发现<br>discovery.seed_hosts: [“192.168.56.20:9300”, “192.168.56.21:9300”, “192.168.56.22:300”]<br>gateway.recover_after_nodes: 2<br>network.tcp.keep_alive: true<br>network.tcp.no_delay: true<br>transport.tcp.compress: true<br>#集群内同时启动的数据任务个数，默认是 2 个<br>cluster.routing.allocation.cluster_concurrent_rebalance: 16<br>#添加或删除节点及负载均衡时并发恢复的线程个数，默认 4 个<br>cluster.routing.allocation.node_concurrent_recoveries: 16<br>#初始化数据恢复时，并发恢复线程的个数，默认 4 个<br>cluster.routing.allocation.node_initial_primaries_recoveries: 16<br></code></pre> </p>
<h3 id="6、修改-etc-security-limits-conf-，分发文件"><a href="#6、修改-etc-security-limits-conf-，分发文件" class="headerlink" title="6、修改/etc/security/limits.conf ，分发文件"></a>6、修改/etc/security/limits.conf ，分发文件</h3><blockquote>
 <pre><code class="language-bash"># 在文件末尾中增加下面内容
es soft nofile 65536
es hard nofile 65536
</code></pre> 
</blockquote>
<h3 id="7、修改-etc-security-limits-d-20-nproc-conf，分发文件"><a href="#7、修改-etc-security-limits-d-20-nproc-conf，分发文件" class="headerlink" title="7、修改/etc/security/limits.d/20-nproc.conf，分发文件"></a>7、修改/etc/security/limits.d/20-nproc.conf，分发文件</h3><blockquote>
</blockquote>
<h1 id="在文件末尾中增加下面内容-es-soft-nofile-65536-es-hard-nofile-65536-hard-nproc-4096-注：-带表-Linux-所有用户名称"><a href="#在文件末尾中增加下面内容-es-soft-nofile-65536-es-hard-nofile-65536-hard-nproc-4096-注：-带表-Linux-所有用户名称" class="headerlink" title="在文件末尾中增加下面内容 es soft nofile 65536 es hard nofile 65536 * hard nproc 4096 # 注： * 带表 Linux 所有用户名称"></a>在文件末尾中增加下面内容 es soft nofile 65536 es hard nofile 65536 * hard nproc 4096 # 注： * 带表 Linux 所有用户名称</h1><h3 id="8、修改-etc-sysctl-conf"><a href="#8、修改-etc-sysctl-conf" class="headerlink" title="8、修改/etc/sysctl.conf"></a>8、修改/etc/sysctl.conf</h3><blockquote>
</blockquote>
<h1 id="在文件中增加下面内容-vm-max-map-count-655360"><a href="#在文件中增加下面内容-vm-max-map-count-655360" class="headerlink" title="在文件中增加下面内容 vm.max_map_count=655360"></a>在文件中增加下面内容 vm.max_map_count=655360</h1><h3 id="9、重新加载"><a href="#9、重新加载" class="headerlink" title="9、重新加载"></a>9、重新加载</h3><blockquote>
<p> sysctl -p </p>
</blockquote>
<h3 id="10、启动软件"><a href="#10、启动软件" class="headerlink" title="10、启动软件"></a>10、启动软件</h3><blockquote>
<p> 分别在不同节点上启动 ES 软件<br> cd /opt/es-cluster #启动 bin/elasticsearch #后台启动 bin/elasticsearch -d </p>
</blockquote>
<h3 id="11、测试集群"><a href="#11、测试集群" class="headerlink" title="11、测试集群"></a>11、测试集群</h3><blockquote>
 <img alt="" height="177" src="https://img-blog.csdnimg.cn/20210624215121174.png" width="636"> 
 <img alt="" height="562" src="https://img-blog.csdnimg.cn/2021062421520751.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="896"> 
 <img alt="" height="579" src="https://img-blog.csdnimg.cn/2021062421522272.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="721"> 
 <img alt="" height="538" src="https://img-blog.csdnimg.cn/20210624215235887.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="740"> 
</blockquote>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>Elasticsearch之analysis</title>
    <url>/2021/07/18/Elasticsearch%E4%B9%8Banalysis/</url>
    <content><![CDATA[<p>title: Elasticsearch之analysis<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、简介</p>
<blockquote>
<p> analysis(只是一个概念)，文本分析是将全文本转换为一系列单词的过程，也叫分词。analysis是通 过analyzer(分词器)来实现的，可以使用Elasticsearch内置的分词器，也可以自己去定制一些分词 器。 除了在数据写入的时候进行分词处理，那么在查询的时候也可以使用分析器对查询语句进行分词。<br> anaylzer是由三部分组成，例如有：Hello a World, the world is beautiful </p>
</blockquote>
<ol>
<li>Character Filter: 将文本中html标签剔除掉。 </li>
<li>Tokenizer: 按照规则进行分词，在英文中按照空格分词。 </li>
<li>Token Filter: 去掉stop world(停顿词，a, an, the, is, are等)，然后转换小写 <img alt="" height="201" src="https://img-blog.csdnimg.cn/20210701230820389.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="739"> </li>
</ol>
<h3 id="2、内置分词器"><a href="#2、内置分词器" class="headerlink" title="2、内置分词器"></a>2、内置分词器</h3><blockquote>
 <img alt="" height="296" src="https://img-blog.csdnimg.cn/20210701230857488.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="740"> 
 内置分词器示例： 
 <img alt="" height="545" src="https://img-blog.csdnimg.cn/20210701231016915.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="779"> 
 <img alt="" height="557" src="https://img-blog.csdnimg.cn/20210701231031310.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="796"> 
</blockquote>
<h3 id="3、ik分词器"><a href="#3、ik分词器" class="headerlink" title="3、ik分词器"></a>3、ik分词器</h3><blockquote>
<p> IK分词器在任何操作系统下安装步骤均⼀样: 在ES的家⽬录下的 plugins ⽬录下创建名为 ik 的 ⽂件夹，然后将下载后的 zip 包拷⻉到 ik 解压即可<br> IK分词器提供了两种分词⽅式：<br> <img alt="" height="271" src="https://img-blog.csdnimg.cn/20210704114331635.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="991"><br> 验证：<br> <img alt="" height="280" src="https://img-blog.csdnimg.cn/20210704114423155.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1007"><br> <img alt="" height="76" src="https://img-blog.csdnimg.cn/20210704114551497.png" width="483"><img alt="" height="205" src="https://img-blog.csdnimg.cn/20210704114605160.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="992"> </p>
</blockquote>
<h3 id="4、⾃定义词库"><a href="#4、⾃定义词库" class="headerlink" title="4、⾃定义词库"></a>4、⾃定义词库</h3><blockquote>
<p> 在很多的时候，业务上的⼀些词库极有可能不在IK分词器的词库中，需要去定制属于我们⾃⼰的词 库。例如下⾯的例⼦中， 正井猫 、 up主 被切分为⼀个个的字，我们希望这两个词语是不被拆 分；另外 的 作为中⽂的停顿词，也不希望出现在分词中，所以我们需要⾃定义词库和停顿词词 库。<br> <img alt="" height="166" src="https://img-blog.csdnimg.cn/20210704115725621.png" width="988"><img alt="" height="798" src="https://img-blog.csdnimg.cn/20210704115746521.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"><br> 进⼊到 $ES_HOME/plugins/ik/config ⽬录下，创建 custom ⽬录，在⽬录下创建 mydic.dic 、 ext_stopword.dic ⽂件，<br> 在 mydic.dic ⽂件中添加两⾏内容：<br> <img alt="" height="101" src="https://img-blog.csdnimg.cn/20210704121115600.png" width="620"> 在 ext_stopword.dic 中添加⼀⾏内容:<br> <img alt="" height="61" src="https://img-blog.csdnimg.cn/20210704121136941.png" width="485"><br> 最后修改 $ES_HOME/plugins/ik/config/IKAnalyzer.cfg.xml ⽂件，内容如下：<br> <img alt="" height="501" src="https://img-blog.csdnimg.cn/2021070412115725.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1102"><br> 重启重启elasticsearch elasticsearch ， 重新执⾏如上的命令，结果如下：<br> <img alt="" height="579" src="https://img-blog.csdnimg.cn/20210704121221247.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> </p>
</blockquote>
<h3 id="5、IK分词器在工作中的实际案例"><a href="#5、IK分词器在工作中的实际案例" class="headerlink" title="5、IK分词器在工作中的实际案例"></a>5、IK分词器在工作中的实际案例</h3><blockquote>
<p> 5.1、首先创建new索引的mapping<br> <pre><code class="language-javascript">PUT news<br>&#123;<br>  "mappings": &#123;<br>    "properties": &#123;<br>      "title":&#123;<br>        "type": "text",<br>        "analyzer": "ik_max_word",<br>        "search_analyzer": "ik_smart"<br>      &#125;,<br>      "content":&#123;<br>        "type": "text",<br>        "analyzer": "ik_max_word",<br>        "search_analyzer": "ik_smart"<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;</code></pre><br> 注意：analyzer和search_analyzer的区别如下：<br>       analyzer：表示数据在进入news这个索引中的时候，我们尽量让它多的对我们数据进行分词，后面才能够达到精准的匹配。<br>       search_analyzer：对我们的数据进行搜索的时候不要进行过多的分词处理，提高效率。<br> 5.2、查看创建的索引结构<br>      GET news/_mapping<br>      <img alt="" height="402" src="https://img-blog.csdnimg.cn/20210704123038178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="520"><br> 5.3、创建数据进入索引<br> <img alt="" height="438" src="https://img-blog.csdnimg.cn/20210704123835184.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="854"><br> 5.4、通过语句查询<br> <img alt="" height="234" src="https://img-blog.csdnimg.cn/20210704124000129.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="659"><br> <img alt="" height="758" src="https://img-blog.csdnimg.cn/20210704124016440.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1157"><br> 下面我们再新增两条数据测试<br> <img alt="" height="212" src="https://img-blog.csdnimg.cn/2021070412571235.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="638"><br> 查询一下柳岩：<br> <img alt="" height="181" src="https://img-blog.csdnimg.cn/20210704125756473.png" width="660"><br> <img alt="" height="766" src="https://img-blog.csdnimg.cn/20210704125822468.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1160"><br> 可以发现我们其实仅仅只是查询柳岩，但是两条数据都查询出来了，那么我们首先配置一下mydic.dic扩展词典：<br> <img alt="" height="212" src="https://img-blog.csdnimg.cn/20210704130118770.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="422"><br> 重新启动elasticsearch:<br> 因为我们之前的数据已经分过词了，所以我们需要重新分词相关数据：<br> 先重新索引柳岩：<br> <pre><code class="language-html">POST news/_update_by_query<br>&#123;<br>  "query": &#123;<br>    "bool": &#123;<br>      "should": [<br>        &#123;<br>          "bool": &#123;<br>            "must": [<br>              &#123;<br>                "term": &#123;<br>                  "title": &#123;<br>                    "value": "柳"<br>                  &#125;<br>                &#125;<br>              &#125;,&#123;<br>                "term": &#123;<br>                  "title": &#123;<br>                    "value": "岩"<br>                  &#125;<br>                &#125;<br>              &#125;<br>            ]<br>          &#125;<br>        &#125;,&#123;<br>          "bool": &#123;<br>            "must": [<br>              &#123;<br>                "term": &#123;<br>                  "content": &#123;<br>                    "value": "柳"<br>                  &#125;<br>                &#125;<br>              &#125;,&#123;<br>                "term": &#123;<br>                  "content": &#123;<br>                    "value": "岩"<br>                  &#125;<br>                &#125;<br>              &#125;<br>            ]<br>          &#125;<br>        &#125;<br>      ]<br>    &#125;<br>  &#125;<br>&#125;</code></pre><br> 先重新索引柳真：<br> <pre><code class="language-html">POST news/_update_by_query<br>&#123;<br>  "query": &#123;<br>    "bool": &#123;<br>      "should": [<br>        &#123;<br>          "bool": &#123;<br>            "must": [<br>              &#123;<br>                "term": &#123;<br>                  "title": &#123;<br>                    "value": "柳"<br>                  &#125;<br>                &#125;<br>              &#125;,&#123;<br>                "term": &#123;<br>                  "title": &#123;<br>                    "value": "真"<br>                  &#125;<br>                &#125;<br>              &#125;<br>            ]<br>          &#125;<br>        &#125;,&#123;<br>          "bool": &#123;<br>            "must": [<br>              &#123;<br>                "term": &#123;<br>                  "content": &#123;<br>                    "value": "柳"<br>                  &#125;<br>                &#125;<br>              &#125;,&#123;<br>                "term": &#123;<br>                  "content": &#123;<br>                    "value": "真"<br>                  &#125;<br>                &#125;<br>              &#125;<br>            ]<br>          &#125;<br>        &#125;<br>      ]<br>    &#125;<br>  &#125;<br>&#125;</code></pre><br> 再次查询：<br> <img alt="" height="200" src="https://img-blog.csdnimg.cn/20210704134645260.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="579"><br> <img alt="" height="625" src="https://img-blog.csdnimg.cn/20210704134700972.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1179"> </p>
</blockquote>
<h3 id="6、pinyin分词器的安装"><a href="#6、pinyin分词器的安装" class="headerlink" title="6、pinyin分词器的安装"></a>6、pinyin分词器的安装</h3><blockquote>
<p> pinyin 分词器在任何操作系统下安装步骤均⼀样: 在ES的家⽬录下的 plugins ⽬录下创建名为 pinyin 的⽂件夹，然后将下载后的 zip 包拷⻉到 pinyin 解压即可<br> <img alt="" height="219" src="https://img-blog.csdnimg.cn/202107041449420.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="827"><br> 重启es<br> 测试pingyin插件<br> <img alt="" height="154" src="https://img-blog.csdnimg.cn/20210704145316140.png" width="653"><br> 效果：<br> <img alt="" height="539" src="https://img-blog.csdnimg.cn/2021070414533563.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="484"> </p>
</blockquote>
<h3 id="6、Elasticsearch之⾃定义分词器以及应⽤"><a href="#6、Elasticsearch之⾃定义分词器以及应⽤" class="headerlink" title="6、Elasticsearch之⾃定义分词器以及应⽤"></a>6、Elasticsearch之⾃定义分词器以及应⽤</h3><blockquote>
<p> 6.1、案例需求：<br> <img alt="" height="58" src="https://img-blog.csdnimg.cn/20210704154206109.png" width="796"><img alt="" height="783" src="https://img-blog.csdnimg.cn/20210704154226316.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="463"><br> 6.2、设置分词器<br> <img alt="" height="621" src="https://img-blog.csdnimg.cn/20210704154308863.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="699"><br> 6.3、验证分词器效果<br> <img alt="" height="135" src="https://img-blog.csdnimg.cn/20210704154525604.png" width="800"><br> <img alt="" height="588" src="https://img-blog.csdnimg.cn/20210704154546577.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="982"><br> 6.4、为属性添加分词器<br> <img alt="" height="373" src="https://img-blog.csdnimg.cn/20210704154634587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="996"><br> 6.5、结果验证<br>    执⾏如下命令添加数据<br>    <img alt="" height="234" src="https://img-blog.csdnimg.cn/20210704154704254.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="452">    <img alt="" height="728" src="https://img-blog.csdnimg.cn/20210704154744408.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"><br> <img alt="" height="462" src="https://img-blog.csdnimg.cn/20210704154800679.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"><br> <img alt="" height="566" src="https://img-blog.csdnimg.cn/20210704154826224.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> </p>
</blockquote>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>Elasticsearch之新闻案例实战</title>
    <url>/2021/07/18/Elasticsearch%E4%B9%8B%E6%96%B0%E9%97%BB%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<p>title: Elasticsearch之新闻案例实战<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、创建数据库表且预置数据</p>
<blockquote>
<p> 1.1、表结构如下<br> <pre><code class="language-sql">DROP TABLE IF EXISTS <code>news</code>;<br>CREATE TABLE <code>news</code> (<br>    <code>id</code> int(11) NOT NULL AUTO_INCREMENT,<br>    <code>title</code> varchar(255) NOT NULL comment '主题',<br>    <code>url</code> varchar(255) DEFAULT NULL comment '连接',<br>    <code>content</code> text comment '内容',<br>    <code>tags</code> varchar(1000) DEFAULT NULL comment '搜索的关键字',<br>    PRIMARY KEY (<code>id</code>) USING BTREE<br>) ENGINE=InnoDB AUTO_INCREMENT=92 DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC;</code></pre><br> 1.2、数据如下<br> <img alt="" height="629" src="https://img-blog.csdnimg.cn/20210704215709241.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> </p>
</blockquote>
<h3 id="2、定义分词器以及属性类型"><a href="#2、定义分词器以及属性类型" class="headerlink" title="2、定义分词器以及属性类型"></a>2、定义分词器以及属性类型</h3><blockquote>
 <pre><code class="language-javascript">PUT news
&#123;
  "settings": &#123;
    "analysis": &#123;
      "analyzer": &#123;
        "news_tags_analyzer": &#123;
          "char_filter": ["html_strip"],
          "tokenizer": "keyword",
          "filter": "news_tags_filter"
        &#125;
      &#125;,
      "filter": &#123;
        "news_tags_filter": &#123;
          "type": "pinyin",
          "keep_full_pinyin": true,
          "keep_joined_full_pinyin": true,
          "keep_original": true
        &#125;
      &#125;
    &#125;
  &#125;,
  "mappings": &#123;
    "properties": &#123;
      "id": &#123;
        "type": "long"
      &#125;,
      "title": &#123;
        "type": "text",
        "analyzer": "ik_max_word",
        "search_analyzer": "ik_smart"
      &#125;,
      "content": &#123;
        "type": "text",
        "analyzer": "ik_max_word",
        "search_analyzer": "ik_smart"
      &#125;,
      "url": &#123;
        "type": "keyword"
      &#125;,
      "tags": &#123;
        "type": "completion",
        "analyzer": "news_tags_analyzer",
        "search_analyzer": "keyword"
      &#125;
    &#125;
  &#125;
&#125;</code></pre> 
<p>  <img alt="" height="590" src="https://img-blog.csdnimg.cn/20210704221658848.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1185"> </p>
</blockquote>
<h3 id="3、将mysql数据导入es"><a href="#3、将mysql数据导入es" class="headerlink" title="3、将mysql数据导入es"></a>3、将mysql数据导入es</h3><blockquote>
<p> 2.1、创建logstash-mysql-news.conf文件<br> <pre><code class="language-html">#input表示将数据读取到logstash中<br>input &#123;<br>  jdbc &#123;<br>    jdbc_driver_library =&gt; "/opt/es781/mysql/mysql-connector-java-5.1.49.jar"<br>    jdbc_driver_class =&gt; "com.mysql.jdbc.Driver"<br>    jdbc_connection_string =&gt; "jdbc:mysql://192.168.1.13:3306/oss?userUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimeZone=UTC"<br>    jdbc_user =&gt; "root"<br>    jdbc_password =&gt; "897570"<br>    #表示是否分页<br>    jdbc_paging_enabled =&gt; "true"<br>    #表示每页的数量<br>    jdbc_page_size =&gt; "20"<br>    #查询语句<br>    statement =&gt; "SELECT * FROM news where tags is not null"<br>  &#125;<br>&#125;<br>#这个filter表示对数据进行过滤<br>filter &#123;<br>  mutate &#123;<br>    #根据逗号切割关键字<br>    split =&gt; &#123; "tags" =&gt; ","&#125;<br>  &#125;<br>  #将下面两个字段过滤掉，logstash会自动帮我们加这两个属性，我们不需要，直接去掉<br>  mutate &#123;<br>    remove_field =&gt; ["@timestamp","@version"]<br>  &#125;<br>&#125;<br>#将logstash中的数据输出到es中<br>output &#123;<br>  elasticsearch &#123;<br>    document_id =&gt; "%&#123;id&#125;"<br>    document_type =&gt; "_doc"<br>    index =&gt; "news"<br>    hosts =&gt; ["<a href="http://192.168.56.20:9200&quot;]">http://192.168.56.20:9200&quot;]</a><br>  &#125;<br>  stdout&#123;<br>    codec =&gt; rubydebug<br>  &#125;<br>&#125;<br></code></pre><br> 2.2、将上面需要的mysql jar包上传到Linux服务器上<br> <img alt="" height="223" src="https://img-blog.csdnimg.cn/20210704220031533.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="804"><br> 2.3、将logstash-mysql-news.conf文件上传到/opt/es781/logstash-7.8.1/目录下<br> <img alt="" height="589" src="https://img-blog.csdnimg.cn/20210704220333418.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="776"><br> 2.4、在/opt/es781/logstash-7.8.1/目录下执行下面的命令将数据从mysql中导入es,<br>      命令：bin/logstash -f /opt/es781/logstash-7.8.1/logstash-mysql-news.conf      <img alt="" height="903" src="https://img-blog.csdnimg.cn/20210704220730172.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1089"><br> 2.5、在kibana上查询news索引是否成功导入数据<br> <img alt="" height="936" src="https://img-blog.csdnimg.cn/20210704220858401.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> </p>
</blockquote>
<h3 id="4、根据需求编写kibana脚本"><a href="#4、根据需求编写kibana脚本" class="headerlink" title="4、根据需求编写kibana脚本"></a>4、根据需求编写kibana脚本</h3><blockquote>
<p> 4.1、自动补全语句<br> <pre><code class="language-javascript">GET news/_search<br>&#123;<br>  "_source": false,<br>  "suggest": &#123;<br>    "news_tags_suggest": &#123;<br>      "prefix": "zh",<br>      "completion":&#123;<br>        "field":"tags",<br>        "size": 10,<br>        "skip_duplicates": true<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;</code></pre><br> <img alt="" height="464" src="https://img-blog.csdnimg.cn/20210704222803907.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"><br> 4.2、内容搜索<br> <pre><code class="language-javascript">GET news/_search<br>&#123;<br>  "_source": false,<br>  "query": &#123;<br>    "multi_match": &#123;<br>      "query": "中国",<br>      "fields": ["title","content"]<br>    &#125;<br>  &#125;,<br>  "highlight": &#123;<br>    "pre_tags": "&lt;span class='highLight'&gt;",<br>    "post_tags": "&lt;/span&gt;",<br>    "fields": &#123;<br>      "title": &#123;&#125;,<br>      "content": &#123;&#125;<br>    &#125;<br>  &#125;<br>&#125;</code></pre><br> <img alt="" height="766" src="https://img-blog.csdnimg.cn/20210704222727872.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> </p>
</blockquote>
<h3 id="5、在java中使用代码实现上面两个搜索"><a href="#5、在java中使用代码实现上面两个搜索" class="headerlink" title="5、在java中使用代码实现上面两个搜索"></a>5、在java中使用代码实现上面两个搜索</h3><blockquote>
<p> 5.1、创建news实体类<br> <pre><code class="language-java">package com.kgf.es.model;</p>
</blockquote>
<p>import lombok.AllArgsConstructor;<br>import lombok.Data;<br>import lombok.NoArgsConstructor;</p>
<p>@Data<br>@AllArgsConstructor<br>@NoArgsConstructor<br>public class News &#123;<br>    private Integer id;<br>    private String title;<br>    private String content;<br>    private String url;<br>&#125;<br></code></pre><br> 5.2、创建NewsController<br> <pre><code class="language-java">package com.kgf.es.controller;</p>
<p>import com.alibaba.fastjson.JSONArray;<br>import com.alibaba.fastjson.JSONObject;<br>import com.kgf.es.model.News;<br>import org.apache.http.util.EntityUtils;<br>import org.elasticsearch.client.Request;<br>import org.elasticsearch.client.Response;<br>import org.elasticsearch.client.RestHighLevelClient;<br>import org.springframework.web.bind.annotation.GetMapping;<br>import org.springframework.web.bind.annotation.RequestMapping;<br>import org.springframework.web.bind.annotation.RestController;</p>
<p>import javax.annotation.Resource;<br>import java.io.IOException;<br>import java.util.ArrayList;<br>import java.util.List;</p>
<p>@RestController<br>@RequestMapping(“/news”)<br>public class NewsController &#123;</p>
<pre><code>@Resource
private RestHighLevelClient restHighLevelClient;


@GetMapping(&quot;/tips&quot;)
public Object autoComplete(String term) throws IOException &#123;
    Request request = new Request(&quot;GET&quot;, &quot;news/_search&quot;);

    request.setJsonEntity(String.format(&quot;&#123;&quot; +
            &quot;  \&quot;_source\&quot;: false, &quot; +
            &quot;  \&quot;suggest\&quot;: &#123;&quot; +
            &quot;    \&quot;news_tags_suggest\&quot;: &#123;&quot; +
            &quot;      \&quot;prefix\&quot;: \&quot;%s\&quot;,&quot; +
            &quot;      \&quot;completion\&quot;: &#123;&quot; +
            &quot;        \&quot;field\&quot;: \&quot;tags\&quot;,&quot; +
            &quot;        \&quot;size\&quot;: 10,&quot; +
            &quot;        \&quot;skip_duplicates\&quot;: true&quot; +
            &quot;      &#125;&quot; +
            &quot;    &#125;&quot; +
            &quot;  &#125;&quot; +
            &quot;&#125;&quot;, term));

    Response response = restHighLevelClient.getLowLevelClient().performRequest(request);

    String jsonString = EntityUtils.toString(response.getEntity()); // &quot;&#123;\&quot;age\&quot;: 10&#125;&quot;  &#123;&quot;age&quot;: 10&#125;

    JSONObject jsonObject = JSONObject.parseObject(jsonString);

    JSONArray suggests = jsonObject.getJSONObject(&quot;suggest&quot;).getJSONArray(&quot;news_tags_suggest&quot;);

    JSONArray options = suggests.getJSONObject(0).getJSONArray(&quot;options&quot;);

    List&amp;lt;String&amp;gt; results = new ArrayList&amp;lt;&amp;gt;();
    for(int i = 0; i &amp;lt; options.size(); i++) &#123;
        JSONObject opt = options.getJSONObject(i);
        results.add(opt.getString(&quot;text&quot;));
    &#125;

    return results;
&#125;

@GetMapping(&quot;/search&quot;)
public List&amp;lt;News&amp;gt; query(String text) throws Exception&#123;
    /**
     * 1.对于高亮的数据，ES是抽取的一个个片段，然后将这些片段设置到一个数组中。
     * 2.对于有些数据，可能title或者content中没有高亮的字眼，那么我们就需要取原始数据的 title 和 content.
     */
    Request request = new Request(&quot;GET&quot;, &quot;news/_search&quot;);
    request.setJsonEntity(String.format(&quot;&#123;&quot; +
            &quot;  \&quot;_source\&quot;: [\&quot;url\&quot;, \&quot;title\&quot;, \&quot;content\&quot;], &quot; +
            &quot;  \&quot;query\&quot;: &#123;&quot; +
            &quot;    \&quot;multi_match\&quot;: &#123;&quot; +
            &quot;      \&quot;query\&quot;: \&quot;%s\&quot;,&quot; +
            &quot;      \&quot;fields\&quot;: [\&quot;title\&quot;, \&quot;content\&quot;]&quot; +
            &quot;    &#125;&quot; +
            &quot;  &#125;,&quot; +
            &quot;  \&quot;highlight\&quot;: &#123;&quot; +
            &quot;    \&quot;pre_tags\&quot;: \&quot;&amp;lt;span class=&#39;highLight&#39;&amp;gt;\&quot;, &quot; +
            &quot;    \&quot;post_tags\&quot;: \&quot;&amp;lt;/span&amp;gt;\&quot;, &quot; +
            &quot;    \&quot;fields\&quot;: &#123;&quot; +
            &quot;      \&quot;title\&quot;: &#123;&#125;,&quot; +
            &quot;      \&quot;content\&quot;: &#123;&#125;&quot; +
            &quot;    &#125;&quot; +
            &quot;  &#125;&quot; +
            &quot;&#125;&quot;, text));

    Response response = restHighLevelClient.getLowLevelClient().performRequest(request);

    JSONObject jsonObject = JSONObject.parseObject(EntityUtils.toString(response.getEntity()));

    JSONArray hits = jsonObject.getJSONObject(&quot;hits&quot;).getJSONArray(&quot;hits&quot;);

    List&amp;lt;News&amp;gt; results = new ArrayList&amp;lt;&amp;gt;();

    for (int i = 0; i &amp;lt; hits.size(); i++) &#123;
        News news = new News();
        JSONObject hit = hits.getJSONObject(i);
        JSONObject highLight = hit.getJSONObject(&quot;highlight&quot;);  //获取高亮的数据结果

        JSONObject _source = hit.getJSONObject(&quot;_source&quot;); //这个是原始的数据
        news.setUrl(_source.getString(&quot;url&quot;));  //设置url

        JSONArray highLightTitle = highLight.getJSONArray(&quot;title&quot;);  //获取高亮的 title 数组
        JSONArray highLightContent = highLight.getJSONArray(&quot;content&quot;);

        if(null != highLightTitle) &#123;
            StringBuffer highLightTitleStringBuffer = new StringBuffer();
            for (int j = 0; j &amp;lt; highLightTitle.size(); j++) &#123;
                String titleSegment = highLightTitle.getString(j);
                highLightTitleStringBuffer.append(titleSegment);
            &#125;
            news.setTitle(highLightTitleStringBuffer.toString());
        &#125;else &#123;  // 如果不存在高亮的数据，那么就取原始数据
            news.setTitle(_source.getString(&quot;title&quot;));
        &#125;

        if(null != highLightContent) &#123;
            StringBuffer highLightContentStringBuffer = new StringBuffer();
            for (int j = 0; j &amp;lt; highLightContent.size(); j++) &#123;
                String contentSegment = highLightContent.getString(j);
                highLightContentStringBuffer.append(contentSegment);
            &#125;
            news.setContent(highLightContentStringBuffer.toString());
        &#125;else &#123;  // 如果不存在高亮的数据，那么就取原始数据
            news.setContent(_source.getString(&quot;content&quot;));
        &#125;

        results.add(news);
    &#125;
    return results;
&#125;
</code></pre>
<p>}<br></code></pre> </p>
<h3 id="6、测试"><a href="#6、测试" class="headerlink" title="6、测试"></a>6、测试</h3><blockquote>
<p> 6.1、测试tips,完成对tags的关键字检索<br> <img alt="" height="726" src="https://img-blog.csdnimg.cn/20210704230043938.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="757"><br> 6.2、测试内容检索<br> <img alt="" height="918" src="https://img-blog.csdnimg.cn/20210704230215251.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> </p>
</blockquote>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>Elasticsearch之自动补全案例实战</title>
    <url>/2021/07/18/Elasticsearch%E4%B9%8B%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<p>title: Elasticsearch之自动补全案例实战<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、案例需求：</p>
<blockquote>
<p> 通过拼音以及汉字筛选对应的明星！ </p>
</blockquote>
<h3 id="2、设置分词器以及mapping"><a href="#2、设置分词器以及mapping" class="headerlink" title="2、设置分词器以及mapping"></a>2、设置分词器以及mapping</h3><blockquote>
 <pre><code class="language-javascript">PUT starts
&#123;
  "settings": &#123;
    "analysis": &#123;
      "analyzer": &#123;
        "start_name_analyzer":&#123;
          "char_filter":["html_strip"],
          "tokenizer":"keyword",
          "filter":"start_name_filter"
        &#125;
      &#125;,
      "filter": &#123;
        "start_name_filter":&#123;
          "type":"pinyin",
          "keep_full_pinyin":false,
          "keep_joined_full_pinyin":true,
          "keep_original": true
        &#125;
      &#125;
    &#125;
  &#125;,
  "mappings": &#123;
    "properties": &#123;
      "name":&#123;
        "type": "completion",
        "analyzer": "start_name_analyzer",
        "search_analyzer": "keyword"
      &#125;
    &#125;
  &#125;
&#125;</code></pre> 
 <img alt="" height="808" src="https://img-blog.csdnimg.cn/20210704163948950.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 
</blockquote>
<h3 id="3、批量插入数据"><a href="#3、批量插入数据" class="headerlink" title="3、批量插入数据"></a>3、批量插入数据</h3><blockquote>
 <pre><code class="language-javascript">PUT starts/_bulk
&#123;"index":&#123;&#125;&#125;
&#123;"name":"张学友"&#125;
&#123;"index":&#123;&#125;&#125;
&#123;"name":"刘德华"&#125;
&#123;"index":&#123;&#125;&#125;
&#123;"name":"柳岩"&#125;
&#123;"index":&#123;&#125;&#125;
&#123;"name":"李易峰"&#125;
&#123;"index":&#123;&#125;&#125;
&#123;"name":"黄晓明"&#125;
&#123;"index":&#123;&#125;&#125;
&#123;"name":"刘青云"&#125;
&#123;"index":&#123;&#125;&#125;
&#123;"name":"易中天"&#125;
&#123;"index":&#123;&#125;&#125;
&#123;"name":"李小璐"&#125;
&#123;"index":&#123;&#125;&#125;
&#123;"name":"黄家驹"&#125;
&#123;"index":&#123;&#125;&#125;
&#123;"name":"李思思"&#125;
&#123;"index":&#123;&#125;&#125;
&#123;"name":"庄媛媛"&#125;
&#123;"index":&#123;&#125;&#125;
&#123;"name":"刘亦菲"&#125;</code></pre> 
 <img alt="" height="688" src="https://img-blog.csdnimg.cn/20210704164406424.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 
</blockquote>
<h3 id="4、在kibana上测试一下效果"><a href="#4、在kibana上测试一下效果" class="headerlink" title="4、在kibana上测试一下效果"></a>4、在kibana上测试一下效果</h3><blockquote>
 <pre><code class="language-java">GET starts/_search
&#123;
  "_source": false,
  "suggest": &#123;
    "start_name_suggest": &#123;
      "prefix":"柳",
      "completion":&#123;
        "field":"name",
        "size": 10,
        "skip_duplicates": true
      &#125;
    &#125;
  &#125;
&#125;</code></pre> 
 <img alt="" height="835" src="https://img-blog.csdnimg.cn/20210704164750795.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 
 <img alt="" height="949" src="https://img-blog.csdnimg.cn/20210704164822955.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 
 <img alt="" height="862" src="https://img-blog.csdnimg.cn/20210704164910346.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 
 <img alt="" height="970" src="https://img-blog.csdnimg.cn/2021070416502437.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 
</blockquote>
<h3 id="5、在java服务端实现上面测试的自动补全案例"><a href="#5、在java服务端实现上面测试的自动补全案例" class="headerlink" title="5、在java服务端实现上面测试的自动补全案例"></a>5、在java服务端实现上面测试的自动补全案例</h3><blockquote>
<p> 5.1、Springboot整合ES7.8.1已经提前整合了<br> 5.2、创建controller类<br> <pre><code class="language-java">package com.kgf.es.controller;</p>
</blockquote>
<p>import com.alibaba.fastjson.JSONArray;<br>import com.alibaba.fastjson.JSONObject;<br>import org.apache.http.util.EntityUtils;<br>import org.elasticsearch.client.Request;<br>import org.elasticsearch.client.Response;<br>import org.elasticsearch.client.RestHighLevelClient;<br>import org.springframework.web.bind.annotation.GetMapping;<br>import org.springframework.web.bind.annotation.RequestMapping;<br>import org.springframework.web.bind.annotation.RestController;</p>
<p>import javax.annotation.Resource;<br>import java.io.IOException;<br>import java.util.ArrayList;<br>import java.util.List;</p>
<p>@RequestMapping(“start”)<br>@RestController<br>public class StartController &#123;</p>
<pre><code>@Resource
private RestHighLevelClient restHighLevelClient;

@GetMapping(&quot;autoComplete&quot;)
public Object autoComplete(String term) throws IOException &#123;
    Request request = new Request(&quot;GET&quot;, &quot;starts/_search&quot;);
    request.setJsonEntity(String.format(&quot;&#123;&quot; +
            &quot;  \&quot;_source\&quot;: false,&quot; +
            &quot;  \&quot;suggest\&quot;: &#123;&quot; +
            &quot;    \&quot;start_name_suggest\&quot;: &#123;&quot; +
            &quot;      \&quot;prefix\&quot;:\&quot;%s\&quot;,&quot; +
            &quot;      \&quot;completion\&quot;:&#123;&quot; +
            &quot;        \&quot;field\&quot;:\&quot;name\&quot;,&quot; +
            &quot;        \&quot;size\&quot;: 10,&quot; +
            &quot;        \&quot;skip_duplicates\&quot;: true&quot; +
            &quot;      &#125;&quot; +
            &quot;    &#125;&quot; +
            &quot;  &#125;&quot; +
            &quot;&#125;&quot;,term));
    Response response = restHighLevelClient.getLowLevelClient().performRequest(request);
    String json = EntityUtils.toString(response.getEntity());
    JSONObject jsonObject = JSONObject.parseObject(json);
    JSONArray suggests = jsonObject.getJSONObject(&quot;suggest&quot;).getJSONArray(&quot;start_name_suggest&quot;);
    JSONArray options = suggests.getJSONObject(0).getJSONArray(&quot;options&quot;);
    List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();
    for (int i = 0; i &amp;lt; options.size(); i++) &#123;
        JSONObject object = options.getJSONObject(i);
        list.add(object.getString(&quot;text&quot;));
    &#125;
    return list;
&#125;
</code></pre>
<p>}<br></code></pre> </p>
<h3 id="6、访问测试效果"><a href="#6、访问测试效果" class="headerlink" title="6、访问测试效果"></a>6、访问测试效果</h3><blockquote>
 <img alt="" height="290" src="https://img-blog.csdnimg.cn/20210704181240367.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="807"> 
</blockquote>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>Elasticsearch优化</title>
    <url>/2021/07/18/Elasticsearch%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<p>title: Elasticsearch优化<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、硬件选择</p>
<blockquote>
<p> Elasticsearch 的基础是 Lucene，所有的索引和文档数据是存储在本地的磁盘中，具体的路径可在 ES 的配置文件…/config/elasticsearch.yml中配置，如下：<br> <pre><code class="language-XML">#</p>
</blockquote>
<h1 id="Path-to-directory-where-to-store-the-data-separate-multiple-locations-by-comma"><a href="#Path-to-directory-where-to-store-the-data-separate-multiple-locations-by-comma" class="headerlink" title="Path to directory where to store the data (separate multiple locations by comma):"></a>Path to directory where to store the data (separate multiple locations by comma):</h1><h1 id=""><a href="#" class="headerlink" title=""></a></h1><p>path.data: /path/to/data<br>#</p>
<h1 id="Path-to-log-files"><a href="#Path-to-log-files" class="headerlink" title="Path to log files:"></a>Path to log files:</h1><h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><p>path.logs: /path/to/logs<br></code></pre><br> 磁盘在现代服务器上通常都是瓶颈。Elasticsearch重度使用磁盘，你的磁盘能处理的吞吐量越大，你的节点就越稳定。这里有一些优化磁盘I/O的技巧： </p>
<ul>
<li>使用SSD就像其他地方提过的，他们比机械磁盘优秀多了。- 使用RAID0。条带化RAID会提高磁盘IO，代价显然就是当一块硬盘故障时整个就故障了。不要使用镜像或者奇偶校验RAID，因为副本已经提供了这个功能。- 另外，使用多块硬盘，并允许Elasticsearch 通过多个path data目录配置把数据条带化分配到它们上面。- 不要使用远程挂载的存储，比如NFS或者SMB/CIFS。这个引入的延迟对性能来说完全是背道而驰的。</li>
</ul>
<h3 id="2、分片策略"><a href="#2、分片策略" class="headerlink" title="2、分片策略"></a>2、分片策略</h3><blockquote>
 <h3>合理设置分片数</h3> 
 分片和副本的设计为 ES 提供了支持分布式和故障转移的特性，但并不意味着分片和副本是可以无限分配的。而且索引的分片完成分配后由于索引的路由机制，我们是不能重新修改分片数的。 
 可能有人会说，我不知道这个索引将来会变得多大，并且过后我也不能更改索引的大小，所以为了保险起见，还是给它设为 1000 个分片吧。但是需要知道的是，一个分片并不是没有代价的。需要了解： 
</blockquote>
<ul>
<li>一个分片的底层即为一个 Lucene 索引，会消耗一定文件句柄、内存、以及 CPU运转。- 每一个搜索请求都需要命中索引中的每一个分片，如果每一个分片都处于不同的节点还好， 但如果多个分片都需要在同一个节点上竞争使用相同的资源就有些糟糕了。- 用于计算相关度的词项统计信息是基于分片的。如果有许多分片，每一个都只有很少的数据会导致很低的相关度。<br>一个业务索引具体需要分配多少分片可能需要架构师和技术人员对业务的增长有个预先的判断，横向扩展应当分阶段进行。为下一阶段准备好足够的资源。 只有当你进入到下一个阶段，你才有时间思考需要作出哪些改变来达到这个阶段。一般来说，我们遵循一些原则： </li>
<li>控制每个分片占用的硬盘容量不超过 ES 的最大 JVM 的堆空间设置（一般设置不超过 32G，参考下文的 JVM 设置原则），因此，如果索引的总容量在 500G 左右，那分片大小在 16 个左右即可；当然，最好同时考虑原则 2。- 考虑一下 node 数量，一般一个节点有时候就是一台物理机，如果分片数过多，大大超过了节点数，很可能会导致一个节点上存在多个分片，一旦该节点故障，即使保持了 1 个以上的副本，同样有可能会导致数据丢失，集群无法恢复。所以， 一般都设置分片数不超过节点数的 3 倍。- 主分片，副本和节点最大数之间数量，我们分配的时候可以参考以下关系：- 节点数&lt;=主分片数 *（副本数+1）</li>
</ul>
<h3 id="3、推迟分片分配"><a href="#3、推迟分片分配" class="headerlink" title="3、推迟分片分配"></a>3、推迟分片分配</h3><blockquote>
<p> 对于节点瞬时中断的问题，默认情况，集群会等待一分钟来查看节点是否会重新加入，如果这个节点在此期间重新加入，重新加入的节点会保持其现有的分片数据，不会触发新的分片分配。这样就可以减少 ES 在自动再平衡可用分片时所带来的极大开销。<br> 通过修改参数 delayed_timeout ，可以延长再均衡的时间，可以全局设置也可以在索引级别进行修改：<br> <pre><code class="language-java">#PUT /_all/_settings<br>&#123;<br>    "settings": &#123;<br>        "index.unassigned.node_left.delayed_timeout": "5m"<br>    &#125;<br>&#125;<br></code></pre> </p>
</blockquote>
<h3 id="4、路由选择"><a href="#4、路由选择" class="headerlink" title="4、路由选择"></a>4、路由选择</h3><blockquote>
<p> 当我们查询文档的时候， Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？它其实是通过下面这个公式来计算出来：<br> <pre><code class="language-java">shard = hash(routing) % number_of_primary_shards<br></code></pre><br> routing 默认值是文档的 id，也可以采用自定义值，比如用户 id。<br> <h3>不带routing查询</h3><br> 在查询的时候因为不知道要查询的数据具体在哪个分片上，所以整个过程分为2个步骤 </p>
</blockquote>
<ul>
<li>分发：请求到达协调节点后，协调节点将查询请求分发到每个分片上。- 聚合：协调节点搜集到每个分片上查询结果，在将查询的结果进行排序，之后给用户返回结果。<h3>带routing查询</h3> 
查询的时候，可以直接根据routing 信息定位到某个分配查询，不需要查询所有的分配，经过协调节点排序。向上面自定义的用户查询，如果routing 设置为userid 的话，就可以直接查询出数据来，效率提升很多。 </li>
</ul>
<h3 id="带routing查询"><a href="#带routing查询" class="headerlink" title="带routing查询"></a>带routing查询</h3><h3 id="5、写入速度优化"><a href="#5、写入速度优化" class="headerlink" title="5、写入速度优化"></a>5、写入速度优化</h3><blockquote>
<p> ES 的默认配置，是综合了数据可靠性、写入速度、搜索实时性等因素。实际使用时，我们需要根据公司要求，进行偏向性的优化。<br> 针对于搜索性能要求不高，但是对写入要求较高的场景，我们需要尽可能的选择恰当写优化策略。综合来说，可以考虑以下几个方面来提升写索引的性能： </p>
</blockquote>
<ul>
<li>加大Translog Flush，目的是降低Iops、Writeblock。- 增加Index Refesh间隔，目的是减少Segment Merge的次数。- 调整Bulk 线程池和队列。- 优化节点间的任务分布。- 优化Lucene层的索引建立，目的是降低CPU及IO。<h3>优化存储设备</h3> 
ES 是一种密集使用磁盘的应用，在段合并的时候会频繁操作磁盘，所以对磁盘要求较高，当磁盘速度提升之后，集群的整体性能会大幅度提高。 
<h3>合理使用合并</h3> 
Lucene 以段的形式存储数据。当有新的数据写入索引时， Lucene 就会自动创建一个新的段。 
随着数据量的变化，段的数量会越来越多，消耗的多文件句柄数及 CPU 就越多，查询效率就会下降。 
由于 Lucene 段合并的计算量庞大，会消耗大量的 I/O，所以 ES 默认采用较保守的策略，让后台定期进行段合并。 
<h3>减少 Refresh 的次数</h3> 
Lucene 在新增数据时，采用了延迟写入的策略，默认情况下索引的refresh_interval 为1 秒。 
Lucene 将待写入的数据先写到内存中，超过 1 秒（默认）时就会触发一次 Refresh，然后 Refresh 会把内存中的的数据刷新到操作系统的文件缓存系统中。 
如果我们对搜索的实效性要求不高，可以将 Refresh 周期延长，例如 30 秒。 
这样还可以有效地减少段刷新次数，但这同时意味着需要消耗更多的 Heap 内存。 
<h3>加大 Flush 设置</h3> 
Flush 的主要目的是把文件缓存系统中的段持久化到硬盘，当 Translog 的数据量达到 512MB 或者 30 分钟时，会触发一次 Flush。 
index.translog.flush_threshold_size 参数的默认值是 512MB，我们进行修改。 
增加参数值意味着文件缓存系统中可能需要存储更多的数据，所以我们需要为操作系统的文件缓存系统留下足够的空间。 
<h3>减少副本的数量</h3> 
ES 为了保证集群的可用性，提供了 Replicas（副本）支持，然而每个副本也会执行分析、索引及可能的合并过程，所以 Replicas 的数量会严重影响写索引的效率。 
当写索引时，需要把写入的数据都同步到副本节点，副本节点越多，写索引的效率就越慢。 
如果我们需要大批量进行写入操作，可以先禁止Replica复制，设置 index.number_of_replicas: 0 关闭副本。在写入完成后， Replica 修改回正常的状态。 </li>
</ul>
<h3 id="合理使用合并"><a href="#合理使用合并" class="headerlink" title="合理使用合并"></a>合理使用合并</h3><h3 id="加大-Flush-设置"><a href="#加大-Flush-设置" class="headerlink" title="加大 Flush 设置"></a>加大 Flush 设置</h3><h3 id="6、内存设置"><a href="#6、内存设置" class="headerlink" title="6、内存设置"></a>6、内存设置</h3><blockquote>
<p> ES 默认安装后设置的内存是 1GB，对于任何一个现实业务来说，这个设置都太小了。如果是通过解压安装的 ES，则在 ES 安装文件中包含一个 jvm.option 文件，添加如下命令来设置 ES 的堆大小， Xms 表示堆的初始大小， Xmx 表示可分配的最大内存，都是 1GB。<br> 确保 Xmx 和 Xms 的大小是相同的，其目的是为了能够在 Java 垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源，可以减轻伸缩堆大小带来的压力。<br> 假设你有一个 64G 内存的机器，按照正常思维思考，你可能会认为把 64G 内存都给ES 比较好，但现实是这样吗， 越大越好？虽然内存对 ES 来说是非常重要的，但是答案是否定的！<br> 因为 ES 堆内存的分配需要满足以下两个原则： </p>
</blockquote>
<ul>
<li>不要超过物理内存的 50%： Lucene 的设计目的是把底层 OS 里的数据缓存到内存中。Lucene 的段是分别存储到单个文件中的，这些文件都是不会变化的，所以很利于缓存，同时操作系统也会把这些段文件缓存起来，以便更快的访问。如果我们设置的堆内存过大， Lucene 可用的内存将会减少，就会严重影响降低 Lucene 的全文本查询性能。- 堆内存的大小最好不要超过 32GB：在 Java 中，所有对象都分配在堆上，然后有一个 Klass Pointer 指针指向它的类元数据。这个指针在 64 位的操作系统上为 64 位， 64 位的操作系统可以使用更多的内存（2^64）。在 32 位的系统上为 32 位， 32 位的操作系统的最大寻址空间为 4GB（2^32）。但是 64 位的指针意味着更大的浪费，因为你的指针本身大了。浪费内存不算，更糟糕的是，更大的指针在主内存和缓存器（例如 LLC, L1 等）之间移动数据的时候，会占用更多的带宽。<br>最终我们都会采用 31 G 设置 </li>
<li>-Xms 31g- -Xmx 31g<br>假设你有个机器有 128 GB 的内存，你可以创建两个节点，每个节点内存分配不超过 32 GB。也就是说不超过 64 GB 内存给 ES 的堆内存，剩下的超过 64 GB 的内存给 Lucene。 </li>
</ul>
<h3 id="7、重要配置"><a href="#7、重要配置" class="headerlink" title="7、重要配置"></a>7、重要配置</h3><blockquote>
 <h3> <img alt="" height="732" src="https://img-blog.csdnimg.cn/20210626214501178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1196"></h3> 
</blockquote>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>Elasticsearch相关核心概念</title>
    <url>/2021/07/18/Elasticsearch%E7%9B%B8%E5%85%B3%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<p>title: Elasticsearch相关核心概念<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—<img alt="" src="https://img-blog.csdnimg.cn/img_convert/146a779da01f53e7f7a8d53132d3c7cf.png"></p>
<h3 id="1、索引Index"><a href="#1、索引Index" class="headerlink" title="1、索引Index"></a>1、索引Index</h3><blockquote>
<p>         一个索引就是一个拥有几分相似特征的文档的集合。比如说，你可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。一个索引由一个名字来标识（必须全部是小写字母），并且当我们要对这个索引中的文档进行索引、搜索、更新和删除（CRUD）的时候，都要使用到这个名字。在一个集群中，可以定义任意多的索引。<br>         能搜索的数据必须索引，这样的好处是可以提高查询速度，比如：新华字典前面的目录就是索引的意思，目录可以提高查询速度。<br>      <strong>Elasticsearch 索引的精髓：一切设计都是为了提高搜索的性能。</strong> </p>
</blockquote>
<h3 id="2、-类型Type"><a href="#2、-类型Type" class="headerlink" title="2、 类型Type"></a>2、 类型Type</h3><blockquote>
<p> 在一个索引中，你可以定义一种或多种类型。<br> 一个类型是你的索引的一个逻辑上的分类/分区，其语义完全由你来定。通常，会为具有一组共同字段的文档定义一个类型。不同的版本，类型发生了不同的变化。<br> <table><thead>|版本|Type</p>
</blockquote>
</thead><tbody>|5.x|支持多种 type
|6.x|只能有一种 type
|7.x|默认不再支持自定义索引类型（默认类型为： _doc）
</tbody></table>


<h3 id="3、文档Document"><a href="#3、文档Document" class="headerlink" title="3、文档Document"></a>3、文档Document</h3><blockquote>
<p> 一个文档是一个可被索引的基础信息单元，也就是一条数据。<br> 比如：你可以拥有某一个客户的文档，某一个产品的一个文档，当然，也可以拥有某个订单的一个文档。文档以 JSON（Javascript Object Notation）格式来表示，而 JSON 是一个到处存在的互联网数据交互格式。<br> 在一个 index/type 里面，你可以存储任意多的文档。 </p>
</blockquote>
<h3 id="4、字段Field"><a href="#4、字段Field" class="headerlink" title="4、字段Field"></a>4、字段Field</h3><blockquote>
<p> 相当于是数据表的字段，对文档数据根据不同属性进行的分类标识。 </p>
</blockquote>
<h3 id="5、映射Mapping"><a href="#5、映射Mapping" class="headerlink" title="5、映射Mapping"></a>5、映射Mapping</h3><blockquote>
<p> mapping 是处理数据的方式和规则方面做一些限制，如：某个字段的数据类型、默认值、分析器、是否被索引等等。这些都是映射里面可以设置的，其它就是处理 ES 里面数据的一些使用规则设置也叫做映射，按着最优规则处理数据对性能提高很大，因此才需要建立映射，并且需要思考如何建立映射才能对性能更好。 </p>
</blockquote>
<h3 id="6、分片Shards"><a href="#6、分片Shards" class="headerlink" title="6、分片Shards"></a>6、分片Shards</h3><blockquote>
<p> 一个索引可以存储超出单个节点硬件限制的大量数据。比如，一个具有 10 亿文档数据<br> 的索引占据 1TB 的磁盘空间，而任一节点都可能没有这样大的磁盘空间。 或者单个节点处理搜索请求，响应太慢。为了解决这个问题，<strong>Elasticsearch 提供了将索引划分成多份的能力，每一份就称之为分片。</strong>当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。<br> 分片很重要，主要有两方面的原因： </p>
</blockquote>
<ul>
<li>允许你水平分割 / 扩展你的内容容量。- 允许你在分片之上进行分布式的、并行的操作，进而提高性能/吞吐量。<br>至于一个分片怎样分布，它的文档怎样聚合和搜索请求，是完全由 Elasticsearch 管理的，对于作为用户的你来说，这些都是透明的，无需过分关心。<br>被混淆的概念是，一个 Lucene 索引 我们在 Elasticsearch 称作 分片 。 一个Elasticsearch 索引 是分片的集合。 当 Elasticsearch 在索引中搜索的时候， 他发送查询到每一个属于索引的分片（Lucene 索引），然后合并每个分片的结果到一个全局的结果集。<br>Lucene 是 Apache 软件基金会 Jakarta 项目组的一个子项目，提供了一个简单却强大的应用程式接口，能够做全文索引和搜寻。在 Java 开发环境里 Lucene 是一个成熟的免费开源工具。就其本身而言， Lucene 是当前以及最近几年最受欢迎的免费 Java 信息检索程序库。但 Lucene 只是一个提供全文搜索功能类库的核心工具包，而真正使用它还需要一个完善的服务框架搭建起来进行应用。<br>目前市面上流行的搜索引擎软件，主流的就两款： Elasticsearch 和 Solr,这两款都是基于 Lucene 搭建的，可以独立部署启动的搜索引擎服务软件。由于内核相同，所以两者除了服务器安装、部署、管理、集群以外，对于数据的操作 修改、添加、保存、查询等等都十分类似。 </li>
</ul>
<h3 id="7、副本Replicas"><a href="#7、副本Replicas" class="headerlink" title="7、副本Replicas"></a>7、副本Replicas</h3><blockquote>
<p> 在一个网络 / 云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于 离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的， Elasticsearch 允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片(副本)。<br> 复制分片之所以重要，有两个主要原因： </p>
</blockquote>
<ul>
<li>在分片/节点失败的情况下，<strong>提供了高可用性</strong>。因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。- 扩展你的搜索量/吞吐量，因为搜索可以在所有的副本上并行运行<br>总之，每个索引可以被分成多个分片。一个索引也可以被复制 0 次（意思是没有复制）或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。<br>分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后不能改变分片的数量。<br>默认情况下，Elasticsearch 中的每个索引被分片 1 个主分片和 1 个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有 1 个主分片和另外 1 个复制分片（1 个完全拷贝），这样的话每个索引总共就有 2 个分片， 我们需要根据索引需要确定分片个数。 </li>
</ul>
<h3 id="8、分配Allocation"><a href="#8、分配Allocation" class="headerlink" title="8、分配Allocation"></a>8、分配Allocation</h3><blockquote>
<p> 将分片分配给某个节点的过程，包括分配主分片或者副本。如果是副本，还包含从主分片复制数据的过程。这个过程是由 master 节点完成的。 </p>
</blockquote>
<h3 id="9、es的系统架构"><a href="#9、es的系统架构" class="headerlink" title="9、es的系统架构"></a>9、es的系统架构</h3><blockquote>
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/e4d13427545dc174eb9ccface85c1f0c.png"> 
 一个运行中的 Elasticsearch 实例称为一个节点，而集群是由一个或者多个拥有相同 cluster.name 配置的节点组成， 它们共同承担数据和负载的压力。当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。 
 当一个节点被选举成为主节点时， 它将负责管理集群范围内的所有变更，例如增加、 删除索引，或者增加、删除节点等。 而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。 任何节点都可以成为主节点。我们的示例集群就只有一个节点，所以它同时也成为了主节点。 
 作为用户，我们可以将请求发送到集群中的任何节点 ，包括主节点。 每个节点都知道 任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的节点。 无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的 
</blockquote>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>Elasticsearch相关问题</title>
    <url>/2021/07/18/Elasticsearch%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>title: Elasticsearch相关问题<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、为什么要使用 Elasticsearch？</p>
<blockquote>
<p> 系统中的数据， 随着业务的发展，时间的推移， 将会非常多， 而业务中往往采用模糊查询进行数据的搜索， 而模糊查询会导致查询引擎放弃索引，导致系统查询数据时都是全表扫描，在百万级别的数据库中，查询效率是非常低下的，而我们使用 ES 做一个全文索引，将经常查询的系统功能的某些字段，比如说电商系统的商品表中商品名，描述、价格还有 id 这些字段我们放入 ES 索引库里，可以提高查询速度。 </p>
</blockquote>
<h3 id="2、Elasticsearch-的-master-选举流程？"><a href="#2、Elasticsearch-的-master-选举流程？" class="headerlink" title="2、Elasticsearch 的 master 选举流程？"></a>2、Elasticsearch 的 master 选举流程？</h3><blockquote>
</blockquote>
<ul>
<li>Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含-一个主机列表以控制哪些节点需要ping通）这两部分。- 对所有可以成为master的节点（node master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。- 如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。- master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。</li>
</ul>
<h3 id="3、Elasticsearch-集群脑裂问题？"><a href="#3、Elasticsearch-集群脑裂问题？" class="headerlink" title="3、Elasticsearch 集群脑裂问题？"></a>3、Elasticsearch 集群脑裂问题？</h3><blockquote>
<p> “脑裂”问题可能的成因： </p>
</blockquote>
<ul>
<li>网络问题：集群间的网络延迟导致一些节点访问不到master, 认为master 挂掉了从而选举出新的master,并对master上的分片和副本标红，分配新的主分片。- 节点负载：主节点的角色既为master又为data,访问量较大时可能会导致ES停止响应造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点。- 内存回收：data 节点上的ES进程占用的内存较大，引发JVM的大规模内存回收，造成ES进程失去响应。<br>脑裂问题解决方案： </li>
<li>减少误判：discovery.zen ping_ timeout 节点状态的响应时间，默认为3s，可以适当调大，如果master在该响应时间的范围内没有做出响应应答，判断该节点已经挂掉了。调大参数（如6s，discovery.zen.ping_timeout:6），可适当减少误判。- 选举触发：discovery.zen.minimum. <em>master</em> nodes:1，该参數是用于控制选举行为发生的最小集群主节点数量。当备选主节点的个數大于等于该参数的值，且备选主节点中有该参数个节点认为主节点挂了，进行选举。官方建议为(n / 2) +1, n为主节点个数（即有资格成为主节点的节点个数）。- 角色分离：即master节点与data节点分离，限制角色 主节点配置为：node master: true，node data: false 从节点配置为：node master: false，node data: true</li>
</ul>
<h3 id="4、Elasticsearch-索引文档的流程？"><a href="#4、Elasticsearch-索引文档的流程？" class="headerlink" title="4、Elasticsearch 索引文档的流程？"></a>4、Elasticsearch 索引文档的流程？</h3><blockquote>
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/1bdc6c30d1be9b1bff83a683c64d2ac7.png"> 
</blockquote>
<ul>
<li>协调节点默认使用文档 ID 参与计算（也支持通过 routing），以便为路由提供合适的分片：shard = hash(document_id) % (num_of_primary_shards)- 当分片所在的节点接收到来自协调节点的请求后，会将请求写入到 Memory Buffer，然后定时（默认是每隔 1 秒）写入到 Filesystem Cache，这个从 Memory Buffer 到 Filesystem Cache 的过程就叫做 refresh；- 当然在某些情况下，存在 Momery Buffer 和 Filesystem Cache 的数据可能会丢失， ES 是通过 translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到 translog 中，当 Filesystemcache 中的数据写入到磁盘中时，才会清除掉，这个过程叫做 flush；- 在 flush 过程中，内存中的缓冲将被清除，内容被写入一个新段，段的 fsync 将创建一个新的提交点，并将内容刷新到磁盘，旧的 translog 将被删除并开始一个新的 translog。- flush 触发的时机是定时触发（默认 30 分钟）或者 translog 变得太大（默认为 512M）时；</li>
</ul>
<h3 id="5、Elasticsearch-更新和删除文档的流程？"><a href="#5、Elasticsearch-更新和删除文档的流程？" class="headerlink" title="5、Elasticsearch 更新和删除文档的流程？"></a>5、Elasticsearch 更新和删除文档的流程？</h3><blockquote>
</blockquote>
<ul>
<li>删除和更新也都是写操作，但是 Elasticsearch 中的文档是不可变的，因此不能被删除或者改动以展示其变更；- 磁盘上的每个段都有一个相应的.del 文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del 文件中被标记为删除的文档将不会被写入新段。- 在新的文档被创建时， Elasticsearch 会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。</li>
</ul>
<h3 id="6、Elasticsearch-搜索的流程？"><a href="#6、Elasticsearch-搜索的流程？" class="headerlink" title="6、Elasticsearch 搜索的流程？"></a>6、Elasticsearch 搜索的流程？</h3><blockquote>
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/053a14eee04ace7b4e5aec0ce53a5284.png"> 
</blockquote>
<ul>
<li>搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch；- 在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。 PS：在搜索的时候是会查询Filesystem Cache 的，但是有部分数据还在 Memory Buffer，所以搜索是近实时的。- 每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。- 接下来就是取回阶段， 协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并丰富文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。- Query Then Fetch 的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确， DFS Query Then Fetch 增加了一个预查询的处理，询问 Term 和 Document frequency，这个评分更准确，但是性能会变差。</li>
</ul>
<h3 id="7、Elasticsearch-在部署时，对-Linux-的设置有哪些优化方法？"><a href="#7、Elasticsearch-在部署时，对-Linux-的设置有哪些优化方法？" class="headerlink" title="7、Elasticsearch 在部署时，对 Linux 的设置有哪些优化方法？"></a>7、Elasticsearch 在部署时，对 Linux 的设置有哪些优化方法？</h3><blockquote>
</blockquote>
<ul>
<li>64 GB 内存的机器是非常理想的， 但是 32 GB 和 16 GB 机器也是很常见的。少于 8 GB 会适得其反。- 如果你要在更快的 CPUs 和更多的核心之间选择，选择更多的核心更好。多个内核提供的额外并发远胜过稍微快一点点的时钟频率。- 如果你负担得起 SSD，它将远远超出任何旋转介质。 基于 SSD 的节点，查询和索引性能都有提升。如果你负担得起， SSD 是一个好的选择。- 即使数据中心们近在咫尺，也要避免集群跨越多个数据中心。绝对要避免集群跨越大的地理距离。- 请确保运行你应用程序的 JVM 和服务器的 JVM 是完全一样的。 在 Elasticsearch 的几个地方，使用 Java 的本地序列化。- 通过设置 gateway.recover_after_nodes、 gateway.expected_nodes、 gateway.recover_after_time 可以在集群重启的时候避免过多的分片交换，这可能会让数据恢复从数个小时缩短为几秒钟。- Elasticsearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。最好使用单播代替组播。- 不要随意修改垃圾回收器（CMS）和各个线程池的大小。- 把你的内存的（少于）一半给 Lucene（但不要超过 32 GB！），通过 ES_HEAP_SIZE 环境变量设置。- 内存交换到磁盘对服务器性能来说是致命的。如果内存交换到磁盘上，一个 100 微秒的操作可能变成 10 毫秒。 再想想那么多 10 微秒的操作时延累加起来。 不难看出 swapping 对于性能是多么可怕。- Lucene 使用了大量的文件。同时， Elasticsearch 在节点和 HTTP 客户端之间进行通信也使用了大量的套接字。 所有这一切都需要足够的文件描述符。你应该增加你的文件描述符，设置一个很大的值，如 64,000。</li>
</ul>
<h3 id="8、GC-方面，在使用-Elasticsearch-时要注意什么？"><a href="#8、GC-方面，在使用-Elasticsearch-时要注意什么？" class="headerlink" title="8、GC 方面，在使用 Elasticsearch 时要注意什么？"></a>8、GC 方面，在使用 Elasticsearch 时要注意什么？</h3><blockquote>
<p> 倒排词典的索引需要常驻内存，无法 GC，需要监控 data node 上 segment memory 增长趋势。<br> 各类缓存， field cache, filter cache, indexing cache, bulk queue 等等，要设置合理的大小，并且要应该根据最坏的情况来看 heap 是否够用，也就是各类缓存全部占满的时候，还有 heap 空间可以分配给其他任务吗？避免采用 clear cache 等“自欺欺人”的方式来释放内存。<br> 避免返回大量结果集的搜索与聚合。确实需要大量拉取数据的场景，可以采用 scan &amp; scroll api 来实现。<br> cluster stats 驻留内存并无法水平扩展，超大规模集群可以考虑分拆成多个集群通过 tribe node 连接。<br> 想知道 heap 够不够，必须结合实际应用场景，并对集群的 heap 使用情况做持续的监控。 </p>
</blockquote>
<h3 id="9、Elasticsearch-对于大数据量（上亿量级）的聚合如何实现？"><a href="#9、Elasticsearch-对于大数据量（上亿量级）的聚合如何实现？" class="headerlink" title="9、Elasticsearch 对于大数据量（上亿量级）的聚合如何实现？"></a>9、Elasticsearch 对于大数据量（上亿量级）的聚合如何实现？</h3><blockquote>
<p> Elasticsearch 提供的首个近似聚合是 cardinality 度量。它提供一个字段的基数，即该字段的 distinct或者 unique 值的数目。它是基于 HLL 算法的。 HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关。 </p>
</blockquote>
<h3 id="10、在并发情况下，-Elasticsearch-如果保证读写一致？"><a href="#10、在并发情况下，-Elasticsearch-如果保证读写一致？" class="headerlink" title="10、在并发情况下， Elasticsearch 如果保证读写一致？"></a>10、在并发情况下， Elasticsearch 如果保证读写一致？</h3><blockquote>
</blockquote>
<ul>
<li>可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；- 另外对于写操作，一致性级别支持 quorum/one/all，默认为 quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。- 对于读操作，可以设置 replication 为 sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置 replication 为 async 时，也可以通过设置搜索请求参数_preference 为 primary 来查询主分片，确保文档是最新版本。</li>
</ul>
<h3 id="11、如何监控-Elasticsearch-集群状态？"><a href="#11、如何监控-Elasticsearch-集群状态？" class="headerlink" title="11、如何监控 Elasticsearch 集群状态？"></a>11、如何监控 Elasticsearch 集群状态？</h3><blockquote>
</blockquote>
<ul>
<li>elasticsearch-head 插件。- 通过 Kibana 监控 Elasticsearch。你可以实时查看你的集群健康状态和性能，也可以分析过去的集群、索引和节点指标</li>
</ul>
<h3 id="12、Elasticsearch-中的集群、节点、索引、文档、类型是什么？"><a href="#12、Elasticsearch-中的集群、节点、索引、文档、类型是什么？" class="headerlink" title="12、Elasticsearch 中的集群、节点、索引、文档、类型是什么？"></a>12、Elasticsearch 中的集群、节点、索引、文档、类型是什么？</h3><blockquote>
</blockquote>
<ul>
<li>集群是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名 称标识，默认情况下为”elasticsearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。- 节点是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。- 索引就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一个或多个主分片，并且可以有零个或多个副本分片。MySQL =&gt;数据库，Elasticsearch=&gt;索引。- 文档类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构(字段)，但是对于通用字段应该具有相同的数据类型。MySQL =&gt; Databases =&gt; Tables =&gt; Columns / Rows，Elasticsearch=&gt; Indices =&gt; Types =&gt;具有属性的文档Doc。- 类型是索引的逻辑类别/分区，其语义完全取决于用户。</li>
</ul>
<h3 id="13、Elasticsearch-中的倒排索引是什么？"><a href="#13、Elasticsearch-中的倒排索引是什么？" class="headerlink" title="13、Elasticsearch 中的倒排索引是什么？"></a>13、Elasticsearch 中的倒排索引是什么？</h3><blockquote>
<p> 倒排索引是搜索引擎的核心。搜索引擎的主要目标是在查找发生搜索条件的文档时提供快速搜索。ES中的倒排索引其实就是 lucene 的倒排索引，区别于传统的正向索引， 倒排索引会再存储数据时将关键词和数据进行关联，保存到倒排表中，然后查询时，将查询内容进行分词后在倒排表中进行查询，最后匹配数据即可。 </p>
</blockquote>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>Elasticsearch简介以及增删改查入门(学习笔记)</title>
    <url>/2021/07/18/Elasticsearch%E7%AE%80%E4%BB%8B%E4%BB%A5%E5%8F%8A%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5%E5%85%A5%E9%97%A8(%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0)/</url>
    <content><![CDATA[<p>title: Elasticsearch简介以及增删改查入门(学习笔记)<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、Elasticsearch 是什么？</p>
<blockquote>
<p>      The Elastic Stack, 包括 Elasticsearch、 Kibana、 Beats 和 Logstash（也称为 ELK Stack）。能够安全可靠地获取任何来源、任何格式的数据，然后实时地对数据进行搜索、分析和可视化。<br>     Elaticsearch，简称为 ES， ES 是一个<strong>开源的高扩展的分布式全文搜索引擎</strong>， 是整个 ElasticStack 技术栈的核心。<br>     它可以近乎实时的存储、检索数据；本身扩展性很好，可以扩展到上百台服务器，处理 PB 级别的数据。 </p>
</blockquote>
<h3 id="2、全文搜索引擎"><a href="#2、全文搜索引擎" class="headerlink" title="2、全文搜索引擎"></a>2、全文搜索引擎</h3><blockquote>
<p>      Google，百度类的网站搜索，它们都是根据网页中的关键字生成索引，我们在搜索的时候输入关键字，它们会将该关键字即索引匹配到的所有网页返回；还有常见的项目中应用日志的搜索等等。对于这些非结构化的数据文本，关系型数据库搜索不是能很好的支持。<br>      一般传统数据库，全文检索都实现的很鸡肋，因为一般也没人用数据库存文本字段。进行全文检索需要扫描整个表，如果数据量大的话即使对 SQL 的语法优化，也收效甚微。建立了索引，但是维护起来也很麻烦，对于 insert 和 update 操作都会重新构建索引。<br>   基于以上原因可以分析得出，在一些生产环境中，使用常规的搜索方式，性能是非常差的： </p>
</blockquote>
<ul>
<li>搜索的数据对象是大量的非结构化的文本数据。- 文件记录量达到数十万或数百万个甚至更多。- 支持大量基于交互式文本的查询。- 需求非常灵活的全文搜索查询。- 对高度相关的搜索结果的有特殊需求，但是没有可用的关系数据库可以满足。- 对不同记录类型、非文本数据操作或安全事务处理的需求相对较少的情况。为了解决结构化数据搜索和非结构化数据搜索性能问题，我们就需要专业，健壮，强大的全文搜索引擎 。<br>这里说到的全文搜索引擎指的是目前广泛应用的主流搜索引擎。它的工作原理是计算机索引程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。这个过程类似于通过字典中的检索字表查字的过程。 </li>
</ul>
<h3 id="3、倒排索引简介"><a href="#3、倒排索引简介" class="headerlink" title="3、倒排索引简介"></a>3、倒排索引简介</h3><blockquote>
<p> 1）案例1<br> <strong>正排索引（传统）</strong><br> <table><thead>|id|content</p>
</blockquote>
</thead><tbody>|1001|my name is zhang san
|1002|my name is li si
</tbody></table>
 **倒排索引** 
 <table><thead>|keyword|id
</thead><tbody>|name|1001, 1002
|zhang|1001
</tbody></table>
  Elasticsearch 是
 **面向文档型数据库**，一条数据在这里就是一个文档。 为了方便大家理解，我们将 Elasticsearch 里存储文档数据和关系型数据库 MySQL 存储数据的概念进行一个类比
 
 <img alt="" height="283" src="https://img-blog.csdnimg.cn/20210619123833679.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1020">
  ES 里的 Index 可以看做一个库，而 Types 相当于表， Documents 则相当于表的行。这里 Types 的概念已经被逐渐弱化， Elasticsearch 6.X 中，一个 index 下已经只能包含一个type， Elasticsearch 7.X 中, Type 的概念已经被删除了。
 
<p>  2）案例2<br>   <br> <img alt="" height="675" src="https://img-blog.csdnimg.cn/20210629215204613.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1150"></p>
 <img alt="" height="333" src="https://img-blog.csdnimg.cn/20210629215230277.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1111">
 
 <img alt="" height="745" src="https://img-blog.csdnimg.cn/20210629215255654.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="914">
 
 <img alt="" height="118" src="https://img-blog.csdnimg.cn/20210629215311587.png" width="1018">


<h3 id="4、索引-创建"><a href="#4、索引-创建" class="headerlink" title="4、索引-创建"></a>4、索引-创建</h3><blockquote>
<p> 对比关系型数据库，创建索引就等同于创建数据库。<br> 在 Postman 中，向 ES 服务器发 PUT 请求 ： <a href="http://127.0.0.1:9200/shopping">http://127.0.0.1:9200/shopping</a><br> 请求后，服务器返回响应：<br> <pre><code class="language-java">&#123;<br>    "acknowledged": true,//响应结果<br>    "shards_acknowledged": true,//分片结果<br>    "index": "shopping"//索引名称<br>&#125;<br></code></pre><br> 如果重复发 PUT 请求 ： <a href="http://127.0.0.1:9200/shopping">http://127.0.0.1:9200/shopping</a> 添加索引，会返回错误信息 :<br> <pre><code class="language-java">&#123;<br>    "error": &#123;<br>        "root_cause": [<br>            &#123;<br>                "type": "resource_already_exists_exception",<br>                "reason": "index [shopping/J0WlEhh4R7aDrfIc3AkwWQ] already exists",<br>                "index_uuid": "J0WlEhh4R7aDrfIc3AkwWQ",<br>                "index": "shopping"<br>            &#125;<br>        ],<br>        "type": "resource_already_exists_exception",<br>        "reason": "index [shopping/J0WlEhh4R7aDrfIc3AkwWQ] already exists",<br>        "index_uuid": "J0WlEhh4R7aDrfIc3AkwWQ",<br>        "index": "shopping"<br>    &#125;,<br>    "status": 400<br>&#125;<br></code></pre> </p>
</blockquote>
<h3 id="5、查看所有索引"><a href="#5、查看所有索引" class="headerlink" title="5、查看所有索引"></a>5、查看所有索引</h3><blockquote>
<p> 在 Postman 中，向 ES 服务器发 GET 请求 ： <a href="http://127.0.0.1:9200/_cat/indices?v">http://127.0.0.1:9200/_cat/indices?v</a><br> 这里请求路径中的_cat 表示查看的意思， indices 表示索引，所以整体含义就是查看当前 ES服务器中的所有索引，就好像 MySQL 中的 show tables 的感觉，服务器响应结果如下 :<br> <pre><code class="language-java">health status index    uuid                   pri rep docs.count docs.deleted store.size pri.store.size<br>yellow open   shopping J0WlEhh4R7aDrfIc3AkwWQ   1   1          0            0       208b           208b<br></code></pre><br> <img alt="" height="534" src="https://img-blog.csdnimg.cn/20210619165148317.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> </p>
</blockquote>
<h3 id="6、查看单个索引"><a href="#6、查看单个索引" class="headerlink" title="6、查看单个索引"></a>6、查看单个索引</h3><blockquote>
<p> 在 Postman 中，向 ES 服务器发 GET 请求 ： <a href="http://127.0.0.1:9200/shopping">http://127.0.0.1:9200/shopping</a><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "shopping": &#123;//索引名<br>        "aliases": &#123;&#125;,//别名<br>        "mappings": &#123;&#125;,//映射<br>        "settings": &#123;//设置<br>            "index": &#123;//设置 - 索引<br>                "creation_date": "1617861426847",//设置 - 索引 - 创建时间<br>                "number_of_shards": "1",//设置 - 索引 - 主分片数量<br>                "number_of_replicas": "1",//设置 - 索引 - 主分片数量<br>                "uuid": "J0WlEhh4R7aDrfIc3AkwWQ",//设置 - 索引 - 主分片数量<br>                "version": &#123;//设置 - 索引 - 主分片数量<br>                    "created": "7080099"<br>                &#125;,<br>                "provided_name": "shopping"//设置 - 索引 - 主分片数量<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre> </p>
</blockquote>
<h3 id="7、删除索引"><a href="#7、删除索引" class="headerlink" title="7、删除索引"></a>7、删除索引</h3><blockquote>
<p> 在 Postman 中，向 ES 服务器发 DELETE 请求 ： <a href="http://127.0.0.1:9200/shopping">http://127.0.0.1:9200/shopping</a><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "acknowledged": true<br>&#125;<br></code></pre><br> 再次查看所有索引，GET <a href="http://127.0.0.1:9200/_cat/indices?v%EF%BC%8C%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/_cat/indices?v，返回结果如下：</a><br> <pre><code class="language-java">health status index uuid pri rep docs.count docs.deleted store.size pri.store.size<br></code></pre><br> 成功删除。 </p>
</blockquote>
<h3 id="8、文档-创建（Put-amp-Post）"><a href="#8、文档-创建（Put-amp-Post）" class="headerlink" title="8、文档-创建（Put &amp; Post）"></a>8、文档-创建（Put &amp; Post）</h3><blockquote>
<p> 假设索引已经创建好了，接下来我们来创建文档，并添加数据。这里的文档可以类比为关系型数据库中的表数据，添加的数据格式为 JSON 格式。<br> 在 Postman 中，向 ES 服务器发 POST 请求 ： <a href="http://127.0.0.1:9200/shopping/_doc%EF%BC%8C%E8%AF%B7%E6%B1%82%E4%BD%93JSON%E5%86%85%E5%AE%B9%E4%B8%BA%EF%BC%9A">http://127.0.0.1:9200/shopping/_doc，请求体JSON内容为：</a><br> <pre><code class="language-java">&#123;<br>    "title":"小米手机",<br>    "category":"小米",<br>    "images":"<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>    "price":3999.00<br>&#125;<br></code></pre><br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/20d54cba223bd9d70ea356d3e40a8161.png"><br> 注意，此处发送请求的方式必须为 POST，不能是 PUT，否则会发生错误 。<br> 返回结果：<br> <pre><code class="language-java">&#123;<br>    "_index": "shopping",//索引<br>    "_type": "_doc",//类型-文档<br>    "_id": "ANQqsHgBaKNfVnMbhZYU",//唯一标识，可以类比为 MySQL 中的主键，随机生成<br>    "_version": 1,//版本<br>    "result": "created",//结果，这里的 create 表示创建成功<br>    "_shards": &#123;//<br>        "total": 2,//分片 - 总数<br>        "successful": 1,//分片 - 总数<br>        "failed": 0//分片 - 总数<br>    &#125;,<br>    "_seq_no": 0,<br>    "_primary_term": 1<br>&#125;<br></code></pre><br> 上面的数据创建后，由于没有指定数据唯一性标识（ID），默认情况下， ES 服务器会随机生成一个。<br> 如果想要自定义唯一性标识，需要在创建时指定： <a href="http://127.0.0.1:9200/shopping/_doc/1%EF%BC%8C%E8%AF%B7%E6%B1%82%E4%BD%93JSON%E5%86%85%E5%AE%B9%E4%B8%BA%EF%BC%9A">http://127.0.0.1:9200/shopping/_doc/1，请求体JSON内容为：</a><br> <pre><code class="language-java">&#123;<br>    "title":"小米手机",<br>    "category":"小米",<br>    "images":"<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>    "price":3999.00<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "_index": "shopping",<br>    "_type": "_doc",<br>    "_id": "1",//&lt;------------------自定义唯一性标识<br>    "_version": 1,<br>    "result": "created",<br>    "_shards": &#123;<br>        "total": 2,<br>        "successful": 1,<br>        "failed": 0<br>    &#125;,<br>    "_seq_no": 1,<br>    "_primary_term": 1<br>&#125;<br></code></pre><br> <strong>此处需要注意：如果增加数据时明确数据主键，那么请求方式也可以为 PUT。</strong> </p>
</blockquote>
<h3 id="9、主键查询-amp-全查询"><a href="#9、主键查询-amp-全查询" class="headerlink" title="9、主键查询 &amp; 全查询"></a>9、主键查询 &amp; 全查询</h3><blockquote>
<p> 查看文档时，需要指明文档的唯一性标识，类似于 MySQL 中数据的主键查询<br> 在 Postman 中，向 ES 服务器发 GET 请求 ： <a href="http://127.0.0.1:9200/shopping/_doc/1">http://127.0.0.1:9200/shopping/_doc/1</a> 。<br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "_index": "shopping",<br>    "_type": "_doc",<br>    "_id": "1",<br>    "_version": 1,<br>    "_seq_no": 1,<br>    "_primary_term": 1,<br>    "found": true,<br>    "_source": &#123;<br>        "title": "小米手机",<br>        "category": "小米",<br>        "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>        "price": 3999<br>    &#125;<br>&#125;<br></code></pre><br> 查找不存在的内容，向 ES 服务器发 GET 请求 ： <a href="http://127.0.0.1:9200/shopping/_doc/1001%E3%80%82">http://127.0.0.1:9200/shopping/_doc/1001。</a><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "_index": "shopping",<br>    "_type": "_doc",<br>    "_id": "1001",<br>    "found": false<br>&#125;<br></code></pre><br> 查看索引下所有数据，向 ES 服务器发 GET 请求 ： <a href="http://127.0.0.1:9200/shopping/_search%E3%80%82">http://127.0.0.1:9200/shopping/_search。</a><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 133,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 2,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 1,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "ANQqsHgBaKNfVnMbhZYU",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 3999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "1",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 3999<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre> </p>
</blockquote>
<h3 id="10、全量修改-amp-局部修改-amp-删除"><a href="#10、全量修改-amp-局部修改-amp-删除" class="headerlink" title="10、全量修改 &amp; 局部修改 &amp; 删除"></a>10、全量修改 &amp; 局部修改 &amp; 删除</h3><blockquote>
 <ol><li> 全量修改 和新增文档一样，输入相同的 URL 地址请求，如果请求体变化，会将原有的数据内容覆盖，在 Postman 中，向 ES 服务器发 POST 请求 http://127.0.0.1:9200/shopping/_doc/1，请求体JSON内容为: <pre><code class="language-java">&#123;
    "title":"华为手机",
    "category":"华为",
    "images":"http://www.gulixueyuan.com/hw.jpg",
    "price":1999.00
&#125;
</code></pre> 修改成功后，服务器响应结果： <pre><code class="language-java">&#123;
    "_index": "shopping",
    "_type": "_doc",
    "_id": "1",
    "_version": 2,
    "result": "updated",//&lt;-----------updated 表示数据被更新
    "_shards": &#123;
        "total": 2,
        "successful": 1,
        "failed": 0
    &#125;,
    "_seq_no": 2,
    "_primary_term": 1
&#125;
</code></pre> </li><li> 局部修改 修改数据时，也可以只修改某一给条数据的局部信息，在 Postman 中，向 ES 服务器发 POST 请求 ： http://127.0.0.1:9200/shopping/_update/1。请求体JSON内容为: <pre><code class="language-java">&#123;
    "doc": &#123;
        "title":"小米手机",
        "category":"小米"
    &#125;
&#125;
</code></pre> 返回结果如下： <pre><code class="language-java">&#123;
    "_index": "shopping",
    "_type": "_doc",
    "_id": "1",
    "_version": 3,
    "result": "updated",//&lt;-----------updated 表示数据被更新
    "_shards": &#123;
        "total": 2,
        "successful": 1,
        "failed": 0
    &#125;,
    "_seq_no": 3,
    "_primary_term": 1
&#125;
</code></pre> 在 Postman 中，向 ES 服务器发 GET请求 ： http://127.0.0.1:9200/shopping/_doc/1，查看修改内容： <pre><code class="language-java">&#123;
    "_index": "shopping",
    "_type": "_doc",
    "_id": "1",
    "_version": 3,
    "_seq_no": 3,
    "_primary_term": 1,
    "found": true,
    "_source": &#123;
        "title": "小米手机",
        "category": "小米",
        "images": "http://www.gulixueyuan.com/hw.jpg",
        "price": 1999
    &#125;
&#125;
</code></pre>  </li></ol>
</blockquote>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>FastDFS测试</title>
    <url>/2021/07/18/FastDFS%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<p>title: FastDFS测试<br>categories:</p>
<ul>
<li>fastdfs</li>
</ul>
<p>—### 1.简介</p>
<blockquote>
<p> FastDFS安装完成之后，可以使用fdfs_test脚本测试文件上传 </p>
</blockquote>
<h3 id="2-测试之前，需要修改client-conf配置文件，修改两个配置"><a href="#2-测试之前，需要修改client-conf配置文件，修改两个配置" class="headerlink" title="2.测试之前，需要修改client.conf配置文件，修改两个配置"></a>2.测试之前，需要修改client.conf配置文件，修改两个配置</h3><blockquote>
 <img alt="" height="280" src="https://img-blog.csdnimg.cn/20210417204142585.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="645"> 
 <img alt="" height="197" src="https://img-blog.csdnimg.cn/20210417204301702.png" width="686"> 
</blockquote>
<ul>
<li>在/opt/FastDFS//目录下创建client<img alt="" height="163" src="https://img-blog.csdnimg.cn/2021041720440960.png" width="507"></li>
</ul>
<h3 id="3-启动fdfs"><a href="#3-启动fdfs" class="headerlink" title="3.启动fdfs"></a>3.启动fdfs</h3><blockquote>
 <img alt="" height="230" src="https://img-blog.csdnimg.cn/20210417205010495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="900"> 
</blockquote>
<h3 id="4-测试文件上传"><a href="#4-测试文件上传" class="headerlink" title="4.测试文件上传"></a>4.测试文件上传</h3><blockquote>
</blockquote>
<ul>
<li>准备需要上传的文件<img alt="" height="177" src="https://img-blog.csdnimg.cn/20210417205317340.png" width="702"><img alt="" height="162" src="https://img-blog.csdnimg.cn/20210417205415154.png" width="640">- 执行上传命令fdfs_test /etc/fdfs/client.conf upload /root/aa.txt<img alt="" height="409" src="https://img-blog.csdnimg.cn/20210417210039610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="704"><img alt="" height="770" src="https://img-blog.csdnimg.cn/20210417211150986.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1009">- 切换到存储目录查看文件上传情况<img alt="" height="206" src="https://img-blog.csdnimg.cn/20210417210240688.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1078"><img alt="" height="188" src="https://img-blog.csdnimg.cn/20210417211219718.png" width="1006">- FastDFS生成的文件目录结构及名称示例<img alt="" height="89" src="https://img-blog.csdnimg.cn/20210417210319330.png" width="527">
  </li>
</ul>
<h3 id="5-测试文件下载"><a href="#5-测试文件下载" class="headerlink" title="5.测试文件下载"></a>5.测试文件下载</h3><blockquote>
 <img alt="" height="563" src="https://img-blog.csdnimg.cn/20210417214249415.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 
 命令：fdfs_test /etc/fdfs/client.conf download group1 M00/00/00/wKg4DWB620aAeye8AAAWdd4My38470.txt 
 group1：表示组名 
 M00/00/00/wKg4DWB620aAeye8AAAWdd4My38470.txt：要下载的文件名称，和上面上传时候的文件路径对应 
</blockquote>
<h3 id="6-测试文件删除"><a href="#6-测试文件删除" class="headerlink" title="6.测试文件删除"></a>6.测试文件删除</h3><blockquote>
<p> 命令：fdfs_test /etc/fdfs/client.conf delete group1 M00/00/00/wKg4DWB620aAeye8AAAWdd4My38470.txt<br> <img alt="" height="328" src="https://img-blog.csdnimg.cn/20210417214624413.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"><br> 查看之前上传的路径：<br> <img alt="" height="168" src="https://img-blog.csdnimg.cn/20210417214929783.png" width="1029"> </p>
</blockquote>
]]></content>
      <categories>
        <category>Fastdfs</category>
      </categories>
  </entry>
  <entry>
    <title>FastDFS环境搭建</title>
    <url>/2021/07/18/FastDFS%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>title: FastDFS环境搭建<br>categories:</p>
<ul>
<li>fastdfs</li>
</ul>
<p>—### 1.安装前的准备</p>
<blockquote>
<p> 检查Linux上是否安装了 gcc、libevent、libevent-devel </p>
</blockquote>
<ul>
<li>yum list installed | grep gcc- yum list installed | grep libevent- yum list installed | grep libevent-devel<br>如果没有安装，则需进行安装<br>命令：yum install gcc libevent libevent-devel -y </li>
</ul>
<h3 id="2-安装-libfastcommon-库"><a href="#2-安装-libfastcommon-库" class="headerlink" title="2.安装 libfastcommon 库"></a>2.安装 libfastcommon 库</h3><blockquote>
<p> libfastcommon 库是 FastDFS 文件系统运行需要的公共 C 语言函数库<br> *<em>注意：目前最新版本的v1.0.39</em><em><strong>和最新版的FastDFS5.11</strong></em><em>不兼容，所有我们这里使用的版本是v1.0.36  <strong>下载地址：<br> 将下载好的libfastcommon文件上传到Linuxs（/opt/FastDFS）<br> <img alt="" height="192" src="https://img-blog.csdnimg.cn/20210417181554593.png" width="877"><br> 解压下载下来的tar.gz压缩包到当前目录<br> 命令：tar -zxvf libfastcommon-1.0.36.tar.gz<br> 切换到解压后的libfastcommon目录<br> <img alt="" height="251" src="https://img-blog.csdnimg.cn/20210417181925833.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="762"><br> 执行make脚本进行编译<br>  ** ./make.sh</strong><br> <img alt="" height="241" src="https://img-blog.csdnimg.cn/20210417182035706.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1005"><br> <strong>注意： make</strong></em><em>编译的时候如果报错，需解决错误后再次进行make</em><em><strong>，通常发生错误是由于Linux</strong></em><em>缺少某些依赖库导致，根据错误提示解决错误</em>*<br> 执行make install进行安装<br> ./make.sh install<br> <img alt="" height="261" src="https://img-blog.csdnimg.cn/20210417182154506.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1152"> </p>
</blockquote>
<h3 id="3-安装FastDFS"><a href="#3-安装FastDFS" class="headerlink" title="3.安装FastDFS"></a>3.安装FastDFS</h3><blockquote>
<p> FastDFS没有Windows版本，不能在Windows下使用。<br> FastDFS需要安装部署在Linux环境下，我们这里使用的是fastdfs-5.11版本（201901）<br> 下载地址：<br> 解压下载下来的tar.gz压缩包到当前目录<br> 命令：tar -zxvf fastdfs-5.11.tar.gz<br> <img alt="" height="305" src="https://img-blog.csdnimg.cn/20210417182356215.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="800"><br> 切换到解压后FastDFS的目录，执行make脚本进行编译<br> <img alt="" height="530" src="https://img-blog.csdnimg.cn/20210417182507948.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="862"><br> 执行make install进行安装<br> 命令：./make.sh install<br> <img alt="" height="501" src="https://img-blog.csdnimg.cn/20210417182626786.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1073"><br> 至此FastDFS安装完成<br> 所有编译出来的文件存放在/usr/bin目录下<br> 所有配置文件存放在/etc/fdfs目录下<br> 查看安装后的效果：<br> 命令：ll /usr/bin/fdfs*<br> <img alt="" height="351" src="https://img-blog.csdnimg.cn/2021041718314329.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="864"><br> /usr/bin是Linux的环境变量，可通过echo $PATH查看<br> 查看FastDFS的配置文件：<br> 命令：ll /etc/fdfs/<br> <img alt="" height="186" src="https://img-blog.csdnimg.cn/20210417183302325.png" width="767"><br> 另外注意需要把解压后的fastdfs-5.11/conf目录下的两个文件拷贝到/etc/fdfs/ ，否则后续会有很多奇怪问题不好解决<br> 命令：<br> cp http.conf /etc/fdfs/<br> cp mime.types /etc/fdfs/<br> <img alt="" height="322" src="https://img-blog.csdnimg.cn/20210417183955536.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="659"> </p>
</blockquote>
<h3 id="4-配置FastDFS"><a href="#4-配置FastDFS" class="headerlink" title="4.配置FastDFS"></a>4.配置FastDFS</h3><blockquote>
<p> 去掉/etc/fdfs/目录下FastDFS配置文件的后缀名<br> <img alt="" height="479" src="https://img-blog.csdnimg.cn/20210417184429614.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="894"><br> 修改tracker.conf文件<br> <strong>默认指向的FastDFS****作者余庆的目录，因为在我们的机器上不存在，所有手动改一下</strong><br>  base_path=/opt/FastDFS/tracker             #配置tracker存储数据的目录，<strong>这个目录需要提前创建</strong><br> 命令：vim tracker.conf<br> <img alt="" height="580" src="https://img-blog.csdnimg.cn/2021041718523648.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="642"><br> 修改storage.conf文件<br>          base_path=/opt/FastDFS/storage                     #storage存储数据目录，<strong>目录需要提前创建</strong><br>          store_path0=/opt/FastDFS/storage/files         #真正存放文件的目录，<strong>目录需要提前创建</strong><br>          tracker_server=192.168.56.13:22122        #注册当前存储节点的跟踪器地址<br> <img alt="" height="124" src="https://img-blog.csdnimg.cn/20210417185931650.png" width="553"><br> <img alt="" height="169" src="https://img-blog.csdnimg.cn/20210417190051272.png" width="956"><br> <img alt="" height="129" src="https://img-blog.csdnimg.cn/20210417190124513.png" width="524"> </p>
</blockquote>
<h3 id="5-启动FastDFS"><a href="#5-启动FastDFS" class="headerlink" title="5.启动FastDFS"></a>5.启动FastDFS</h3><blockquote>
</blockquote>
<ul>
<li>启动FastDFS的tracker服务 在任意目录下执行：fdfs_trackerd /etc/fdfs/tracker.conf- 查看启动的进程<img alt="" height="139" src="https://img-blog.csdnimg.cn/20210417195757797.png" width="898">- 启动FastDFS的storage服务 在任意目录下执行：fdfs_storaged /etc/fdfs/storage.conf- 查看启动进程<img alt="" height="147" src="https://img-blog.csdnimg.cn/20210417200521133.png" width="898">- 查看storage是否已经注册到了tracker下 命令：fdfs_monitor /etc/fdfs/storage.conf<img alt="" height="437" src="https://img-blog.csdnimg.cn/20210417201359824.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="780">- 首次启动storage后，会在配置的路径下创建存储文件的目录<img alt="" height="289" src="https://img-blog.csdnimg.cn/20210417201437435.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="533"></li>
</ul>
<h3 id="6-FastDFS重启"><a href="#6-FastDFS重启" class="headerlink" title="6.FastDFS重启"></a>6.FastDFS重启</h3><blockquote>
</blockquote>
<ul>
<li>重启tracker 命令：fdfs_trackerd /etc/fdfs/tracker.conf restart<img alt="" height="115" src="https://img-blog.csdnimg.cn/20210417201950615.png" width="828">- 重启storage 命令：fdfs_storaged /etc/fdfs/storage.conf restart<img alt="" height="87" src="https://img-blog.csdnimg.cn/20210417202025395.png" width="773"></li>
</ul>
<h3 id="7-​​​​​​​FastDFS关闭"><a href="#7-​​​​​​​FastDFS关闭" class="headerlink" title="7.​​​​​​​FastDFS关闭"></a>7.​​​​​​​FastDFS关闭</h3><blockquote>
</blockquote>
<ul>
<li>关闭tracker执行命令 在任意目录下执行：fdfs_trackerd /etc/fdfs/tracker.conf stop<img alt="" height="112" src="https://img-blog.csdnimg.cn/20210417202141922.png" width="757">- 关闭storage执行命令 在任意目录下执行：fdfs_storaged /etc/fdfs/storage.conf stop<img alt="" height="89" src="https://img-blog.csdnimg.cn/20210417202212646.png" width="723"><img alt="" height="80" src="https://img-blog.csdnimg.cn/20210417202444469.png" width="734">- 或者kill关闭fastdfs，但不建议在线上使用 kill -9 强制关闭，因为可能会导致文件信息不同步问题 ​​​​​​​</li>
</ul>
]]></content>
      <categories>
        <category>Fastdfs</category>
      </categories>
  </entry>
  <entry>
    <title>FastDFS简介</title>
    <url>/2021/07/18/FastDFS%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>title: FastDFS简介<br>categories:</p>
<ul>
<li>fastdfs</li>
</ul>
<p>—### 1.什么是分布式文件系统</p>
<blockquote>
<p>         分布式文件系统 (Distributed File System) 是一个软件/软件服务器，这个软件可以用来管理文件。但这个软件所管理的文件通常不是在一个服务器节点上，而是在多个服务器节点上，这些服务器节点通过网络相连构成一个庞大的文件存储服务器集群，这些服务器都用于存储文件资源，通过分布式文件系统来管理这些服务器上的文件。<br>        常见的分布式文件系统有：FastDFS、GFS、HDFS、Lustre 、Ceph 、GridFS 、mogileFS、TFS等。<br>        分布式文件系统与传统文件系统对比<br> <img alt="" height="292" src="https://img-blog.csdnimg.cn/20210417174637335.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="553"><br> 传统方式弊端 </p>
</blockquote>
<ul>
<li>如果用户数量多，IO操作比较多，对磁盘访问压力很大- 如果磁盘发生故障，会造成数据丢失- 存储容量有限</li>
</ul>
<h3 id="2-​​​​​​​FastDFS简介"><a href="#2-​​​​​​​FastDFS简介" class="headerlink" title="2.​​​​​​​FastDFS简介"></a>2.​​​​​​​FastDFS简介</h3><blockquote>
<p>         FastDFS是一个开源的轻量级分布式文件系统，为互联网应用量身定做，简单、灵活、高效，采用C语言开发，由阿里巴巴开发并开源。<br>        FastDFS对文件进行管理，功能包括：文件存储、文件同步、文件访问（文件上传、文件下载、文件删除）等，解决了大容量文件存储的问题，特别适合以文件为载体的在线服务，如相册网站、文档网站、图片网站、视频网站等等。<br>        FastDFS充分考虑了冗余备份、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。 </p>
</blockquote>
<h3 id="3-​​​​​​​FastDFS整体架构"><a href="#3-​​​​​​​FastDFS整体架构" class="headerlink" title="3.​​​​​​​FastDFS整体架构"></a>3.​​​​​​​FastDFS整体架构</h3><blockquote>
<p>       FastDFS文件系统由两大部分构成，一个是客户端，一个是服务端<br>       客户端通常指我们的程序，比如我们的Java程序去连接FastDFS、操作FastDFS，那我们的Java程序就是一个客户端，FastDFS提供专有API访问，目前提供了C、Java和PHP几种编程语言的API，用来访问FastDFS文件系统。<br>          服务端由两个部分构成：一个是跟踪器（tracker），一个是存储节点（storage）<br>          跟踪器（tracker）主要做调度工作，在内存中记录集群中存储节点storage的状态信息，是前端Client和后端存储节点storage的枢纽。因为相关信息全部在内存中，Tracker server的性能非常高，一个较大的集群（比如上百个group）中有3台就足够了。<br>          存储节点（storage）用于存储文件，包括文件和文件属性（meta data）都保存到存储服务器磁盘上，完成文件管理的所有功能：文件存储、文件同步和提供文件访问等。 ​​​​​​​</p>
</blockquote>
]]></content>
      <categories>
        <category>Fastdfs</category>
      </categories>
  </entry>
  <entry>
    <title>Flume Taildir Source监听实时追加内容的文件</title>
    <url>/2021/07/18/Flume%20Taildir%20Source%E7%9B%91%E5%90%AC%E5%AE%9E%E6%97%B6%E8%BF%BD%E5%8A%A0%E5%86%85%E5%AE%B9%E7%9A%84%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<p>title: Flume Taildir Source监听实时追加内容的文件<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—title: Flume Taildir Source监听实时追加内容的文件<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—1. 简介         flume中有三种可监控文件或目录的source、分别是Exec Source、Spooling Directory Source和Taildir Source。         Taildir Source是1.7版本的新特性，综合了Spooling Directory Source和Exec Source的优点。1. Exec Source使用场景         Exec Source可通过tail -f命令去tail住一个文件，然后实时同步日志到sink。但存在的问题是，当agent进程挂掉重启后，会有重复消费的问题。可以通过增加UUID来解决，或通过改进ExecSource来解决。1.  Spooling Directory Source使用场景        Spooling Directory Source可监听一个目录，同步目录中的新文件到sink,被同步完的文件可被立即删除或被打上标记。适合用于同步新文件，但不适合对实时追加日志的文件进行监听并同步。如果需要实时监听追加内容的文件，可对SpoolDirectorySource进行改进 1.  Taildir Source使用场景  Taildir Source可实时监控一批文件，并记录每个文件最新消费位置，agent进程重启后不会有重复消费的问题。  使用时建议用1.8.0版本的flume，1.8.0版本中解决了Taildir Source一个可能会丢数据的bug。 <li> TailSource配置如下   <pre class="has"><code class="language-bash"># source的名字<br>agent.sources = s1</p>
<h1 id="channels的名字"><a href="#channels的名字" class="headerlink" title="channels的名字"></a>channels的名字</h1><p>agent.channels = c1</p>
<h1 id="sink的名字"><a href="#sink的名字" class="headerlink" title="sink的名字"></a>sink的名字</h1><p>agent.sinks = r1</p>
<h1 id="指定source使用的channel"><a href="#指定source使用的channel" class="headerlink" title="指定source使用的channel"></a>指定source使用的channel</h1><p>agent.sources.s1.channels = c1</p>
<h1 id="指定sink使用的channel"><a href="#指定sink使用的channel" class="headerlink" title="指定sink使用的channel"></a>指定sink使用的channel</h1><p>agent.sinks.r1.channel = c1</p>
<p>######## source相关配置 ########</p>
<h1 id="source类型"><a href="#source类型" class="headerlink" title="source类型"></a>source类型</h1><p>agent.sources.s1.type = TAILDIR</p>
<h1 id="元数据位置"><a href="#元数据位置" class="headerlink" title="元数据位置"></a>元数据位置</h1><p>agent.sources.s1.positionFile = /Users/wangpei/tempData/flume/taildir_position.json</p>
<h1 id="监控的目录"><a href="#监控的目录" class="headerlink" title="监控的目录"></a>监控的目录</h1><p>agent.sources.s1.filegroups = f1<br>agent.sources.s1.filegroups.f1=/Users/wangpei/tempData/flume/data/.*log<br>agent.sources.s1.fileHeader = true</p>
<p>######## channel相关配置 ########</p>
<h1 id="channel类型"><a href="#channel类型" class="headerlink" title="channel类型"></a>channel类型</h1><p>agent.channels.c1.type = file</p>
<h1 id="数据存放路径"><a href="#数据存放路径" class="headerlink" title="数据存放路径"></a>数据存放路径</h1><p>agent.channels.c1.dataDirs = /Users/wangpei/tempData/flume/filechannle/dataDirs</p>
<h1 id="检查点路径"><a href="#检查点路径" class="headerlink" title="检查点路径"></a>检查点路径</h1><p>agent.channels.c1.checkpointDir = /Users/wangpei/tempData/flume/filechannle/checkpointDir</p>
<h1 id="channel中最多缓存多少"><a href="#channel中最多缓存多少" class="headerlink" title="channel中最多缓存多少"></a>channel中最多缓存多少</h1><p>agent.channels.c1.capacity = 1000</p>
<h1 id="channel一次最多吐给sink多少"><a href="#channel一次最多吐给sink多少" class="headerlink" title="channel一次最多吐给sink多少"></a>channel一次最多吐给sink多少</h1><p>agent.channels.c1.transactionCapacity = 100</p>
<p>######## sink相关配置 ########</p>
<h1 id="sink类型"><a href="#sink类型" class="headerlink" title="sink类型"></a>sink类型</h1><p>agent.sinks.r1.type = org.apache.flume.sink.kafka.KafkaSink</p>
<h1 id="brokers地址"><a href="#brokers地址" class="headerlink" title="brokers地址"></a>brokers地址</h1><p>agent.sinks.r1.kafka.bootstrap.servers = localhost:9092</p>
<h1 id="topic"><a href="#topic" class="headerlink" title="topic"></a>topic</h1><p>agent.sinks.r1.kafka.topic = testTopic3</p>
<h1 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h1><p>agent.sinks.r1.kafka.producer.compression.type = snappy<br></code></pre>   </li><li> 记录每个文件消费位置的元数据 <pre class="has"><code class="language-bash">#配置<br>agent.sources.s1.positionFile = /Users/wangpei/tempData/flume/taildir_position.json<br>#内容<br>[<br>&#123;<br>    "inode":6028358,<br>    "pos":144,<br>    "file":"/Users/wangpei/tempData/flume/data/test.log"<br>&#125;,<br>&#123;<br>    "inode":6028612,<br>    "pos":20,<br>    "file":"/Users/wangpei/tempData/flume/data/test_a.log"<br>&#125;<br>]  </p>
<p>可以看到，在taildir_position.json文件中，通过json数组的方式，记录了每个文件最新的消费位置，每消费一次便去更新这个文件。<br></code></pre> 转载自： </li></p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Flume知识点入门学习</title>
    <url>/2021/07/18/Flume%E7%9F%A5%E8%AF%86%E7%82%B9%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>title: Flume知识点入门学习<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—title: Flume知识点入门学习<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—1. 1. 1. </p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Flume知识点入门学习一</title>
    <url>/2021/07/18/Flume%E7%9F%A5%E8%AF%86%E7%82%B9%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%B8%80/</url>
    <content><![CDATA[<p>title: Flume知识点入门学习一<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：简介</p>
<p>         <img alt="" class="has" height="250" src="https://img-blog.csdnimg.cn/20190907164649823.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="817"></p>
<h1 id="二：Flume-角色"><a href="#二：Flume-角色" class="headerlink" title="二：Flume 角色"></a>二：Flume 角色</h1><p>          <img alt="" class="has" height="387" src="https://img-blog.csdnimg.cn/20190907170335438.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="570">           <img alt="" class="has" height="242" src="https://img-blog.csdnimg.cn/20190907170416665.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="570"></p>
<h1 id="三：Flume-传输过程"><a href="#三：Flume-传输过程" class="headerlink" title="三：Flume 传输过程"></a>三：Flume 传输过程</h1><p>        <img alt="" class="has" height="116" src="https://img-blog.csdnimg.cn/20190907170520627.png" width="699"></p>
<h1 id="四：安装flume"><a href="#四：安装flume" class="headerlink" title="四：安装flume"></a>四：安装flume</h1><ol>
<li>上传安装包到linux,并且解压到指定目录下   <img alt="" class="has" height="210" src="https://img-blog.csdnimg.cn/20190907212016939.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="723">    <img alt="" class="has" height="217" src="https://img-blog.csdnimg.cn/20190907212204323.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="717">1. 修改配置文件名称  <img alt="" class="has" height="306" src="https://img-blog.csdnimg.cn/20190907212941545.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="660">1. 修改flume-env.sh文件  <img alt="" class="has" height="186" src="https://img-blog.csdnimg.cn/20190907213705941.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="547">        <h1 id="五：案例一：监控端口数据"><a href="#五：案例一：监控端口数据" class="headerlink" title="五：案例一：监控端口数据"></a>五：案例一：监控端口数据</h1></li>
<li>需求：Flume 监控一端 Console，另一端 Console 发送消息，使被监控端实时显示1. 创建 Flume Agent 配置文件 job_flume_telnet.conf   <img alt="" class="has" height="445" src="https://img-blog.csdnimg.cn/20190907220902438.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="635">1. 判断 44444 端口是否被占用   <img alt="" class="has" height="151" src="https://img-blog.csdnimg.cn/20190907221017173.png" width="681">1. 先开启 flume 先听端口   <img alt="" class="has" height="147" src="https://img-blog.csdnimg.cn/201909072224329.png" width="669">  <img alt="" class="has" height="304" src="https://img-blog.csdnimg.cn/20190907222655263.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="644">1.  使用 telnet 工具向本机的 44444 端口发送内容   <img alt="" class="has" height="561" src="https://img-blog.csdnimg.cn/20190907222854781.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="566">
 </li>
</ol>
<h1 id="六：案例二：实时读取本地文件到-HDFS"><a href="#六：案例二：实时读取本地文件到-HDFS" class="headerlink" title="六：案例二：实时读取本地文件到 HDFS"></a>六：案例二：实时读取本地文件到 HDFS</h1><ol>
<li>需求：**实时监控 hive 日志，并上传到 HDFS 中 **1.  拷贝 Hadoop 相关 jar 到 Flume 的 /opt/module/apache-flume-1.7.0-bin/lib/ 目录下：  <img alt="" class="has" height="172" src="https://img-blog.csdnimg.cn/20190908130750465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="635"><li>创建job_flume_2hdfs.conf 文件    <img alt="" class="has" height="142" src="https://img-blog.csdnimg.cn/20190908134244861.png" width="412">         内容：    <pre class="has"><code class="language-bash">#把agent起个名叫a2,sources叫r2,sinks叫k2.hdfs,channels叫c2<br>a2.sources = r2<br>a2.sinks = k2<br>a2.channels = c2 </li>
</ol>
<h1 id="Describe-configure-the-source"><a href="#Describe-configure-the-source" class="headerlink" title="Describe/configure the source"></a>Describe/configure the source</h1><h1 id="exec即execute执行命令"><a href="#exec即execute执行命令" class="headerlink" title="exec即execute执行命令"></a>exec即execute执行命令</h1><p>a2.sources.r2.type = exec </p>
<h1 id="要执行的命令"><a href="#要执行的命令" class="headerlink" title="要执行的命令"></a>要执行的命令</h1><p>a2.sources.r2.command = tail -F /opt/module/hive/logs/hive.log </p>
<h1 id="执行shell脚本的绝对路径"><a href="#执行shell脚本的绝对路径" class="headerlink" title="执行shell脚本的绝对路径"></a>执行shell脚本的绝对路径</h1><p>a2.sources.r2.shell = /bin/bash -c </p>
<h1 id="Describe-the-sink"><a href="#Describe-the-sink" class="headerlink" title="Describe the sink"></a>Describe the sink</h1><p>a2.sinks.k2.type = hdfs </p>
<h1 id="上传到hdfs的路径"><a href="#上传到hdfs的路径" class="headerlink" title="上传到hdfs的路径"></a>上传到hdfs的路径</h1><p>a2.sinks.k2.hdfs.path = hdfs://hadoop102:9000/flume/%Y%m%d/%H<br>#上传文件的前缀<br>a2.sinks.k2.hdfs.filePrefix = logs-<br>#是否按照时间滚动文件夹<br>a2.sinks.k2.hdfs.round = true<br>#多少时间单位创建一个新的文件夹<br>a2.sinks.k2.hdfs.roundValue = 1<br>#重新定义时间单位<br>a2.sinks.k2.hdfs.roundUnit = hour<br>#是否使用本地时间戳<br>a2.sinks.k2.hdfs.useLocalTimeStamp = true<br>#积攒多少个 Event 才 flush 到 HDFS 一次<br>a2.sinks.k2.hdfs.batchSize = 1000<br>#设置文件类型，可支持压缩<br>a2.sinks.k2.hdfs.fileType = DataStream<br>#多久生成一个新的文件 （单位：秒）<br>a2.sinks.k2.hdfs.rollInterval = 600<br>#设置每个文件的滚动大小 （单位：字节）<br>a2.sinks.k2.hdfs.rollSize = 134217700<br>#文件的滚动与 Event 数量无关<br>a2.sinks.k2.hdfs.rollCount = 0<br>#最小副本数<br>a2.sinks.k2.hdfs.minBlockReplicas = 1 </p>
<h1 id="Use-a-channel-which-buffers-events-in-memory"><a href="#Use-a-channel-which-buffers-events-in-memory" class="headerlink" title="Use a channel which buffers events in memory"></a>Use a channel which buffers events in memory</h1><p>#channels阶段以内存的形式保存数据  event数量100<br>a2.channels.c2.type = memory<br>a2.channels.c2.capacity = 1000<br>a2.channels.c2.transactionCapacity = 100 </p>
<h1 id="Bind-the-source-and-sink-to-the-channel"><a href="#Bind-the-source-and-sink-to-the-channel" class="headerlink" title="Bind the source and sink to the channel"></a>Bind the source and sink to the channel</h1><p>#把source和sink和channel对接   source可以对接多个channels  sinks只能对接一个channel<br>a2.sources.r2.channels = c2<br>a2.sinks.k2.channel = c2</code></pre>   </li>1. 启动hdfs集群1. 执行监控配置   <img alt="" class="has" height="360" src="https://img-blog.csdnimg.cn/20190908135744365.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="734">  下面我们再次打开一个控制台，操作hive:  <img alt="" class="has" height="497" src="https://img-blog.csdnimg.cn/20190908140009436.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="590">  在浏览器上查看hdfs:  <img alt="" class="has" height="260" src="https://img-blog.csdnimg.cn/20190908141649630.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="574">  </p>
<h1 id="七：案例三：实时读取目录文件到-HDFS"><a href="#七：案例三：实时读取目录文件到-HDFS" class="headerlink" title="七：案例三：实时读取目录文件到 HDFS"></a>七：案例三：实时读取目录文件到 HDFS</h1><ol>
<li>需求：使用 flume 监听整个目录的文件 <li>创建配置文件job_flume_dir.conf  <img alt="" class="has" height="242" src="https://img-blog.csdnimg.cn/20190908163632722.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="764">   内容：    <pre class="has"><code class="language-bash">#把agent起个名叫a3,sources叫r3,sinks叫k3.hdfs,channels叫c3<br>a3.sources = r3<br>a3.sinks = k3<br>a3.channels = c3 </li>
</ol>
<h1 id="Describe-configure-the-source-1"><a href="#Describe-configure-the-source-1" class="headerlink" title="Describe/configure the source"></a>Describe/configure the source</h1><p>a3.sources.r3.type = spooldir<br>#要监听的目录<br>a3.sources.r3.spoolDir = /opt/module/apache-flume-1.7.0-bin/upload<br>#上传后的文件结尾<br>a3.sources.r3.fileSuffix = .COMPLETED<br>a3.sources.r3.fileHeader = true<br>#忽略所有以.tmp 结尾的文件，不上传<br>a3.sources.r3.ignorePattern = ([^ ]*.tmp) </p>
<h1 id="Describe-the-sink-1"><a href="#Describe-the-sink-1" class="headerlink" title="Describe the sink"></a>Describe the sink</h1><p>a3.sinks.k3.type = hdfs<br>a3.sinks.k3.hdfs.path = hdfs://hadoop102:9000/flume/upload/%Y%m%d/%H<br>#上传文件的前缀<br>a3.sinks.k3.hdfs.filePrefix = upload-<br>#是否按照时间滚动文件夹<br>a3.sinks.k3.hdfs.round = true<br>#多少时间单位创建一个新的文件夹<br>a3.sinks.k3.hdfs.roundValue = 1<br>#重新定义时间单位<br>a3.sinks.k3.hdfs.roundUnit = hour<br>#是否使用本地时间戳<br>a3.sinks.k3.hdfs.useLocalTimeStamp = true<br>#积攒多少个 Event 才 flush 到 HDFS 一次<br>a3.sinks.k3.hdfs.batchSize = 100<br>#设置文件类型，可支持压缩<br>a3.sinks.k3.hdfs.fileType = DataStream<br>#多久生成一个新的文件<br>a3.sinks.k3.hdfs.rollInterval = 600<br>#设置每个文件的滚动大小大概是 128M<br>a3.sinks.k3.hdfs.rollSize = 134217700<br>#文件的滚动与 Event 数量无关<br>a3.sinks.k3.hdfs.rollCount = 0<br>#最小副本数<br>a3.sinks.k3.hdfs.minBlockReplicas = 1 </p>
<h1 id="Use-a-channel-which-buffers-events-in-memory-1"><a href="#Use-a-channel-which-buffers-events-in-memory-1" class="headerlink" title="Use a channel which buffers events in memory"></a>Use a channel which buffers events in memory</h1><p>a3.channels.c3.type = memory<br>#通道中存储的最大事件数<br>a3.channels.c3.capacity = 1000<br>#每个事务通道从源或提供给接收器的最大事件数<br>a3.channels.c3.transactionCapacity = 100 </p>
<h1 id="Bind-the-source-and-sink-to-the-channel-1"><a href="#Bind-the-source-and-sink-to-the-channel-1" class="headerlink" title="Bind the source and sink to the channel"></a>Bind the source and sink to the channel</h1><p>a3.sources.r3.channels = c3<br>a3.sinks.k3.channel = c3 </code></pre>   </li>1.  创建监听的目录，并且添加测试的文件   <img alt="" class="has" height="211" src="https://img-blog.csdnimg.cn/20190908163901941.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="600">1. 执行测试：执行如下脚本后，请向 upload 文件夹中添加文件试试   <img alt="" class="has" height="311" src="https://img-blog.csdnimg.cn/20190908164224658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="601">1. 查看upload目录  <img alt="" class="has" height="233" src="https://img-blog.csdnimg.cn/20190908164321635.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="737">  再添加2个文件  <img alt="" class="has" height="347" src="https://img-blog.csdnimg.cn/20190908164505248.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="588">1.  到hdfs上查看  <img alt="" class="has" height="259" src="https://img-blog.csdnimg.cn/20190908164653537.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="595">         <img alt="" class="has" height="207" src="https://img-blog.csdnimg.cn/20190908164809207.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="565"></p>
<h1 id=""><a href="#" class="headerlink" title=""></a></h1>]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Flume知识点入门学习二</title>
    <url>/2021/07/18/Flume%E7%9F%A5%E8%AF%86%E7%82%B9%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%BA%8C/</url>
    <content><![CDATA[<p>title: Flume知识点入门学习二<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：案例四：Flume 与 Flume 之间数据传递，单 Flume 多 Channel、Sink</p>
<ol>
<li> 需求：使用 flume-1 监控文件变动，flume-1 将变动内容传递给 flume-2，flume-2 负责存储到HDFS。             同时 flume-1 将变动内容传递给 flume-3，flume-3 负责输出到local filesystem      <img alt="" class="has" height="319" src="https://img-blog.csdnimg.cn/20190908221502846.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="640"><li>创建 flume-1.conf，用于监控 hive.log 文件的变动，同时产生两个 channel 和两个 sink 分 别输送给 flume-2 和 flume3，文件名称为job_flume1.conf   <pre class="has"><code class="language-bash"># Name the components on this agent<br>#把agent起个名叫a1,sources叫r1,sinks叫k1 k2,channels叫c1 c2<br>a1.sources = r1<br>a1.sinks = k1 k2<br>a1.channels = c1 c2 <h1 id="将数据流复制给多个-channel"><a href="#将数据流复制给多个-channel" class="headerlink" title="将数据流复制给多个 channel"></a>将数据流复制给多个 channel</h1>a1.sources.r1.selector.type = replicating </li>
</ol>
<h1 id="Describe-configure-the-source"><a href="#Describe-configure-the-source" class="headerlink" title="Describe/configure the source"></a>Describe/configure the source</h1><p>#配置执行监控hive日志<br>a1.sources.r1.type = exec<br>a1.sources.r1.command = tail -F /opt/module/hive/logs/hive.log<br>a1.sources.r1.shell = /bin/bash -c </p>
<h1 id="Describe-the-sink"><a href="#Describe-the-sink" class="headerlink" title="Describe the sink"></a>Describe the sink</h1><p>#这里我们flume1中的sinks对接的是flume2,flume3中的sources,这种对接方式类型我们使用avro<br>a1.sinks.k1.type = avro<br>a1.sinks.k1.hostname = hadoop102<br>a1.sinks.k1.port = 4141 </p>
<p>a1.sinks.k2.type = avro<br>a1.sinks.k2.hostname = hadoop102<br>a1.sinks.k2.port = 4142 </p>
<h1 id="Describe-the-channel"><a href="#Describe-the-channel" class="headerlink" title="Describe the channel"></a>Describe the channel</h1><p>a1.channels.c1.type = memory<br>#通道中存储的最大事件数<br>a1.channels.c1.capacity = 1000<br>#每个事务通道从源或提供给接收器的最大事件数<br>a1.channels.c1.transactionCapacity = 100 </p>
<p>a1.channels.c2.type = memory<br>a1.channels.c2.capacity = 1000<br>a1.channels.c2.transactionCapacity = 100 </p>
<h1 id="Bind-the-source-and-sink-to-the-channel"><a href="#Bind-the-source-and-sink-to-the-channel" class="headerlink" title="Bind the source and sink to the channel"></a>Bind the source and sink to the channel</h1><p>a1.sources.r1.channels = c1 c2<br>a1.sinks.k1.channel = c1<br>a1.sinks.k2.channel = c2 </code></pre> <img alt="" class="has" height="184" src="https://img-blog.csdnimg.cn/20190908223703379.png" width="534"> </li><li> 创建 flume-2.conf，用于接收 flume-1 的 event，同时产生 1 个 channel 和 1 个 sink，将数据输送给 hdfs ,名称为job_flume2.conf    <pre class="has"><code class="language-bash"># Name the components on this agent<br>a2.sources = r1<br>a2.sinks = k1<br>a2.channels = c1 </p>
<h1 id="Describe-configure-the-source-1"><a href="#Describe-configure-the-source-1" class="headerlink" title="Describe/configure the source"></a>Describe/configure the source</h1><p>#表示这个flume的source去hadoop102服务器的4141获取数据<br>a2.sources.r1.type = avro<br>a2.sources.r1.bind = hadoop102<br>a2.sources.r1.port = 4141 </p>
<h1 id="Describe-the-sink-1"><a href="#Describe-the-sink-1" class="headerlink" title="Describe the sink"></a>Describe the sink</h1><p>#这个flume的sinks是将数据传输到hdfs上<br>a2.sinks.k1.type = hdfs<br>a2.sinks.k1.hdfs.path = hdfs://hadoop102:9000/flume2/%Y%m%d/%H<br>#上传文件的前缀<br>a2.sinks.k1.hdfs.filePrefix = flume2-<br>#是否按照时间滚动文件夹<br>a2.sinks.k1.hdfs.round = true<br>#多少时间单位创建一个新的文件夹<br>a2.sinks.k1.hdfs.roundValue = 1<br>#重新定义时间单位<br>a2.sinks.k1.hdfs.roundUnit = hour<br>#是否使用本地时间戳<br>a2.sinks.k1.hdfs.useLocalTimeStamp = true<br>#积攒多少个 Event 才 flush 到 HDFS 一次<br>a2.sinks.k1.hdfs.batchSize = 100<br>#设置文件类型，可支持压缩<br>a2.sinks.k1.hdfs.fileType = DataStream<br>#多久生成一个新的文件<br>a2.sinks.k1.hdfs.rollInterval = 600<br>#设置每个文件的滚动大小大概是 128M<br>a2.sinks.k1.hdfs.rollSize = 134217700<br>#文件的滚动与 Event 数量无关<br>a2.sinks.k1.hdfs.rollCount = 0<br>#最小冗余数<br>a2.sinks.k1.hdfs.minBlockReplicas = 1 </p>
<h1 id="Describe-the-channel-1"><a href="#Describe-the-channel-1" class="headerlink" title="Describe the channel"></a>Describe the channel</h1><p>a2.channels.c1.type = memory<br>a2.channels.c1.capacity = 1000<br>a2.channels.c1.transactionCapacity = 100 </p>
<h1 id="Bind-the-source-and-sink-to-the-channel-1"><a href="#Bind-the-source-and-sink-to-the-channel-1" class="headerlink" title="Bind the source and sink to the channel"></a>Bind the source and sink to the channel</h1><p>a2.sources.r1.channels = c1<br>a2.sinks.k1.channel = c1 </code></pre> <img alt="" class="has" height="184" src="https://img-blog.csdnimg.cn/20190908224342894.png" width="645"> </li><li>创建 flume-3.conf，用于接收 flume-1 的 event，同时产生 1 个 channel 和 1 个 sink，将数据输送给本地目录，名称job_flume3.conf   <pre class="has"><code class="language-bash"># Name the components on this agent<br>a3.sources = r1<br>a3.sinks = k1<br>a3.channels = c1 </p>
<h1 id="Describe-configure-the-source-2"><a href="#Describe-configure-the-source-2" class="headerlink" title="Describe/configure the source"></a>Describe/configure the source</h1><p>#表示这个flume的source去hadoop102服务器的4142获取数据<br>a3.sources.r1.type = avro<br>a3.sources.r1.bind = hadoop102<br>a3.sources.r1.port = 4142 </p>
<h1 id="Describe-the-sink-2"><a href="#Describe-the-sink-2" class="headerlink" title="Describe the sink"></a>Describe the sink</h1><p>#sinks将数据写到本地模式的类型<br>a3.sinks.k1.type = file_roll<br>#注意：输出的本地目录必须是已经存在的目录，如果该目录不存在，并不会创建新的目录<br>a3.sinks.k1.sink.directory = /opt/module/datas/flume3 </p>
<h1 id="Describe-the-channel-2"><a href="#Describe-the-channel-2" class="headerlink" title="Describe the channel"></a>Describe the channel</h1><p>a3.channels.c1.type = memory<br>a3.channels.c1.capacity = 1000<br>a3.channels.c1.transactionCapacity = 100 </p>
<h1 id="Bind-the-source-and-sink-to-the-channel-2"><a href="#Bind-the-source-and-sink-to-the-channel-2" class="headerlink" title="Bind the source and sink to the channel"></a>Bind the source and sink to the channel</h1><p>a3.sources.r1.channels = c1<br>a3.sinks.k1.channel = c1 </code></pre> <img alt="" class="has" height="246" src="https://img-blog.csdnimg.cn/20190908224909157.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="597"> </li>1. 启动hadoop集群，并且开3个hadoop102窗口，用来启动3个flume  <img alt="" class="has" height="137" src="https://img-blog.csdnimg.cn/20190908225340812.png" width="917">1. 执行测试：分别开启对应 flume-job（依次启动 flume-3，flume-2，flume-1），  <img alt="" class="has" height="253" src="https://img-blog.csdnimg.cn/2019090822573657.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="639">   <img alt="" class="has" height="242" src="https://img-blog.csdnimg.cn/20190908225805265.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="637">  <img alt="" class="has" height="251" src="https://img-blog.csdnimg.cn/20190908225834660.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="642">1. 再开一个hadoop102操作hive  <img alt="" class="has" height="355" src="https://img-blog.csdnimg.cn/20190908230034423.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="649">1. 查看效果  ⑴先看flume3是否写到本地，如下，是有数据 的。       <img alt="" class="has" height="293" src="https://img-blog.csdnimg.cn/20190908232517648.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="678">   ⑵查看hdfs上数据           <img alt="" class="has" height="293" src="https://img-blog.csdnimg.cn/20190908232553876.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="660">
 </p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Git之克隆仓库</title>
    <url>/2021/07/18/Git%E4%B9%8B%E5%85%8B%E9%9A%86%E4%BB%93%E5%BA%93/</url>
    <content><![CDATA[<p>title: Git之克隆仓库<br>categories:</p>
<ul>
<li>git</li>
</ul>
<p>—一：简介</p>
<p>      首先我们需要了解一下，我们为什么要克隆仓库？它的作用是什么？        因为在日常的工作中，我们开发项目是一个小团队，是多个人一起开发项目，而不是一个人开发。        那么这样的话，我们就需要将远程仓库的代码克隆一份到本地，然后在本地进行开发，同时在我们        开发完成之后我们是需要将我们开发完成后的代码提交到远程仓库的，这样的话别人就可以获取到        对方提交的代码，才可以一起协作开发。注意：<strong>克隆GitHub上面的仓库前提是本地Git已经和GitHub        远程连接起来了</strong>。</p>
<p>二：我们在GitHub上面创建一个远程仓库进行操作</p>
<p>       ⑴在GitHub上新建一个仓库            <img alt="" class="has" height="604" src="https://img-blog.csdn.net/20180923220712244?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="599">            <img alt="" class="has" height="485" src="https://img-blog.csdn.net/20180923220748307?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="716">       ⑵下面我们需要将在GitHub上创建的远程仓库克隆到本地             a：首先我们在本地新建一个文件夹用于存放仓库                   <img alt="" class="has" height="184" src="https://img-blog.csdn.net/2018092322105792?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="459">           b：通过命令窗口进行操作：先进入到指定的目录下，然后使用克隆命令：                git clone <a href="https://github.com/kangf897570/clone_reso_demo.git">https://github.com/kangf897570/clone_reso_demo.git</a>                注释：git clone +GitHub上创建的仓库地址（被克隆仓库的地址）                <img alt="" class="has" height="145" src="https://img-blog.csdn.net/20180923221720458?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="454">           c：下面我们通过命令创建一个文件提交到本地仓库，并且同步到远程仓库               <img alt="" class="has" height="320" src="https://img-blog.csdn.net/20180923222316889?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="546">               <img alt="" class="has" height="284" src="https://img-blog.csdn.net/20180923222430525?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="566">               <img alt="" class="has" height="268" src="https://img-blog.csdn.net/20180923222659693?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="547">               <img alt="" class="has" height="237" src="https://img-blog.csdn.net/20180923223007917?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="539">               效果：                 <img alt="" class="has" height="361" src="https://img-blog.csdn.net/20180923223049167?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="508"></p>
<p>三：通过SourceTree的图形化界面进行操作</p>
<p>       ⑴在GitHub上面创建一个远程仓库             <img alt="" class="has" height="592" src="https://img-blog.csdn.net/20180923223844860?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="632"><img alt="" class="has" height="476" src="https://img-blog.csdn.net/20180923223914359?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="732">         ⑵打开SourceTree对远程仓库进行克隆操作，点击克隆              <img alt="" class="has" height="532" src="https://img-blog.csdn.net/20180923224315314?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="681">              <img alt="" class="has" height="335" src="https://img-blog.csdn.net/20180923224514744?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="582">        ⑶我们在本地管理器中添加一点文件同步到远程仓库中             <img alt="" class="has" height="382" src="https://img-blog.csdn.net/20180923224737138?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="809">             <img alt="" class="has" height="374" src="https://img-blog.csdn.net/20180923224828279?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="695">               <img alt="" class="has" height="386" src="https://img-blog.csdn.net/20180923225018780?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="540">               <img alt="" class="has" height="330" src="https://img-blog.csdn.net/20180923225322641?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="533">               <img alt="" class="has" height="491" src="https://img-blog.csdn.net/20180923225352768?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="597">             效果：                  <img alt="" class="has" height="419" src="https://img-blog.csdn.net/20180923225441117?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="580"></p>
<p><strong>以上就是克隆的基本操作了。</strong></p>
<p>                             </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
  </entry>
  <entry>
    <title>Git仓库之分支管理</title>
    <url>/2021/07/18/Git%E4%BB%93%E5%BA%93%E4%B9%8B%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<p>title: Git仓库之分支管理<br>categories:</p>
<ul>
<li>git</li>
</ul>
<p>—一：简介</p>
<p>       在日常工作中，如果我们要开发一个功能，但是这个功能模块需要几天的时间才能够完成，那么我们这几天就        无法将我们没有开发完成的代码提交到仓库中，因为怕没有开发完的代码有问题会对原有的功能产生影响，但是        如果我们把这个功能开发完成之后再提交，就会存在丢失进度的风险，因为你不敢去更新别人上传的最新代码，怕        产生冲突。那么这个时候我们就可以使用git仓库的分支管理策略，这个实际上就是一种生成现有代码的物理拷贝，        我们开发的时候只需要切换到当前的分支即可。当然我们的代码库只会有一个主分支，所有提供给用户使用的正式        版本都会在这个主分支上发布。</p>
<p>二：下面我们在本地新建一个本地仓库进行实际演示</p>
<p>       ⑴初始化一个新的仓库，并且向里面添加一个新的文件，然后提交commit到本地仓库             <img alt="" class="has" height="204" src="https://img-blog.csdn.net/20180924215335935?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="510">               <img alt="" class="has" height="275" src="https://img-blog.csdn.net/20180924221746113?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="534">             从上面的git status命令中可以发现，我们默认是在master分支上。        ⑵创建一个新的分支branch_x             <img alt="" class="has" height="99" src="https://img-blog.csdn.net/20180924222103185?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="455">             命令：git branch +分支命令              <img alt="" class="has" height="129" src="https://img-blog.csdn.net/20180924222321248?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="468">              命令：git branch         ⑶切换到我们新建的分支上             <img alt="" class="has" height="179" src="https://img-blog.csdn.net/2018092422270061?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="486">             命令：git checkout + 分支名称        ⑷下面我们在我们新建的分支上向文件中添加内容，并且提交到本地仓库            <img alt="" class="has" height="285" src="https://img-blog.csdn.net/20180924223026874?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="507">       ⑸我们需要切换到master分支，然后将branch_x分支上的新增内容合并到主分支master上           <img alt="" class="has" height="228" src="https://img-blog.csdn.net/20180924223304248?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="484">           合并命令：git merge +要合并到主分支的其他分支名称。       ⑸查看主分支上文件内容            <img alt="" class="has" height="173" src="https://img-blog.csdn.net/20180924223425699?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="443">        ⑹删除分支的命令             <img alt="" class="has" height="161" src="https://img-blog.csdn.net/2018092422355437?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="497">            命令：git branch -d +要删除分支的名称</p>
<p>三：下面我们使用图形化界面演示一下</p>
<p>       ⑴新建一个仓库             <img alt="" class="has" height="424" src="https://img-blog.csdn.net/20180924223830511?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="704">          ⑵向这个仓库中初始化添加一个文件                <img alt="" class="has" height="340" src="https://img-blog.csdn.net/20180924224037552?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="578">           ⑶我们将文件暂存并且提交commit到本地仓库                <img alt="" class="has" height="416" src="https://img-blog.csdn.net/20180924224224235?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="559">         ⑷创建一个分支，点击分支并且指定在哪一个版本代码基础上创建新的分支              <img alt="" class="has" height="341" src="https://img-blog.csdn.net/2018092422434625?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="729">         ⑸在branch_one分支下修改文件内容，并且提交             <img alt="" class="has" height="272" src="https://img-blog.csdn.net/2018092422464935?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="812">             <img alt="" class="has" height="340" src="https://img-blog.csdn.net/20180924224807270?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="679">        ⑹切换到master分支              <img alt="" class="has" height="289" src="https://img-blog.csdn.net/20180924225051280?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="705">         ⑺合并branch_demo上的内容              <img alt="" class="has" height="616" src="https://img-blog.csdn.net/20180924225343341?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="751">             效果：OK               <img alt="" class="has" height="336" src="https://img-blog.csdn.net/20180924225516380?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="749"></p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
  </entry>
  <entry>
    <title>Git工具之标签管理</title>
    <url>/2021/07/18/Git%E5%B7%A5%E5%85%B7%E4%B9%8B%E6%A0%87%E7%AD%BE%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<p>title: Git工具之标签管理<br>categories:</p>
<ul>
<li>git</li>
</ul>
<p>—# 一：简介</p>
<p>         首先我们需要知道标签是用来做什么的？它具体的作用是什么？          在我们平时的工作中，当我们开发完一个模块或者功能时，我们需要发布一个新的版本，通常我们会在版本库中打一个标                 签，这样我们就可以知道版本所对应的时间，那么以后如果我们想要回滚到某一时刻的版本，那么我们就可以通过标签找到             这一时间的版本，从而实现回滚。并且创建标签和删除标签的效率是很高的。在实际的项目中一般都是通过标签来进行版本             回滚的。</p>
<p>二：和标签相关的命令：</p>
<p>         1：查看所有标签                  git tag</p>
<p>          2：创建标签                   git tag name   —-&gt;name就是你要创建的标签的名称           3：指定提交标签的备注信息                  git tag -a name -m “标签备注信息”           4：删除标签                   git tag -d name   —-&gt;name就是你要删除的标签的名称          5：标签发布(这个是将本地仓库的标签同步到远程仓库中)                   git push origin name   </p>
<p>三：下面我们通过实际的例子来看一下</p>
<p>        1：我们关联好GitHub上的远程仓库和本地仓库               <img alt="" class="has" height="432" src="https://img-blog.csdn.net/20180924102746651?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="582">               <img alt="" class="has" height="196" src="https://img-blog.csdn.net/20180924102851586?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="560"></p>
<p>         2：我们向本地仓库中添加一个文件                <img alt="" class="has" height="296" src="https://img-blog.csdn.net/20180924103229919?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="539">                <img alt="" class="has" height="317" src="https://img-blog.csdn.net/20180924103814964?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="428">                <img alt="" class="has" height="217" src="https://img-blog.csdn.net/20180924104003831?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="556">                <img alt="" class="has" height="430" src="https://img-blog.csdn.net/20180924104026921?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="554">               3：下面我们来查看一下当前仓库的所有标签                    <img alt="" class="has" height="163" src="https://img-blog.csdn.net/20180924104315571?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="549">                 4：下面我们来创建一个标签                    <img alt="" class="has" height="149" src="https://img-blog.csdn.net/20180924104753986?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="395">               5：因为我们刚刚文件已经上传到远程仓库，所以我们将标签页同步过去                   <img alt="" class="has" height="111" src="https://img-blog.csdn.net/20180924105727186?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="532">                   <img alt="" class="has" height="437" src="https://img-blog.csdn.net/20180924105810825?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="425"></p>
<p>              6：那么下面我们再通过SourceTree工具再次提交一次修改后的文件                     <img alt="" class="has" height="278" src="https://img-blog.csdn.net/20180924191657488?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="617">                     <img alt="" class="has" height="416" src="https://img-blog.csdn.net/20180924191908206?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="702">                     <img alt="" class="has" height="392" src="https://img-blog.csdn.net/2018092419213989?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="598">                     <img alt="" class="has" height="417" src="https://img-blog.csdn.net/20180924193734365?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="635">               7：下面我们使用SourceTree工具为刚刚提交的版本打上标签                    <img alt="" class="has" height="366" src="https://img-blog.csdn.net/20180924194043137?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="634">                   <img alt="" class="has" height="464" src="https://img-blog.csdn.net/20180924194314598?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="508">                      8：下面我们如果将标签删除会怎么样呢？                       <img alt="" class="has" height="254" src="https://img-blog.csdn.net/20180924194730285?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="363">                               <img alt="" class="has" height="136" src="https://img-blog.csdn.net/20180924194756286?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="369">                       <img alt="" class="has" height="247" src="https://img-blog.csdn.net/20180924194924736?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="483">            <strong>上面就是Git标签管理基本的内容了OK!</strong></p>
<p> </p>
<p>  </p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
  </entry>
  <entry>
    <title>Git查看某一个文件的历史提交信息</title>
    <url>/2021/07/18/Git%E6%9F%A5%E7%9C%8B%E6%9F%90%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6%E7%9A%84%E5%8E%86%E5%8F%B2%E6%8F%90%E4%BA%A4%E4%BF%A1%E6%81%AF/</url>
    <content><![CDATA[<p>title: Git查看某一个文件的历史提交信息<br>categories:</p>
<ul>
<li>git</li>
</ul>
<p>—工作中我们有时候想要查看某一个文件的历史提交版本,]</p>
<p>还想看都修改过那些内容,那么这两个简单的命令就会帮到你了,</p>
<p>话不多说,comeBaby……</p>
<p>1,首先查看一个文件的历史提交信息</p>
<p>**git log 文件名 **</p>
<img alt="" src="https://img-blog.csdnimg.cn/img_convert/b6e7617d09735246118484559efcd0a7.png">

<p>2.查看某个版本文件修改情况</p>
<p><strong>git show 版本号  文件名</strong></p>
<img alt="" src="https://img-blog.csdnimg.cn/img_convert/b556f11dc21547773f506a6bac15483f.png">
]]></content>
      <categories>
        <category>Git</category>
      </categories>
  </entry>
  <entry>
    <title>Git版本控制工具之Windows系统安装</title>
    <url>/2021/07/18/Git%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%B7%A5%E5%85%B7%E4%B9%8BWindows%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>title: Git版本控制工具之Windows系统安装<br>categories:</p>
<ul>
<li>git</li>
</ul>
<p>—1：Git安装</p>
<p>        ⑴Windows版本Git下载</p>
<p>                a：地址</p>
<p>                        </p>
<p>                        <img alt="" class="has" height="514" src="https://img-blog.csdn.net/20180922114746546?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="672"></p>
<p>                        注意：我们上面下载的是2.19.0的windows 64位的版本。</p>
<p>       </p>
<p>⑵进行安装如下</p>
<p>               a：点击安装的包</p>
<p>                        <img alt="" class="has" height="46" src="https://img-blog.csdn.net/20180922114821871?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="350">      </p>
<p>                        <img alt="" class="has" height="392" src="https://img-blog.csdn.net/20180922114822778?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="509"></p>
<p>                        <img alt="" class="has" height="387" src="https://img-blog.csdn.net/20180922114822704?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="508"></p>
<p>                        </p>
<p>                        <img alt="" class="has" height="394" src="https://img-blog.csdn.net/20180922114824350?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="509"></p>
<p>                        <img alt="" class="has" height="394" src="https://img-blog.csdn.net/20180922114822622?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="506"></p>
<p>                        <img alt="" class="has" height="392" src="https://img-blog.csdn.net/20180922114824786?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="507"></p>
<p>                        <img alt="" class="has" height="389" src="https://img-blog.csdn.net/20180922114824339?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="508"></p>
<p>                        <img alt="" class="has" height="392" src="https://img-blog.csdn.net/20180922114824317?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="507"></p>
<p>                        后面一路Next即可，对于初级的用户而言，不需要太关注里面的安装信息。</p>
<p>      ⑶安装完成之后我们需要配置自己的用户信息</p>
<p>            a：为什么我们需要配置用户信息呢？</p>
<p>                    因为Git是分布式版本控制系统， 所以要链接Git我们需要设置相应的链接用户。</p>
<p>            b：配置用户信息的命令</p>
<p>                    1：git config –global user.name “tyler”   ——&gt;这个是用来设置用户名的</p>
<p>                    2：git config –global user.email “<a href="mailto:&#x74;&#121;&#x6c;&#101;&#x72;&#x40;&#x31;&#54;&#x33;&#x2e;&#x63;&#x6f;&#x6d;">&#x74;&#121;&#x6c;&#101;&#x72;&#x40;&#x31;&#54;&#x33;&#x2e;&#x63;&#x6f;&#x6d;</a>“   ——&gt;这个是用来设置用户邮箱的</p>
<p>                    </p>
<p>                    注释：  这两条信息很重要，每次Git提交时都会引用这两条信息，说明是谁提交了更新，所以</p>
<p>                                会随着更新内容一起被永久的纳入历史记录。</p>
<p>                                <img alt="" class="has" height="77" src="https://img-blog.csdn.net/20180922114849953?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="674"></p>
<p>2：安装之后我们需要通过命令窗口打开Git的配置信息</p>
<p>        a：在开始—》搜索Git Bash</p>
<p>                <img alt="" class="has" height="607" src="https://img-blog.csdn.net/20180922114930158?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="392"></p>
<p>         b：打开后的效果</p>
<p>                 <img alt="" class="has" height="376" src="https://img-blog.csdn.net/201809221149314?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="583">      </p>
<p>         c：在窗口配置我们的用户信息</p>
<p>                <img alt="" class="has" height="215" src="https://img-blog.csdn.net/20180922114931757?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="464"></p>
<p>        d：下面我们通过下面的命令查看用户信息是否配置成功</p>
<p>                <img alt="" class="has" height="63" src="https://img-blog.csdn.net/20180922114931217?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="264"></p>
<p>                <img alt="" class="has" height="365" src="https://img-blog.csdn.net/20180922114931759?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="478"></p>
<p>         OK上面的操作之后就代表Git已经安装OK了。</p>
<p> </p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
  </entry>
  <entry>
    <title>Hadoop之HDFS文件系统</title>
    <url>/2021/07/18/Hadoop%E4%B9%8BHDFS%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>title: Hadoop之HDFS文件系统<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：HDFS概述</p>
<ol>
<li>HDFS产生的背景       随着数据量越来越大，在一个操作系统管辖的范围内存不下了，那么就分配到更多的操作系统 管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式 文件管理系统。HDFS只是分布式文件管理系统中的一种。1.  HDFS概念       HDFS它是一个文件系统，用于存储文件，通过目录树来定位文件，其次它是分布式的，由很多 服务器联合起来实现其功能，集群中的服务器有各自的角色。       HDFS的设计适合一次写入，多次读出的场景，且不支持文件的修改。适合用来做数据分析，并 不适合用来做网盘应用。1. HDFS的优缺点       优点：                a：高容错性                             ⑴数据自动保存多个副本。它通过增加副本的形式，提高容错性。                             ⑵某一个副本丢失以后，它可以自动恢复。                b：适合大数据处理                             ⑴数据规模：                                         能够处理数据规模达到GB,TB甚至PB级别的数据。                             ⑵文件规模：                                         能够处理百万规模以上的文件数量，数量相当之大。                c：流式数据访问                             ⑴一次写入，多次读取，不能修改，只能追加                             ⑵它能保证数据的一致性。                d：可构建在廉价的机器上，通过多副本机制，提高可靠性。       缺点：                a：不适合低延迟数据访问。比如毫秒级的存储数据，是做不到的。                b：无法高效的对大量小文件进行存储                              ⑴存储大量小文件的话，它会占用NameNode大量的内存来存储文件，目录                                  和块信息。这样是不可取的，因为NameNode的内存总是有限的。                              ⑵小文件存储的寻道时间会超过读取时间，它违反了HDFS的设计目标。                c：并发写入，文件随机修改                               ⑴一个文件只能有一个写，不允许多个线程同时写。                               ⑵仅支持数据append(追加)，不支持文件随机修改。              <h1 id="二：HDFS块大小"><a href="#二：HDFS块大小" class="headerlink" title="二：HDFS块大小"></a>二：HDFS块大小</h1></li>
</ol>
<p>        <img alt="" class="has" height="136" src="https://img-blog.csdnimg.cn/20190714220247623.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="775">                    <img alt="" class="has" height="372" src="https://img-blog.csdnimg.cn/2019071422120926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="667">   </p>
<h1 id="三：HDFS命令行操作"><a href="#三：HDFS命令行操作" class="headerlink" title="三：HDFS命令行操作"></a>三：HDFS命令行操作</h1><ol>
<li>首先启动集群  a：集群的部署重新调整了一下       <img alt="" class="has" height="151" src="https://img-blog.csdnimg.cn/20190717215248590.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="630">  b：在hadoop102上启动namenode,datanode以及secondarynamenode        <img alt="" class="has" height="199" src="https://img-blog.csdnimg.cn/20190717215346270.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="516">  c：在hadoop103上启动yarn        <img alt="" class="has" height="134" src="https://img-blog.csdnimg.cn/2019071721551871.png" width="403">       OK集群启动完毕。1. 相关命令  <img alt="" class="has" height="380" src="https://img-blog.csdnimg.cn/20190717215855669.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="720">  <img alt="" class="has" height="352" src="https://img-blog.csdnimg.cn/20190717220258474.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="687">         <h1 id="四：HDFS客户端环境准备"><a href="#四：HDFS客户端环境准备" class="headerlink" title="四：HDFS客户端环境准备"></a>四：HDFS客户端环境准备</h1></li>
<li>通过Eclipse去连接hdfs，首先准备jar包  a：将hadoop-2.7.2.tar.gz解压到非中文目录       <img alt="" class="has" height="228" src="https://img-blog.csdnimg.cn/20190717223355164.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="350">  b：进入hadoop-2.7.2\share\hadoop文件夹，查找所有jar包，并且把jar都拷贝出来到新建的lib文件夹      <img alt="" class="has" height="341" src="https://img-blog.csdnimg.cn/20190717223948728.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="572">  c：新建一个source文件夹，将-source.jar结尾的jar挑出来，放到source文件夹中       <img alt="" class="has" height="322" src="https://img-blog.csdnimg.cn/20190717224052282.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="551">   d：再建立一个test文件夹，将-tests.jar结尾的jar挑出来，放到test文件夹中           <img alt="" class="has" height="281" src="https://img-blog.csdnimg.cn/20190718210547295.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="686">      1. Eclipse环境准备   ⑴配置hadoop环境变量         <img alt="" class="has" height="268" src="https://img-blog.csdnimg.cn/20190718212303557.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="414">         1. 创建第一个java工程HdfsClientDemo1         <img alt="" class="has" height="191" src="https://img-blog.csdnimg.cn/20190718212853542.png" width="374">    引入上面准备的jar包，除了test和source挑出的jar，其它的都引入。 ⑴将本地文件上传到hdfs上的第一种方式       <img alt="" class="has" height="325" src="https://img-blog.csdnimg.cn/20190718220301321.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="504">       注意：运行的时候我们需要配置环境变量，最后执行main方法       <img alt="" class="has" height="254" src="https://img-blog.csdnimg.cn/20190718220359443.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="411">      效果：     <img alt="" class="has" height="189" src="https://img-blog.csdnimg.cn/20190718220450436.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="476">     <img alt="" class="has" height="338" src="https://img-blog.csdnimg.cn/20190718220523822.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="473">  ⑵第二种方式，不需要配置环境变量，直接在代码中配置用户名，效果和上面一样       <img alt="" class="has" height="260" src="https://img-blog.csdnimg.cn/20190718221021277.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="591">       1. HDFS文件上传   ⑴在项目的src根目录下引入hdfs-site.xml配置文件，默认会读取根目录下的这个文件        <img alt="" class="has" height="303" src="https://img-blog.csdnimg.cn/20190719221020921.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="700">        <img alt="" class="has" height="362" src="https://img-blog.csdnimg.cn/20190719221208565.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="577">       效果：       <img alt="" class="has" height="254" src="https://img-blog.csdnimg.cn/20190719221310378.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="605">1. 同理，我们可以直接在代码里面配置，这个优先级最高，可覆盖配置文件中的配置  <img alt="" class="has" height="343" src="https://img-blog.csdnimg.cn/20190719221451855.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="540">  效果：  <img alt="" class="has" height="328" src="https://img-blog.csdnimg.cn/20190719221609756.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="570">1. HDFS文件下载  <img alt="" class="has" height="403" src="https://img-blog.csdnimg.cn/20190719223003129.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="567"> 效果：<img alt="" class="has" height="214" src="https://img-blog.csdnimg.cn/20190719223041958.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="512">1. HDFS创建目录  <img alt="" class="has" height="212" src="https://img-blog.csdnimg.cn/20190719223816315.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="612"><img alt="" class="has" height="245" src="https://img-blog.csdnimg.cn/20190719223835240.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="615">1. HDFS文件删除操作  <img alt="" class="has" height="217" src="https://img-blog.csdnimg.cn/20190719225219938.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="571">1. HDFS上文件名称修改，第一个参数是原文件名，第二个是新的名称  <img alt="" class="has" height="196" src="https://img-blog.csdnimg.cn/20190719225736608.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="570"><li>HDFS文件详情的查看，主要是查看文件的名称，权限，长度，块信息   <pre class="has"><code class="language-java">public void readListFiles() throws IOException, InterruptedException, URISyntaxException &#123;<pre><code> //1：获取hadoop的文件系统
 Configuration configuration = new Configuration();
 //这里配置的是和core-site.xml文件中一样，主要是namenode的路径
 FileSystem fs = FileSystem.get(new URI(&quot;hdfs://hadoop102:9000&quot;), configuration, &quot;kgf&quot;);
 //2:在HDFS上修改文件名称
 RemoteIterator&amp;lt;LocatedFileStatus&amp;gt; fileStatus = fs.listFiles(new Path(&quot;/&quot;),true);
 while(fileStatus.hasNext()) &#123;
     LocatedFileStatus file = fileStatus.next();
     //文件名称
     System.out.println(file.getPath().getName());
     //文件大小
     System.out.println(file.getLen());
     //文件权限
     System.out.println(file.getPermission());
     //文件所属组
     System.out.println(file.getGroup());
     //获取文件块信息
     BlockLocation[] blockLocations = file.getBlockLocations();
     for (BlockLocation blockLocation : blockLocations) &#123;
         //获取文件所属节点信息
         String[] hosts = blockLocation.getHosts();
         for (String host : hosts) &#123;
             System.out.println(host);
         &#125;
     &#125;
     System.out.println(&quot;====================================&quot;);
 &#125;
 //3:关闭资源
 fs.close();
</code></pre>
 }</code></pre> 效果：<img alt="" class="has" height="455" src="https://img-blog.csdnimg.cn/20190719231824473.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="446"> </li>1. HDFS上文件和文件夹的判断  <img alt="" class="has" height="375" src="https://img-blog.csdnimg.cn/2019071923260996.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="636"></li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hadoop之编译源码</title>
    <url>/2021/07/18/Hadoop%E4%B9%8B%E7%BC%96%E8%AF%91%E6%BA%90%E7%A0%81/</url>
    <content><![CDATA[<p>title: Hadoop之编译源码<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：服务器，jar包等准备</p>
<ol>
<li>首先我们需要准备一台内存大约4G左右的服务器，2G的内存不一定够，4G的稳妥一点，并且  最好是一个纯净版的服务器，就是除了网络，主机名之外其它什么都没有配置的。1. 采用root用户编译，减少文件夹权限出现问题1. 将准备好的包上传到服务器上             <img alt="" class="has" height="249" src="https://img-blog.csdnimg.cn/20190713212010732.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="730">1. 安装JDK A：将jdk解压到module文件夹，并且配置JAVA_HOME路径在/etc/profile        <img alt="" class="has" height="157" src="https://img-blog.csdnimg.cn/2019071321231673.png" width="469">        <img alt="" class="has" height="196" src="https://img-blog.csdnimg.cn/20190713212339654.png" width="509">        效果：          <img alt="" class="has" height="181" src="https://img-blog.csdnimg.cn/20190713212419149.png" width="609"><h1 id="二：开始配置MAVEN"><a href="#二：开始配置MAVEN" class="headerlink" title="二：开始配置MAVEN"></a>二：开始配置MAVEN</h1></li>
<li>解压软件包到module  <img alt="" class="has" height="191" src="https://img-blog.csdnimg.cn/20190714104529965.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="699">  <img alt="" class="has" height="145" src="https://img-blog.csdnimg.cn/20190714104557576.png" width="589">1.  配置MAVEN的环境变量  在/etc/profile中配置  <img alt="" class="has" height="107" src="https://img-blog.csdnimg.cn/20190714104718607.png" width="470">            <img alt="" class="has" height="226" src="https://img-blog.csdnimg.cn/2019071410500076.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="511">      <img alt="" class="has" height="74" src="https://img-blog.csdnimg.cn/20190714105045844.png" width="465">   <img alt="" class="has" height="188" src="https://img-blog.csdnimg.cn/201907141051189.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="718"><h1 id="三：开始配置ANT"><a href="#三：开始配置ANT" class="headerlink" title="三：开始配置ANT"></a>三：开始配置ANT</h1></li>
<li>解压软件包        <img alt="" class="has" height="118" src="https://img-blog.csdnimg.cn/20190714105350368.png" width="771">        <img alt="" class="has" height="191" src="https://img-blog.csdnimg.cn/20190714105419404.png" width="643">1.   配置ANT的环境变量        <img alt="" class="has" height="285" src="https://img-blog.csdnimg.cn/20190714105658799.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="556">1.   效果       <img alt="" class="has" height="129" src="https://img-blog.csdnimg.cn/20190714105742835.png" width="552">        <h1 id="四：安装glibc-headers-和g-命令"><a href="#四：安装glibc-headers-和g-命令" class="headerlink" title="四：安装glibc-headers 和g++命令"></a>四：安装glibc-headers 和g++命令</h1></li>
<li>安装glibc-headers  命令：yum install glibc-headers1. 安装g++   命令：yum install gcc-c++         1. 安装make    命令：yum install make1. 安装cmake    命令：yum install cmake<h1 id="五：开始配置protobuf"><a href="#五：开始配置protobuf" class="headerlink" title="五：开始配置protobuf"></a>五：开始配置protobuf</h1></li>
<li>解压软件包      <img alt="" class="has" height="104" src="https://img-blog.csdnimg.cn/20190714110646897.png" width="642">      <img alt="" class="has" height="206" src="https://img-blog.csdnimg.cn/20190714110706298.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="620">1.  开始配置protobuf   a：进入到/opt/module/protobuf-2.5.0目录下，执行./configure命令         <img alt="" class="has" height="117" src="https://img-blog.csdnimg.cn/20190714110911980.png" width="457">     b：在使用make命令编译一下        <img alt="" class="has" height="98" src="https://img-blog.csdnimg.cn/2019071411114969.png" width="443">   c：使用make check命令         <img alt="" class="has" height="104" src="https://img-blog.csdnimg.cn/20190714111522363.png" width="451">    d：执行make install          <img alt="" class="has" height="105" src="https://img-blog.csdnimg.cn/20190714111653738.png" width="451">    e：执行ldconfig          <img alt="" class="has" height="84" src="https://img-blog.csdnimg.cn/2019071411185587.png" width="399">    f：配置环境变量           <img alt="" class="has" height="246" src="https://img-blog.csdnimg.cn/20190714112330812.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="389">           <img alt="" class="has" height="114" src="https://img-blog.csdnimg.cn/20190714112231262.png" width="531">         1. 安装openssl库  命令：yum install openssl-devel  <img alt="" class="has" height="119" src="https://img-blog.csdnimg.cn/20190714112516456.png" width="560">1. 安装ncurses-devel库      命令：yum install ncurses-devel   <img alt="" class="has" height="89" src="https://img-blog.csdnimg.cn/20190714112653636.png" width="564">    <h1 id="六：开始编译源码"><a href="#六：开始编译源码" class="headerlink" title="六：开始编译源码"></a>六：开始编译源码</h1></li>
<li> 将hadoop-2.7.2-src.tar.gz源码包解压到/opt目录  <img alt="" class="has" height="157" src="https://img-blog.csdnimg.cn/20190714113147233.png" width="569"><img alt="" class="has" height="186" src="https://img-blog.csdnimg.cn/20190714113210834.png" width="632">1.  进入到/opt/hadoop-2.7.2-src目录，通过MAVEN执行编译命令 （时间大约30分钟）  命令：mvn package -Pdist,native -DskipTests -Dtar  <img alt="" class="has" height="107" src="https://img-blog.csdnimg.cn/20190714113733978.png" width="747">1. 效果  <img alt="" class="has" height="799" src="https://img-blog.csdnimg.cn/20190714131840370.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="770">1. 成功后的64位hadoop包在/opt/hadoop-2.7.2-src/hadoop-dist/target目录下  <img alt="" class="has" height="239" src="https://img-blog.csdnimg.cn/20190714132131141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="712">​​​​​​​</li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hadoop之完全分布式模式环境搭建</title>
    <url>/2021/07/18/Hadoop%E4%B9%8B%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>title: Hadoop之完全分布式模式环境搭建<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—title: Hadoop之完全分布式模式环境搭建<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—rsync -rvl $pdir/$fname $user@hadoop202:$pdir<br></code></pre>  b:在103的服务器上，在/opt/module/hadoop-2.7.2/etc下执行下面命令      <img alt="" class="has" height="402" src="https://img-blog.csdnimg.cn/20190710224709359.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="417">           </li></p>
<h1 id="七：集群启动及测试"><a href="#七：集群启动及测试" class="headerlink" title="七：集群启动及测试"></a>七：集群启动及测试</h1><ol>
<li> 进入/opt/module/hadoop-2.7.2目录下，103，104，202三台服务器都要清理之前启动的数据   <img alt="" class="has" height="427" src="https://img-blog.csdnimg.cn/20190710225308526.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="395">1.  第一次启动集群，需要格式化namenode,进入/opt/module/hadoop-2.7.2目录下，只需要格式化103即可，因为我们  的namenode节点配置在103节点上   命令：bin/hdfs namenode -format   <img alt="" class="has" height="327" src="https://img-blog.csdnimg.cn/20190710225826151.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="607">1. 下面我们在103这个namenode的节点上去启动集群，当然ssh必须要配置完成的情况下,进入/opt/module/hadoop-2.7.2目录下  命令：sbin/start-dfs.sh  这个命令一次性把namenode和datanode启动起来   <img alt="" class="has" height="239" src="https://img-blog.csdnimg.cn/20190710230437871.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="568">          我们可以分别到104，202服务器去看看   <img alt="" class="has" height="141" src="https://img-blog.csdnimg.cn/20190710230549856.png" width="328"><img alt="" class="has" height="138" src="https://img-blog.csdnimg.cn/20190710230604118.png" width="415">1. 因为我们的resourcemanager是在104上面的，我们在104上启动resourcemanager和nodemanager, 进入/opt/module/hadoop-2.7.2目录下  命令：sbin/start-yarn.sh<img alt="" class="has" height="364" src="https://img-blog.csdnimg.cn/20190710231012172.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="567">  可以到103，202服务器上查看，发现NodeManager也启动了，可以对比上面我们的集群规划。1. 集群测试    ⑴集群基本测试           ①上传文件到集群                      a：上传小文件                                ㈠首先在103的hdfs上创建一个文件夹                                           命令：hadoop fs -mkdir -p /user/kgf/input                                            <img alt="" class="has" height="179" src="https://img-blog.csdnimg.cn/20190712223047447.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="579">                                            可以通过浏览器50070端口页面看效果：                                            <img alt="" class="has" height="302" src="https://img-blog.csdnimg.cn/20190712223135342.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="513">                                 ㈡下面我们创建一个文件通过命令上传到上面刚建的hdfs上的文件夹中                                       <img alt="" class="has" height="176" src="https://img-blog.csdnimg.cn/20190712223517227.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="572">                                         <img alt="" class="has" height="200" src="https://img-blog.csdnimg.cn/20190712223543887.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="585">                                       点击发现，三台服务器上都有该文件备份：                                       <img alt="" class="has" height="338" src="https://img-blog.csdnimg.cn/201907122245459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="373">                      b：上传一个大文件试试，大于128M的，因为我们可以发现上面Block Size是128，那么                            大于128M时，会怎么样呢？ 下面开始上传：                           <img alt="" class="has" height="114" src="https://img-blog.csdnimg.cn/20190712225153998.png" width="479">                           <img alt="" class="has" height="140" src="https://img-blog.csdnimg.cn/20190712225307761.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="530">                          效果：                             <img alt="" class="has" height="230" src="https://img-blog.csdnimg.cn/20190712225509961.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="577">                             <img alt="" class="has" height="343" src="https://img-blog.csdnimg.cn/20190712225627630.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="416">                                                       1. 集群时间同步        ⑴问题：因为我们配置的是集群，那么我们在跑数据的时候，这几台服务器的时间必须要保持一致，                       不然会出现问题。        ⑵时间同步的方式                    找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，比如每隔十分钟同步一次。             注意：配置时间同步操作必须使用root用户。        ⑶时间服务器配置（必须是root用户）                    a：检测ntp是否安装，命令：rpm -qa | grep ntp                          <img alt="" class="has" height="179" src="https://img-blog.csdnimg.cn/20190713084812614.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="486">                   b：修改ntp配置文件，路径：/etc/ntp.conf                           ①设置本地网络上的主机不受限制                                  <img alt="" class="has" height="113" src="https://img-blog.csdnimg.cn/20190713085230255.png" width="567">                            ②设置为不采用公共的服务器                                  <img alt="" class="has" height="102" src="https://img-blog.csdnimg.cn/20190713085539502.png" width="433">                            ③添加默认的一个内部时钟数据，使用它为局域网用户提供服务                                 <img alt="" class="has" height="165" src="https://img-blog.csdnimg.cn/20190713085904915.png" width="499">                  c：修改/etc/sysconfig/ntpd文件                             a：让硬件时间与系统时间一起同步                                  <img alt="" class="has" height="137" src="https://img-blog.csdnimg.cn/2019071309050714.png" width="378">                             b：重启ntpd                                  命令：systemctl status ntpd   查看ntpd状态                                  启动命令：systemctl start ntpd                             c：设置开启自启动ntp服务                                   执行：systemctl enable ntpd.service         ⑷其它机器配置（必须是root用户）               a：在其它机器上配置10分钟与时间服务器同步一次（生产环境一般是10分钟，这里我们演示就1分钟）                      命令：crontab -e然后编写下面的脚本命令                       */1 * * * * /usr/sbin/ntpdate 要同步时间的服务器地址               b：下面我们先同步104服务器                        <img alt="" class="has" height="179" src="https://img-blog.csdnimg.cn/20190713093634836.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="454">                        <img alt="" class="has" height="122" src="https://img-blog.csdnimg.cn/20190713093705895.png" width="454">               c：同理，我们同步202的时间                     <img alt="" class="has" height="138" src="https://img-blog.csdnimg.cn/20190713093825473.png" width="623">               d：测试，我们分别查看3台服务器时间，三台目前都是这个时间                    <img alt="" class="has" height="98" src="https://img-blog.csdnimg.cn/20190713094042110.png" width="369">                    下面我们将104的时间修改掉                     <img alt="" class="has" height="222" src="https://img-blog.csdnimg.cn/20190713094506658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="425">                    一分钟后…..可以发现时间又同步回来了。                     <img alt="" class="has" height="211" src="https://img-blog.csdnimg.cn/2019071309463594.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="749"><h1 id=""><a href="#" class="headerlink" title=""></a></h1></li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hadoop知识点学习</title>
    <url>/2021/07/18/Hadoop%E7%9F%A5%E8%AF%86%E7%82%B9%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>title: Hadoop知识点学习<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—title: Hadoop知识点学习<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—1. 1. 1. 1. 1. 1. 1. </p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hbase入门知识点入门学习一</title>
    <url>/2021/07/18/Hbase%E5%85%A5%E9%97%A8%E7%9F%A5%E8%AF%86%E7%82%B9%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%B8%80/</url>
    <content><![CDATA[<p>title: Hbase入门知识点入门学习一<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：简介</p>
<ol>
<li>Hbase角色   Hbase一共存在两个角色，一个HMaster(主节点) ，一个RegionServer (从节点)1. HMaster功能  ⑴监控 RegionServer   ⑵处理 RegionServer 故障转移   ⑶处理元数据的变更   ⑷处理 region 的分配或移除   ⑸在空闲时间进行数据的负载均衡   ⑹通过 Zookeeper 发布自己的位置给客户端 1. RegionServer 功能  ⑴负责存储 HBase 的实际数据   ⑵处理分配给它的 Region(可以理解为table，用来存储数据)   ⑶刷新缓存到 HDFS  ⑷维护 HLog   ⑸执行压缩   ⑹负责处理 Region 分片 1.          <h1 id="二：Hbase架构"><a href="#二：Hbase架构" class="headerlink" title="二：Hbase架构"></a>二：Hbase架构</h1></li>
<li> 架构图如下：  <img alt="" class="has" height="476" src="https://img-blog.csdnimg.cn/20190921111927883.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="679">  ⑴客户端client:           Client 访问用户数据前需要首先访问 ZooKeeper，因为ZooKeeper中存放着数据的元数据地址信息，      ZooKeeper负责维护元数据信息。  ⑵HRegionServer：           client通过ZooKeeper找到了元数据信息，那么就找到了这个数据的地址，这个数据又是存放在       HRegionServer中的，那么现在需要通过HRegionServer去访问数据本身了。       HRegionServer中又分为如下几个模块：       a：HLog               存在本地磁盘中用来做灾难恢复使用，HLog记录数据的所有变更，一旦region server 宕机，就可以从log中进行恢复。       b：HRegion（一个HRegionServer可以维护和管理多个HRegion）                  table在行的方向上分隔为多个Region。Region是HBase中分布式存储和负载均衡的最小单元，             即不同的region可以分别在不同的Region Server上，但同一个Region是不会拆分到多个server上。                  Region按大小分隔，每个表一般是只有一个region。随着数据不断插入表，region不断增大，             当region的某个列族达到一个阈值时就会分成两个新的region。       c：Store（一个HRegion中包含多个store）                   每一个region由一个或多个store组成，至少是一个store，hbase会把一起访问的数据放在一个store里面，             即为每个 ColumnFamily建一个store，如果有几个ColumnFamily，也就有几个Store。一个Store由一个             memStore和0或者 多个StoreFile组成。 HBase以store的大小来判断是否需要切分region。             HFile 存储在 Store 中，一个 Store 对应 HBase 表中的一个列族。        d：MemStore（一个Store对应一个MemStore）                    memStore 是放在内存里的。保存修改的数据即keyValues。当memStore的大小达到一个             阀值（默认128MB）时，memStore会被flush到文 件，即生成一个快照。目前hbase 会有一个            线程来负责memStore的flush操作。        e：StoreFile                    memStore内存中的数据写到文件后就是StoreFile，StoreFile底层是以HFile的格式保存。             当storefile文件的数量增长到一定阈值后，系统会进行合并（minor、major compaction），              在合并过程中会进行版本合并和删除工作（majar），形成更大的storefile。            f：HFile                   HBase中KeyValue数据的存储格式，HFile是Hadoop的 二进制格式文件，实际上StoreFile就是              对Hfile做了轻量级包装，即StoreFile底层就是HFile。这是在磁盘上保存原始数据的实际的物理文件，             是实际的存储文件。    <h1 id="三：HBase-部署与使用"><a href="#三：HBase-部署与使用" class="headerlink" title="三：HBase 部署与使用"></a>三：HBase 部署与使用</h1></li>
<li> 解压 HBase 到指定目录  <img alt="" class="has" height="223" src="https://img-blog.csdnimg.cn/20190921205105140.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="474">1.  修改hbase-env.sh 配置文件，在/opt/module/hbase-1.3.1/conf/目录下  <img alt="" class="has" height="216" src="https://img-blog.csdnimg.cn/20190921205813426.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="600">   <img alt="" class="has" height="123" src="https://img-blog.csdnimg.cn/20190921205944145.png" width="682">   注意：如果使用的是 JDK8 以 上 版 本 ， 则 应 在 hbase-evn.sh 中 移除“HBASE_MASTER_OPTS”和“HBASE_REGIONSERVER_OPTS”配置。   <img alt="" class="has" height="146" src="https://img-blog.csdnimg.cn/2019092122161818.png" width="767"><li>修改hbase-site.xml 配置文件，在/opt/module/hbase-1.3.1/conf/目录下    <pre class="has"><code class="language-html">&lt;configuration&gt;<br>   &lt;!--设置HBase将数据写到哪个目录下--&gt;<pre><code> &amp;lt;property&amp;gt;
         &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
         &amp;lt;value&amp;gt;hdfs://hadoop102:9000/hbase&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
  &amp;lt;!--设置集群模式，完全分布式模式--&amp;gt;
</code></pre>
 &lt;property&gt;<pre><code>         &amp;lt;name&amp;gt;hbase.cluster.distributed&amp;lt;/name&amp;gt;
         &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
</code></pre>
&lt;!– 0.98 后的新变动，之前版本没有.port,默认端口为 60000 –&gt;<br>&lt;property&gt;<pre><code>         &amp;lt;name&amp;gt;hbase.master.port&amp;lt;/name&amp;gt;
         &amp;lt;value&amp;gt;16000&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
 &amp;lt;!--设置zookeeper集群 --&amp;gt;
 &amp;lt;property&amp;gt;
         &amp;lt;name&amp;gt;hbase.zookeeper.quorum&amp;lt;/name&amp;gt;
         &amp;lt;value&amp;gt;hadoop102:2181,hadoop103:2181,hadoop104:2181&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
</code></pre>
 &lt;!–配置hbase中的元数据信息存放在zookeeper中的位置 –&gt;<pre><code> &amp;lt;property&amp;gt;
         &amp;lt;name&amp;gt;hbase.zookeeper.property.dataDir&amp;lt;/name&amp;gt;
         &amp;lt;value&amp;gt;/opt/module/zookeeper-3.4.10/zkData&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
</code></pre>
&lt;/configuration&gt;<br></code></pre>   </li>1. 修改regionservers配置文件，在/opt/module/hbase-1.3.1/conf/目录下  <img alt="" class="has" height="371" src="https://img-blog.csdnimg.cn/20190921212321348.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="799">1. HBase 需要依赖的 Jar 包  a：简介       由于 HBase 需要依赖 Hadoop，所以替换 HBase 的 lib 目录下的 jar 包，以解决兼容问题。 b：删除原有的 jar，zookeeper默认jar也删掉       <img alt="" class="has" height="413" src="https://img-blog.csdnimg.cn/20190921214043277.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="595">       <img alt="" class="has" height="204" src="https://img-blog.csdnimg.cn/2019092121420143.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="599">1. 拷贝新 jar，涉及的 jar 有：    <img alt="" class="has" height="346" src="https://img-blog.csdnimg.cn/20190921214846224.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="508">     1. HBase 软连接 Hadoop 配置 (软链接文件有类似于Windows的快捷方式)   <img alt="" class="has" height="265" src="https://img-blog.csdnimg.cn/20190921215538868.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="652">1. HBase 远程 scp 到其他集群节点  <img alt="" class="has" height="113" src="https://img-blog.csdnimg.cn/20190921215728703.png" width="755">  <img alt="" class="has" height="122" src="https://img-blog.csdnimg.cn/20190921215846729.png" width="732"> 1. 启动zookeeper和hadoop  <img alt="" class="has" height="223" src="https://img-blog.csdnimg.cn/20190921220543107.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="469">1. HBase 服务的启动   <img alt="" class="has" height="265" src="https://img-blog.csdnimg.cn/20190921222209840.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="705">  <img alt="" class="has" height="272" src="https://img-blog.csdnimg.cn/20190921222254952.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="653">   <img alt="" class="has" height="200" src="https://img-blog.csdnimg.cn/20190921222311207.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="718">1. 效果，通过Hbase提供的页面查看  <img alt="" class="has" height="422" src="https://img-blog.csdnimg.cn/2019092122250398.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="562">
 </li>
</ol>
<h1 id="四：Hbase基本操作"><a href="#四：Hbase基本操作" class="headerlink" title="四：Hbase基本操作"></a>四：Hbase基本操作</h1><ol>
<li> 进入 HBase 客户端命令行   命令：bin/hbase shell  <img alt="" class="has" height="263" src="https://img-blog.csdnimg.cn/20190923210239122.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="569">1. 查看当前数据库中有哪些表   <img alt="" class="has" height="234" src="https://img-blog.csdnimg.cn/20190923210745340.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="528">1.  创建表 ，表名：student,列簇：info  <img alt="" class="has" height="264" src="https://img-blog.csdnimg.cn/20190923212010264.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="383">  <img alt="" class="has" height="418" src="https://img-blog.csdnimg.cn/2019092321222874.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="449">1.  向表中插入数据(Hbase擅长存储非结构化数据)  语法：put ‘表名’,’rowkey(不用在创建表时候指定)’,’列簇:列名(这个列名不用在创建表时候指定)’,’数据’   <img alt="" class="has" height="183" src="https://img-blog.csdnimg.cn/20190923213227652.png" width="649">1. 扫描查看表数据   语法：scan ‘表名’  <img alt="" class="has" height="238" src="https://img-blog.csdnimg.cn/20190923213333224.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="790">  <img alt="" class="has" height="242" src="https://img-blog.csdnimg.cn/20190923213511452.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="766">1.   将之前的name覆盖掉  <img alt="" class="has" height="229" src="https://img-blog.csdnimg.cn/20190923213643557.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="718">1. 可以指定不同的rowkey  <img alt="" class="has" height="233" src="https://img-blog.csdnimg.cn/20190923213825286.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="837">1. 查看表结构 <img alt="" class="has" height="289" src="https://img-blog.csdnimg.cn/20190923214405355.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="614">1.   查看“指定行”或“指定列族:列”的数据 (会扫描整张表，性能很低)  <img alt="" class="has" height="187" src="https://img-blog.csdnimg.cn/20190923214547336.png" width="829">  <img alt="" class="has" height="195" src="https://img-blog.csdnimg.cn/20190923214639676.png" width="787">1.  删除数据   a：删除某 rowkey 的全部数据：         <img alt="" class="has" height="151" src="https://img-blog.csdnimg.cn/20190923215109964.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="614">  b：删除某 rowkey 的某一列数据：         <img alt="" class="has" height="207" src="https://img-blog.csdnimg.cn/20190923215158162.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="631">1.  清空表数据  <img alt="" class="has" height="198" src="https://img-blog.csdnimg.cn/20190923215248408.png" width="609"> 1. 删除表  a：首先需要先让该表为 disable 状态        <img alt="" class="has" height="158" src="https://img-blog.csdnimg.cn/20190923215411519.png" width="424">   b：然后才能 drop 这个表：         <img alt="" class="has" height="217" src="https://img-blog.csdnimg.cn/20190923215449943.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="482">1. 统计表数据行数 （这里统计的是rowkey的数量，因为Hbase是按列存储的）  <img alt="" class="has" height="314" src="https://img-blog.csdnimg.cn/20190923215918117.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="536"></li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hbase与 Sqoop 的集成</title>
    <url>/2021/07/18/Hbase%E4%B8%8E%20Sqoop%20%E7%9A%84%E9%9B%86%E6%88%90/</url>
    <content><![CDATA[<p>title: Hbase与 Sqoop 的集成<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—title: Hbase与 Sqoop 的集成<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—1. 需求：         将 RDBMS(关系型数据库) 中的数据抽取到 HBase 中 。1. 修改/usr/local/module/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/conf/目录下配置 文件sqoop-env.sh  <img alt="" class="has" height="83" src="https://img-blog.csdnimg.cn/2019100821594772.png" width="618">1. 在 Mysql 中新建一个数据库 db_library，一张表 book   <img alt="" class="has" height="229" src="https://img-blog.csdnimg.cn/20191008220410503.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="246">  <img alt="" class="has" height="398" src="https://img-blog.csdnimg.cn/20191008220524952.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="569">1. 向表中插入一些数据   <img alt="" class="has" height="422" src="https://img-blog.csdnimg.cn/20191008220650498.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="857"><li> 执行 Sqoop 导入数据的操作    <pre class="has"><code class="language-bash">bin/sqoop import \<br>--connect jdbc:mysql://hadoop111:3306/db_library \<br>--username root \<br>--password 897570 \<br>--table book \<br>--columns "id,name,price" \<br>--column-family "info" \<br>--hbase-create-table \<br>--hbase-row-key "id" \<br>--hbase-table "hbase_book" \<br>--num-mappers 1 \<br>--split-by id</code></pre> –num-mappers 1 \    表示1个mapper –split-by id                表示按照ID分割，一个id一条数据<img alt="" class="has" height="290" src="https://img-blog.csdnimg.cn/20191008221348362.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="744">  出错：  <img alt="" class="has" height="266" src="https://img-blog.csdnimg.cn/20191008221956830.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="740"> </li>1. 原因以及解决办法  原因：：sqoop1.4.6 只支持 HBase1.0.1 之前的版本的自动创建 HBase 表的功能 。  解决方案：手动创建 HBase 表     <img alt="" class="has" height="298" src="https://img-blog.csdnimg.cn/20191008222134693.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="507">1. 再次执行  <img alt="" class="has" height="222" src="https://img-blog.csdnimg.cn/20191008222242933.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="555">  <img alt="" class="has" height="243" src="https://img-blog.csdnimg.cn/20191008222313120.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="855"></p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hbase入门知识点入门学习三</title>
    <url>/2021/07/18/Hbase%E5%85%A5%E9%97%A8%E7%9F%A5%E8%AF%86%E7%82%B9%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%B8%89/</url>
    <content><![CDATA[<p>title: Hbase入门知识点入门学习三<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：Hbase和Hive对比</p>
<ol>
<li>Hive简介         <strong>Hive</strong>是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能， 可以将sql语句转换为MapReduce任务进行运行。         <strong>Hive <strong>是建立在 Hadoop 之上为了</strong>降低 MapReduce 编程复杂度</strong>的 ETL 工具。         <strong>Hive</strong>的本质其实就相当于将HDFS中已经存储的文件在Mysql中做了一个双射关系，以方便使用HQL去管理查询。         <strong>Hive</strong>适用于离线的数据分析和清洗，延迟较高。         <strong>Hive</strong>存储的数据依旧在DataNode上，编写的HQL语句终将是转换为MapReduce代码执行。         <strong>Hive</strong> 表是<strong>纯逻辑表</strong>，因为 Hive 的本身并不能做数据存储和计算，而是完全依赖 Hadoop        ** Hive <strong>是</strong>数据仓库工具，需要全表扫描<strong>，就用 Hive，因为 Hive 是</strong>文件存储，<strong>运行Hive查询会花费很长时间， 因为它会默认遍历表中所有的数据。1.  Hbase简介         <strong>HBase</strong>是Hadoop的数据库，一个分布式、可扩展、大数据的存储。         <strong>Hbase</strong>是一种面向列存储的非关系型数据库。          <strong>Hbase</strong>用于存储结构化和非结构化的数据,适用于单表非关系型数据的存储，不适合做关联查询，类似JOIN等操作.         <strong>Hbase</strong>基于HDFS,数据持久化存储的体现形式是Hfile，存放于DataNode中，被ResionServer以region的形式进行管理。         <strong>Hbase</strong>延迟较低，接入在线业务使用.面对大量的企业数据，HBase可以直线单表大量数据的存储，同时提供了高效的数据访问速度。         <strong>HBase</strong>通过存储key/value来工作。         <strong>HBase</strong> 是</strong>数据库，需要索引访问<strong>，则用 HBase，因为 HBase 是面向列的 NoSQL 数据库.         <strong>HBase</strong> 是</strong>物理表<strong>，提供了一张</strong>超大的内存 Hash 表来存储索引<strong>，方便查询.         <strong>HBase</strong> 是为了</strong>弥补 Hadoop 对实时操作的缺陷**         <h1 id="二：Hbase常用的-Shell-操作"><a href="#二：Hbase常用的-Shell-操作" class="headerlink" title="二：Hbase常用的 Shell 操作"></a>二：Hbase常用的 Shell 操作</h1></li>
</ol>
<p>         <img alt="" class="has" height="719" src="https://img-blog.csdnimg.cn/20191008223627732.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="768">         <img alt="" class="has" height="239" src="https://img-blog.csdnimg.cn/20191008223646373.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="408">         <img alt="" class="has" height="839" src="https://img-blog.csdnimg.cn/2019100822370882.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="749"></p>
<h1 id="三：Hbase数据的备份与恢复"><a href="#三：Hbase数据的备份与恢复" class="headerlink" title="三：Hbase数据的备份与恢复"></a>三：Hbase数据的备份与恢复</h1><ol>
<li>简介        停止 HBase 服务后，使用 distcp 命令运行 MapReduce 任务进行备份，将数据备份到另一个 地方，可以是同一个集群，也可以是专用的备份集群。1. 下面我们操作即，把数据转移到当前集群的其他目录下（也可以不在同一个集群中）:   a：我们将下面hdfs上的/hbase备份到另外一个目录下       <img alt="" class="has" height="492" src="https://img-blog.csdnimg.cn/20191008224456659.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="566">1. 命令如下：  <img alt="" class="has" height="224" src="https://img-blog.csdnimg.cn/2019100822480886.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="754">1.  效果  <img alt="" class="has" height="489" src="https://img-blog.csdnimg.cn/20191008225258202.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="687">       <h1 id="四：Hbase高可用"><a href="#四：Hbase高可用" class="headerlink" title="四：Hbase高可用"></a>四：Hbase高可用</h1></li>
<li>简介       在 HBase 中 Hmaster 负责监控 RegionServer 的生命周期，均衡 RegionServer 的负载，如果 Hmaster 挂掉了，那么整个 HBase 集群将陷入不健康的状态，并且此时的工作状态并不会维持太久。 所以 HBase 支持对 Hmaster 的高可用配置。1. 在hadoop111机器的 /usr/local/module/hbase-1.3.1/conf 目录下创建 backup-masters 文件      <img alt="" class="has" height="227" src="https://img-blog.csdnimg.cn/20191011215946527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="661">  hadoop111是之前的master节点，现在是让hadoop112成为备用的master节点1.  分发到其他的两台机器  <img alt="" class="has" height="106" src="https://img-blog.csdnimg.cn/20191011220348823.png" width="782">1.  在hadoop111机器上执行启动脚本      <img alt="" class="has" height="404" src="https://img-blog.csdnimg.cn/201910112205116.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 1. 效果  <img alt="" class="has" height="435" src="https://img-blog.csdnimg.cn/20191011220635680.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="444"><img alt="" class="has" height="365" src="https://img-blog.csdnimg.cn/20191011220654648.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="484"><h1 id=""><a href="#" class="headerlink" title=""></a></h1>                        </li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hbase知识点学习</title>
    <url>/2021/07/18/Hbase%E7%9F%A5%E8%AF%86%E7%82%B9%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>title: Hbase知识点学习<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—title: Hbase知识点学习<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—1. 1. 1. 1. 1. </p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hive整合Hbase详解</title>
    <url>/2021/07/18/Hive%E6%95%B4%E5%90%88Hbase%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p>title: Hive整合Hbase详解<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—title: Hive整合Hbase详解<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—1. <strong>简介</strong>     Hive提供了与HBase的集成，使得能够在HBase表上使用HQL语句进行查询 插入操作以及进行Join和Union等复杂查询、 同时也可以将hive表中的数据映射到Hbase中。在工作中很常见。它的应用场景有很多，比如在Hadoop业务的开发流程如下：<img alt="" class="has" height="300" src="https://img-blog.csdnimg.cn/20191007212421103.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 其中在数据存入hbase—&gt;Hive对数据进行统计分析的这个步骤中就涉及到了Hive与Hbase的整合，所以了解Hive与Hbase的整合是很有必要的。 1. <strong>Hive与Hbase整合的必要性 **         Hive是建立在Hadoop之上的数据仓库基础构架、是为了减少MapReduce编写工作的批处理系统， Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce。Hive可以理解为一个客户端工具， 将我们的sql操作转换为相应的MapReduce jobs，然后在Hadoop上面运行。         Hbase全称为Hadoop Database，即Hbase是Hadoop的数据库，是一个分布式的存储系统。Hbase利用 Hadoop的HDFS作为其文件存储系统，利用Hadoop的MapReduce来处理Hbase中的海量数据。利用zookeeper 作为其协调工具。          Hbase数据库的缺点在于—-语法格式异类，没有类sql的查询方式，因此在实际的业务当中操作和计算数据非 常不方便，但是Hive就不一样了，Hive支持标准的sql语法，于是我们就希望通过Hive这个客户端工具对Hbase中的 数据进行操作与查询，进行相应的数据挖掘，这就是所谓Hive与hbase整合的含义。Hive与Hbase整合的示意图如下：<img alt="" class="has" height="263" src="https://img-blog.csdnimg.cn/20191007212726676.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="832">1. <strong>hive与hbase版本兼容性</strong>  Hive版本：1.2.1  Hbase版本：1.3.1  ⑴hbase与hive哪些版本兼容？         a：hive0.90与hbase0.92是兼容的，早期的hive版本与hbase0.89/0.90兼容。         b：hive1.x与hbase0.98.x或则更低版本是兼容的。         c：hive2.x与hbase1.x及比hbase1.x更高版本兼容。           Hive 0.6.0推出了storage-handler，用于将数据存储到HDFS以外的其他存储上。并方便的通过hive进行插入、查询等操作。   同时hive提供了针对Hbase的hive-hbase-handler。这使我们在使用hive节省开发M/R代码成本的同时还能获得HBase的特性来快  速响应随机查询。           但是，hive自带的hive-hbase-handler是针对特定版本的Hbase的，比如，0.7.0版本的hive编译时使用的是0.89.0版本的Hbase，0.6.0版本的hive默认使用0.20.3版本的hbase进行编译。如果能够找到对应的版本，可以跳过编译的步骤直接使用。不过，我们现状已经找不到这些版本的Hbase与之配合使用了。所以只好自己来编译这个jar包。           注：使用不匹配的版本，一些功能会发生异常。其原因是由于没有重新编译storage-handler组件，发现在hive中查询HBase表存在问题。hive-hbase-handler.jar的作用在hbase与hive整合的时候发挥了重要作用，有了这个包，hbase与hive才能通信。 如果想hbase1.x与hive1.x整合，需要编译hive1.x 代码本身。1. <strong>下面我们创建项目去编译源码   <strong>⑴首先我们需要去网上下载对应hive版本的源码包         <img alt="" class="has" height="42" src="https://img-blog.csdnimg.cn/20191007220454629.png" width="290">        解压后：        <img alt="" class="has" height="49" src="https://img-blog.csdnimg.cn/2019100722080049.png" width="356">   ⑵在eclipse中创建一个项目。Java project即可。       <img alt="" class="has" height="76" src="https://img-blog.csdnimg.cn/20191007220540543.png" width="314">            ⑶在创建好的项目上点击右键，选择Import，选择General下的FileSystem，       找到源码包apache-hive-1.2.1-src\hbase-handler\src\java目录选择其中的java目录导入         <img alt="" class="has" height="339" src="https://img-blog.csdnimg.cn/20191007221108593.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="301"><img alt="" class="has" height="338" src="https://img-blog.csdnimg.cn/20191007221351985.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="354">   ⑷添加依赖包，导入代码后可以看到很多的错误提示。这时由于没有引入依赖的jar包导致的。        <img alt="" class="has" height="306" src="https://img-blog.csdnimg.cn/20191007221534971.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="339">      下面，我们引入,需要hive、hbase下相关的lib包。新建lib目录，把对应的依赖包，导入       a：首先我们进入到hive的lib目录下，下载下来所有的jar,注意：文件夹不要，以及.pom文件不要。             <img alt="" class="has" height="125" src="https://img-blog.csdnimg.cn/20191007221946884.png" width="409">       b：我们再进入hbase的lib目录下，下载下来所有的jar，有相同的就去掉，注意：文件夹不要，以及.pom文件不要。            <img alt="" class="has" height="157" src="https://img-blog.csdnimg.cn/20191007223116271.png" width="377"><img alt="" class="has" height="157" src="https://img-blog.csdnimg.cn/20191007223124805.png" width="377">            <img alt="" class="has" height="468" src="https://img-blog.csdnimg.cn/20191007223902727.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="468">    ⑸至此可以导出我们需要的jar包了。在项目上点击右键，选择export ，选择JAR file            <img alt="" class="has" height="149" src="https://img-blog.csdnimg.cn/20191007224110155.png" width="653">            我们只编译源码，不要lib，名称就是我们要替换的原本的jar包名称hive-hbase-handler-1.2.1.jar             <img alt="" class="has" height="380" src="https://img-blog.csdnimg.cn/20191007224336482.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="326">         到这里我们就生成了符合自己Hbase版本的hive-hbase-handler了。1. <strong>下面我们进入到hive的lib目录下删除原来的hive-hbase-handler-1.2.1.jar，****换成我们自己的</strong>   <img alt="" class="has" height="413" src="https://img-blog.csdnimg.cn/20191007224615174.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="579">1. <strong>hive与hbase整合环境配置  ⑴</strong>进入/usr/local/module/apache-hive-1.2.1/conf目录下修改hive-site.xml文件，添加配置属性（zookeeper的地址）        <img alt="" class="has" height="83" src="https://img-blog.csdnimg.cn/20191007225110949.png" width="658">1. <strong>引入hbase的依赖包</strong>  ⑴将hbase安装目录下的lib文件夹下的包导入到hive的环境变量中        a：在hive-env.sh 文件中添加             <img alt="" class="has" height="51" src="https://img-blog.csdnimg.cn/20191007225432137.png" width="819">1. 至此、hive与hbase整合环境准备完成<li>实战操作 ⑴</strong>建立 Hive 表，关联 HBase 表，插入数据到 Hive 表的同时能够影响 HBase 表。        a：在 Hive 中创建表同时关联 HBase                   ** <pre class="has"><code class="language-sql">CREATE TABLE hive_hbase_emp_table(<br>     empno int,<br>     ename string,<br>     job string,<br>     mgr int,<br>     hiredate string,<br>     sal double,<br>     comm double,<br>     deptno int<br>)<br>STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'<br>WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,info:ename,info:job,info:mgr,info:hiredate,info:sal,info:comm,info:deptno")<br>TBLPROPERTIES ("hbase.table.name" = "hbase_emp_table");    </code></pre> STORED BY ‘org.apache.hadoop.hive.hbase.HBaseStorageHandler’  //指定存储处理器Hbase.table.name属性是可选的，用它来指定此表在hbase中的名字，这就是说，允许同一个表在hive和hbase中有不同的名字。 每个hive的列，都需要在参数hbase.columns.mapping中指定一个对应的条目，多个列之间的条目通过逗号分隔；也就是说，如果某个表有n个列，则参数hbase.columns.mapping的值中就有n个以逗号分隔的条目，比如： <pre>"hbase.columns.mapping" = ":key,a:b,a:c,d:e" 代表有两个列族，一个是a一个是d，a列族中有两列，分别为b和c<br>注意，hbase.columns.mapping的值中是不允许出现空格的<br><strong>    b:效果<br>         </strong></strong>         <strong><strong><br>     c：现在我们需要向hive库中的hive_hbase_emp_table表中添加数据，注意：不能直接load数据到这张表中，<br>         否则数据不会同步到hbase对应的hbase_emp_table表中。 <br>         在 Hive 中创建临时中间表，用于 load 文件中的数据 </strong><br></pre> <pre class="has"><code class="language-sql">CREATE TABLE emp(<br>   empno int,<br>   ename string,<br>   job string,<br>   mgr int,<br>   hiredate string,<br>   sal double,<br>   comm double,<br>  deptno int<br>)<br>row format delimited fields terminated by '\t'; </code></pre> <pre></strong> **<br><strong>     d:向 Hive 中间表中 load 数据 <br>          </strong></strong>         <strong><strong>      e：通过 insert 命令将中间表中的数据导入到 Hive 关联 HBase 的那张表中 <br>         </strong><strong>      f：查看 Hive 以及关联的 HBase 表中是否已经成功的同步插入了数据 <br>         </strong></strong>         **<strong><br> <br>⑵在 HBase 中已经存储了某一张表 hbase_emp_table，然后在 Hive 中创建一个外部表来关联 HBase 中的<br>  hbase_emp_table 这张表，使之可以借助 Hive 来分析 HBase 这张表中的数据。<br>   a：在 Hive 中创建外部表 </strong><br></pre> <pre class="has"><code class="language-sql">CREATE EXTERNAL TABLE relevance_hbase_emp(<br>   empno int,<br>   ename string,<br>   job string,<br>   mgr int,<br>   hiredate string,<br>   sal double,<br>   comm double,<br>   deptno int<br>)<br>STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'<br>WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,info:ename,info:job,info:mgr,info:hiredate,info:sal,info:comm,info:deptno")<br>TBLPROPERTIES ("hbase.table.name" = "hbase_emp_table"); </code></pre> <pre></p>
<p>b：关联后就可以使用 Hive 函数进行一些分析操作了 ，数据自动填充进来<br> <br> 这里使用外部表映射到HBase中的表，这样，在Hive中删除表，并不会删除HBase中的表，否则，就会删除。<br></pre> </li><br>参考文章：                      </p>
<p> </p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hive知识点入门学习</title>
    <url>/2021/07/18/Hive%E7%9F%A5%E8%AF%86%E7%82%B9%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>title: Hive知识点入门学习<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—title: Hive知识点入门学习<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—1. 1. 1. 1. 1. </p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hive知识点入门学习一</title>
    <url>/2021/07/18/Hive%E7%9F%A5%E8%AF%86%E7%82%B9%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%B8%80/</url>
    <content><![CDATA[<p>title: Hive知识点入门学习一<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：Hive基本概念</p>
<ol>
<li> 什么是Hive？    <img alt="" class="has" height="298" src="https://img-blog.csdnimg.cn/20190814222311472.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="620">1. Hive优缺点  ⑴优点           <img alt="" class="has" height="208" src="https://img-blog.csdnimg.cn/20190815214618589.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="616">  ⑵缺点           <img alt="" class="has" height="264" src="https://img-blog.csdnimg.cn/20190815214836193.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="622">1. Hive 架构原理 <img alt="" class="has" height="566" src="https://img-blog.csdnimg.cn/201908152155550.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="611"><img alt="" class="has" height="412" src="https://img-blog.csdnimg.cn/20190815215626780.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="610"><img alt="" class="has" height="182" src="https://img-blog.csdnimg.cn/2019081521564683.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="610"><img alt="" class="has" height="112" src="https://img-blog.csdnimg.cn/20190815215701849.png" width="610">1. Hive 和数据库比较  由于 Hive 采用了类似 SQL 的查询语言 HQL(Hive Query Language)，因此很容易 将 Hive 理解为数据库。其实从结构上来看，Hive 和数据库除了拥有类似的查询语言，再无 类似之处。数据库可以用在 Online 的应用中，但是 Hive 是为数据仓库而设计的，类似mysql, Oracle等常规数据库一般用于增删改查，但是Hive一般只用于查询。清楚这一点，有助于从应 用角度理解 Hive 的特性。 ⑴查询语言         <img alt="" class="has" height="61" src="https://img-blog.csdnimg.cn/20190815221532680.png" width="546"> ⑵数据存储位置          <img alt="" class="has" height="63" src="https://img-blog.csdnimg.cn/2019081522160170.png" width="551"> ⑶数据更新          <img alt="" class="has" height="128" src="https://img-blog.csdnimg.cn/2019081522163091.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="553">  ⑷ 索引         <img alt="" class="has" height="209" src="https://img-blog.csdnimg.cn/20190815221713667.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="559"> ⑸执行         <img alt="" class="has" height="61" src="https://img-blog.csdnimg.cn/20190815221748180.png" width="558"> ⑹执行延迟         <img alt="" class="has" height="167" src="https://img-blog.csdnimg.cn/2019081522181594.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="555"> ⑺可扩展性         <img alt="" class="has" height="136" src="https://img-blog.csdnimg.cn/20190815221845638.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="556"> ⑻数据规模         <img alt="" class="has" height="62" src="https://img-blog.csdnimg.cn/20190815221911671.png" width="572"><h1 id="二：Hive-安装环境准备以及基本操作"><a href="#二：Hive-安装环境准备以及基本操作" class="headerlink" title="二：Hive 安装环境准备以及基本操作"></a>二：Hive 安装环境准备以及基本操作</h1></li>
<li>Hive各个版本下载地址 ：****  <img alt="" class="has" height="343" src="https://img-blog.csdnimg.cn/20190816213210468.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="435">        1. 使用hive的版本  <img alt="" class="has" height="42" src="https://img-blog.csdnimg.cn/2019081621555789.png" width="311">1. 将软件包上传到/opt/software目录下  <img alt="" class="has" height="166" src="https://img-blog.csdnimg.cn/2019081621592082.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="593">1. 解压软件到/opt/module目录下<img alt="" class="has" height="59" src="https://img-blog.csdnimg.cn/20190816220052503.png" width="757"><img alt="" class="has" height="137" src="https://img-blog.csdnimg.cn/20190816220118970.png" width="579">1. 将名称修改为hive  <img alt="" class="has" height="226" src="https://img-blog.csdnimg.cn/20190816220446367.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="484">1. 将/opt/module/hive/conf目录下的配置文件hive-env.sh.template名称修改为hive-env.sh<img alt="" class="has" height="264" src="https://img-blog.csdnimg.cn/20190816220725287.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="512">1. 修改hive-env.sh文件内容  <img alt="" class="has" height="217" src="https://img-blog.csdnimg.cn/20190816221104424.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="568">1. hadoop集群配置，因为hive是依赖于hadoop的，所以hadoop的hdfs和yarn必须启动 ⑴在hadoop102启动hdfs       <img alt="" class="has" height="191" src="https://img-blog.csdnimg.cn/20190816221531105.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="564"> ⑵到hadoop103上启动yarn        <img alt="" class="has" height="215" src="https://img-blog.csdnimg.cn/2019081622173717.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="478">     1. 在 HDFS 上创建/tmp 和/user/hive/warehouse(这个目录主要给hive存储数据用) 两个目录并修改他们的同组权限可写     <img alt="" class="has" height="100" src="https://img-blog.csdnimg.cn/20190816223829322.png" width="647">1. 修改新建目录权限   ⑴目前目录权限，同组用户可读，可执行，不可写,修改为可读可写          <img alt="" class="has" height="110" src="https://img-blog.csdnimg.cn/20190816224122506.png" width="763">          <img alt="" class="has" height="61" src="https://img-blog.csdnimg.cn/20190816224502264.png" width="586">          <img alt="" class="has" height="96" src="https://img-blog.csdnimg.cn/20190816224531899.png" width="587">           1. hive基本操作   ⑴启动hive          a：进入/opt/module/hive目录下，出现下面效果就启动完成                  <img alt="" class="has" height="200" src="https://img-blog.csdnimg.cn/20190816225102613.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="465">  ⑵查看数据库命令        <img alt="" class="has" height="180" src="https://img-blog.csdnimg.cn/20190816225235943.png" width="423"> ⑶打开默认数据库        <img alt="" class="has" height="192" src="https://img-blog.csdnimg.cn/20190816225325485.png" width="442">  ⑷显示数据库中的表         <img alt="" class="has" height="100" src="https://img-blog.csdnimg.cn/20190816225406640.png" width="326">  ⑸创建表         <img alt="" class="has" height="201" src="https://img-blog.csdnimg.cn/2019081622554793.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="489">  ⑹向表中插入数据         <img alt="" class="has" height="228" src="https://img-blog.csdnimg.cn/20190816225815241.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="443">  ⑺查表中的数据        <img alt="" class="has" height="156" src="https://img-blog.csdnimg.cn/20190816225935445.png" width="484">    ⑻退出：          <img alt="" class="has" height="79" src="https://img-blog.csdnimg.cn/20190816225958759.png" width="395">
 </li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hive知识点入门学习三</title>
    <url>/2021/07/18/Hive%E7%9F%A5%E8%AF%86%E7%82%B9%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%B8%89/</url>
    <content><![CDATA[<p>title: Hive知识点入门学习三<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：Hive 常见属性配置 </p>
<ol>
<li>  Hive 数据仓库位置配置     ⑴Default 数据仓库的最原始位置是在 hdfs 上的：/user/hive/warehouse 路径下 。    ⑵在仓库目录下，没有对默认的数据库 default 创建文件夹。如果某张表属于 default        数据库，直接在数据仓库目录下创建一个文件夹。        <img alt="" class="has" height="199" src="https://img-blog.csdnimg.cn/20190819223122673.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="594">    ⑶修改 default 数据仓库原始位置（将 hive-default.xml.template 如下配置信息拷贝到        hive-site.xml 文件中）         <img alt="" class="has" height="147" src="https://img-blog.csdnimg.cn/20190819223236422.png" width="665">         配置同组用户有执行权限 ：        bin/hdfs dfs -chmod g+w /user/hive/warehouse 1.  显示当前数据库，以及查询表的头信息配置  ⑴在 hive-site.xml 文件中添加如下配置信息         <img alt="" class="has" height="162" src="https://img-blog.csdnimg.cn/20190819223610457.png" width="437">  ⑵效果：        <img alt="" class="has" height="309" src="https://img-blog.csdnimg.cn/20190819223716280.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="466"> 1.  Hive 运行日志信息配置     ⑴Hive 的 log 默认存放在/tmp/kgf/hive.log 目录下（当前用户名下）。     ⑵修改 hive 的 log 存放日志到/opt/module/hive/logs           a：修改/opt/module/hive/conf/hive-log4j.properties.template 文件名称为hive-log4j.properties                   <img alt="" class="has" height="287" src="https://img-blog.csdnimg.cn/20190819224138274.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="505">                b：在 hive-log4j.properties 文件中修改 log 存放位置                  <img alt="" class="has" height="157" src="https://img-blog.csdnimg.cn/2019081922430168.png" width="447">          c：重新启动hive,查看日志                <img alt="" class="has" height="228" src="https://img-blog.csdnimg.cn/20190819224456124.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="591">               <img alt="" class="has" height="204" src="https://img-blog.csdnimg.cn/20190819224522341.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="610">        <h1 id="二：Hive-数据类型"><a href="#二：Hive-数据类型" class="headerlink" title="二：Hive 数据类型"></a>二：Hive 数据类型</h1></li>
<li> 基本数据类型   <img alt="" class="has" height="526" src="https://img-blog.csdnimg.cn/20190820220115405.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="623">1. 集合数据类型   <img alt="" class="has" height="194" src="https://img-blog.csdnimg.cn/2019082022021964.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="680">  <img alt="" class="has" height="365" src="https://img-blog.csdnimg.cn/2019082022030196.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="670">1. 案例实操  ⑴需求：         <img alt="" class="has" height="298" src="https://img-blog.csdnimg.cn/20190820220418141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="599">  ⑵基于上述数据结构，我们在 Hive 里创建对应的表，并导入数据。          a：创建本地测试文件 test.txt                <img alt="" class="has" height="86" src="https://img-blog.csdnimg.cn/20190820220903466.png" width="672">               <img alt="" class="has" height="197" src="https://img-blog.csdnimg.cn/20190820223457971.png" width="714">         b：Hive 上创建测试表 test                <img alt="" class="has" height="198" src="https://img-blog.csdnimg.cn/20190820222540748.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="693">               <img alt="" class="has" height="242" src="https://img-blog.csdnimg.cn/20190820223114431.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="492">               <img alt="" class="has" height="206" src="https://img-blog.csdnimg.cn/20190820223229937.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="492">       c：导入数据             <img alt="" class="has" height="139" src="https://img-blog.csdnimg.cn/20190820223714627.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="619">    ⑶访问三种集合列里的数据，以下分别是 ARRAY，MAP，STRUCT 的访问方式           <img alt="" class="has" height="205" src="https://img-blog.csdnimg.cn/20190820224559347.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="664">1.  类型转化   <img alt="" class="has" height="459" src="https://img-blog.csdnimg.cn/2019082022464613.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="568">      <h1 id="三：DDL数据定义"><a href="#三：DDL数据定义" class="headerlink" title="三：DDL数据定义"></a>三：DDL数据定义</h1></li>
<li>创建数据库  <img alt="" class="has" height="281" src="https://img-blog.csdnimg.cn/2019082121445173.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="457">  注意：避免要创建的数据库已经存在错误，增加 if not exists 判断。（标准写法）   <img alt="" class="has" height="154" src="https://img-blog.csdnimg.cn/20190821214719765.png" width="525">    <img alt="" class="has" height="297" src="https://img-blog.csdnimg.cn/20190821214826855.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="631">1. 创建一个数据库，指定数据库在 HDFS 上存放的位置   <img alt="" class="has" height="173" src="https://img-blog.csdnimg.cn/2019082121542295.png" width="727">  <img alt="" class="has" height="280" src="https://img-blog.csdnimg.cn/20190821215432560.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="468">1. 修改数据库  <img alt="" class="has" height="328" src="https://img-blog.csdnimg.cn/20190821220003912.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="648">1.  查询数据库   <img alt="" class="has" height="509" src="https://img-blog.csdnimg.cn/20190821220237936.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="563">1.   删除数据库   <img alt="" class="has" height="210" src="https://img-blog.csdnimg.cn/20190821221230754.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="606">  <img alt="" class="has" height="196" src="https://img-blog.csdnimg.cn/20190821221244886.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="597">1. 管理表   ⑴简介         <img alt="" class="has" height="144" src="https://img-blog.csdnimg.cn/20190821223046384.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="622">  ⑵案例实操         a：普通创建表                 <img alt="" class="has" height="131" src="https://img-blog.csdnimg.cn/20190821223705196.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="576">                <img alt="" class="has" height="195" src="https://img-blog.csdnimg.cn/2019082122372787.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="553">         b：根据查询结果创建表（查询的结果会添加到新创建的表中）                <img alt="" class="has" height="390" src="https://img-blog.csdnimg.cn/20190821224316559.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="481">         c：根据已经存在的表结构创建表                <img alt="" class="has" height="231" src="https://img-blog.csdnimg.cn/20190821224448961.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="683">         d：查询表的类型               <img alt="" class="has" height="427" src="https://img-blog.csdnimg.cn/20190821224556752.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="503">1.  外部表   ⑴简介         <img alt="" class="has" height="73" src="https://img-blog.csdnimg.cn/20190822221648101.png" width="625">  ⑵使用场景         <img alt="" class="has" height="109" src="https://img-blog.csdnimg.cn/20190822221740240.png" width="651">  ⑶案例实操：分别创建部门和员工外部表，并向表中导入数据。          a：创建部门表               <img alt="" class="has" height="186" src="https://img-blog.csdnimg.cn/20190822222033545.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="581">        b：创建员工表               <img alt="" class="has" height="211" src="https://img-blog.csdnimg.cn/20190822222211120.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="585">        c：<strong>我们向表中导入数据后，数据存储在hdfs上，删除表后，数据不会删除，重新建立表后，数据会重新              关联起来</strong>。</li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hive知识点入门学习二</title>
    <url>/2021/07/18/Hive%E7%9F%A5%E8%AF%86%E7%82%B9%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%BA%8C/</url>
    <content><![CDATA[<p>title: Hive知识点入门学习二<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：将本地文件导入Hive案例</p>
<ol>
<li>需求：  将本地/opt/module/datas/student.txt这个目录下的数据导入到hive的student(id int, name string)表中。1. 数据准备：  ⑴在/opt/module/datas/student.txt 这个目录下准备数据        <img alt="" class="has" height="230" src="https://img-blog.csdnimg.cn/20190818155847518.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="474">1. 启动hive，在数据库中创建的student表，并声明文件分隔符’\t’   sql为：create table student(id int,name string) row format delimited fields terminated by ‘\t’;<img alt="" class="has" height="231" src="https://img-blog.csdnimg.cn/20190818161243241.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="885">1.  加载/opt/module/datas/student.txt 文件到 student 数据库表中。   sql：load data local inpath ‘/opt/module/datas/student.txt’ into table student;   <img alt="" class="has" height="265" src="https://img-blog.csdnimg.cn/20190818162112793.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="766">1.   遇到的问题   ⑴现在我们使用的是一个102连接窗口启动hive数据库，如果我们再打开一个102连接窗口去启动hive,就会报错        <img alt="" class="has" height="290" src="https://img-blog.csdnimg.cn/20190818162627607.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="600">        我们在第二个窗口也启动hive试试：        <img alt="" class="has" height="278" src="https://img-blog.csdnimg.cn/20190818162737579.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="631">    ⑵原因：        Metastore（元数据） 默认存储在自带的 derby 数据库中，只支持一个hive客户端连接。        推荐使用 MySQL 存储 Metastore;       <h1 id="二：Mysql安装"><a href="#二：Mysql安装" class="headerlink" title="二：Mysql安装"></a>二：Mysql安装</h1></li>
<li>查看mysql是否安装，如果安装了，可以先卸载掉  <img alt="" class="has" height="168" src="https://img-blog.csdnimg.cn/20190818163504163.png" width="639">1.  版本：  <img alt="" class="has" height="36" src="https://img-blog.csdnimg.cn/20190818164417782.png" width="395">1. 上传到Linux上  <img alt="" class="has" height="174" src="https://img-blog.csdnimg.cn/2019081816460563.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="681">1. 将文件解压到/usr/local/目录下  <img alt="" class="has" height="262" src="https://img-blog.csdnimg.cn/20190818174205322.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="698">   <img alt="" class="has" height="291" src="https://img-blog.csdnimg.cn/20190818174236815.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="625">1. 修改文件夹的名称  <img alt="" class="has" height="304" src="https://img-blog.csdnimg.cn/20190818174306725.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="735">1.  检查并创建用户和用户组  <img alt="" class="has" height="181" src="https://img-blog.csdnimg.cn/20190818165556903.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="529"> 1.  创建data文件夹<img alt="" class="has" height="130" src="https://img-blog.csdnimg.cn/20190818174340602.png" width="481"> 1.  授权授权目录和用户  <img alt="" class="has" height="331" src="https://img-blog.csdnimg.cn/20190818174438487.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="568"> 1.  安装并初始化  命令如下：datadir就是安装路径，basedir就是根目录  /usr/local/mysql/bin/mysqld –initialize –user=mysql –datadir=/usr/local/mysql/data –basedir=/usr/local/mysql  <img alt="" class="has" height="194" src="https://img-blog.csdnimg.cn/20190818174556621.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="683"> 1.  复制启动脚本到资源目录  <img alt="" class="has" height="173" src="https://img-blog.csdnimg.cn/20190818174655432.png" width="806"> 1.  增加mysqld服务控制脚本执行权限  <img alt="" class="has" height="63" src="https://img-blog.csdnimg.cn/20190818173327480.png" width="523"> 1.  将mysqld服务加入到系统服务  <img alt="" class="has" height="74" src="https://img-blog.csdnimg.cn/20190818173349521.png" width="475"> 1.  检查mysqld服务是否已经生效  <img alt="" class="has" height="304" src="https://img-blog.csdnimg.cn/20190818173412493.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="730"> 1.  启动mysql（注意：安装目录一定要在/usr/local下）  <img alt="" class="has" height="203" src="https://img-blog.csdnimg.cn/20190818174808466.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="653"> 1.  登录mysql（提示找不到mysql命令）  <img alt="" class="has" height="150" src="https://img-blog.csdnimg.cn/2019081817500748.png" width="477"> 1.  解决  <img alt="" class="has" height="113" src="https://img-blog.csdnimg.cn/20190818175110764.png" width="660"> 1.  再次登录  <img alt="" class="has" height="328" src="https://img-blog.csdnimg.cn/20190818175148527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="662"> 1.  修改密码  <img alt="" class="has" height="204" src="https://img-blog.csdnimg.cn/20190818175332282.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="614"> 1.  最后退出使用修改后的密码登录  <img alt="" class="has" height="395" src="https://img-blog.csdnimg.cn/20190818175419923.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="597"> 1.  连接出现如下  <img alt="" class="has" height="212" src="https://img-blog.csdnimg.cn/2019081817592794.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="587"> 1.  解决  <img alt="" class="has" height="177" src="https://img-blog.csdnimg.cn/20190818180225818.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="690"> 1.  连接成功  <img alt="" class="has" height="503" src="https://img-blog.csdnimg.cn/20190818180303108.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="576"> <h1 id="三：将Hive元数据拷贝到mysql"><a href="#三：将Hive元数据拷贝到mysql" class="headerlink" title="三：将Hive元数据拷贝到mysql"></a>三：将Hive元数据拷贝到mysql</h1></li>
<li>驱动拷贝，将mysql-connector-java-5.1.38.jar拷贝到/opt/module/hive/lib/   <img alt="" class="has" height="137" src="https://img-blog.csdnimg.cn/20190818183931789.png" width="727">1.  在/opt/module/hive/conf 目录下创建一个 hive-site.xml   <img alt="" class="has" height="258" src="https://img-blog.csdnimg.cn/20190818184128415.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="709"><li> 根据官方文档配置mysql参数，拷贝数据到 hive-site.xml 文件中。    <pre class="has"><code class="language-html">&lt;?xml version="1.0"?&gt;<br>&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;<br>&lt;configuration&gt;<br> &lt;property&gt;    <pre><code> &amp;lt;name&amp;gt;javax.jdo.option.ConnectionURL&amp;lt;/name&amp;gt;    
 &amp;lt;value&amp;gt;jdbc:mysql://hadoop102:3306/metastore?createDatabaseIfNotExist=true&amp;amp;amp;useSSL=false&amp;lt;/value&amp;gt;    
 &amp;lt;description&amp;gt;JDBC connect string for a JDBC metastore&amp;lt;/description&amp;gt;  
</code></pre>
 &lt;/property&gt;<br> &lt;property&gt;    <pre><code> &amp;lt;name&amp;gt;javax.jdo.option.ConnectionDriverName&amp;lt;/name&amp;gt;    
 &amp;lt;value&amp;gt;com.mysql.jdbc.Driver&amp;lt;/value&amp;gt;    
 &amp;lt;description&amp;gt;Driver class name for a JDBC metastore&amp;lt;/description&amp;gt;  
</code></pre>
 &lt;/property&gt;<br> &lt;property&gt;    <pre><code> &amp;lt;name&amp;gt;javax.jdo.option.ConnectionUserName&amp;lt;/name&amp;gt;    
 &amp;lt;value&amp;gt;root&amp;lt;/value&amp;gt;    
 &amp;lt;description&amp;gt;username to use against metastore database&amp;lt;/description&amp;gt;  
</code></pre>
 &lt;/property&gt;<br> &lt;property&gt;    <pre><code> &amp;lt;name&amp;gt;javax.jdo.option.ConnectionPassword&amp;lt;/name&amp;gt;    
 &amp;lt;value&amp;gt;897570&amp;lt;/value&amp;gt;    
 &amp;lt;description&amp;gt;password to use against metastore database&amp;lt;/description&amp;gt;  
</code></pre>
 &lt;/property&gt;<br> &lt;property&gt;         <pre><code> &amp;lt;name&amp;gt;hive.cli.print.current.db&amp;lt;/name&amp;gt;         
 &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;         
 &amp;lt;description&amp;gt;Whether to include the current database in the Hive prompt.&amp;lt;/description&amp;gt;      
</code></pre>
 &lt;/property&gt;<br> &lt;property&gt;     <pre><code> &amp;lt;name&amp;gt;hive.cli.print.header&amp;lt;/name&amp;gt;     
 &amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;     
 &amp;lt;description&amp;gt;Whether to print the names of the columns in query output.&amp;lt;/description&amp;gt;   
</code></pre>
 &lt;/property&gt;<br>&lt;/configuration&gt; </code></pre>   </li>1. 配置完毕后，如果启动 hive 异常，可以重新启动虚拟机。（重启后，别忘了启动 hadoop 集群）,启动hive后可以发现我们之前的student表不见了，我们看看mysql数据库变化  <img alt="" class="has" height="298" src="https://img-blog.csdnimg.cn/20190818185323958.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="428">1.  mysql数据库变化，多了一个元数据库，之前是没有的  <img alt="" class="has" height="303" src="https://img-blog.csdnimg.cn/20190818185545416.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="530">1.   多窗口启动测试，可以的  <img alt="" class="has" height="184" src="https://img-blog.csdnimg.cn/20190818185724384.png" width="688"><h1 id="四：Hive中常用的交互命令"><a href="#四：Hive中常用的交互命令" class="headerlink" title="四：Hive中常用的交互命令"></a>四：Hive中常用的交互命令</h1></li>
<li> 首先在hive中新建一张表，并且导入一些数据   <img alt="" class="has" height="312" src="https://img-blog.csdnimg.cn/20190819213852186.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="660">1. “-e”不进入 hive 的交互窗口执行 sql 语句     <img alt="" class="has" height="284" src="https://img-blog.csdnimg.cn/20190819214253808.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="794">1.  “-f”执行脚本中 sql 语句    ⑴新建一个sql脚本         <img alt="" class="has" height="182" src="https://img-blog.csdnimg.cn/20190819214823235.png" width="496">  ⑵执行sql脚本         <img alt="" class="has" height="268" src="https://img-blog.csdnimg.cn/20190819214939544.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="552">1.   执行文件中的 sql 语句并将结果写入文件中     <img alt="" class="has" height="314" src="https://img-blog.csdnimg.cn/20190819215111211.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="755"><h1 id="五：-Hive-其他命令操作"><a href="#五：-Hive-其他命令操作" class="headerlink" title="五： Hive 其他命令操作"></a>五： Hive 其他命令操作</h1></li>
<li> 在 hive cli 命令窗口中如何查看 hdfs 文件系统   <img alt="" class="has" height="211" src="https://img-blog.csdnimg.cn/20190819220124828.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="739">1. 在 hive cli 命令窗口中如何查看 hdfs 本地系统   <img alt="" class="has" height="187" src="https://img-blog.csdnimg.cn/20190819220235303.png" width="548">1. 查看在 hive 中输入的所有历史命令   a：进入到当前用户的根目录         <img alt="" class="has" height="29" src="https://img-blog.csdnimg.cn/20190819220435242.png" width="291">  b：查看. hivehistory 文件         <img alt="" class="has" height="233" src="https://img-blog.csdnimg.cn/20190819220505938.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="376">      </li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>MapReduce之Reduce join以及map join分布式缓存</title>
    <url>/2021/07/18/MapReduce%E4%B9%8BReduce%20join%E4%BB%A5%E5%8F%8Amap%20join%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/</url>
    <content><![CDATA[<p>title: MapReduce之Reduce join以及map join分布式缓存<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：Reduce join </p>
<ol>
<li>简介：       ⑴原理：               Map 端的主要工作：                        为来自不同表(文件)的 key/value 对打标签以区别不同来源的记录然后用连接字段作为 key，                   其余部分和新加的标志作为 value，最后进行输出。                Reduce 端的主要工作：                        在 reduce 端以连接字段作为 key 的分组已经完成，我们只需要在每一个分组当中将那些来                   源于不同文件的记录(在 map 阶段已经打标志)分开，最后进行合并就 ok 了。         ⑵缺点：                这种方式的缺点很明显就是会造成 map和 reduce 端也就是 shuffle 阶段出现大量的数据传输，效率很低。   1.  案例：reduce 端表合并（数据倾斜）         ⑴需求：               订单数据表 t_order，在order.txt中：                     <img alt="" class="has" height="156" src="https://img-blog.csdnimg.cn/20190805220657652.png" width="435">                商品信息表 t_product，在t_product.txt文件中。                    <img alt="" class="has" height="119" src="https://img-blog.csdnimg.cn/20190805210117522.png" width="247">                将商品信息表中数据根据商品 pid 合并到订单数据表中。 最终数据如下：                 <img alt="" class="has" height="128" src="https://img-blog.csdnimg.cn/20190806205404170.png" width="254"> <li>代码实现     ⑴数据准备             <img alt="" class="has" height="168" src="https://img-blog.csdnimg.cn/20190806205500385.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="311"><img alt="" class="has" height="97" src="https://img-blog.csdnimg.cn/20190806205522863.png" width="368">      ⑵思路分析：             a：首先订单表和产品表是多对一的关系，因为每个pid在产品表中是唯一的，而在订单表中可能很多个订单都包含                   这个产品。             b：我们需要定义一个bean对象，如下：                     <img alt="" class="has" height="237" src="https://img-blog.csdnimg.cn/20190806205902974.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="314">             c：我们以pId作为Mapper阶段输出的key，其它内容为value                   mapper中整合后的数据如下：                   <img alt="" class="has" height="179" src="https://img-blog.csdnimg.cn/20190806210343656.png" width="227">            d：在ruducer阶段，我们以key（pId）作为条件，一个pId在产品表中只有一条数据，那么就好办了，直接查出产品                  表中对应的名称，将order表中的名称填充上即可输出。      ⑶TableBean对象代码如下：             <pre class="has"><code class="language-java">package com.kgf.mapreduce.reducerJoin;</li>
</ol>
<p>import java.io.DataInput;<br>import java.io.DataOutput;<br>import java.io.IOException;</p>
<p>import org.apache.hadoop.io.Writable;</p>
<p>/***</p>
<ul>
<li><p>定义实体对象</p>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class TableBean implements Writable &#123;</p>
<p>  /<strong>订单ID</strong>/<br>  private String orderId;<br>  /<strong>产品ID</strong>/<br>  private String pId;<br>  /<strong>产品数量</strong>/<br>  private int amount;<br>  /<strong>产品名称</strong>/<br>  private String pName;<br>  /<strong>表类型：0-订单表，1-产品表</strong>/<br>  private String tableType;</p>
<p>  public TableBean(String orderId, String pId, int amount, String pName, String tableType) &#123;</p>
<pre><code>  super();
  this.orderId = orderId;
  this.pId = pId;
  this.amount = amount;
  this.pName = pName;
  this.tableType = tableType;
</code></pre>
<p>  }</p>
<p>  public TableBean() {</p>
<pre><code>  super();
</code></pre>
<p>  }<br>  /***</p>
<ul>
<li>反序列化方法</li>
<li>/<br>@Override<br>public void readFields(DataInput di) throws IOException {<br>  this.orderId = di.readUTF();<br>  this.pId = di.readUTF();<br>  this.amount = di.readInt();<br>  this.pName = di.readUTF();<br>  this.tableType = di.readUTF();<br>}<br>/***</li>
<li>序列化操作方法</li>
<li>/<br>@Override<br>public void write(DataOutput dot) throws IOException {<br>  dot.writeUTF(orderId);<br>  dot.writeUTF(pId);<br>  dot.writeInt(amount);<br>  dot.writeUTF(pName);<br>  dot.writeUTF(tableType);<br>}</li>
</ul>
<p>  @Override<br>  public String toString() {</p>
<pre><code>  return orderId+&quot;\t&quot;+ pName + &quot;\t&quot;+amount;
</code></pre>
<p>  }</p>
<p>  public String getOrderId() {</p>
<pre><code>  return orderId;
</code></pre>
<p>  }</p>
<p>  public void setOrderId(String orderId) {</p>
<pre><code>  this.orderId = orderId;
</code></pre>
<p>  }</p>
<p>  public String getpId() {</p>
<pre><code>  return pId;
</code></pre>
<p>  }</p>
<p>  public void setpId(String pId) {</p>
<pre><code>  this.pId = pId;
</code></pre>
<p>  }</p>
<p>  public int getAmount() {</p>
<pre><code>  return amount;
</code></pre>
<p>  }</p>
<p>  public void setAmount(int amount) {</p>
<pre><code>  this.amount = amount;
</code></pre>
<p>  }</p>
<p>  public String getpName() {</p>
<pre><code>  return pName;
</code></pre>
<p>  }</p>
<p>  public void setpName(String pName) {</p>
<pre><code>  this.pName = pName;
</code></pre>
<p>  }</p>
<p>  public String getTableType() {</p>
<pre><code>  return tableType;
</code></pre>
<p>  }</p>
<p>  public void setTableType(String tableType) {</p>
<pre><code>  this.tableType = tableType;
</code></pre>
<p>  }<br>}<br></code></pre> ⑷TableMapper类代码： <pre class="has"><code class="language-java">package com.kgf.mapreduce.reducerJoin;</p>
</li>
</ul>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.io.LongWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;<br>import org.apache.hadoop.mapreduce.lib.input.FileSplit;</p>
<p>/***</p>
<ul>
<li><p>   创建mapper类：主要功能如下</p>
</li>
<li><p>   a：获取读取数据来自的标名称</p>
</li>
<li><p>   b：对每一行数据进行切割，将我们需要的数据筛选出来，并且标记来自的文件表</p>
</li>
<li><p>   c：最后将数据写出到reducer</p>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class TableMapper extends Mapper&lt;LongWritable, Text, Text, TableBean&gt; &#123;</p>
<p>  TableBean v = new TableBean();</p>
<p>  Text k = new Text();</p>
<p>  @Override<br>  protected void map(LongWritable key, Text value, Context context)</p>
<pre><code>      throws IOException, InterruptedException &#123;
  //1：获取读取文件的名称
  FileSplit splitFile = (FileSplit) context.getInputSplit();
  String fileName = splitFile.getPath().getName();
  //2：获取一行数据
  String line = value.toString();
  //3：判断表文件，对数据进行切割
  String[] files = line.split(&quot;\t&quot;);
  if(fileName.startsWith(&quot;order&quot;)) &#123;
      //订单表
      v.setOrderId(files[0]);
      v.setpId(files[1]);
      v.setAmount(Integer.parseInt(files[2]));
      v.setpName(&quot;&quot;);
      v.setTableType(&quot;0&quot;);
      k.set(files[1]);
  &#125;else &#123;
      //产品表
      v.setOrderId(&quot;&quot;);
      v.setpId(files[0]);
      v.setAmount(0);
      v.setpName(files[1]);
      v.setTableType(&quot;1&quot;);
      k.set(files[0]);
  &#125;
  //4:写出数据
  context.write(k,v);
</code></pre>
<p>  }</p>
</li>
</ul>
<p>}<br></code></pre> ⑸TableReducer类代码： <pre class="has"><code class="language-java">package com.kgf.mapreduce.reducerJoin;</p>
<p>import java.io.IOException;<br>import java.lang.reflect.InvocationTargetException;<br>import java.util.ArrayList;<br>import java.util.List;</p>
<p>import org.apache.commons.beanutils.BeanUtils;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Reducer;<br>/***</p>
<ul>
<li><pre><code>创建TableReducer类：
</code></pre>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class TableReducer extends Reducer&lt;Text, TableBean, TableBean, NullWritable&gt; {</p>
<p>  @Override<br>  protected void reduce(Text key, Iterable&lt;TableBean&gt; values,Context context) </p>
<pre><code>      throws IOException, InterruptedException &#123;
  //1：循环所有的values,
  List&amp;lt;TableBean&amp;gt; tbList = new ArrayList&amp;lt;TableBean&amp;gt;();//用来存放订单表数据
  TableBean tBean = new TableBean();//存放产品表数据
  for (TableBean val : values) &#123;
      //2：判断表类型
      if(&quot;0&quot;.equals(val.getTableType())) &#123;//订单表
          try &#123;
              //3：创建一个TableBean对象
              TableBean tb = new TableBean();
              //4：将val拷贝到tb中
              BeanUtils.copyProperties(tb, val);
              tbList.add(tb);//注意：如果我们不进行拷贝会出问题，都是最后一个对象的值，前面的对象数据会被覆盖
          &#125; catch (IllegalAccessException e) &#123;
              e.printStackTrace();
          &#125; catch (InvocationTargetException e) &#123;
              e.printStackTrace();
          &#125;
      &#125;else &#123;//产品表
          try &#123;
              BeanUtils.copyProperties(tBean, val);
          &#125; catch (IllegalAccessException e) &#123;
              e.printStackTrace();
          &#125; catch (InvocationTargetException e) &#123;
              e.printStackTrace();
          &#125;
      &#125;
  &#125;
  //拼接表
  for (TableBean tableBean : tbList) &#123;
      tableBean.setpName(tBean.getpName());
      context.write(tableBean, NullWritable.get());
  &#125;
</code></pre>
<p>  }</p>
</li>
</ul>
<p>}<br></code></pre> ⑹TableDriver类代码 <pre class="has"><code class="language-java">package com.kgf.mapreduce.reducerJoin;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</p>
<p>public class TableDriver &#123;</p>
<pre><code>public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123;
    //1：获取job对象
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf);
    //2:设置jar对象
    job.setJarByClass(TableDriver.class);
    //3:关联mapper和reducer
    job.setMapperClass(TableMapper.class);
    job.setReducerClass(TableReducer.class);
    //4:设置mapper输出参数
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(TableBean.class);
    //5:设置最终输出参数
    job.setOutputKeyClass(TableBean.class);
    job.setOutputValueClass(NullWritable.class);
    //6：设置数据路径
    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    //7:提交
    boolean result = job.waitForCompletion(true);
    System.exit(result?0:1);
&#125;
</code></pre>
<p>}<br></code></pre>   </li>1.  缺点       上面这种方式中，合并的操作是在 reduce 阶段完成，reduce 端的处理压力太大，map节点的运算负载则很低，资源利用率不高，且在 reduce 阶段极易产生数据倾斜 。 <li>  解决方案：map 端实现数据合并 之Map Join    ⑴ 使用场景：           Map Join适用于一张表十分小、一张表很大的场景    。  ⑵优点：         在Map端缓存多张表，提前处理业务逻辑，这样增加Map端业务，减少Reduce端数据的压力，尽可能的减少数据倾斜。  ⑶具体解决办法：        采用DistributedCache。        a:<strong>在Mapper的setup阶段，将文件读取到缓存集合中。        b:在驱动函数中加载缓存</strong>。  ⑷DistributedCacheDriver类代码： <pre class="has"><code class="language-java">package com.kgf.mapreduce.mapperJoin;</p>
<p>import java.io.IOException;<br>import java.net.URI;<br>import java.net.URISyntaxException;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</p>
<p>public class DistributedCacheDriver &#123;</p>
<pre><code>public static void main(String[] args) throws IOException, URISyntaxException, ClassNotFoundException, InterruptedException &#123;
    //1：获取job对象
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf);
    //2:设置jar对象
    job.setJarByClass(DistributedCacheDriver.class);
    //3:关联mapper
    job.setMapperClass(DistributedCacheMapper.class);
    //4:设置最终输出参数
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(NullWritable.class);
    //5：设置数据路径
    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    
    //6：加载缓存数据
    job.addCacheFile(new URI(&quot;file:///e:/t_product.txt&quot;));
    
    //7：map端join的逻辑不需要reducer阶段，设置reducetask的数量为0
    job.setNumReduceTasks(0);
    
    //8:提交
    boolean result = job.waitForCompletion(true);
    System.exit(result?0:1);
&#125;
</code></pre>
<p>}<br></code></pre> ⑸DistributedCacheMapper类： <pre class="has"><code class="language-java">package com.kgf.mapreduce.mapperJoin;</p>
<p>import java.io.BufferedReader;<br>import java.io.File;<br>import java.io.FileInputStream;<br>import java.io.IOException;<br>import java.io.InputStreamReader;<br>import java.net.URI;<br>import java.util.HashMap;<br>import java.util.Map;</p>
<p>import org.apache.commons.lang3.StringUtils;<br>import org.apache.hadoop.io.LongWritable;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;</p>
<p>public class DistributedCacheMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</p>
<pre><code>Map&amp;lt;String, String&amp;gt; pdMap = new HashMap&amp;lt;String, String&amp;gt;();

/***
 * 这个属于初始化方法，只执行一些，这个我们用来加载缓存中文件数据
 */
@Override
protected void setup(Mapper&amp;lt;LongWritable, Text, Text, NullWritable&amp;gt;.Context context)
        throws IOException, InterruptedException &#123;
    // 1：获取缓存文件
    URI[] cacheFiles = context.getCacheFiles();
    String path = cacheFiles[0].getPath().toString();
    BufferedReader reader = new BufferedReader(
            new InputStreamReader(new FileInputStream(path), &quot;UTF-8&quot;));
    String line = null;
    while(StringUtils.isNoneBlank(line=reader.readLine())) &#123;
        //对一行进行切割
        String[] fields = line.split(&quot;\t&quot;);
        //数据缓存到集合中
        pdMap.put(fields[0],fields[1]);
    &#125;
    //关闭流
    reader.close();
&#125;

Text k = new Text();

@Override
protected void map(LongWritable key, Text value,
        Mapper&amp;lt;LongWritable, Text, Text, NullWritable&amp;gt;.Context context)
        throws IOException, InterruptedException &#123;
    //1：读取一行
    String line = value.toString();
    //2：切割
    String[] fields = line.split(&quot;\t&quot;);
    //3：获取pId
    String pid = fields[1];
    //4：获取pid对应的名称
    String pName = pdMap.get(pid);
    //5：替换掉名称
    line = fields[0]+&quot;\t&quot;+pName+&quot;\t&quot;+fields[2];
    k.set(line);
    context.write(k, NullWritable.get());
&#125;
</code></pre>
<p>}<br></code></pre> ⑹这里我们不需要reducer类，注意：可以没有reducer,但是mapper必须有，效果如下：       <img alt="" class="has" height="210" src="https://img-blog.csdnimg.cn/20190806231953323.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="600"> </li></p>
<h1 id=""><a href="#" class="headerlink" title=""></a></h1>]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>MapReduce之入门概述以及WordCount 案例</title>
    <url>/2021/07/18/MapReduce%E4%B9%8B%E5%85%A5%E9%97%A8%E6%A6%82%E8%BF%B0%E4%BB%A5%E5%8F%8AWordCount%20%E6%A1%88%E4%BE%8B/</url>
    <content><![CDATA[<p>title: MapReduce之入门概述以及WordCount 案例<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：MapReduce定义</p>
<ol>
<li> 简介       Mapreduce 是一个分布式运算程序的编程框架，是用户开发“基于 hadoop 的数据分析应用”的核心框架。       Mapreduce 核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序， 并发运行在一个 hadoop 集群上。1. Mapreduce 优缺点       ⑴优点：                 a：MapReduce  易于编程                           它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量                      廉价的 PC 机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模                      一样的。就是因为这个特点使得 MapReduce 编程变得非常流行。                 b：良好的 扩展性                            当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。                 c： 高容错性                            MapReduce 设计的初衷就是使程序能够部署在廉价的 PC 机器上，这就要求它具有很高的容错性。                       比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行                       失败，而且这个过程不需要人工参与，而完全是由Hadoop 内部完成的。                 d：适合 PB  级以上海量数据的 离线处理                            这里加红字体离线处理，说明它适合离线处理而不适合在线处理。比如像毫秒级别的返回一个结果，                       MapReduce 很难做到。       ⑵缺点：                 a：MapReduce 不 擅长做实时计算、流式计算、DAG（有向图 ） 计算                 b：实时计算：                            MapReduce 无法像 Mysql 一样，在毫秒或者秒级内返回结果。                 c：流式计算：                             流式计算的输入数据是动态的，而 MapReduce 的输入数据集是静态的，不能动态变化。                       这是因为 MapReduce 自身的设计特点决定了数据源必须是静态的。                 d：DAG （有向图）计算：                              多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，                       MapReduce 并不是不能做，而是使用后，每个 MapReduce 作业的输出结果都会写入到磁盘，                       会造成大量的磁盘 IO，导致性能非常的低下。1. MapReduce的核心思想      <img alt="" class="has" height="478" src="https://img-blog.csdnimg.cn/20190727112452226.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="591">      <img alt="" class="has" height="278" src="https://img-blog.csdnimg.cn/20190727112523638.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="633">          <h1 id="二：MapReduce进程"><a href="#二：MapReduce进程" class="headerlink" title="二：MapReduce进程"></a>二：MapReduce进程</h1></li>
<li> 简介   <img alt="" class="has" height="251" src="https://img-blog.csdnimg.cn/20190727112710794.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="706">         <h1 id="三：MapReduce-编程规范-（八股文）"><a href="#三：MapReduce-编程规范-（八股文）" class="headerlink" title="三：MapReduce  编程规范 （八股文）"></a>三：MapReduce  编程规范 （八股文）</h1></li>
<li>简介       用户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行 mr 程序的客户端)。1. Mapper阶段       <img alt="" class="has" height="228" src="https://img-blog.csdnimg.cn/20190727113717265.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="587">1. Reducer阶段       <img alt="" class="has" height="204" src="https://img-blog.csdnimg.cn/20190727114144791.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="658">1. Driver 阶段      整个程序需要一个 Drvier 来进行提交，提交的是一个描述了各种必要信息的 job 对象            <h1 id="四：WordCount-案例"><a href="#四：WordCount-案例" class="headerlink" title="四：WordCount 案例"></a>四：WordCount 案例</h1></li>
<li>需求：         在一堆给定的文本文件中统计输出每一个单词出现的总次数。1. 数据准备，一个文件hello.txt,内容如下   <img alt="" class="has" height="287" src="https://img-blog.csdnimg.cn/20190727114806278.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="354">1. 案例分析   <img alt="" class="has" height="361" src="https://img-blog.csdnimg.cn/20190727115633681.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="539"><li>代码实现     ⑴在eclipse中创建工程               <img alt="" class="has" height="154" src="https://img-blog.csdnimg.cn/2019072712170054.png" width="347">               jar包和之前的一样，从hadoop安装包中拷贝出来。环境变量之前已经配置好了。              <img alt="" class="has" height="212" src="https://img-blog.csdnimg.cn/20190727121812316.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="437">     ⑵创建自定义的Mapper类去对数据进行分类，注意：我们这里会将所有数据分类完成后才会进入到下一阶段           <pre class="has"><code class="language-java">package com.kgf.mapreduce;</li>
</ol>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.io.IntWritable;<br>import org.apache.hadoop.io.LongWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;</p>
<p>/***</p>
<ul>
<li></li>
<li><p>继承的Mapper参数如下：</p>
</li>
<li><p>第一个参数key：LongWritable表示输入的key的行号</p>
</li>
<li><p>第二个参数value：Text表示一行内容</p>
</li>
<li><p>第三个参数key： Text表示单词</p>
</li>
<li><p>第四个参数value:IntWritable表示计算后的单词的个数</p>
</li>
<li><p>@author kgf</p>
</li>
<li></li>
<li><p>/<br>public class WordCountMapper extends Mapper&lt;LongWritable,Text,Text,IntWritable&gt;&#123;</p>
<p>  Text k = new Text();<br>  IntWritable v = new IntWritable(1);</p>
<p>  /**</p>
<ul>
<li>使用map方法去处理数据，数据是一行一行进入到这个方法处理的</li>
<li>key：表示行号</li>
<li>value：表示一行数据内容</li>
<li>/<br>@Override<br>protected void map(LongWritable key, Text value, Context context)<pre><code>  throws IOException, InterruptedException &#123;
</code></pre>
  //首先我们将一行内容转换成String<br>  String line = value.toString();<br>  //数据的单词之间是以空格切割的<br>  String[] words = line.split(“ “);<br>  //将数据循环写出到下一阶段<br>  for (String word : words) {<pre><code>  k.set(word);
  context.write(k, v);
</code></pre>
  }<br>}<br>}<br></code></pre> ⑶创建自定义的Reducer类对分类的数据进行汇总      <pre class="has"><code class="language-java">package com.kgf.mapreduce;</li>
</ul>
</li>
</ul>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.io.IntWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Reducer;</p>
<p>/**</p>
<ul>
<li><p>注意：这里继承Reducer的前两个入参就是Mappper的出参数</p>
</li>
<li><p>@author kgf</p>
</li>
<li></li>
<li><p>/<br>public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt;&#123;</p>
<p>  /**</p>
<ul>
<li>这个方法主要是对map分类之后的数据进行聚合的</li>
<li>/<br>@Override<br>protected void reduce(Text key, Iterable&lt;IntWritable&gt; values,<pre><code>  Context context) throws IOException, InterruptedException &#123;
</code></pre>
  //统计单词个数<br>  int sum = 0;<br>  for (IntWritable count : values) {<pre><code>  sum+=count.get();
</code></pre>
  }<br>  //输出单词总个数<br>  context.write(key, new IntWritable(sum));<br>}</li>
</ul>
</li>
</ul>
<p>}<br></code></pre> ⑷创建Driver提交任务      <pre class="has"><code class="language-java">package com.kgf.mapreduce;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.IntWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</p>
<p>public class WordCountDriver &#123;</p>
<pre><code>public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123;
    
    //1:首先获取job信息
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf);
    
    //2:获取jar包位置,指定入口类，hadoop会自己找到
    job.setJarByClass(WordCountDriver.class);
    
    //3：关联自定义的mapper和reducer
    job.setMapperClass(WordCountMapper.class);
    job.setReducerClass(WordCountReducer.class);
    
    //4:设置map输出类型
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(IntWritable.class);
    
    //5:设置reducer输出类型
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    
    //6:设置数据输入和输出文件路径,这里我们通过main方法获取参数路径
    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    
    //7:提交代码
    boolean result = job.waitForCompletion(true);
    System.exit(result?0:1);
&#125;
</code></pre>
<p>}<br></code></pre>   </li>1.   在eclispe上将程序打成jar包   <img alt="" class="has" height="111" src="https://img-blog.csdnimg.cn/2019072715265789.png" width="150">1.  对jar包进行测试  ⑴启动集群  ⑵将jar包以及准备的hello.txt数据文本上传到/opt/module/hadoop-2.7.2目录下，并且设置有权限        <img alt="" class="has" height="336" src="https://img-blog.csdnimg.cn/20190727154242481.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="404">           ⑶将准备的hello.txt文件上传的hdfs指定目录下         <img alt="" class="has" height="79" src="https://img-blog.csdnimg.cn/20190727154354678.png" width="652">         <img alt="" class="has" height="179" src="https://img-blog.csdnimg.cn/20190727154506556.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="548">   ⑷使用我们的jar去测试（当前路径：/opt/module/hadoop-2.7.2）：         命令:hadoop jar +jar名称 +Driver入口的全路径 +输入路径 +输出路径         <img alt="" class="has" height="85" src="https://img-blog.csdnimg.cn/20190727155045147.png" width="666">        执行成功生成的文件：        <img alt="" class="has" height="225" src="https://img-blog.csdnimg.cn/20190727155247312.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="578">    ⑸查看文件内容           <img alt="" class="has" height="158" src="https://img-blog.csdnimg.cn/20190727155447856.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="488">1. 本地模式运行     ⑴上面我们是将jar包放到集群上运行，这里我们们需要在本地直接运行，因为本地我们有hadoop的jar包     ⑵在eclise上配置环境变量          <img alt="" class="has" height="189" src="https://img-blog.csdnimg.cn/20190727160144166.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="405">          注意：输出路径不能提前建好。         <img alt="" class="has" height="168" src="https://img-blog.csdnimg.cn/20190727160219740.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="366">     ⑶执行效果：         <img alt="" class="has" height="195" src="https://img-blog.csdnimg.cn/20190727160422404.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="365">         <img alt="" class="has" height="229" src="https://img-blog.csdnimg.cn/20190727160525354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="405">        </p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>MapReduce实现寻找共同好友</title>
    <url>/2021/07/18/MapReduce%E5%AE%9E%E7%8E%B0%E5%AF%BB%E6%89%BE%E5%85%B1%E5%90%8C%E5%A5%BD%E5%8F%8B/</url>
    <content><![CDATA[<p>title: MapReduce实现寻找共同好友<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—title: MapReduce实现寻找共同好友<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—1. 需求：给出A-O个人中每个人的好友列表，求出哪些人两两之间有共同好友，以及他们的共同好友都有谁。    注意：这些人好友都是单向的，可能A是B的好友，但是B不一定是A的好友，这种类似的微博的关注，               A关注B，但是B不一定关注了A。1. 原始文件如下：   <img alt="" class="has" height="345" src="https://img-blog.csdnimg.cn/20190811145226975.png" width="289">  1. 要求输出的格式如下：  <img alt="" class="has" height="266" src="https://img-blog.csdnimg.cn/20190811145317894.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="328">1. 思路分析：    ⑴我们从上面可以现在我们知道A-O每个人拥有哪些好友，但是我们现在是要找出两两之间的人有哪些共同好友。那么        我们可以逆向思维，第一步找出哪些好友拥有A,哪些好友拥有B…..依次找出，结果如下：        <img alt="" class="has" height="264" src="https://img-blog.csdnimg.cn/20190811145923175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="320">    ⑵通过得出上面的数据后，我们可以对后面的好友进行排序，避免重复，将 “拥有这名朋友的所有人”进行两两配对，并将配对后的         字符串当做键，“朋友”当做值输出，即输出&lt;人-人，共同朋友&gt;        <img alt="" class="has" height="362" src="https://img-blog.csdnimg.cn/20190811150157279.png" width="206"> <li>代码实现，通过两次job运算  a：FriendMapper01         <pre class="has"><code class="language-java">package com.kgf.mapreduce.friend;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.io.LongWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;</p>
<p>public class FriendMapper01 extends Mapper&lt;LongWritable, Text, Text, Text&gt;&#123;</p>
<pre><code>Text k  =new Text();
Text v  =new Text();

@Override
protected void map(LongWritable key, Text value,Context context)
        throws IOException, InterruptedException &#123;
    //1：获取一行数据
    String line = value.toString();
    //2：对一行数据进行切割
    String[] fields = line.split(&quot;:&quot;);
    String person = fields[0];
    String[] friends = fields[1].split(&quot;,&quot;);
    for (String friend : friends) &#123;
        k.set(friend);
        v.set(person);
        context.write(k, v);
    &#125;
&#125;
</code></pre>
<p>}<br></code></pre> b：FriendReducer       <pre class="has"><code class="language-java">package com.kgf.mapreduce.friend;</p>
<p>import java.io.IOException;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Reducer;</p>
<p>public class FriendReducer extends Reducer&lt;Text, Text, Text, Text&gt; &#123;</p>
<pre><code>@Override
protected void reduce(Text key, Iterable&amp;lt;Text&amp;gt; values,Context context)
        throws IOException, InterruptedException &#123;
    
    StringBuffer sb = new StringBuffer();
    //1：获取哪些好友都有对应的人
    for (Text text : values) &#123;
        sb.append(text.toString()+&quot;,&quot;);
    &#125;
    sb.deleteCharAt(sb.length()-1);
    context.write(key, new Text(sb.toString()));
&#125;
</code></pre>
<p>}<br></code></pre> c：FriendDriver01       <pre class="has"><code class="language-java">package com.kgf.mapreduce.friend;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</p>
<p>public class FriendDriver01 &#123;</p>
<pre><code>public static void main(String[] args) throws Exception &#123;
    //1：获取Job对象
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf);
    
    //2:设置jar
    job.setJarByClass(FriendDriver01.class);
    
    //3:关联Mapper和reducer
    job.setMapperClass(FriendMapper01.class);
    job.setReducerClass(FriendReducer.class);
    
    //4:设置mapper输出参数
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(Text.class);
    
    //5：设置最终输出
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(Text.class);
    
    //6:设置文件输入输出路径
    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    
    //7：提交
    boolean result = job.waitForCompletion(true);
    System.exit(result?0:1);
&#125;
</code></pre>
<p>}<br></code></pre> d：FriengMapper02 <pre class="has"><code class="language-java">package com.kgf.mapreduce.friend;</p>
<p>import java.io.IOException;<br>import java.util.Arrays;</p>
<p>import org.apache.hadoop.io.LongWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;</p>
<p>public class FriengMapper02 extends Mapper&lt;LongWritable, Text, Text, Text&gt;&#123;</p>
<pre><code>@Override
protected void map(LongWritable key, Text value,Context context)
        throws IOException, InterruptedException &#123;
    //1：获取一行
    String line = value.toString();
    //2：切割数据
    String[] fileds = line.split(&quot;\t&quot;);
    String friend = fileds[0];
    String[] persons = fileds[1].split(&quot;,&quot;);
    Arrays.sort(persons);//排序
    for (int i = 0; i &amp;lt; persons.length; i++) &#123;
        for (int j = i+1; j &amp;lt; persons.length; j++) &#123;
            context.write(new Text(persons[i]+&quot;-&quot;+persons[j]),new Text(friend));
        &#125;
    &#125;
&#125;
</code></pre>
<p>}<br></code></pre> e：FriendReducer2 <pre class="has"><code class="language-java">package com.kgf.mapreduce.friend;</p>
<p>import java.io.IOException;<br>import java.util.HashSet;</p>
<p>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Reducer;</p>
<p>public class FriendReducer2 extends Reducer&lt;Text, Text, Text, Text&gt; &#123;</p>
<pre><code>@Override
protected void reduce(Text key, Iterable&amp;lt;Text&amp;gt; values,Context context)
        throws IOException, InterruptedException &#123;
    
    StringBuffer sb = new StringBuffer();
    HashSet&amp;lt;String&amp;gt; set = new HashSet&amp;lt;String&amp;gt;();
    
    for (Text value : values) &#123;
        String v = value.toString();
        if(!set.contains(v)) &#123;
            set.add(v);
            sb.append(v).append(&quot;,&quot;);
        &#125;
    &#125;
    sb.deleteCharAt(sb.length()-1);
    context.write(key, new Text(sb.toString()));
&#125;
</code></pre>
<p>}<br></code></pre> f：FriendDriver2 <pre class="has"><code class="language-java">package com.kgf.mapreduce.friend;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</p>
<p>public class FriendDriver2 &#123;</p>
<pre><code>public static void main(String[] args) throws Exception &#123;
    //1：获取Job对象
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf);
    
    //2:设置jar
    job.setJarByClass(FriendDriver2.class);
    
    //3:关联Mapper和reducer
    job.setMapperClass(FriengMapper02.class);
    job.setReducerClass(FriendReducer2.class);
    
    //4:设置mapper输出参数
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(Text.class);
    
    //5：设置最终输出
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(Text.class);
    
    //6:设置文件输入输出路径
    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    
    //7：提交
    boolean result = job.waitForCompletion(true);
    System.exit(result?0:1);
&#125;
</code></pre>
<p>}<br></code></pre>   </li></p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>MapReduce知识点学习</title>
    <url>/2021/07/18/MapReduce%E7%9F%A5%E8%AF%86%E7%82%B9%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>title: MapReduce知识点学习<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—title: MapReduce知识点学习<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—1. 1. 1. 1. 1. 1. 1. 1. </p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>clickHouse基本介绍</title>
    <url>/2021/07/18/clickHouse%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<p>title: clickHouse基本介绍<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—## 1.简介</p>
<blockquote>
<p>       ClickHouse是俄罗斯的Yandex于2016年开源的一个用于联机分析(OLAP:Online Analytical Processing)的列式数据库管理系统(DBMS:Database Management System)，简称CK , 主要用于在线分析处理查询（OLAP），能够使用SQL查询实时生成分析数据报告。<br>       ClickHouse是一个完全的列式数据库管理系统，允许在运行时创建表和数据库，加载数据和运行查询，而无需重新配置和重新启动服务器，支持线性扩展，简单方便，高可靠性，容错。它在大数据领域没有走 Hadoop 生态，而是采用 Local attached storage 作为存储，这样整个 IO 可能就没有 Hadoop 那一套的局限。它的系统在生产环境中可以应用到比较大的规模，因为它的线性扩展能力和可靠性保障能够原生支持 shard + replication 这种解决方案。它还提供了一些 SQL 直接接口，有比较丰富的原生 client。另外就是它比较快。 </p>
</blockquote>
<h2 id="2-ClickHouse的特点"><a href="#2-ClickHouse的特点" class="headerlink" title="2.ClickHouse的特点"></a>2.<strong><strong>ClickHouse的特点</strong></strong></h2><blockquote>
</blockquote>
<ul>
<li>开源的列存储数据库管理系统，支持线性扩展，简单方便，高可靠性，- 容错跑分快：比Vertica快5倍，比Hive快279倍，比MySQL快800倍,其可处理的数据级别已达到10亿级别- 功能多：支持数据统计分析各种场景，支持类SQL查询，异地复制部署</li>
</ul>
<h2 id="3-clickHouse的性能"><a href="#3-clickHouse的性能" class="headerlink" title="3.clickHouse的性能"></a><strong><strong>3.clickHouse的性能</strong></strong></h2><blockquote>
</blockquote>
<ul>
<li>低延迟：对于数据量（几千行，列不是很多）不是很大的短查询，如果数据已经被载入缓存，且使用主码，延迟在50MS左右。- 并发量：虽然 ClickHouse 是一种在线分析型数据库，也可支持一定的并发。当单个查询比较短时，官方建议 100 Queries / second- 写入速度：在使用 MergeTree 引擎的情况下，写入速度大概是 50 - 200 M / s，如果按照 1 K 一条记录来算，大约每秒可写入 50000 ~ 200000 条记录每秒。如果每条记录比较小的话写入速度会更快</li>
</ul>
<h2 id="4-clickhouse的优缺点介绍"><a href="#4-clickhouse的优缺点介绍" class="headerlink" title="4.clickhouse的优缺点介绍"></a><strong><strong>4.</strong></strong>clickhouse的优缺点介绍</h2><blockquote>
<p> 优点： </p>
</blockquote>
<ul>
<li>快，超乎想象的快（单表），clickhouse目前测试和使用中来看，单表的查询性能无人能敌。- 压缩率高，目前clickhouse的数据压缩能够达到30%～40%之前，这对于一个 精打细算的公司来说是一件很划算的事情（省磁盘） 总结起来就是吃的是草，挤的是奶（手动滑稽）<br>缺点： </li>
<li>就是对于并发支持不够友好。在高并发查询，大概同时的查询数量在上千级别的话，就很容易出问题，因 此，用来做面向用户的查询的存储肯定就不是一个正确的选择- 相对于查询来说，他的写入速度没有那么优秀，目前测试 来看，单台机器的写入速度只能达到大概30W/s～60W/s- 相比较他自己单表查询性能来说，join的性能就不是很优秀了，但是相 比较传统的hive和spark来说，性能还是很很不错的</li>
</ul>
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>azkaban的安装</title>
    <url>/2021/07/18/azkaban%E7%9A%84%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>title: azkaban的安装<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—title: azkaban的安装<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—1. 上传安装包  机器：hadoop112  <img alt="" class="has" height="348" src="https://img-blog.csdnimg.cn/20191112221358405.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="752">1. 解压安装包   <img alt="" class="has" height="319" src="https://img-blog.csdnimg.cn/20191112221732490.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="614">1. 创建一个azkaban文件夹，讲安装包都放入  <img alt="" class="has" height="334" src="https://img-blog.csdnimg.cn/20191112222008392.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="730">1. azkaban脚本导入，进入mysql，创建azkaban数据库，并将解压的脚本导入到azkaban数据库。  <img alt="" class="has" height="384" src="https://img-blog.csdnimg.cn/20191112223412370.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="369">  因为我们的sql文件在hadoop112,mysql在hadoop111,那么我们需要将文件移到hadoop111上  <img alt="" class="has" height="415" src="https://img-blog.csdnimg.cn/20191112223751905.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="646">  在mysql上执行移动过来的脚本  <img alt="" class="has" height="276" src="https://img-blog.csdnimg.cn/20191112223929718.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="542">  执行后相关表  <img alt="" class="has" height="410" src="https://img-blog.csdnimg.cn/20191112224041285.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="341">1. 生成密钥对和证书  a：进入/usr/local/module/azkaban/azkaban-web-2.5.0目录下          <img alt="" class="has" height="174" src="https://img-blog.csdnimg.cn/20191112224817159.png" width="683">  b：生成 keystore的密码及相应信息的密钥库        命令：keytool -keystore keystore -alias jetty -genkey -keyalg RSA        <img alt="" class="has" height="194" src="https://img-blog.csdnimg.cn/20191112224858272.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="680">       <img alt="" class="has" height="473" src="https://img-blog.csdnimg.cn/20191112225112551.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="666">      <img alt="" class="has" height="275" src="https://img-blog.csdnimg.cn/20191112225143399.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="582">1. 配置时间的同步，（集群之间服务器需要同步，之前通过ntp配置过了）<li>开始配置文件/usr/local/module/azkaban/azkaban-web-2.5.0/conf目录下azkaban.properties   <pre class="has"><code class="language-bash">#Azkaban Personalization Settings<br>#服务器UI名称,用于服务器上方显示的名字<br>azkaban.name=Test<br>#描述<br>azkaban.label=My Local Azkaban<br>#UI颜色<br>azkaban.color=#FF3601<br>azkaban.default.servlet.path=/index<br>#默认web server存放web文件的目录<br>web.resource.dir=/usr/local/module/azkaban/azkaban-web-2.5.0/web/<br>#默认时区,已改为亚洲/上海 默认为美国<br>default.timezone.id=Asia/Shanghai</p>
<p>#Azkaban UserManager class<br>user.manager.class=azkaban.user.XmlUserManager<br>#用户权限管理默认类（绝对路径）<br>user.manager.xml.file=/usr/local/module/azkaban/azkaban-web-2.5.0/conf/azkaban-users.xml</p>
<p>#Loader for projects<br>#global配置文件所在位置（绝对路径）<br>executor.global.properties=/usr/local/module/azkaban/azkaban-executor-2.5.0/conf/global.properties<br>azkaban.project.dir=projects</p>
<p>#mysql链接<br>database.type=mysql<br>mysql.port=3306<br>mysql.host=hadoop111<br>mysql.database=azkaban<br>mysql.user=root<br>mysql.password=897570<br>#最大连接数<br>mysql.numconnections=100</p>
<h1 id="Velocity-dev-mode"><a href="#Velocity-dev-mode" class="headerlink" title="Velocity dev mode"></a>Velocity dev mode</h1><p>velocity.dev.mode=false</p>
<h1 id="Azkaban-Jetty-server-properties"><a href="#Azkaban-Jetty-server-properties" class="headerlink" title="Azkaban Jetty server properties."></a>Azkaban Jetty server properties.</h1><p>jetty.maxThreads=25<br>jetty.ssl.port=8443<br>jetty.port=8081<br>#SSL文件名（绝对路径）<br>jetty.keystore=/usr/local/module/azkaban/azkaban-web-2.5.0/keystore<br>#SSL文件密码<br>jetty.password=897570<br>#Jetty主密码与keystore文件相同<br>jetty.keypassword=897570<br>#SSL文件名（绝对路径）<br>jetty.truststore=/usr/local/module/azkaban/azkaban-web-2.5.0/keystore<br>#SSL文件密码<br>jetty.trustpassword=897570</p>
<h1 id="Azkaban-Executor-settings"><a href="#Azkaban-Executor-settings" class="headerlink" title="Azkaban Executor settings"></a>Azkaban Executor settings</h1><p>executor.port=12321</p>
<h1 id="mail-settings"><a href="#mail-settings" class="headerlink" title="mail settings"></a>mail settings</h1><p>mail.sender=<br>mail.host=<br>job.failure.email=<br>job.success.email=</p>
<p>lockdown.create.projects=false</p>
<p>cache.directory=cache<br></code></pre>   </li><li>/usr/local/module/azkaban/azkaban-web-2.5.0/conf目录下azkaban-users.xml   <pre class="has"><code class="language-html">&lt;azkaban-users&gt;<br>    &lt;user username="azkaban" password="azkaban" roles="admin" groups="azkaban" /&gt;<br>    &lt;user username="metrics" password="metrics" roles="metrics"/&gt;<br>    &lt;!--添加自己的用户--&gt;<br>    &lt;user username="kgf" password="897570" roles="admin"/&gt;</p>
<pre><code>&amp;lt;role name=&quot;admin&quot; permissions=&quot;ADMIN&quot; /&amp;gt;
&amp;lt;role name=&quot;metrics&quot; permissions=&quot;METRICS&quot;/&amp;gt;
</code></pre>
<p>&lt;/azkaban-users&gt;<br></code></pre>   </li><li>修改/usr/local/module/azkaban/azkaban-executor-2.5.0/conf/目录下的azkaban.properties文件   <pre class="has"><code class="language-bash">#Azkaban<br>#修改时区<br>default.timezone.id=Asia/Shanghai</p>
<h1 id="Azkaban-JobTypes-Plugins"><a href="#Azkaban-JobTypes-Plugins" class="headerlink" title="Azkaban JobTypes Plugins"></a>Azkaban JobTypes Plugins</h1><p>azkaban.jobtype.plugin.dir=plugins/jobtypes</p>
<p>#Loader for projects<br>executor.global.properties=/usr/local/module/azkaban/azkaban-executor-2.5.0/conf/global.properties<br>azkaban.project.dir=projects</p>
<p>database.type=mysql<br>mysql.port=3306<br>mysql.host=hadoop111<br>mysql.database=azkaban<br>mysql.user=root<br>mysql.password=897570<br>mysql.numconnections=100</p>
<h1 id="Azkaban-Executor-settings-1"><a href="#Azkaban-Executor-settings-1" class="headerlink" title="Azkaban Executor settings"></a>Azkaban Executor settings</h1><p>executor.maxThreads=50<br>executor.port=12321<br>executor.flow.threads=30</p>
<p></code></pre>   </li>1. 进入/usr/local/module/azkaban目录下启动  a：先启动executor        <img alt="" class="has" height="215" src="https://img-blog.csdnimg.cn/20191113222540471.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="686"> b：再启动web        <img alt="" class="has" height="266" src="https://img-blog.csdnimg.cn/20191113222655646.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="612">        <img alt="" class="has" height="163" src="https://img-blog.csdnimg.cn/20191113222740327.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="683">1. 效果,用户名就是刚配置的kgf/897570  <img alt="" class="has" height="357" src="https://img-blog.csdnimg.cn/2019111322292215.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="665"></p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>azkaban知识点学习</title>
    <url>/2021/07/18/azkaban%E7%9F%A5%E8%AF%86%E7%82%B9%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>title: azkaban知识点学习<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—title: azkaban知识点学习<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—1. </p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>clickhouse20.1.4.14-2单机版安装</title>
    <url>/2021/07/18/clickhouse20.1.4.14-2%E5%8D%95%E6%9C%BA%E7%89%88%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>title: clickhouse20.1.4.14-2单机版安装<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—## 1.安装文件清单</p>
<blockquote>
 <img alt="" height="126" src="https://img-blog.csdnimg.cn/20210405111422953.png" width="481"> 
</blockquote>
<h2 id="2-安装方式"><a href="#2-安装方式" class="headerlink" title="2.安装方式"></a>2.安装方式</h2><blockquote>
</blockquote>
<ul>
<li>rpm方式，这种方式适用于环境的依赖都很全，不需要安装其他的环境依赖包  命令：rpm -ivh ./*.rpm- yum方式，这种方式依赖于yum，但是不需要安装其他的环境依赖包，缺少的话会自动帮你安装  命令：yum install *.rpm</li>
</ul>
<h3 id="3-使用rpm方式安装"><a href="#3-使用rpm方式安装" class="headerlink" title="3.使用rpm方式安装"></a>3.使用rpm方式安装</h3><p>   1)在/opt/clickhouse目录下        <img alt="" height="250" src="https://img-blog.csdnimg.cn/20210405112658964.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1004"></p>
<p>   2）安装           <img alt="" height="295" src="https://img-blog.csdnimg.cn/20210405112853346.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">        </p>
<h3 id="4-启动clickhouse命令"><a href="#4-启动clickhouse命令" class="headerlink" title="4.启动clickhouse命令"></a>4.启动clickhouse命令</h3><blockquote>
<p> systemctl start clickhouse-server </p>
</blockquote>
<h3 id="5-查看状态命令"><a href="#5-查看状态命令" class="headerlink" title="5.查看状态命令"></a>5.查看状态命令</h3><blockquote>
<p> systemctl status clickhouse-server<br> <img alt="" height="297" src="https://img-blog.csdnimg.cn/20210405113223195.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> </p>
</blockquote>
<h3 id="6-重启命令"><a href="#6-重启命令" class="headerlink" title="6.重启命令"></a>6.重启命令</h3><blockquote>
<p> systemctl restart clickhouse-server </p>
</blockquote>
<h3 id="7-使用客户端命令进入"><a href="#7-使用客户端命令进入" class="headerlink" title="7.使用客户端命令进入"></a>7.使用客户端命令进入</h3><blockquote>
<p> 命令：clickhouse-client -m<br> <img alt="" height="373" src="https://img-blog.csdnimg.cn/20210405113420792.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="814"> </p>
</blockquote>
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>clickhouse之TSKV格式</title>
    <url>/2021/07/18/clickhouse%E4%B9%8BTSKV%E6%A0%BC%E5%BC%8F/</url>
    <content><![CDATA[<p>title: clickhouse之TSKV格式<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—# TSKV需要了解的点</p>
<ul>
<li>TSKV格式不适合有大量小列的输出.(因为每一行都是需要输出key，value，会比较浪费)- TSKV的效率并不比JSONEachRow差.- TSKV支持数据查询和数据导入。- 不需要保证列的顺序。- 支持忽略某些值，这些列使用默认值，例如0和空白行。复杂类型的值必须指定，无法使用默认值。<h2 id="数据的查询"><a href="#数据的查询" class="headerlink" title="数据的查询"></a>数据的查询</h2></li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>常规的数据查询<img alt="" height="473" src="https://img-blog.csdnimg.cn/20210411120539536.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="719">- 使用TSKV格式化之后的查询 命令：<strong>select * from escape_demo format TSKV;</strong><img alt="" height="434" src="https://img-blog.csdnimg.cn/202104111206194.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="828"> 可以发现每个数据前面都拼接上了字段名称。</li>
</ul>
<h2 id="数据的导出"><a href="#数据的导出" class="headerlink" title="数据的导出"></a>数据的导出</h2><blockquote>
<p> 命令：clickhouse-client –query “select * from tutorial.escape_demo FORMAT TSKV” &gt; tskv.demo </p>
</blockquote>
<h3 id="查看导出数据"><a href="#查看导出数据" class="headerlink" title="查看导出数据"></a>查看导出数据</h3><img alt="" height="269" src="https://img-blog.csdnimg.cn/20210411122533734.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="807">

<h2 id="数据的导入"><a href="#数据的导入" class="headerlink" title="数据的导入"></a>数据的导入</h2><blockquote>
<p> 命令：clickhouse-client –query “insert into tutorial.escape_demo FORMAT TSKV” &lt; tskv.demo </p>
</blockquote>
<h3 id="查看数据的导入"><a href="#查看数据的导入" class="headerlink" title="查看数据的导入"></a>查看数据的导入</h3><img alt="" height="631" src="https://img-blog.csdnimg.cn/20210411123055692.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="724">

<p>可以发现上面的数据发生了翻倍。</p>
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>clickhouse之表和列的TTL规则与实践</title>
    <url>/2021/07/18/clickhouse%E4%B9%8B%E8%A1%A8%E5%92%8C%E5%88%97%E7%9A%84TTL%E8%A7%84%E5%88%99%E4%B8%8E%E5%AE%9E%E8%B7%B5/</url>
    <content><![CDATA[<p>title: clickhouse之表和列的TTL规则与实践<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—### 1.表和列的TTL</p>
<blockquote>
<p> 定义值的生命周期<br> 可以为整个表设置，也可以为每个单独的列设置。<br> 表级的TTL也可以指定在磁盘和卷之间自动移动数据的逻辑。<br> 设置TTL的表，必须包含Date或DateTime类型的字段。<br> 定义数据的生命周期，需要在这个日期字段使用操作符：<br> <pre><code>TTL time_column<br>TTL time_column + interval<br></code></pre><br> 示例：<br> <pre><code>TTL date_time + INTERVAL 1 MONTH</p>
</blockquote>
<p>TTL date_time + INTERVAL 15 HOUR</code></pre> </p>
<h3 id="2-列级TTL"><a href="#2-列级TTL" class="headerlink" title="2.列级TTL"></a>2.列级TTL</h3><blockquote>
<p> 当列中的值过期时，ClickHouse将它们替换为该列对应数据类型的默认值。<br> 如果数据片段中所有列值都过期，则删除该数据片段下的该列的文件。<br> TTL子句不能用于key列。<br> 示例： </p>
</blockquote>
<ul>
<li>创建TTL表- TTL过期验证- 给列增加TTL- 修改列的TTL</li>
</ul>
<h3 id="3-表级TTL"><a href="#3-表级TTL" class="headerlink" title="3.表级TTL"></a>3.表级TTL</h3><blockquote>
 <ol>- 表级的TTL定义了过期行的删除、磁盘和卷之间自动移动数据的逻辑。- 一张表可以定义一个过期行移除的表达式和多个磁盘和卷之间自动移动数据的逻辑的表达式。 TTL expr [DELETE|TO DISK 'aaa'|TO VOLUME 'bbb'], ...- 当表中的数据过期时，ClickHouse删除所有对应的行。- TTL规则的类型跟在每个TTL表达式后面，它表示表达式满足后（达到当前时间）要执行的操作。**DELETE - 删除过期的行（默认操作）； TO DISK ‘aaa’ - 将片段移至磁盘aaa； TO VOLUME ‘bbb’ - 将片段移动至磁盘bbb；**<li>创建表示例： <pre><code class="language-sql">CREATE TABLE example_table
(
    d DateTime, 
    a Int 
)ENGINE = MergeTree 
PARTITION BY toYYYYMM(d) 
ORDER BY d 
TTL d + INTERVAL 1 MONTH [DELETE], 
    d + INTERVAL 1 WEEK TO VOLUME 'aaa',
    d + INTERVAL 2 WEEK TO DISK 'bbb'
SETTINGS storage_policy = 'moving_from_ssd_to_hdd';
</code></pre> 注意：当TTL表达式指定了磁盘和卷之间移动数据的逻辑，那么ClickHouse的表必须指定存储策略，且该存储策略中要包含相应的磁盘和卷。 </li>- **使用案例：TTL过期后执行数据删除案例。** 1).当ClickHouse合并数据片段时， 将删除TTL过期的数据。 2).当ClickHouse发现数据过期时， 它将执行一个计划外的合并。 要控制这类合并的频率， 可设置参数 merge_with_ttl_timeout。如果该值设置的过低， 它将导致执行许多的计划外合并，这可能会消耗大量资源。 3).如果在合并的时候执行SELECT查询， 则可能会得到过期的数据。 为了避免这种情况， 可以在SELECT 之前使用OPTIMIZE查询。</ol>
</blockquote>
<h3 id="4-列级TTL示例"><a href="#4-列级TTL示例" class="headerlink" title="4.列级TTL示例"></a>4.列级TTL示例</h3><blockquote>
 <ol><li>**创建带TTL的表** <pre><code class="language-sql">DROP TABLE example_table;
CREATE TABLE example_table 
(
    d DateTime,
    a Int TTL d + INTERVAL 1 MINUTE,
    b String TTL d + INTERVAL 1 MINUTE,
    c String
)
ENGINE = MergeTree
ORDER BY d;
xxxxx :) show create table example_table;
</blockquote>
<p>SHOW CREATE TABLE example_table</p>
<p>┌─statement─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐<br>│ CREATE TABLE default.example_table<br>(<br>    <code>d</code> DateTime,<br>    <code>a</code> Int32 TTL d + toIntervalMinute(1),<br>    <code>b</code> String TTL d + toIntervalMinute(1),<br>    <code>c</code> String<br>)<br>ENGINE = MergeTree<br>ORDER BY d<br>SETTINGS index_granularity = 8192 │<br>└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘</p>
<p>1 rows in set. Elapsed: 0.007 sec. </p>
<p>xxxxx :)<br></code></pre> </li><li><strong>插入数据</strong> <pre><code class="language-sql">insert into example_table values (now(), 1, 'value1', 'ccc1');<br>insert into example_table values(now(), 2, 'value2', 'ccc2');<br></code></pre> 等待1分钟之后，执行： <pre><code class="language-sql">xxxxx :) select * from example_table;</p>
<p>SELECT *<br>FROM example_table</p>
<p>┌───────────────────d─┬─a─┬─b──────┬─c────┐<br>│ 2020-11-26 14:53:16 │ 2 │ value2 │ ccc2 │<br>└─────────────────────┴───┴────────┴──────┘<br>┌───────────────────d─┬─a─┬─b──────┬─c────┐<br>│ 2020-11-26 14:53:15 │ 1 │ value1 │ ccc1 │<br>└─────────────────────┴───┴────────┴──────┘</p>
<p>2 rows in set. Elapsed: 0.009 sec. </p>
<p>xxxxx :) optimize table example_table;</p>
<p>OPTIMIZE TABLE example_table</p>
<p>Ok.</p>
<p>0 rows in set. Elapsed: 0.004 sec. </p>
<p>xxxxx :) select * from example_table;</p>
<p>SELECT *<br>FROM example_table</p>
<p>┌───────────────────d─┬─a─┬─b─┬─c────┐<br>│ 2020-11-26 14:53:15 │ 0 │   │ ccc1 │<br>│ 2020-11-26 14:53:16 │ 0 │   │ ccc2 │<br>└─────────────────────┴───┴───┴──────┘</p>
<p>2 rows in set. Elapsed: 0.007 sec. </p>
<p>xxxxx :)<br></code></pre>   </li><li><strong>给表的列添加TTL：</strong> <pre><code class="language-sql">ALTER TABLE example_table<br>MODIFY COLUMN<br>c String TTL d + INTERVAL 1 DAY;<br>xxxxx :) ALTER TABLE example_table<br>:-] MODIFY COLUMN<br>:-] c String TTL d + INTERVAL 1 DAY;</p>
<p>ALTER TABLE example_table<br>    MODIFY COLUMN <code>c</code> String TTL d + toIntervalDay(1)</p>
<p>Ok.</p>
<p>0 rows in set. Elapsed: 0.018 sec. </p>
<p>xxxxx :)<br></code></pre> 修改列的TTL： <pre><code class="language-sql">ALTER TABLE example_table<br>    MODIFY COLUMN<br>    c String TTL d + INTERVAL 1 MONTH;<br>xxxxx :) ALTER TABLE example_table<br>:-]     MODIFY COLUMN<br>:-]     c String TTL d + INTERVAL 1 MONTH;</p>
<p>ALTER TABLE example_table<br>    MODIFY COLUMN <code>c</code> String TTL d + toIntervalMonth(1)</p>
<p>Ok.</p>
<p>0 rows in set. Elapsed: 0.015 sec. </p>
<p>xxxxx :) show create table example_table;</p>
<p>SHOW CREATE TABLE example_table</p>
<p>┌─statement────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐<br>│ CREATE TABLE default.example_table<br>(<br>    <code>d</code> DateTime,<br>    <code>a</code> Int32 TTL d + toIntervalMinute(1),<br>    <code>b</code> String TTL d + toIntervalMinute(1),<br>    <code>c</code> String TTL d + toIntervalMonth(1)<br>)<br>ENGINE = MergeTree<br>ORDER BY d<br>SETTINGS index_granularity = 8192 │<br>└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘</p>
<p>1 rows in set. Elapsed: 0.004 sec. </p>
<p>xxxxx :)<br></code></pre>   </li></ol></p>
<h3 id="5-表级TTL示例"><a href="#5-表级TTL示例" class="headerlink" title="5.表级TTL示例"></a>5.表级TTL示例</h3><blockquote>
 <ol><li>**创建表** <pre><code class="language-sql">drop table example_table ;
CREATE TABLE example_table 
(
    d DateTime,
    a Int,
    b String,
    c String
)
ENGINE = MergeTree
ORDER BY d
TTL d + INTERVAL 1 MINUTE DELETE;
</code></pre> </li><li>**插入数据** <pre><code class="language-sql">insert into example_table values (now(), 1, 'value1', 'ccc1');
insert into example_table values(now(), 2, 'value2', 'ccc2');
</code></pre> 然后查询结果： <pre><code class="language-sql">xxxxx :) select * from example_table;
</blockquote>
<p>SELECT *<br>FROM example_table</p>
<p>┌───────────────────d─┬─a─┬─b──────┬─c────┐<br>│ 2020-11-26 15:24:53 │ 1 │ value1 │ ccc1 │<br>│ 2020-11-26 15:24:54 │ 2 │ value2 │ ccc2 │<br>└─────────────────────┴───┴────────┴──────┘</p>
<p>2 rows in set. Elapsed: 0.008 sec. </p>
<p>xxxxx :)<br></code></pre> 等待1分钟后， 执行optimize操作。 <pre><code class="language-sql">xxxxx :) optimize table example_table;</p>
<p>OPTIMIZE TABLE example_table</p>
<p>Ok.</p>
<p>0 rows in set. Elapsed: 0.006 sec. </p>
<p>xxxxx :) select * from example_table;</p>
<p>SELECT *<br>FROM example_table</p>
<p>Ok.</p>
<p>0 rows in set. Elapsed: 0.003 sec. </p>
<p>xxxxx :)<br></code></pre>   </li></ol></p>
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>clickhouse分布式集群部署</title>
    <url>/2021/07/18/clickhouse%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>title: clickhouse分布式集群部署<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—### 1.节点规划</p>
<blockquote>
 <table align="left" border="1" cellpadding="1" cellspacing="1"><thead><th style="width:268px;text-align:center;vertical-align:middle;">主机名</th><th style="width:265px;text-align:center;vertical-align:middle;">IP地址</th><th style="width:250px;text-align:center;vertical-align:middle;">分片</th><th style="width:213px;text-align:center;vertical-align:middle;">副本</th>
</blockquote>
</thead><tbody><td style="width:268px;">docker01-node</td><td style="width:265px;">192.168.56.10</td><td style="width:250px;">shard1</td><td style="width:213px;">副本1</td>
<td style="width:268px;">docker02-node</td><td style="width:265px;">192.168.56.11</td><td style="width:250px;">shard1</td><td style="width:213px;">副本2</td>
<td style="width:268px;">docker03-node</td><td style="width:265px;">192.168.56.12</td><td style="width:250px;">shard2</td><td style="width:213px;">副本1</td>
<td style="width:268px;">docker04-node</td><td style="width:265px;">192.168.56.13</td><td style="width:250px;">shard2</td><td style="width:213px;"> 副本2 </td>
</tbody></table>


<p>规划4个节点， 2个分片， 每个分片2个副本。 分片1的副本在主机clickhouse1和clickhouse2上， 2分片的副本在主机clickhouse3和clickhouse4上。 </p>
<h3 id="2-操作系统准备工作"><a href="#2-操作系统准备工作" class="headerlink" title="2.操作系统准备工作"></a>2.<strong>操作系统准备工作</strong></h3><blockquote>
<p> 1）<strong>修改主机名</strong><br> **      <strong>hostname按照上面主机名进行修改。<br> 2）</strong>关闭防火墙、selinux等。**<br> <pre><code class="language-bash">关闭防火墙：<br>systemctl stop firewalld.service<br>systemctl disable firewalld.service<br>systemctl is-enabled firewalld.service</p>
</blockquote>
<p>selinux的配置：<br>vim /etc/sysconfig/selinux<br>SELINUX=enforcing 改为 SELINUX=disabled</p>
<p>检查SELinux的状态<br>[root@localhost etc]# getenforce<br>Disabled<br>[root@localhost etc]#<br></code></pre><br> 3）<strong>配置/etc/hosts</strong><br> **        **必须在/etc/hosts配置主机名和ip地址映射关系， 否则副本之间的数据不能同步。<br> <img alt="" height="183" src="https://img-blog.csdnimg.cn/20210424113605739.png" width="925"> </p>
<h3 id="3-安装配置zookeeper"><a href="#3-安装配置zookeeper" class="headerlink" title="3.安装配置zookeeper"></a><strong>3.安装配置zookeeper</strong></h3><blockquote>
<p> 下载zookeeper,zookeeper版本要求3.4.5以上。<br> 1)将下载的安装包上传到Linux上<br>       <img alt="" height="158" src="https://img-blog.csdnimg.cn/20210424122424231.png" width="872"><br> 2)将conf目录下的zoo_sample.cfg复制一份，命名为：zoo.cfg<br>       <img alt="" height="203" src="https://img-blog.csdnimg.cn/20210424122632832.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="735"><br>       在zoo.cfg增加配置：<br>       <img alt="" height="146" src="https://img-blog.csdnimg.cn/20210424123230341.png" width="696"><br>     上面配置目录需要手工创建。<br> 3)<strong>环境配置：</strong><br> <pre><code class="language-bash">export ZOOKEEPER_HOME=/opt/zk/apache-zookeeper-3.6.2-bin/<br>export PATH=$PATH:$ZOOKEEPER_HOME/bin<br></code></pre><br> **4)**然后启动zookeeper即可。<br>      启动命令： ./bin/zkServer.sh start<br>      <img alt="" height="646" src="https://img-blog.csdnimg.cn/20210424124150418.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="868"> </p>
</blockquote>
<h3 id="4-在所有的主机安装clickhouse-参考之前的安装即可"><a href="#4-在所有的主机安装clickhouse-参考之前的安装即可" class="headerlink" title="4.在所有的主机安装clickhouse,参考之前的安装即可"></a><strong>4.在所有的主机安装clickhouse,参考之前的安装即可</strong></h3><h3 id="5-修改clickhouse的网络相关配置"><a href="#5-修改clickhouse的网络相关配置" class="headerlink" title="5.修改clickhouse的网络相关配置"></a><strong>5.修改clickhouse的网络相关配置</strong></h3><blockquote>
<p> 修改配置文件：/etc/clickhouse-server/config.xml<br> 打开以下注释，并做相关修改：<br> <img alt="" height="116" src="https://img-blog.csdnimg.cn/20210424130017519.png" width="731"><br> <strong>clickhouse1上的修改如下：</strong><br> <img alt="" height="104" src="https://img-blog.csdnimg.cn/20210424130128454.png" width="552"><br> <strong>Clickhouse2上的修改如下：</strong><br> <img alt="" height="75" src="https://img-blog.csdnimg.cn/20210424130246450.png" width="553"><br> <strong>Clickhouse3上的修改如下：</strong><br> <img alt="" height="91" src="https://img-blog.csdnimg.cn/20210424130315221.png" width="507"><br> <strong>Clickhouse4上的修改如下：</strong><br> <img alt="" height="115" src="https://img-blog.csdnimg.cn/20210424130406733.png" width="538"> </p>
</blockquote>
<h3 id="6-增加配置文件：-etc-metrika-xml"><a href="#6-增加配置文件：-etc-metrika-xml" class="headerlink" title="6.增加配置文件：/etc/metrika.xml"></a><strong>6.增加配置文件：/etc/metrika.xml</strong></h3><blockquote>
<p> docker01-node的配置如下：<br> <pre><code class="language-XML">&lt;?xml version="1.0" encoding="utf-8"?&gt;</p>
</blockquote>
<p>&lt;yandex&gt;<br>  &lt;clickhouse_remote_servers&gt;<br>    &lt;mycluster&gt;<br>      &lt;shard&gt;<br>        &lt;internal_replication&gt;true&lt;/internal_replication&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.10&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.11&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>      &lt;/shard&gt;<br>      &lt;shard&gt;<br>        &lt;internal_replication&gt;true&lt;/internal_replication&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.12&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.13&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>      &lt;/shard&gt;<br>    &lt;/mycluster&gt;<br>  &lt;/clickhouse_remote_servers&gt;<br>  &lt;zookeeper-servers&gt;<br>    &lt;node index=”1”&gt;<br>      &lt;host&gt;192.168.56.10&lt;/host&gt;<br>      &lt;port&gt;2181&lt;/port&gt;<br>    &lt;/node&gt;<br>  &lt;/zookeeper-servers&gt;<br>  &lt;macros&gt;<br>    &lt;layer&gt;01&lt;/layer&gt;<br>    &lt;shard&gt;01&lt;/shard&gt;<br>    &lt;replica&gt;192.168.56.10&lt;/replica&gt;<br>  &lt;/macros&gt;<br>&lt;/yandex&gt;<br></code></pre><br> docker02-node的配置如下：<br> <pre><code class="language-XML">&lt;?xml version="1.0" encoding="utf-8"?&gt;</p>
<p>&lt;yandex&gt;<br>  &lt;clickhouse_remote_servers&gt;<br>    &lt;mycluster&gt;<br>      &lt;shard&gt;<br>        &lt;internal_replication&gt;true&lt;/internal_replication&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.10&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.11&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>      &lt;/shard&gt;<br>      &lt;shard&gt;<br>        &lt;internal_replication&gt;true&lt;/internal_replication&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.12&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.13&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>      &lt;/shard&gt;<br>    &lt;/mycluster&gt;<br>  &lt;/clickhouse_remote_servers&gt;<br>  &lt;zookeeper-servers&gt;<br>    &lt;node index=”1”&gt;<br>      &lt;host&gt;192.168.56.10&lt;/host&gt;<br>      &lt;port&gt;2181&lt;/port&gt;<br>    &lt;/node&gt;<br>  &lt;/zookeeper-servers&gt;<br>  &lt;macros&gt;<br>    &lt;layer&gt;01&lt;/layer&gt;<br>    &lt;shard&gt;01&lt;/shard&gt;<br>    &lt;replica&gt;192.168.56.11&lt;/replica&gt;<br>  &lt;/macros&gt;<br>&lt;/yandex&gt;<br></code></pre><br> docker03-node<strong>的配置如下：</strong><br> <pre><code class="language-XML">&lt;?xml version="1.0" encoding="utf-8"?&gt;<br>&lt;yandex&gt;<br>  &lt;clickhouse_remote_servers&gt;<br>    &lt;mycluster&gt;<br>      &lt;shard&gt;<br>        &lt;internal_replication&gt;true&lt;/internal_replication&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.10&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.11&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>      &lt;/shard&gt;<br>      &lt;shard&gt;<br>        &lt;internal_replication&gt;true&lt;/internal_replication&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.12&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.13&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>      &lt;/shard&gt;<br>    &lt;/mycluster&gt;<br>  &lt;/clickhouse_remote_servers&gt;<br>  &lt;zookeeper-servers&gt;<br>    &lt;node index="1"&gt;<br>      &lt;host&gt;192.168.56.10&lt;/host&gt;<br>      &lt;port&gt;2181&lt;/port&gt;<br>    &lt;/node&gt;<br>  &lt;/zookeeper-servers&gt;<br>  &lt;macros&gt;<br>    &lt;layer&gt;01&lt;/layer&gt;<br>    &lt;shard&gt;02&lt;/shard&gt;<br>    &lt;replica&gt;192.168.56.12&lt;/replica&gt;<br>  &lt;/macros&gt;<br>&lt;/yandex&gt;<br></code></pre><br> docker04-node<strong>的配置如下：</strong><br> <pre><code class="language-XML">&lt;?xml version="1.0" encoding="utf-8"?&gt;<br>&lt;yandex&gt;<br>  &lt;clickhouse_remote_servers&gt;<br>    &lt;mycluster&gt;<br>      &lt;shard&gt;<br>        &lt;internal_replication&gt;true&lt;/internal_replication&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.10&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.11&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>      &lt;/shard&gt;<br>      &lt;shard&gt;<br>        &lt;internal_replication&gt;true&lt;/internal_replication&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.12&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>        &lt;replica&gt;<br>          &lt;host&gt;192.168.56.13&lt;/host&gt;<br>          &lt;port&gt;9000&lt;/port&gt;<br>        &lt;/replica&gt;<br>      &lt;/shard&gt;<br>    &lt;/mycluster&gt;<br>  &lt;/clickhouse_remote_servers&gt;<br>  &lt;zookeeper-servers&gt;<br>    &lt;node index="1"&gt;<br>      &lt;host&gt;192.168.56.10&lt;/host&gt;<br>      &lt;port&gt;2181&lt;/port&gt;<br>    &lt;/node&gt;<br>  &lt;/zookeeper-servers&gt;<br>  &lt;macros&gt;<br>    &lt;layer&gt;01&lt;/layer&gt;<br>    &lt;shard&gt;02&lt;/shard&gt;<br>    &lt;replica&gt;192.168.56.13&lt;/replica&gt;<br>  &lt;/macros&gt;<br>&lt;/yandex&gt;<br></code></pre><br> 其中如下这段配置在每个节点是不相同的：<br> <pre><code class="language-XML">&lt;macros&gt;<br>    &lt;layer&gt;01&lt;/layer&gt;<br>    &lt;shard&gt;01&lt;/shard&gt;<br>    &lt;replica&gt;192.168.56.10&lt;/replica&gt;<br>&lt;/macros&gt;<br></code></pre><br> layer表示分层， shard表示分片的编号， 按照配置顺序从1开始。这里的01表示第一个分片。 replica配置副本的标识， 这里配置为本机的主机名。 使用这三个参数可以唯一表示一个副本分片。 这里表示layer为01的分片1的副本，副本标识：192.168.106.103。<br> 配置完成后， 在每个节点启动ClickHouse服务。 systemctl start clickhouse-server<br> 查看状态：systemctl status clickhouse-server<br> <img alt="" height="868" src="https://img-blog.csdnimg.cn/20210424133344316.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> </p>
<h3 id="7-进入docker01-node查看系统表"><a href="#7-进入docker01-node查看系统表" class="headerlink" title="7.进入docker01-node查看系统表"></a><strong>7.进入</strong>docker01-node查看系统表</h3><p>命令：clickhouse-client -h 服务器ip地址</p>
<img alt="" height="169" src="https://img-blog.csdnimg.cn/20210424133428164.png" width="707">

<p>查看系统表命令：select * from system.clusters where cluster=’mycluster’;</p>
<img alt="" height="359" src="https://img-blog.csdnimg.cn/20210424133513204.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>clickhouse基础语法简介</title>
    <url>/2021/07/18/clickhouse%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>title: clickhouse基础语法简介<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—## 1.常用SQL语法</p>
<blockquote>
 <pre><code class="language-sql">-- 列出数据库列表
show databases;
</blockquote>
<p>– 列出数据库中表列表<br>show tables;</p>
<p>– 创建数据库<br>create database test;</p>
<p>–选中数据库<br>use test;</p>
<p>– 删除一个表<br>drop table if exists test.t1;</p>
<p>– 创建第一个表<br>create /<em>temporary</em>/ table /<em>if not exists</em>/ test.m1 (<br> id UInt16<br>,name String<br>) ENGINE = Memory<br>;<br>– 插入测试数据<br>insert into test.m1 (id, name) values (1, ‘abc’), (2, ‘bbbb’);</p>
<p>– 查询<br>select * from test.m1;</p>
<p></code></pre> 
   </p>
<h2 id="2-默认值"><a href="#2-默认值" class="headerlink" title="2.默认值"></a>2.默认值</h2><blockquote>
<p> 默认值 的处理方面， ClickHouse 中，默认值总是有的，如果没有显示式指定的话，会按字段类型处理： </p>
</blockquote>
<ul>
<li>数字类型， 0- 字符串，空字符串- 数组，空数组- 日期， 0000-00-00- 时间， 0000-00-00 00:00:00- 注：NULLs 是不支持的</li>
</ul>
<h3 id="3-数据类型"><a href="#3-数据类型" class="headerlink" title="3.数据类型"></a>3.数据类型</h3><blockquote>
 <ul>- 整型：UInt8,UInt16,UInt32,UInt64,Int8,Int16,Int32,Int64<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20201127184612320.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x1eGlhbmd5MTMxNA==,size_16,color_FFFFFF,t_70">- 枚举类型：Enum8,Enum16 存储为Int8或Int16的一组枚举字符串值。例： Enum8（'hello'= 1，'world'= 2）， 这个数据类型有两个值  'hello'和'world'。 该数值必须在-128..127为Enum8和-32768..32767为Enum16。枚举的每个成员也必须有不同的数字。空字符串是一个有效的值。数字不需要是连续的，可以以任何顺序。是顺序无关的。 在内存中，数据的存储方式与数字类型Int8和Int16相同。以文本格式读取时，读取字符串并查找相应的数值。如果找不到，则会抛出异常。当以文本格式写入时，查找存储的数字并写出相应的字符串。 如果数字不对应已知的值，则会抛出异常。以二进制格式，信息以与Int8和Int16相同的方式保存。Enum的隐式默认值是具有最小数值的值 -  字符串(String、FixedString 和 UUID) 1)String         String 不限制长度，相当于Varchar、Text、Clob 和 Blob 等字符类型 2)FixedString(N)        FixedString(N)相当于Char，长度固定，数据长度不够时，添加空字节（null）；长度过长返回错误消息 3)UUID        32位，格式8-4-4-4-12，如果未被赋值，则用0填充 -  日期时间类型 1)Date: 2020-02-02 精确到天 2)DateTime: 2020-02-02 20:20:20 精确到秒 3)DateTime64: 2020-02-02 20:20:20.335 精确到亚秒，可以设置精度均支持字符串写入 -  数组类型 Array(T) T 类型的数组。T型可以是任何类型，包括数组。我们不推荐使用多维数组，因为它们不被很好的支持（例如，除了内存表之外，你不能在多维数组中存储多维数组） -  元组：Tuple 由多个元素组成，允许不同类型 创建数据：(T1, T2, …)，Tuple(T1, T2, …) <li> 嵌套（Nested(Name1 Type1, Name2 Type2, ...)） 嵌套数据结构类似于嵌套表。嵌套数据结构的参数（列名和类型）与 CREATE 查询类似。每个表可以包含任意多行嵌套数据结构。 只支持一级嵌套。嵌套结构的列中，若列的类型是数组类型，那么该列其实和多维数组是相同的，所以目前嵌套层级的支持很局限（MergeTree 引擎中不支持存储这样的列） 大多数情况下，处理嵌套数据结构时，会指定一个单独的列。为了这样实现，列的名称会与点号连接起来。这些列构成了一组匹配类型。在同一条嵌套数据中，所有的列都具有相同的长度。 不能对整个嵌套数据结构执行 SELECT。只能明确列出属于它一部分列。 <pre><code class="language-sql">CREATE TABLE test.visits
(
    CounterID UInt32,
    StartDate Date,
    Sign Int8,
    IsNew UInt8,
    VisitID UInt64,
    UserID UInt64,
    ...
    Goals Nested
    (
        ID UInt32,
        Serial UInt32,
        EventTime DateTime,
        Price Int64,
        OrderID String,
        CurrencyID UInt32
    ),
    ...
) ENGINE = CollapsingMergeTree(StartDate, intHash32(UserID), (CounterID, StartDate, intHash32(UserID), VisitID), 8192, Sign)</code></pre>  作者：盗梦者_56f2 链接：https://www.jianshu.com/p/39e675ccbf3b 来源：简书 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 </li>-  浮点数 Float32 和 Float64<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20201127184649655.png"> float精度是：7~8位有效数字 double精度是：16~17位有效数字 -  定点数 Decimal32、Decimal64 和Decimal128 Decimal(P, S)：P代表精度，决定总位数（整数部分+小数部分），取值范围是1~38; S代表规模，决定小数位数，取值范围是0～P。<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20201127185044682.png#pic_center"> <li> 缺失值（Nullable(TypeName)） 允许用特殊标记NULL表示"缺失值"，可以与 `TypeName` 的正常值存放一起。例如，`Nullable(Int8)` 类型的列可以存储 `Int8` 类型值，而没有值的行将存储 `NULL`。 对于 `TypeName`，不能使用复合数据类型 Array和 Tuple。复合数据类型可以包含 `Nullable` 类型值，例如`Array(Nullable(Int8))`。`Nullable` 类型字段不能包含在表索引中。 除非在 ClickHouse 服务器配置中另有说明，否则 `NULL` 是任何 `Nullable` 类型的默认值。 使用 Nullable 几乎总是对性能产生负面影响。 <pre><code class="language-sql"> CREATE TABLE t_null(x Int8, y Nullable(Int8)) ENGINE TinyLog
#
INSERT INTO t_null VALUES (1, NULL)</code></pre>   </li></ul>
</blockquote>
<h3 id="4-物化列"><a href="#4-物化列" class="headerlink" title="4.物化列"></a>4.物化列</h3><blockquote>
<p> 指定 MATERIALIZED 表达式，即将一个列作为<code>物化列</code>处理了，这意味着这个列的值不能从<code>insert</code> 语句获取，只能是自己计算出来的。同时，物化列也不会出现在 <code>select *</code> 的结果中：<br> <pre><code class="language-sql">drop table if exists test.m2;<br>create table test.m2 (<br> a MATERIALIZED (b+1)<br>,b UInt16<br>) ENGINE = Memory;<br>insert into test.m2 (b) values (1);<br>select * from test.m2;<br>select a, b from test.m2; --这个可以查出来</code></pre> 
   </p>
</blockquote>
<h3 id="5-表达式列"><a href="#5-表达式列" class="headerlink" title="5.表达式列"></a>5.表达式列</h3><blockquote>
<p> ALIAS 表达式列某方面跟物化列相同，就是它的值不能从 insert 语句获取。不同的是， 物化列 是会真正保存数据（这样查询时不需要再计算），<br> 而表达式列不会保存数据（这样查询时总是需要计算），只是在查询时返回表达式的结果。<br> <pre><code class="language-sql">create table test.m3 (a ALIAS (b+1), b UInt16) ENGINE = Memory;<br>insert into test.m3(b) values (1);<br>select * from test.m3;<br>select a, b from test.m3;</code></pre> 
   </p>
</blockquote>
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>clickhouse算术函数</title>
    <url>/2021/07/18/clickhouse%E7%AE%97%E6%9C%AF%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<p>title: clickhouse算术函数<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—&gt;<br> <pre><code class="language-sql">--求和<br>SELECT plus(12, 21), plus(10, -10), plus(-10, -10);<br>+------------+-------------+--------------+<br>|plus(12, 21)|plus(10, -10)|plus(-10, -10)|<br>+------------+-------------+--------------+<br>|33          |0            |-20           |<br>+------------+-------------+--------------+</p>
<p>–差值<br>SELECT minus(10, 5), minus(10, -10), minus(-10, -10);<br>+————+————–+—————+<br>|minus(10, 5)|minus(10, -10)|minus(-10, -10)|<br>+————+————–+—————+<br>|5           |20            |0              |<br>+————+————–+—————+</p>
<p>–积<br>SELECT multiply(12, 2), multiply(12, -2), multiply(-12, -2);<br>+—————+—————-+—————–+<br>|multiply(12, 2)|multiply(12, -2)|multiply(-12, -2)|<br>+—————+—————-+—————–+<br>|24             |-24             |24               |<br>+—————+—————-+—————–+</p>
<p>–平均值<br>SELECT divide(12, 4), divide(10, 3), divide(2, 4), divide(-4, -2), divide(-4, 2), divide(-4.5, 3);<br>+————-+——————+————+————–+————-+—————+<br>|divide(12, 4)|divide(10, 3)     |divide(2, 4)|divide(-4, -2)|divide(-4, 2)|divide(-4.5, 3)|<br>+————-+——————+————+————–+————-+—————+<br>|3            |3.3333333333333335|0.5         |2             |-2           |-1.5           |<br>+————-+——————+————+————–+————-+—————+</p>
<p>SELECT intDiv(10, 3), divide(10, 3);<br>+————-+——————+<br>|intDiv(10, 3)|divide(10, 3)     |<br>+————-+——————+<br>|3            |3.3333333333333335|<br>+————-+——————+</p>
<p>SELECT divide(10, 0), divide(-10, 0); – 出现无穷大字符“ ∞ ”或“ -∞ ”<br>+————-+————–+<br>|divide(10, 0)|divide(-10, 0)|<br>+————-+————–+<br>|∞            |-∞            |<br>+————-+————–+</p>
<p>SELECT divide(0, 0); – 特殊字符（类似乱码）<br>+————+<br>|divide(0, 0)|<br>+————+<br>|NaN         |<br>+————+</p>
<p>SELECT intDivOrZero(10, 0);<br>– 0<br>+——————-+<br>|intDivOrZero(10, 0)|<br>+——————-+<br>|0                  |<br>+——————-+</p>
<p>–求余数<br>SELECT modulo(10, 3); –1<br>+————-+<br>|modulo(10, 3)|<br>+————-+<br>|1            |<br>+————-+</p>
<p>SELECT modulo(10.5, 3);<br>+—————+<br>|modulo(10.5, 3)|<br>+—————+<br>|1              |<br>+—————+</p>
<p>–取反<br>SELECT negate(10), negate(-10);<br>+———-+———–+<br>|negate(10)|negate(-10)|<br>+———-+———–+<br>|-10       |10         |<br>+———-+———–+</p>
<p>–绝对值<br>SELECT abs(-10), abs(10);<br>+——–+——-+<br>|abs(-10)|abs(10)|<br>+——–+——-+<br>|10      |10     |<br>+——–+——-+</p>
<p>–最大公约数<br>SELECT gcd(12, 24), gcd(-12, -24), gcd(-12, 24);<br>+———–+————-+————+<br>|gcd(12, 24)|gcd(-12, -24)|gcd(-12, 24)|<br>+———–+————-+————+<br>|12         |12           |12          |<br>+———–+————-+————+</p>
<p>–最小公倍数<br>SELECT lcm(12, 24), lcm(-12, -24), lcm(-3, 4);<br>+———–+————-+———-+<br>|lcm(12, 24)|lcm(-12, -24)|lcm(-3, 4)|<br>+———–+————-+———-+<br>|24         |24           |12        |<br>+———–+————-+———-+</p>
<p></code></pre> 
   </p>
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>clickhouse输入输出格式之CSV系列【CSV、CSVWithNames】</title>
    <url>/2021/07/18/clickhouse%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F%E4%B9%8BCSV%E7%B3%BB%E5%88%97%E3%80%90CSV%E3%80%81CSVWithNames%E3%80%91/</url>
    <content><![CDATA[<p>title: clickhouse输入输出格式之CSV系列【CSV、CSVWithNames】<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—# CSV</p>
<ul>
<li>CSV默认的分隔符为逗号，format_csv_delimiter设置自定义的分隔符。- CSV中的双引号使用两个双引号转义。- 支持数据的查询和数据导入的。<h2 id="案例演示"><a href="#案例演示" class="headerlink" title="案例演示"></a>案例演示</h2></li>
</ul>
<h3 id="clickhouse中建表"><a href="#clickhouse中建表" class="headerlink" title="clickhouse中建表"></a>clickhouse中建表</h3><blockquote>
<p> create table csv_demo(create_date Date, update_time DateTime, desc String) ENGINE=TinyLog; </p>
</blockquote>
<h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><blockquote>
</blockquote>
<h1 id="创建csv-demo-csv文件-vim-csv-demo-csv-填入以下数据-2014-03-23-2014-03-23-14-10-14-Apache-Spark-achieves-high-performance-2014-03-23-2014-03-23-15-10-30-Spark-offers-over-80-high-level-operators-1395990600-1395904200-Learning-Apache-“Spark”-is-easy"><a href="#创建csv-demo-csv文件-vim-csv-demo-csv-填入以下数据-2014-03-23-2014-03-23-14-10-14-Apache-Spark-achieves-high-performance-2014-03-23-2014-03-23-15-10-30-Spark-offers-over-80-high-level-operators-1395990600-1395904200-Learning-Apache-“Spark”-is-easy" class="headerlink" title="创建csv_demo.csv文件 vim csv_demo.csv # 填入以下数据 2014-03-23|2014-03-23 14:10:14|Apache Spark achieves high performance 2014-03-23|2014-03-23 15:10:30|Spark offers over 80 high-level operators 1395990600|1395904200|Learning Apache “Spark” is easy"></a>创建csv_demo.csv文件 vim csv_demo.csv # 填入以下数据 2014-03-23|2014-03-23 14:10:14|Apache Spark achieves high performance 2014-03-23|2014-03-23 15:10:30|Spark offers over 80 high-level operators 1395990600|1395904200|Learning Apache “Spark” is easy</h1><h3 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h3><blockquote>
<p> clickhouse-client –format_csv_delimiter=”|” –query=”INSERT INTO tutorial.csv_demo FORMAT CSV” &lt; csv_dmeo.csv </p>
</blockquote>
<h3 id="数据查询"><a href="#数据查询" class="headerlink" title="数据查询"></a>数据查询</h3><blockquote>
<p> select * from csv_demo FORMAT CSV; </p>
</blockquote>
<img alt="" height="314" src="https://img-blog.csdnimg.cn/20210411124429818.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="826">

<h1 id="CSVWithNames"><a href="#CSVWithNames" class="headerlink" title="CSVWithNames"></a>CSVWithNames</h1><ul>
<li>CSVWithNames会打印表头的信息。- 支持数据的导入和数据的查看。<h2 id="查询数据演示"><a href="#查询数据演示" class="headerlink" title="查询数据演示"></a>查询数据演示</h2></li>
</ul>
<blockquote>
<p> select * from csv_demo FORMAT CSVWithNames; </p>
</blockquote>
<img alt="" height="327" src="https://img-blog.csdnimg.cn/20210411124532485.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="871">
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>clickhouse输入输出格式之JSON系列【JSON、JSONCompact和JSONEachRow】</title>
    <url>/2021/07/18/clickhouse%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F%E4%B9%8BJSON%E7%B3%BB%E5%88%97%E3%80%90JSON%E3%80%81JSONCompact%E5%92%8CJSONEachRow%E3%80%91/</url>
    <content><![CDATA[<p>title: clickhouse输入输出格式之JSON系列【JSON、JSONCompact和JSONEachRow】<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—# JSON</p>
<h2 id="JSON格式的输入输出"><a href="#JSON格式的输入输出" class="headerlink" title="JSON格式的输入输出"></a>JSON格式的输入输出</h2><p>JSON格式只支持数据的输出，不支持数据的解析（数据导入）。</p>
<h2 id="案例演示"><a href="#案例演示" class="headerlink" title="案例演示"></a>案例演示</h2><h3 id="建表插数据"><a href="#建表插数据" class="headerlink" title="建表插数据"></a>建表插数据</h3><blockquote>
 <pre><code class="language-sql">create table t_json_demo(id UInt8, prov String) ENGINE=TinyLog;
insert into t_json_demo values(1, 'jiangsu'),
(1, 'jiangsu'),
(2, 'anhui'),
(2, 'anihu'),
(3, 'beijing');
</code></pre> 
</blockquote>
<h3 id="查询演示"><a href="#查询演示" class="headerlink" title="查询演示"></a>查询演示</h3><p><strong>以JSON格式查询</strong></p>
<blockquote>
<p> 命令：select id,count() as cnt from t_json_demo group by id format JSON;<br> <img alt="" height="854" src="https://img-blog.csdnimg.cn/20210411144340734.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="532"> </p>
</blockquote>
<h3 id="取出value的双引号"><a href="#取出value的双引号" class="headerlink" title="取出value的双引号"></a>取出value的双引号</h3><blockquote>
<p> 默认情况下， Int64和UInit64的整型使用双引号包裹， 如果要移除双引号，设置配置参数output_format_json_quote_64bit_integers为0。<br> 命令：set output_format_json_quote_64bit_integers=0;<br> 再进行同样的查询<br> 命令：select id,count() as cnt from t_json_demo group by id format JSON;<br> <img alt="" height="843" src="https://img-blog.csdnimg.cn/20210411144556516.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="528"> </p>
</blockquote>
<h3 id="查询时出现rows-before-limit-at-least"><a href="#查询时出现rows-before-limit-at-least" class="headerlink" title="查询时出现rows_before_limit_at_least"></a>查询时出现rows_before_limit_at_least</h3><blockquote>
<p> 只有查询包含LIMIT时才输出， 只有在包含group by的语句中才有意义。当查询没有LIMIT时， 执行结果的最小行数。 </p>
</blockquote>
<h3 id="设置显示极值的参数extremes-1（默认为0）"><a href="#设置显示极值的参数extremes-1（默认为0）" class="headerlink" title="设置显示极值的参数extremes=1（默认为0）"></a>设置显示极值的参数extremes=1（默认为0）</h3><blockquote>
<p> set extremes=1;<br> 在进行查询<code>select id,count() as cnt from t_json_demo group by id format JSON;</code><br> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20210318151530860.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x5cTcyNjk=,size_16,color_FFFFFF,t_70"> </p>
</blockquote>
<p> </p>
<h1 id="JSONCompact"><a href="#JSONCompact" class="headerlink" title="JSONCompact"></a>JSONCompact</h1><h2 id="JSONCompact的输入输出"><a href="#JSONCompact的输入输出" class="headerlink" title="JSONCompact的输入输出"></a>JSONCompact的输入输出</h2><blockquote>
</blockquote>
<ul>
<li>JSON格式的数据以对象的方式输出， 而JSONCompact以数组的方式输出。- JSONCompact只支持数据的查看， 不支持数据的导入。<h2>案例演示</h2> 
`select id,count() as cnt from t_json_demo group by id format JSONCompact;` 
<img alt="" height="729" src="https://img-blog.csdnimg.cn/20210411145009619.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="521"> </li>
</ul>
<h1 id="JSONEachRow"><a href="#JSONEachRow" class="headerlink" title="JSONEachRow"></a>JSONEachRow</h1><h2 id="JSONEachRow数据输入输出"><a href="#JSONEachRow数据输入输出" class="headerlink" title="JSONEachRow数据输入输出"></a>JSONEachRow数据输入输出</h2><blockquote>
</blockquote>
<ul>
<li>每行数据以换行符分隔的JSON对象。- 支持数据的输出和数据导入。<h2>案例演示</h2> 
`select id,count() as cnt from t_json_demo group by id format JSONEachRow;` 
<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20210318152711341.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x5cTcyNjk=,size_16,color_FFFFFF,t_70"> </li>
</ul>
<h3 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h3><blockquote>
</blockquote>
<ul>
<li>对象中键值对的顺序可任意排列。- 缺失某些字段。<h3>建表插入数据</h3> 
<pre><code class="language-sql">#建表
create table UserActivity (PageViews UInt8, UserID String, Duration UInt64, Sign Int8) ENGINE TinyLog;
#插入数据
INSERT INTO UserActivity FORMAT JSONEachRow &#123;"PageViews":5, "UserID":"4324182021466249494", "Duration":146,"Sign":-1&#125; &#123;"UserID":"4324182021466249494","PageViews":6,"Duration":185,"Sign":1&#125;
</code></pre> 
<h2>缺失值处理演示</h2> 
<pre><code class="language-sql">CREATE TABLE IF NOT EXISTS example_table
(
 x UInt32,
 a DEFAULT x + 2
) ENGINE = Memory;
# 第二条数据第二个值没有设置
insert into example_table FORMAT JSONEachRow &#123;"x":3, "a":5&#125; &#123;"x":4&#125;;
</code></pre> 
<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20210318154207105.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x5cTcyNjk=,size_16,color_FFFFFF,t_70"> </li>
</ul>
<h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><blockquote>
<p> 参数：input_format_defaults_for_omitted_fields 如果为0， 则x和a的默认值等于0（即UInt32数据类型的默认值）。 如果为1， 则x的默认值等于0， 但a的默认值等于x+2。 input_format_defaults_for_omitted_fields=1 </p>
</blockquote>
<h3 id="嵌套数据结构"><a href="#嵌套数据结构" class="headerlink" title="嵌套数据结构"></a>嵌套数据结构</h3><p><strong>案例演示</strong></p>
<p><strong>建表插入数据</strong></p>
<blockquote>
<p> #建表 CREATE TABLE json_each_row_nested (n Nested (s String, i Int32) ) ENGINE = Memory; # 插入数据 INSERT INTO json_each_row_nested FORMAT JSONEachRow {“n.s”: [“abc”, “def”], “n.i”: [1, 23]}; # 查看数据 select * from json_each_row_nested;<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20210318154828387.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x5cTcyNjk=,size_16,color_FFFFFF,t_70"> </p>
</blockquote>
<h3 id="要将数据作为分层JSON对象插入"><a href="#要将数据作为分层JSON对象插入" class="headerlink" title="要将数据作为分层JSON对象插入"></a>要将数据作为分层JSON对象插入</h3><blockquote>
<p> 需要设置input_format_import_nested_json=1。（默认为0） </p>
</blockquote>
<h3 id="当参数设置为零时"><a href="#当参数设置为零时" class="headerlink" title="当参数设置为零时"></a>当参数设置为零时</h3><blockquote>
<p> 当需要设置input_format_import_nested_json=0时： INSERT INTO json_each_row_nested FORMAT JSONEachRow {“n”: {“s”: [“abc”, “def”], “i”: [1, 23]}}<br> Exception on client: Code: 117. DB::Exception: Unknown field found while parsing JSONEachRow format: n<br> Connecting to 192.168.0.200:9000 as user default. Connected to ClickHouse server version 20.1.4 revision 54431. </p>
</blockquote>
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>clickhouse输入输出格式之ORC</title>
    <url>/2021/07/18/clickhouse%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F%E4%B9%8BORC/</url>
    <content><![CDATA[<p>title: clickhouse输入输出格式之ORC<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—# ORC数据的输入输出</p>
<p>仅支持ORC格式的写入。</p>
<h1 id="ORC和CH数据类型的匹配关系"><a href="#ORC和CH数据类型的匹配关系" class="headerlink" title="ORC和CH数据类型的匹配关系"></a>ORC和CH数据类型的匹配关系</h1><blockquote>
 <img alt="" height="721" src="https://img-blog.csdnimg.cn/20210411172805489.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 
 **备注：** 
</blockquote>
<ul>
<li>不支持的ORC数据类型：DATE32, TIME32, FIXED_SIZE_BINARY, JSON, UUID, ENUM。- ClickHouse表的列名必须与ORC表的列名一致。</li>
</ul>
<h1 id="使用Spark生成ORC文件"><a href="#使用Spark生成ORC文件" class="headerlink" title="使用Spark生成ORC文件"></a>使用Spark生成ORC文件</h1><blockquote>
<p> val list = List(   (“113.248.234.232”, “123.212.22.01”, “2018-07-12 14:35:31”),   (“115.248.158.231”, “154.245.56.23”, “2020-07-12 13:26:26”),   (“115.248.158.231”, “154.245.56.23”, “2020-07-12 13:22:13”),   (“187.248.135.230”, “221.228.112.45”, “2019-08-09 13:17:39”),   (“187.248.234.232”, “221.228.112.24”, “2019-08-09 20:51:16”),   (“115.248.158.231”, “154.245.56.23”, “2020-07-12 17:22:56”) )<br> val rdd = sc.makeRDD(list) import spark.implicits._ val df = rdd.toDF(“srcip”, “destip”, “time”) df.repartition(1).write.format(“orc”).mode(“append”).save(“/tmp/orc”)   </p>
</blockquote>
<h1 id="创建测试表"><a href="#创建测试表" class="headerlink" title="创建测试表"></a>创建测试表</h1><blockquote>
<p> create table orc_demo (srcip String, destip String, time DateTime) ENGINE=TinyLog; </p>
</blockquote>
<h1 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h1><blockquote>
<p> cat file.orc | clickhouse-client –query=”INSERT INTO test.orc_demo FORMAT ORC” </p>
</blockquote>
<h1 id="查询结果"><a href="#查询结果" class="headerlink" title="查询结果"></a>查询结果</h1><blockquote>
<p> <code>select * from orc_demo</code> </p>
</blockquote>
<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20210318163404299.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x5cTcyNjk=,size_16,color_FFFFFF,t_70">
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>clickhouse输入输出格式之Parquet</title>
    <url>/2021/07/18/clickhouse%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F%E4%B9%8BParquet/</url>
    <content><![CDATA[<p>title: clickhouse输入输出格式之Parquet<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—# Parquet输入输出格式</p>
<blockquote>
<p> 支持Parquet格式的导出和导入。 </p>
</blockquote>
<h1 id="Parquet和ClickHouse类型的匹配关系"><a href="#Parquet和ClickHouse类型的匹配关系" class="headerlink" title="Parquet和ClickHouse类型的匹配关系"></a>Parquet和ClickHouse类型的匹配关系</h1><blockquote>
 <img alt="" height="772" src="https://img-blog.csdnimg.cn/20210411161702364.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 
 不支持的Parquet数据类型：DATE32, TIME32, FIXED_SIZE_BINARY, JSON, UUID, ENUM。 
 **注意：** 
</blockquote>
<ul>
<li>ClickHouse表的列名必须与Parquet表的列名一致。- ClickHouse表的列数据类型可以不同于插入的Parquet数据类型。 在插入数据时， ClickHouse根据上表解释数据类型， 然后将数据类型转换为ClickHouse表的列数据类型。</li>
</ul>
<h1 id="数据的导出："><a href="#数据的导出：" class="headerlink" title="数据的导出："></a>数据的导出：</h1><p>备注：表随便找一张</p>
<blockquote>
<p> 命令：clickhouse-client –query=”SELECT * FROM tutorial.tsv_demo FORMAT Parquet” &gt; parquet_demo.parquet<br> <img alt="" height="142" src="https://img-blog.csdnimg.cn/20210411165153551.png" width="1200"> </p>
</blockquote>
<h1 id="数据的导入："><a href="#数据的导入：" class="headerlink" title="数据的导入："></a>数据的导入：</h1><blockquote>
<p> 创建测试表：<br> 命令：create table parquet_demo (srcip String, destip String, time String) ENGINE=TinyLog;<br> 导入命令：<br> cat parquet_demo.parquet | clickhouse-client –query=”INSERT INTO parquet_demo FORMAT Parquet” </p>
</blockquote>
<h3 id="导入的数据查询："><a href="#导入的数据查询：" class="headerlink" title="导入的数据查询："></a>导入的数据查询：</h3><blockquote>
 <img alt="" height="311" src="https://img-blog.csdnimg.cn/20210411171838671.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="716"> 
</blockquote>
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>clickhouse输入输出格式之不常用数据格式</title>
    <url>/2021/07/18/clickhouse%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F%E4%B9%8B%E4%B8%8D%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F/</url>
    <content><![CDATA[<p>title: clickhouse输入输出格式之不常用数据格式<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—# 1. Native</p>
<blockquote>
<p> 数据以二进制数据块的方式进行读写。 数据的导出： clickhouse-client –query=“SELECT * FROM tsv_demo FORMAT Native” &gt; a.native<br> 数据的导入： clickhouse-client –query=“insert into tsv_demo FORMAT Native” &lt; a.native </p>
</blockquote>
<h1 id="2-Null"><a href="#2-Null" class="headerlink" title="2. Null"></a>2. Null</h1><blockquote>
<p> 主要用于测试性能。 查询会被处理，并且数据会被传送到客户端，但是什么也不输出。 Null格式只能用于查询， 不能用于数据的导入。 </p>
</blockquote>
<h1 id="3-Pretty"><a href="#3-Pretty" class="headerlink" title="3. Pretty"></a>3. Pretty</h1><blockquote>
<p> PrettyCompact：在交互式模式下，默认的数据显示格式。 PrettySpace </p>
</blockquote>
<h1 id="4-Values"><a href="#4-Values" class="headerlink" title="4. Values"></a>4. Values</h1><blockquote>
<p> 每行之间使用逗号分隔，列之间也是使用逗号分隔。在括号中打印每一行。 INSERT INTO XX values<br> INSERT INTO XX FORMAT Values<br> insert into tsv_demo FORMAT Values (‘115.248.158.231’, ‘115.248.158.232’, ‘2020-07-12 17:22:56’), (‘115.248.158.231’, ‘115.248.158.232’, ‘2020-07-12 17:22:56’); </p>
</blockquote>
<h1 id="5-Vertical"><a href="#5-Vertical" class="headerlink" title="5. Vertical"></a>5. Vertical</h1><blockquote>
<p> 数据以垂直的格式进行展示。 \G </p>
</blockquote>
<ul>
<li>XML 只支持数据的查看。<br>select * from tsv_demo limit 2 FORMAT XML; </li>
</ul>
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>css之盒子模型</title>
    <url>/2021/07/18/css%E4%B9%8B%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>title: css之盒子模型<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—1.简介</p>
<blockquote>
</blockquote>
<ul>
<li> 盒子模型就是把HTML页面中的布局元素看作是一个矩形的盒子，也就是一个盛装内容的容器。 -  盒子模型由元素的内容、边框（border）、内边距（padding）、和外边距（margin）组成。 -  盒子里面的文字和图片等元素是 内容区域 -  盒子的厚度 我们称为为盒子的边框 -  盒子内容与边框的距离是内边距 -  盒子与盒子之间的距离是外边距 </li>
</ul>
<p> <strong>W3c标准盒子模型</strong><br> 标准 w3c 盒子模型的范围包括 margin、border、padding、content<br> 当设置为box-sizing: content-box;时，将采用标准模式解析计算，也是默认模式；<br> <code>内盒尺寸计算(元素实际大小)</code> </p>
<ul>
<li>宽度：Element Height = content height + padding + border （Height为内容高度） -  高度：Element  Width = content width + padding + border （Width为内容宽度） -  盒子的实际大小：**内容的宽度和高度 +  内边距   +  边框  **<img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/bf54c2dc5e1b1168c841434a540ac30c.png"><strong>IE盒子模型</strong><br>IE 盒子模型的 content 部分包含了 border 和 pading<br>当设置为box-sizing: border-box时，将采用怪异模式解析计算； </li>
</ul>
<p>2.盒子边框(border)</p>
<blockquote>
 <table><thead>|属性|作用
</blockquote>
</thead><tbody>|border-width|定义边框粗细，单位是px
|border-style|边框的样式
|border-color|边框颜色
</tbody></table>
 **边框的样式：** 
 -  none：没有边框即忽略所有边框的宽度（默认值） -  solid：边框为单实线(最为常用的) -  dashed：边框为虚线 -  dotted：边框为点线 
 <pre><code>边框综合设置
border : border-width || border-style || border-color 

<p>border: 1px solid red;  没有顺序要求  <br></code></pre><br> <strong>盒子边框写法总结表：</strong><br> 很多情况下，我们不需要指定4个边框，我们是可以单独给4个边框分别指定的。<br> <table><thead>|上边框|下边框|左边框|右边框</p>
</thead><tbody>|border-top-style:样式;|border-bottom-style:样式;|border-left-style:样式;|border-right-style:样式;
|border-top-width:宽度;|border- bottom-width:宽度;|border-left-width:宽度;|border-right-width:宽度;
|border-top-color:颜色;|border- bottom-color:颜色;|border-left-color:颜色;|border-right-color:颜色;
|border-top:宽度 样式 颜色;|border-bottom:宽度 样式 颜色;|border-left:宽度 样式 颜色;|border-right:宽度 样式 颜色;
</tbody></table>
 **表格的细线边框：** 
 <img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/23f51af60551a3684fcb8aee07b48a7a.png"> 
 <ul>-  通过表格的`cellspacing="0"`,将单元格与单元格之间的距离设置为0， -  但是两个单元格之间的边框会出现重叠，从而使边框变粗 <li> 通过css属性：table{ border-collapse:collapse; }   
   -  `collapse` 单词是合并的意思,`border-collapse: collapse;`表示相邻边框合并在一起。 </li></ul>
 <pre><code class="language-html">&lt;style&gt;
 table &#123;
  width: 500px;
  height: 300px;
  border: 1px solid red;
 &#125;
 td &#123;
  border: 1px solid red;
  text-align: center;
 &#125;
 table, td &#123;
  border-collapse: collapse; 
 &#125;
&lt;/style&gt;</code></pre> 


<p>3.内边距(padding)</p>
<blockquote>
<p> padding属性用于设置内边距。是指边框与内容之间的距离。<br> <strong>设置</strong><br> <table><thead>|属性|作用</p>
</blockquote>
</thead><tbody>|padding-left|左内边距
|padding-right|右内边距
|padding-top|上内边距
|padding-bottom|下内边距
</tbody></table>
 **padding简写** 
 <table><thead>|值的个数|表达意思
</thead><tbody>|1个值|padding：上下左右内边距;
|2个值|padding: 上下内边距    左右内边距 ；
|3个值|padding：上内边距   左右内边距   下内边距；
|4个值|padding: 上内边距 右内边距 下内边距 左内边距 ；
</tbody></table>
 当我们给盒子指定padding值之后， 发生了2件事情： 
 -  内容和边框 有了距离，添加了内边距。 -  盒子会变大 
 **解决措施：**通过给设置了宽高的盒子，减去相应的内边距的值，维持盒子原有的大小。 
 **padding不影响盒子大小情况：👉**如果没有给一个盒子指定宽度， 此时，如果给这个盒子指定padding， 则不会撑开盒子。 


<p>4.外边距（margin）</p>
<blockquote>
<p> margin属性用于设置外边距。margin就是控制<code>盒子和盒子之间的距离</code><br> <strong>设置</strong><br> <table><thead>|属性|作用</p>
</blockquote>
</thead><tbody>|margin-left|左外边距
|margin-right|右外边距
|margin-top|上外边距
|margin-bottom|下外边距
</tbody></table>
 margin值的简写 （复合写法）代表意思  跟 padding 完全相同。 
 **块级盒子水平居中** 
 -  盒子必须指定宽度（width） -  然后就给左右的外边距都设置为auto 
 实际工作中常用这种方式进行网页布局，示例代码如下： 
 <pre><code class="language-css">.header  &#123; width: 960px; margin: 0 auto;&#125;
</code></pre> 
 常见的写法，以下下三种都可以👇👇。 
 -  margin-left: auto;   margin-right: auto; -  margin: auto; -  margin: 0 auto; 
 **文字居中和盒子居中区别👇👇** 
 -  盒子内的文字水平居中是 text-align: center; 而且还可以让 行内元素和行内块居中对齐 -  块级盒子水平居中  左右margin 改为 auto 
 **插入图片和背景图片区别👇👇** 
 -  `插入图片`我们用的最多 比如产品展示类  移动位置只能靠盒模型 padding margin -  `背景图片`我们一般用于小图标背景或者超大背景图片、背景图片，移动位置只能通过  background-position 
 **清除元素的默认内外边距👇👇** 
 -  行内元素为了照顾兼容性,尽量只设置左右内外边距，不要设置上下内外边距。 
 <pre><code class="language-css">* &#123;
   padding:0;         /* 清除内边距 */
   margin:0;          /* 清除外边距 */
&#125;</code></pre> 


<p>5.外边距合并</p>
<blockquote>
<p> 使用margin定义块元素的<strong>「垂直外边距」</strong>时，可能会出现外边距的合并。<br> (1). 相邻块元素垂直外边距的合并 </p>
</blockquote>
<ul>
<li>当上下相邻的两个块元素相遇时，如果上面的元素有下外边距margin-bottom -  下面的元素有上外边距margin-top，则他们之间的垂直间距不是margin-bottom与margin-top之和 -  <strong>「取两个值中的较大者」</strong>这种现象被称为相邻块元素垂直外边距的合并（也称外边距塌陷）。<br><img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/5801d248713b0b007278d83da53fe65b.png"><strong>「解决方案：尽量给只给一个盒子添加margin值」</strong>。<br>(2). 嵌套块元素垂直外边距的合并（塌陷） </li>
<li>对于两个嵌套关系的块元素，如果父元素没有上内边距及边框 -  父元素的上外边距会与子元素的上外边距发生合并 -  合并后的外边距为两者中的较大者<br><img alt="图片" src="https://img-blog.csdnimg.cn/img_convert/d3bafd9c994eb54f101ad55ce9983fba.png"><strong>「解决方案：」</strong> </li>
<li>可以为父元素定义上边框。 -  可以为父元素定义上内边距 -  可以为父元素添加overflow: hidden。<br>还有其他方法，比如浮动、固定、绝对定位的盒子不会有问题，后面咱们再总结。。。 </li>
</ul>
]]></content>
      <categories>
        <category>Css</category>
      </categories>
  </entry>
  <entry>
    <title>css相关属性</title>
    <url>/2021/07/18/css%E7%9B%B8%E5%85%B3%E5%B1%9E%E6%80%A7/</url>
    <content><![CDATA[<p>title: css相关属性<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—title: css相关属性<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—1. css3中opacity属性   指定透明度的属性是opacity,属性值从 0.0 到 1.0。值越小，越透明。   从 0.0 （完全透明）到 1.0（完全不透明）。<li>transition属性   过渡transition是一个复合属性，包括transition-property、transition-duration、transition-timing-function、   transition-delay这四个子  属性。通过这四个子属性的配合来完成一个完整的过渡效果。    transition: opacity 3s  —&gt;过渡：不透明度3s <pre><code class="language-html hljs">transition-property: 过渡属性(默认值为all)<br>transition-duration: 过渡持续时间(默认值为0s)<br>transiton-timing-function: 过渡函数(默认值为ease函数)<br>transition-delay: 过渡延迟时间(默认值为0s)</code></pre> </li>1.  CSS3 @keyframes 规则  a：简介        @keyframes 规则是创建动画。        @keyframes 规则内指定一个 CSS 样式和动画将逐步从目前的样式更改为新的样式   1.  transform属性   Transform属性应用于元素的2D或3D转换。这个属性允许你将元素旋转，缩放，移动，倾斜等。 1.  scale,  <img alt="" class="has" height="297" src="https://img-blog.csdnimg.cn/20191214095833437.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="582">  <img alt="" class="has" height="462" src="https://img-blog.csdnimg.cn/20191214095851711.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="586">  <img alt="" class="has" height="428" src="https://img-blog.csdnimg.cn/2019121409591750.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="670">  <img alt="" class="has" height="409" src="https://img-blog.csdnimg.cn/20191214095937591.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="607">  <img alt="" class="has" height="504" src="https://img-blog.csdnimg.cn/20191214100042785.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="590"> 1.  CSS3 Animation,CSS3 Animation 是由三部分组成    a：关键帧(keyframes) - 定义动画在不同阶段的状态           关键帧主要分为3个阶段，0%、50%、100%   b：动画属性(properties) - 决定动画的播放时长，播放次数，以及用何种函数式去播放动画等。（可以类比音视频播放器）   c：css属性 - 就是css元素不同关键帧下的状态。 1.  border-top 属性  CSS属性 <strong>border-top</strong>是属性 border-top-width, border-top-style, and border-top-color的三者的缩写  例如：border-top: 10px solid #409EFF;  <img alt="" class="has" height="152" src="https://img-blog.csdnimg.cn/20191214145118918.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="640"> 
 </p>
]]></content>
      <categories>
        <category>Css</category>
      </categories>
  </entry>
  <entry>
    <title>commit镜像</title>
    <url>/2021/07/18/commit%E9%95%9C%E5%83%8F/</url>
    <content><![CDATA[<p>title: commit镜像<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—一个案例 从Hub上下载tomcat并运行成功</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull tomcat</span><br><span class="line">docker run -d -p 8888:8080 tomcat</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p> -p 主机端口：docker容器端口 -P 随机分配端口 -i：交互 -t：终端 </p>
</blockquote>
<p> <img alt="" height="46" src="https://img-blog.csdnimg.cn/20201224212013162.png" width="679"> 进入正在运行的容器将webapps.dist中的文件移到webapps中：<img alt="" height="301" src="https://img-blog.csdnimg.cn/20201224212122242.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 访问tomcat:<img alt="" height="455" src="https://img-blog.csdnimg.cn/20201224212221133.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1034"></p>
<h3 id="commit的使用"><a href="#commit的使用" class="headerlink" title="commit的使用"></a>commit的使用</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker commit 提交容器副本是指成为一个新的容器</span><br><span class="line">docker commit -a=作者&quot; -m=&quot;提交的描述信息&quot; 容器ID 要创建的目标容器名：标签</span><br><span class="line">docker commit -a=&#x27;kgf&#x27; -m=&#x27;tomcat without doc&#x27; 11af2115ae1a mytomcat:v1.0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>案例：****1. 删除 docs，访问tomcat点击Documentation显示404</strong> 当前未删除时点击Documentation是 正常显示的 </p>
<img alt="" height="416" src="https://img-blog.csdnimg.cn/20201224212451724.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="950">

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 进入交互式容器</span><br><span class="line">docker exec -it 11af2115ae1a /bin/bash</span><br><span class="line"># root@b0674466db1c:/usr/local/tomcat#</span><br><span class="line"># 进入webapps目录，删除docs</span><br><span class="line">cd webapps</span><br><span class="line">rm -rf docs</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p> <img alt="" height="154" src="https://img-blog.csdnimg.cn/20201224212706560.png" width="635"></p>
<p>删除docs后重新访问，点击Documentation</p>
<img alt="" height="299" src="https://img-blog.csdnimg.cn/20201224212806940.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="666">

<p><strong>2. 提交并生成一个新的容器</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker commit -a=&#x27;kgf&#x27; -m=&#x27;tomcat without doc&#x27; 11af2115ae1a mytomcat:v1.0</span><br></pre></td></tr></table></figure>

<img alt="" height="291" src="https://img-blog.csdnimg.cn/20201224213109939.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200">

<ol start="3">
<li>停止当前运行的tomcat容器，并运行mytomcat这个新的容器</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker stop 11af2115ae1a </span><br><span class="line">docker run -d -p 7788:8080 mytomcat:v1.0  # 注意加版本号</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<img alt="" height="155" src="https://img-blog.csdnimg.cn/20201224213836588.png" width="1200">

<p>此时运行一下，由结果分析是正确的，这样就创建了一个没有docs的tomcat镜像</p>
<img alt="" height="299" src="https://img-blog.csdnimg.cn/20201224213912968.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="913">

<p><strong>总结：commit后会重新生成一个镜像，可以自定义该镜像的名称以及版本号</strong></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>css简介以及引入规范</title>
    <url>/2021/07/18/css%E7%AE%80%E4%BB%8B%E4%BB%A5%E5%8F%8A%E5%BC%95%E5%85%A5%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<p>title: css简介以及引入规范<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—## CSS构造块</p>
<p><strong>「1. HTML的局限性」</strong></p>
<ul>
<li> HTML满足不了设计者的需求，可以将网页结构与样式相分离，这样就可以在不更改网页结构的前提下，更换网站的样式。 -  操作html属性不方便 -  HTML里面添加样式带来的是无尽的臃肿和繁琐 </li>
</ul>
<p><strong>「2. CSS网页的美容师」</strong></p>
<ul>
<li> 让我们的网页更加丰富多彩，布局更加灵活自如。 -  CSS最大的贡献：让HTML从样式中脱离，实现了HTML专注去做结构呈现，样式交给CSS </li>
</ul>
<p><strong>「3. CSS」</strong>CSS(Cascading Style Sheets)通常称为CSS样式表或层叠样式表(级联样式表)。</p>
<li> **作用** 
  <ul>-  主要用于设置HTML页面中的文本内容(字体、大小、对齐方式等)\图片的外形(宽高、边框样式、边距等)以及版面的布局和外观显示样式。 -  CSS以HTML为基础，提供了丰富的功能，如字体、样式、背景的控制及整体排版等，而且可以针对不同的浏览器设置不同的样式。 
**「4. CSS注释」**

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/* 这是注释 */</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="引入CSS样式表"><a href="#引入CSS样式表" class="headerlink" title="引入CSS样式表"></a>引入CSS样式表</h3><p><strong>「1.行内式(内联样式)」</strong></p>
<p>通过标签的style属性来设置元素的样式</p>
<ul>
<li> style其实就是标签的属性 -  样式属性和值中间是: -  多组属性值直接用;隔开 -  只能控制当前的标签和以及嵌套在其中的字标签，造成代码冗余。 -  **缺点:**没有实现样式和结构相分离。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&amp;lt;标签名 style=&quot;属性1:属性值1; 属性2:属性值2; 属性3:属性值3;&quot;&amp;gt; 内容 &amp;lt;/标签名&amp;gt;</span><br><span class="line">例如：</span><br><span class="line">&amp;lt;div style=&quot;color: red; font-size: 12px;&quot;&amp;gt;青春不常在，抓紧谈恋爱&amp;lt;/div&amp;gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>「2.内部样式表(内嵌样式表)」</strong></p>
<p>也称为内嵌式，将CSS代码集中写在HTML文档的head头部标签中，并且用style标签定义。</p>
<ul>
<li> style标签一般位于head标签中，当然理论上他可以放在HTML文档的任何地方。 -  type=”text/css”  在html5中可以省略。 -  只能控制当前的页面 -  **缺点:**没有彻底分离结构与样式 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&amp;lt;head&amp;gt;</span><br><span class="line">&amp;lt;style type=&quot;text/CSS&quot;&amp;gt;</span><br><span class="line">    选择器（选择的标签） &#123; </span><br><span class="line">      属性1: 属性值1;</span><br><span class="line">      属性2: 属性值2; </span><br><span class="line">      属性3: 属性值3;</span><br><span class="line">    &#125;</span><br><span class="line">&amp;lt;/style&amp;gt;</span><br><span class="line">&amp;lt;/head&amp;gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>「3.外部样式表(外链式)」</strong></p>
<p>也称链入式，是将所有的样式放在一个或多个以.css为扩展名的外部样式表文件中，通过link标签将外部样式表文件链接到HTML文档中。</p>
<ul>
<li> <code>rel</code>:定义当前文档与被链接文档之间的关系，在这里需要指定为“stylesheet”，表示被链接的文档是一个样式表文件。 -  <code>href</code>:定义所链接外部样式表文件的URL，可以是相对路径，也可以是绝对路径。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&amp;lt;link rel=&quot;stylesheet&quot; href=&quot;index.css&quot;&amp;gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>「4.团队约定-代码风格」</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/*1.紧凑格式 (Compact)*/</span><br><span class="line">h3 &#123; color: deeppink;font-size: 20px;&#125;</span><br><span class="line">// 2.一种是展开格式（推荐）</span><br><span class="line">h3 &#123;</span><br><span class="line"> color: deeppink;</span><br><span class="line">    font-size: 20px;    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/* 团队约定-代码大小写*/</span><br><span class="line">/* 样式选择器，属性名，属性值关键字全部使用小写字母书写，属性字符串允许使用大小写。*/</span><br><span class="line">/* 推荐 */</span><br><span class="line">h3&#123;</span><br><span class="line"> color: pink;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">/* 不推荐 */</span><br><span class="line">H3&#123;</span><br><span class="line"> COLOR: PINK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Css</category>
      </categories>
  </entry>
  <entry>
    <title>css选择器的使用</title>
    <url>/2021/07/18/css%E9%80%89%E6%8B%A9%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>title: css选择器的使用<br>categories:</p>
<ul>
<li>css</li>
</ul>
<p>—1.CSS选择器作用</p>
<blockquote>
<p> 找到指定的HTML页面元素，选择标签。 </p>
</blockquote>
<p>2.标签选择器</p>
<blockquote>
</blockquote>
<ul>
<li>标签选择器（元素选择器）是指用HTML标签名称作为选择器，按标签名称分类，为页面中某一类标签指定统一的CSS样式。 -  作用：可以把某一类标签全部选择出来。 -  优点：快速为网页中同类型的标签统一样式 -  缺点：不能设计差异化样式。 <pre>`标签名{属性1:属性值1; 属性2:属性值2; 属性3:属性值3; } `</pre> </li>
</ul>
<p>3.类选择器</p>
<blockquote>
</blockquote>
<ul>
<li>类选择器使用”.”(英文点号)进行标识，后面紧跟类名。 -  语法：类名选择器 <pre><code>.类名  &#123;   
    属性1:属性值1; 
    属性2:属性值2; 
    属性3:属性值3;     
&#125;
</code></pre> 
<pre><code class="language-html">&lt;p class='类名'&gt;&lt;/p&gt;
</code></pre> 
<ul>-  `优点`：可以为元素对象定义单独或相同的样式。可以选择一个或者多个标签。 <li> `注意`：类选择器使用“.”（英文点号）进行标识，后面紧跟类名(自定义，我们自己命名的) </li>
<li> 长名称或词组可以使用中横线来为选择器命名。 -  不要纯数字、中文等命名， 尽量使用英文字母来表示。 -  多类名选择器：各个类名中间用空格隔开。 </li></ul></li>
</ul>
<p>4.<strong>id选择器」</strong>id选择器使用<code>#</code>进行标识，后面紧跟id名</p>
<blockquote>
</blockquote>
<ul>
<li>元素的id值是唯一的，只能对应于文档中某一个具体的元素。 <pre><code>#id名 &#123;属性1:属性值1; 属性2:属性值2; 属性3:属性值3; &#125;
</code></pre> 
<pre>`&lt;p id="id名"&gt;&lt;/p&gt;`</pre> </li>
</ul>
<p>5.通配符选择器</p>
<blockquote>
<p> 通配符选择器用<code>*</code>号表示，<code>*</code> 就是选择所有的标签。它是所有选择器中作用范围最广的，能匹配页面中所有的元素。 </p>
</blockquote>
<ul>
<li><code>注意</code>：会匹配页面所有的元素，降低页面响应速度，不建议随便使用 <pre><code>* &#123; 属性1:属性值1; 属性2:属性值2; 属性3:属性值3; &#125;
</code></pre> 
例如下面代码，使用通配符选择器定义CSS样式，清除所有HTML标记的默认边距。 <pre><code class="language-css">* &#123;
  margin: 0;                    /* 定义外边距*/
  padding: 0;                   /* 定义内边距*/
&#125;</code></pre> </li>
</ul>
<p>6.基础选择器总结</p>
<blockquote>
 <table><thead>|选择器|作用|缺点|使用情况|用法
</blockquote>
</thead><tbody>|标签选择器|可以选出所有相同的标签，比如p|不能差异化选择|较多|p { color：red;}
|类选择器|可以选出1个或者多个标签|可以根据需求选择|非常多|.nav { color: red; }
|id选择器|一次只能选择器1个标签|只能使用一次|不推荐使用|#nav {color: red;}
|通配符选择器|选择所有的标签|选择的太多，有部分不需要|不推荐使用|* {color: red;}
</tbody></table>

]]></content>
      <categories>
        <category>Css</category>
      </categories>
  </entry>
  <entry>
    <title>docker stack的相关编排指令</title>
    <url>/2021/07/18/docker%20stack%E7%9A%84%E7%9B%B8%E5%85%B3%E7%BC%96%E6%8E%92%E6%8C%87%E4%BB%A4/</url>
    <content><![CDATA[<p>title: docker stack的相关编排指令<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—### 一、简介</p>
<p>　　Docker有个编排工具docker-compose，可以将组成某个应该的多个docker容器编排在一起，同时管理。同样在Swarm集群中，可以使用docker stack 将一组相关联的服务进行编排管理。</p>
<p>　　Docker stack 也是一个yaml文件，和一份docker-compose.yml文件差不多，指令也基本一致。但是与compose相比其不支持build、links和network_mode。Docker stack有一个新的指令deploy。</p>
<p>　　注：stack不支持的指令</p>
<p>　　<img alt="" src="https://img-blog.csdnimg.cn/img_convert/27f8fd7935d60d35321c8b34dd5021f6.png" width="600"></p>
<p> </p>
<h3 id="二、Deploy"><a href="#二、Deploy" class="headerlink" title="二、Deploy"></a>二、Deploy</h3><p>　　Deploy是用来指定swarm服务部署和运行时的相关配置，并且只有使用docker stack deploy 部署swarm集群时才会生效。如果使用docker-compose up 或者docker-compose run时，该选项会被忽略。要使用deploy选项，compose-file中version版本要在3或3+。　　<br>| 1 2 3 4 5 6 7 8 9 10 11 | <code>version: ``&#39;3&#39;</code> <code>services:</code> <code>  ``redis:</code> <code>    ``image: redis:alpine</code> <code>    ``deploy:</code> <code>      ``replicas: ``6</code> <code>      ``update_config:</code> <code>        ``parallelism: ``2</code> <code>        ``delay: ``10s</code> <code>      ``restart_policy:</code> <code>        ``condition: on``-``failure</code> </p>
<p>2</p>
<p>4</p>
<p>6</p>
<p>8</p>
<p>10</p>
<p><code>version: ``&#39;3&#39;</code></p>
<p><code>  ``redis:</code></p>
<p><code>    ``deploy:</code></p>
<p><code>      ``update_config:</code></p>
<p><code>        ``delay: ``10s</code></p>
<p><code>        ``condition: on``-``failure</code></p>
<p>　　（1）ENDPOINT_MODE</p>
<p>　　 <strong>指定swarm服务发现的模式</strong></p>
<ul>
<li>endpoint_mode: vip - Docker为swarm集群服务分配一个虚拟IP(VIP)，作为客户端到达集群服务的“前端”。Docker 在客户端和可用工作节点之间对服务的请求进行路由。而客户端不用知道有多少节点参与服务或者是这些节点的IP/端口。（这是默认模式）- endpoint_mode: dnsrr -  DNS轮询（DNSRR）服务发现不使用单个虚拟IP。 Docker为服务设置DNS条目，使得服务名称的DNS查询返回一个IP地址列表，并且客户端直接连接到其中的一个。如果您想使用自己的负载平衡器，或者混合Windows和Linux应用程序，则DNS轮询功能非常有用。<br>　　注：version 3.3+<br>| 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 | <code>version: ``&quot;3.3&quot;</code>   <code>services:</code> <code>  ``wordpress:</code> <code>    ``image: wordpress</code> <code>    ``ports:</code> <code>      ``-</code> <code>8080``:``80</code> <code>    ``networks:</code> <code>      ``-</code> <code>overlay</code> <code>    ``deploy:</code> <code>      ``mode: replicated</code> <code>      ``replicas: ``2</code> <code>      ``endpoint_mode: vip</code>   <code>  ``mysql:</code> <code>    ``image: mysql</code> <code>    ``volumes:</code> <code>       ``-</code> <code>db``-``data:``/``var``/``lib``/``mysql``/``data</code> <code>    ``networks:</code> <code>       ``-</code> <code>overlay</code> <code>    ``deploy:</code> <code>      ``mode: replicated</code> <code>      ``replicas: ``2</code> <code>      ``endpoint_mode: dnsrr</code>   <code>volumes:</code> <code>  ``db``-``data:</code>   <code>networks:</code> <code>  ``overlay:</code> </li>
</ul>
<p>2</p>
<p>4</p>
<p>6</p>
<p>8</p>
<p>10</p>
<p>12</p>
<p>14</p>
<p>16</p>
<p>18</p>
<p>20</p>
<p>22</p>
<p>24</p>
<p>26</p>
<p>28</p>
<p>30</p>
<p> </p>
<p><code>  ``wordpress:</code></p>
<p><code>    ``ports:</code></p>
<p><code>    ``networks:</code></p>
<p><code>    ``deploy:</code></p>
<p><code>      ``replicas: ``2</code></p>
<p> </p>
<p><code>    ``image: mysql</code></p>
<p><code>       ``-</code> <code>db``-``data:``/``var``/``lib``/``mysql``/``data</code></p>
<p><code>       ``-</code> <code>overlay</code></p>
<p><code>      ``mode: replicated</code></p>
<p><code>      ``endpoint_mode: dnsrr</code></p>
<p><code>volumes:</code></p>
<p> </p>
<p><code>  ``overlay:</code></p>
<p>　　（2）LABELS　　</p>
<p>　　指定服务的标签。这些标签仅在服务上设置，而不在服务的任何容器上设置　　<br>| 1 2 3 4 5 6 7 | <code>version: ``&quot;3&quot;</code> <code>services:</code> <code>  ``web:</code> <code>    ``image: web</code> <code>    ``deploy:</code> <code>      ``labels:</code> <code>        ``com.example.description: ``&quot;This label will appear on the web service&quot;</code> </p>
<p>2</p>
<p>4</p>
<p>6</p>
<p><code>version: ``&quot;3&quot;</code></p>
<p><code>  ``web:</code></p>
<p><code>    ``deploy:</code></p>
<p><code>        ``com.example.description: ``&quot;This label will appear on the web service&quot;</code></p>
<p>　　要改为在容器上设置标签，请在deploy之外使用标签键<br>| 1 2 3 4 5 6 | <code>version: ``&quot;3&quot;</code> <code>services:</code> <code>  ``web:</code> <code>    ``image: web</code> <code>    ``labels:</code> <code>      ``com.example.description: ``&quot;This label will appear on all containers for the web service&quot;</code> </p>
<p>2</p>
<p>4</p>
<p>6</p>
<p><code>services:</code></p>
<p><code>    ``image: web</code></p>
<p><code>      ``com.example.description: ``&quot;This label will appear on all containers for the web service&quot;</code></p>
<p>　　（3）MODE</p>
<p>　　全局（每个群集节点只有一个容器）或副本（指定容器的数量）。默认值被副本。　<br>| 1 2 3 4 5 6 | <code>version: ``&#39;3&#39;</code> <code>services:</code> <code>  ``worker:</code> <code>    ``image: dockersamples``/``examplevotingapp_worker</code> <code>    ``deploy:</code> <code>      ``mode: ``global</code> </p>
<p>2</p>
<p>4</p>
<p>6</p>
<p><code>services:</code></p>
<p><code>    ``image: dockersamples``/``examplevotingapp_worker</code></p>
<p><code>      ``mode: ``global</code></p>
<p>　　（4）PLACEMENT</p>
<p>　　指定约束和偏好设置　<br>| 1 2 3 4 5 6 7 8 9 10 11 | <code>version: ``&#39;3&#39;</code> <code>services:</code> <code>  ``db:</code> <code>    ``image: postgres</code> <code>    ``deploy:</code> <code>      ``placement:</code> <code>        ``constraints:</code> <code>          ``-</code> <code>node.role ``=``=</code> <code>manager</code> <code>          ``-</code> <code>engine.labels.operatingsystem ``=``=</code> <code>ubuntu ``14.04</code> <code>        ``preferences:</code> <code>          ``-</code> <code>spread: node.labels.zone</code> </p>
<p>2</p>
<p>4</p>
<p>6</p>
<p>8</p>
<p>10</p>
<p><code>version: ``&#39;3&#39;</code></p>
<p><code>  ``db:</code></p>
<p><code>    ``deploy:</code></p>
<p><code>        ``constraints:</code></p>
<p><code>          ``-</code> <code>engine.labels.operatingsystem ``=``=</code> <code>ubuntu ``14.04</code></p>
<p><code>          ``-</code> <code>spread: node.labels.zone</code></p>
<p>　　（5）REPLICAS</p>
<p>　　如果服务是副本模式（默认模式），可以指定该服务运行的容器数量。　<br>| 1 2 3 4 5 6 7 8 9 10 | <code>version: ``&#39;3&#39;</code> <code>services:</code> <code>  ``worker:</code> <code>    ``image: dockersamples``/``examplevotingapp_worker</code> <code>    ``networks:</code> <code>      ``-</code> <code>frontend</code> <code>      ``-</code> <code>backend</code> <code>    ``deploy:</code> <code>      ``mode: replicated</code> <code>      ``replicas: ``6</code> </p>
<p>2</p>
<p>4</p>
<p>6</p>
<p>8</p>
<p>10</p>
<p><code>services:</code></p>
<p><code>    ``image: dockersamples``/``examplevotingapp_worker</code></p>
<p><code>      ``-</code> <code>frontend</code></p>
<p><code>    ``deploy:</code></p>
<p><code>      ``replicas: ``6</code></p>
<p>　　（6）RESOURCES</p>
<p>　　资源限制配置　<br>| 1 2 | <code>注意：这会替换版本``3``之前的Compose文件（cpu_shares，cpu_quota，cpuset，mem_limit，memswap_limit，mem_swappiness）</code> <code>中的非群集模式的旧资源约束选项，如升级``2.x``版至``3.x``中所述。　　</code> </p>
<p>2</p>
<p><code>中的非群集模式的旧资源约束选项，如升级``2.x``版至``3.x``中所述。　　</code></p>
<p>　　在下例中，redis服务限制使用不超过50M的内存和0.50（50％）的可用处理时间（CPU），并且拥有20M的内存和0.25个CPU时间（总是可用）。　　<br>| 1 2 3 4 5 6 7 8 9 10 11 12 | <code>version: ``&#39;3&#39;</code> <code>services:</code> <code>  ``redis:</code> <code>    ``image: redis:alpine</code> <code>    ``deploy:</code> <code>      ``resources:</code> <code>        ``limits:</code> <code>          ``cpus: ``&#39;0.50&#39;</code> <code>          ``memory: ``50M</code> <code>        ``reservations:</code> <code>          ``cpus: ``&#39;0.25&#39;</code> <code>          ``memory: ``20M</code> </p>
<p>2</p>
<p>4</p>
<p>6</p>
<p>8</p>
<p>10</p>
<p>12</p>
<p><code>services:</code></p>
<p><code>    ``image: redis:alpine</code></p>
<p><code>      ``resources:</code></p>
<p><code>          ``cpus: ``&#39;0.50&#39;</code></p>
<p><code>        ``reservations:</code></p>
<p><code>          ``memory: ``20M</code></p>
<p>　　（7）RESTART_POLICY</p>
<p>　　配置在容器退出时是否并如何重启容器。取代restart指令。</p>
<ul>
<li>condition ：none、on-failure和any（默认any）- delay ：在重启尝试之间等待多久（默认0）- max_attempts ：尝试重启的次数（默认一直重启，直到成功）- window ： 在确实一个重启是否成功前需要等待的窗口时间　| 1 2 3 4 5 6 7 8 9 10 | <code>version: ``&quot;3&quot;</code> <code>services:</code> <code>  ``redis:</code> <code>    ``image: redis:alpine</code> <code>    ``deploy:</code> <code>      ``restart_policy:</code> <code>        ``condition: on``-``failure</code> <code>        ``delay: ``5s</code> <code>        ``max_attempts: ``3</code> <code>        ``window: ``120s</code> </li>
</ul>
<p>2</p>
<p>4</p>
<p>6</p>
<p>8</p>
<p>10</p>
<p><code>services:</code></p>
<p><code>    ``image: redis:alpine</code></p>
<p><code>      ``restart_policy:</code></p>
<p><code>        ``delay: ``5s</code></p>
<p><code>        ``window: ``120s</code></p>
<p>　　（8）UPDATE_CONFIG</p>
<p>　　配置服务如何升级</p>
<ul>
<li>parallelism：同一时间升级的容器数量- delay：容器升级间隔时间- failure_action：升级失败后的动作（continue、rollback和pause。默认pause）。- monitor：更新完成后确实成功的时间（ns|us|ms|s|m|h）。（默认0s）- max_failure_ratio：更新期间允许的失败率- order： 更新期间的操作顺序。停止优先（旧任务在开始新任务之前停止）或者先启动（首先启动新任务，并且正在运行的任务短暂重叠）（默认停止优先）注意：只支持v3.4及更高版本。　　| 1 2 3 4 5 6 7 8 9 10 11 12 | <code>version: ``&#39;3.4&#39;</code> <code>services:</code> <code>  ``vote:</code> <code>    ``image: dockersamples``/``examplevotingapp_vote:before</code> <code>    ``depends_on:</code> <code>      ``-</code> <code>redis</code> <code>    ``deploy:</code> <code>      ``replicas: ``2</code> <code>      ``update_config:</code> <code>        ``parallelism: ``2</code> <code>        ``delay: ``10s</code> <code>        ``order: stop``-``first</code> </li>
</ul>
<p>2</p>
<p>4</p>
<p>6</p>
<p>8</p>
<p>10</p>
<p>12</p>
<p><code>services:</code></p>
<p><code>    ``image: dockersamples``/``examplevotingapp_vote:before</code></p>
<p><code>      ``-</code> <code>redis</code></p>
<p><code>      ``replicas: ``2</code></p>
<p><code>        ``parallelism: ``2</code></p>
<p><code>        ``order: stop``-``first</code></p>
<p>　　（9）depends_on</p>
<p>　　表示服务之间的依赖关系　　<br>| 1 2 3 4 5 6 7 8 9 10 11 | <code>version: ``&#39;3&#39;</code> <code>services:</code> <code>  ``web:</code> <code>    ``build: .</code> <code>    ``depends_on:</code> <code>      ``-</code> <code>db</code> <code>      ``-</code> <code>redis</code> <code>  ``redis:</code> <code>    ``image: redis</code> <code>  ``db:</code> <code>    ``image: postgres</code> </p>
<p>2</p>
<p>4</p>
<p>6</p>
<p>8</p>
<p>10</p>
<p><code>version: ``&#39;3&#39;</code></p>
<p><code>  ``web:</code></p>
<p><code>    ``depends_on:</code></p>
<p><code>      ``-</code> <code>redis</code></p>
<p><code>    ``image: redis</code></p>
<p><code>    ``image: postgres</code></p>
<p>　　（10）dns　　</p>
<p>　　自定义DNS服务器。可以是单个值或列表。　<br>| 1 2 3 4 | <code>dns: ``8.8``.``8.8</code> <code>dns:</code> <code>  ``-</code> <code>8.8``.``8.8</code> <code>  ``-</code> <code>9.9``.``9.9</code> </p>
<p>2</p>
<p>4</p>
<p><code>dns:</code></p>
<p><code>  ``-</code> <code>9.9``.``9.9</code></p>
<p>　　（11）dns_search　　<br>| 1 2 3 4 | <code>dns_search: example.com</code> <code>dns_search:</code> <code>  ``-</code> <code>dc1.example.com</code> <code>  ``-</code> <code>dc2.example.com</code> </p>
<p>2</p>
<p>4</p>
<p><code>dns_search:</code></p>
<p><code>  ``-</code> <code>dc2.example.com</code></p>
<p>　　（12）environment　　</p>
<p>　　添加环境变量。您可以使用数组或字典。任何布尔值;真/假，是/否，需要用引号括起来以确保它们不被YML解析器转换为True或False。　<br>| 1 2 3 4 5 6 7 8 9 | <code>environment:</code> <code>  ``RACK_ENV: development</code> <code>  ``SHOW: ``&#39;true&#39;</code> <code>  ``SESSION_SECRET:</code>   <code>environment:</code> <code>  ``-</code> <code>RACK_ENV``=``development</code> <code>  ``-</code> <code>SHOW``=``true</code> <code>  ``-</code> <code>SESSION_SECRET</code> </p>
<p>2</p>
<p>4</p>
<p>6</p>
<p>8</p>
<p><code>environment:</code></p>
<p><code>  ``SHOW: ``&#39;true&#39;</code></p>
<p> </p>
<p><code>  ``-</code> <code>RACK_ENV``=``development</code></p>
<p><code>  ``-</code> <code>SESSION_SECRET</code></p>
<p>　　（13）expose</p>
<p>　　开放容器的端口而不用在主机上暴露端口，它们只能被相关联的服务获取。只能指定内部端口。**　**<br>| 1 2 3 | <code>expose:</code> <code> ``-</code> <code>&quot;3000&quot;</code> <code> ``-</code> <code>&quot;8000&quot;</code> </p>
<p>2</p>
<p><code>expose:</code></p>
<p><code> ``-</code> <code>&quot;8000&quot;</code></p>
<p>转载自： </p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker stack相关命令</title>
    <url>/2021/07/18/docker%20stack%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>title: docker stack相关命令<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker stack相关命令<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. 部署项目命令 docker stack -c docker-compose.yml 服务名称1. 显示stack列表 命令：docker stack ls<img alt="" height="187" src="https://img-blog.csdnimg.cn/20210103201830867.png" width="654"> 可以看到名称叫ormis-service的stack中存在3个服务1. 列出stack中的任务 命令：docker stack ps stack名称<img alt="" height="274" src="https://img-blog.csdnimg.cn/20210103202135897.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 通过这个命令我们可以看到在ormis-service这个stack下面的具体信息，比如总共存在5个任务，这5个任务分别在哪一台服务器节点上运行，以及这5个任务服务的运行状态。1. 列出我们stack中创建出来的服务详情 命令：docker service ls<img alt="" height="203" src="https://img-blog.csdnimg.cn/2021010320261078.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1198"> 可以发现我们总共创建了3个服务，以及每个服务后面对应的副本数。1. 查看指定服务运行在哪一台服务器上 命令：docker service ps 服务id<img alt="" height="209" src="https://img-blog.csdnimg.cn/20210103202856601.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1144">1. 查看指定服务的日志信息,这样我们就不用去指定的子服务器上查看日志了，直接主节点可以看到 命令：docker service logs -f 服务id<img alt="" height="194" src="https://img-blog.csdnimg.cn/20210103203119834.png" width="1061">  1. 移除stack 命令：docker stack rm stack名称</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker swarm 删除节点 (解散集群)</title>
    <url>/2021/07/18/docker%20swarm%20%E5%88%A0%E9%99%A4%E8%8A%82%E7%82%B9%20(%E8%A7%A3%E6%95%A3%E9%9B%86%E7%BE%A4)/</url>
    <content><![CDATA[<p>title: docker swarm 删除节点 (解散集群)<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker swarm 删除节点 (解散集群)<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. 排空节点上的集群容器 。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker node update --availability drain g36lvv23ypjd8v7ovlst2n3yt</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>主动离开集群，让节点处于down状态，才能删除<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker swarm leave</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>删除指定节点 （管理节点上操作）<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker node rm g36lvv23ypjd8v7ovlst2n3yt</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>管理节点，解散集群<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker swarm leave --force</span><br></pre></td></tr></table></figure></li>
</ul>
<p>转载自： </p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker tag 详解</title>
    <url>/2021/07/18/docker%20tag%20%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p>title: docker tag 详解<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—### 1.简介</p>
<blockquote>
<p> docker tag 用于给镜像打标签，语法如下：<br> <pre><code>docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]</code></pre> </p>
</blockquote>
<h3 id="2-案例"><a href="#2-案例" class="headerlink" title="2.案例"></a>2.案例</h3><blockquote>
<p> 比如我现在有一个 centos 镜像：<br> <pre><code class="language-bash">[root@localhost ~]$ docker images<br>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE<br>centos              latest              1e1148e4cc2c        2 weeks ago         202MB</code></pre><br> 我对 centos 进行开发，开发了第一个版本，我就可以对这个版本打标签，打完标签后会生成新的镜像：<br> <pre><code>[root@localhost ~]$ docker tag centos centos:v1</code></pre><br> <pre><code class="language-bash">[root@localhost ~]$ docker images<br>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE<br>centos              latest              1e1148e4cc2c        2 weeks ago         202MB<br>centos              v1                  1e1148e4cc2c        2 weeks ago         202MB</code></pre><br> 我继续对 centos 进行开发，开发了第二个版本，继续打标签：<br> <pre>[root@localhost ~]$ docker tag centos centos:v2</pre><br> <pre>[root@localhost ~]$ docker images<br>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE<br>centos              latest              1e1148e4cc2c        2 weeks ago         202MB<br>centos              v1                  1e1148e4cc2c        2 weeks ago         202MB<br>centos              v2                  1e1148e4cc2c        2 weeks ago         202MB</pre><br> 以此类推，每开发一个版本打一个标签，如果以后我想回滚版本，就可以使用指定标签的镜像来创建容器：<br> <pre>[root@localhost ~]$ docker run -itd centos:v1</pre> </p>
</blockquote>
<p> </p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker-19.03.11离线安装</title>
    <url>/2021/07/18/docker-19.03.11%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>title: docker-19.03.11离线安装<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—有时候docker运行环境连不了互联网，怎么安装呢？这里介绍docker 离线安装方法，非常简单，只需要一个下载包和几个命令就能搞好！</p>
<p>1、去官网下载docker 安装二进制包，选择适合自己的版本。这里下载的是docker-19.03.11.tgz，在centos7中安装（cento6无法使用，提示linux版本内核版本太低）</p>
<p>下载地址：<a href="https://download.docker.com/linux/static/stable/x86_64/">https://download.docker.com/linux/static/stable/x86_64/</a></p>
<p>2、复制docker-19.03.11.tgz到服务器上，解压：tar xzvf docker-19.03.11.tgz</p>
<p>3、进入docker目录复制所有文件到/usr/bin目录下，目的/user/bin是环境变量目录，在路径下都可以运行docker命令</p>
<p>ls -l docker</p>
<p>cp docker/* /usr/bin/</p>
<blockquote>
 <pre><code>[root@localhost local]# tar xvf docker-19.03.11.tgz
docker/
docker/docker-init
docker/runc
docker/docker
docker/docker-proxy
docker/containerd
docker/ctr
docker/dockerd
docker/containerd-shim
[root@localhost local]# ls -l docker
total 195504
-rwxr-xr-x. 1 lr lr 32751272 May 14 17:29 containerd
-rwxr-xr-x. 1 lr lr  6012928 May 14 17:29 containerd-shim
-rwxr-xr-x. 1 lr lr 18194536 May 14 17:29 ctr
-rwxr-xr-x. 1 lr lr 61113382 May 14 17:29 docker
-rwxr-xr-x. 1 lr lr 68874208 May 14 17:29 dockerd
-rwxr-xr-x. 1 lr lr   708616 May 14 17:29 docker-init
-rwxr-xr-x. 1 lr lr  2928514 May 14 17:29 docker-proxy
-rwxr-xr-x. 1 lr lr  9600696 May 14 17:29 runc
[root@localhost local]# mv docker/* /usr/bin/
[root@localhost local]#</code></pre> 
<p>   </p>
</blockquote>
<p>vim /etc/systemd/system/docker.service</p>
<p>添加文件内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line"></span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line"></span><br><span class="line">Documentation=https://docs.docker.com</span><br><span class="line"></span><br><span class="line">After=network-online.target firewalld.service</span><br><span class="line"></span><br><span class="line">Wants=network-online.target</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line"></span><br><span class="line">Type=notify</span><br><span class="line"></span><br><span class="line">ExecStart=/usr/bin/dockerd</span><br><span class="line"></span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line"></span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line"></span><br><span class="line">LimitNPROC=infinity</span><br><span class="line"></span><br><span class="line">TimeoutStartSec=0</span><br><span class="line"></span><br><span class="line">Delegate=yes</span><br><span class="line"></span><br><span class="line">KillMode=process</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">StartLimitBurst=3</span><br><span class="line"></span><br><span class="line">StartLimitInterval=60s</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line"></span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>

<p>赋执行权限</p>
<p>chmod +x /etc/systemd/system/docker.service</p>
<p>systemctl daemon-reload </p>
<p>#开机启动</p>
<p>systemctl enable docker.service</p>
<p>启动docker</p>
<p>systemctl start docker</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker-swarm简介</title>
    <url>/2021/07/18/docker-swarm%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>title: docker-swarm简介<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker-swarm简介<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1.  什么是Docker Swarm? Swarm是Docker的一个编排工具，在之前我们只是在一台机器来进行docker的管理：<img alt="" src="https://img-blog.csdnimg.cn/img_convert/ab7861100c2cb8903ab02d28b7c8ae18.png"> 但是有时容器并不一定都在一台主机上，如果是分布式的处于多台主机上，这时就可以借助于Swarm，Swarm是Docker自带的编排工具，只要你安装了Docker就会存在Docker Swarm工具。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/db33a0c994117f706f5286619e0fe19e.png"> Swarm中的模式是有两大类节点，一类是manager节点，另一类是worker节点，manager节点相当于对服务的创建和调度，worker节点主要是运行容器服务，当然manager节点也是可以运行的。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/6833ae9814f2ac492420cddd5930f2ea.png"> manager节点状态、信息的同步根据Raft consensus group(Raft一致性算法)的网络进行通信同步的，而worker之间的通信依靠的是Gossip network(<strong>Gossip</strong>协议是电脑之间的通信协议)做到的。 另外一个重要的概念就是service，我们可以在一个manager节点上创建一个服务，但是可以根据这一个服务创建多个容器的任务，这些容器任务运行在不同的节点上。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/25f70b33292dfbfeaa2a3ab246dbd122.png"> 那么如何进行Swarm集群的搭建呢？       1)在swarm模式下初始化一个Swarm集群，并且将当前主机加入到该集群作为manager节点       2)加入其它节点到该集群中       3)部署service到该集群中 1.  Docker Swarm集群搭建，这里我们总共有4台机器，我们准备创建的1主3从  主节点：192.168.56.10(docker01)  从节点：192.168.56.11(docker02)  从节点：192.168.56.12(docker03)  从节点：192.168.56.13(docker04) 1)创建多节点集群        1.1)查看docker-swarm命令              <img alt="" height="389" src="https://img-blog.csdnimg.cn/20210102202358243.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="780">             可以看到其中有一个 init的命令，这就是初始化一个Swarm，我们再看看这个init的参数：             <img alt="" height="412" src="https://img-blog.csdnimg.cn/20210102202500999.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1104">              可以看到它有很多的参数，其中第一个就是将本机的地址添加进去，让自己成为一个Manager节点，这样其它的节点都可以知道这个节点的存在。 2)创建一个Manager节点       命令：docker swarm init –advertise-addr=当前机器的ip地址        <img alt="" height="205" src="https://img-blog.csdnimg.cn/20210102203033169.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1112">       可以看到已经创建了一个swarm manager节点–advertise-addr参数的值192.168.56.10是自己的ip，相当于将自己加入到swarm中。它也说明了其它worker加入的方式。       其它work加入的命令是：           docker swarm join –token SWMTKN-1-42k5spdc2goa6lqy2o858uu43x3r6yne03aoaa4267wdxozq1a-9ak1flizh9gckgulxanvjvsqe 192.168.56.10:2377 3)创建一个worker节点 ,另外再开启一台虚拟机，将这台机器加入到swarm中成为worker节点,这一台机器ip为192.168.56.11        命令： docker swarm join –token SWMTKN-1-42k5spdc2goa6lqy2o858uu43x3r6yne03aoaa4267wdxozq1a-9ak1flizh9gckgulxanvjvsqe 192.168.56.10:2377        <img alt="" height="148" src="https://img-blog.csdnimg.cn/20210102204131147.png" width="1200">        可以看到已经成功了。 4)查看节点状态 ,注意的是查看节点状态只能在manager节点那台机器上查看，普通节点无法执行查看命令：     命令：docker node ls      <img alt="" height="126" src="https://img-blog.csdnimg.cn/20210102204249673.png" width="1200">      可以看到有两台机器了。  5)这里我们总共有4台机器，我们将剩余两台机器创建好work节点      <img alt="" height="120" src="https://img-blog.csdnimg.cn/20210102204623906.png" width="1160">      <img alt="" height="127" src="https://img-blog.csdnimg.cn/20210102204639503.png" width="1129"> 6)在docker01主节点上查看节点状态      <img alt="" height="283" src="https://img-blog.csdnimg.cn/20210102204901728.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1011">     可以看到有4台机器了。  7)多节点容器创建      上面我们已经将节点创建好了，现在可以在这些节点上创建容器了，那么就需要看看docker service 的帮助信息：      <img alt="" height="419" src="https://img-blog.csdnimg.cn/20210102205215457.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="851">     可以看到有create这个命令，可以这样理解，docker server create 相当于docker run 就是创建容器，只不过在swarm中是不同的表现方式。     7.1)manager节点上创建容器服务，这里我们以nginx为例            命令：docker service create -p 8888:80 –name my-nginx nginx            <img alt="" height="138" src="https://img-blog.csdnimg.cn/20210102210024130.png" width="823">           可以查看是否创建成功：           <img alt="" height="91" src="https://img-blog.csdnimg.cn/2021010221010672.png" width="906">           可以具体看这个service的内容：          <img alt="" height="76" src="https://img-blog.csdnimg.cn/20210102210206529.png" width="1177">     7.2)水平扩展容器服务,使用scale对容器服务的数量进行水平扩展，它可以帮助我们创建多个service            命令：docker service scale 服务名=数量           <img alt="" height="208" src="https://img-blog.csdnimg.cn/20210102210716663.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="618">            通过命令docker service ls查看            <img alt="" height="96" src="https://img-blog.csdnimg.cn/20210102210842456.png" width="849">           再看看具体的容器数量：           命令：docker service ps 服务命令：           <img alt="" height="106" src="https://img-blog.csdnimg.cn/20210102210959533.png" width="991">           我们可以通过docker ps命令在4台服务器上查看我们创建的4个服务分别运行在哪个服务器上           <img alt="" height="248" src="https://img-blog.csdnimg.cn/20210102211302898.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1120">            如上可以发现4台服务器一台机器运行了一个容器服务     7.3)scale在swarm中除了水平扩展外，还有一个作用，那就是修复作用，比如将某一个节点中的容器删除掉，那么很快swarm中发觉并进行修复，数量保持原先的样子         假如现在删除worker中的一个容器，我们就删除docker02中的容器：         <img alt="" height="138" src="https://img-blog.csdnimg.cn/20210102211638906.png" width="1191">         我们在manager节点中查看容器情况：         <img alt="" height="127" src="https://img-blog.csdnimg.cn/20210102211803643.png" width="1158">        可以看到红色就是我们删掉的容器，但是后面它又马上补充了一个，保持了整个系统的稳定性。 8)我们在浏览器上访问4台服务器的nginx试试      <img alt="" height="244" src="https://img-blog.csdnimg.cn/20210102211940503.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1049"><img alt="" height="278" src="https://img-blog.csdnimg.cn/20210102212003689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1087"><img alt="" height="293" src="https://img-blog.csdnimg.cn/20210102212028823.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1098"><img alt="" height="278" src="https://img-blog.csdnimg.cn/20210102212048178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1105"> 1.  将我们部署的service移除命令：<img alt="" height="403" src="https://img-blog.csdnimg.cn/20210102212452219.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="772">  <img alt="" height="120" src="https://img-blog.csdnimg.cn/20210102212536429.png" width="1110"> 转载自： </p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker之mongo数据库忘记用户名密码</title>
    <url>/2021/07/18/docker%E4%B9%8Bmongo%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BF%98%E8%AE%B0%E7%94%A8%E6%88%B7%E5%90%8D%E5%AF%86%E7%A0%81/</url>
    <content><![CDATA[<p>title: docker之mongo数据库忘记用户名密码<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker之mongo数据库忘记用户名密码<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. 首先通过docker命令停止容器 docker stop 容器id1. 修改主机上与容器同步的mongod.conf文件,将认证注释掉<img alt="" height="288" src="https://img-blog.csdnimg.cn/20201231150258250.png" width="290">1. 重新启动容器 docker start 容器id1. 进入容器内部 命令：docker exec -it 容器id mongo admin<img alt="" height="359" src="https://img-blog.csdnimg.cn/20201231152709320.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="803">1. 通过命令查询用户信息 命令：show users<img alt="" height="309" src="https://img-blog.csdnimg.cn/20201231152834540.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="568">1. 修改指定用户的密码 命令：db.changeUserPassword(‘用户名’,’新密码’)<img alt="" height="304" src="https://img-blog.csdnimg.cn/20201231153328484.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="560">1. 最后退出容器，并且重新将mongod.conf文件中的认证打开，并且重新启动容器<img alt="" height="234" src="https://img-blog.csdnimg.cn/20201231153816737.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="792"></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker之自定义网络</title>
    <url>/2021/07/18/docker%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<p>title: docker之自定义网络<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker之自定义网络<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. 简介 建议使用用户定义的网桥来控制哪些容器可以相互通信，以及启用容器名称到IP地址的自动DNS解析。1. 查看所有的Docker网络 命令：docker network ls<img alt="" height="179" src="https://img-blog.csdnimg.cn/20201227130109653.png" width="492">1. 网络模式解释 1)bridge ：桥接 docker（默认）,一般我们创建网络也使用桥接模式 2)host ：和宿主机共享网络 3)none ：不配置网络 4)container：容器网络连通（用的少！局限很大!） 1. 启动容器命令解释 1)我们直接启动命令，有默认的参数，只是省略掉了 –net bridge,而这个就是我们的docker0       docker run -d -P –name tomcat01 tomcat        上面的命令等同于下面的启动容器命令       docker run -d -P –name tomcat01 –net bridge tomcat1. 自定义创建一个网络 1)命令：        docker network create –driver bridge –subnet 192.168.0.0/16 –gateway 192.168.0.1 mynet        解释：            –driver bridge 表示使用桥接模式            –subnet 192.168.0.0/16 表示子网ip 可以分配 192.168.0.2 到 192.168.255.255            –gateway 192.168.0.1 表示网关,就是路由器            mynet- 网络名         注意：                 192.168.0.0/16：表示网络码占16位，也就是说该网络上只可以有65534个主机(2^16-2)IP范围：192.168.0.1~192.168.255.254 192.168.255.255是广播地址，          不能被主机使用。设置IP地址的时候：192.168.x.y 子网掩码：255.255.0.0 2)执行上面的命令       <img alt="" height="201" src="https://img-blog.csdnimg.cn/20201227140833230.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="927"> 3)查看我们刚刚自定义的网络       命令：docker network inspect mynet        <img alt="" height="486" src="https://img-blog.csdnimg.cn/20201227141022782.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="647"> 4)下面我们启动容器并且指定使用我们刚刚创建的网络        <img alt="" height="347" src="https://img-blog.csdnimg.cn/20201227141259664.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> 5)我们再次查看网络信息       命令：docker network inspect mynet        <img alt="" height="389" src="https://img-blog.csdnimg.cn/2020122714151580.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="767"> 6)下面我们直接使用两个容器进行ping一下，测试是否能够连接       <img alt="" height="271" src="https://img-blog.csdnimg.cn/20201227141907294.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1029">        我们再次使用mytomcat01去连接mytomcat02         <img alt="" height="230" src="https://img-blog.csdnimg.cn/20201227142012483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1000">        可以发现我们使用自定义的网络，容器直接网络都是可以互通的(可以使用容器名称，也可以使用ip地址)，它修复了docker0所不完善的地方，我们不需要再使用–link了。 7)小节：       a：不同集群可以使用不同网络，保证集群的健康和安全，比如我们搭建一个mysql集群和一个redis集群，那么我们就自定义两个网络即可       b:  自定义网络已经维护好了对应的关系，方便使用服务名通讯1. 网络连通  1)简介         上面我们创建了两个容器mytomcat01和mytomcat02，它们指定的都是我们自定义的网络mynet，那么我们如何让它们和不同网络的容器链接呢？      比如我们先又创建两个容器mytomcat03和mytomcat04，我们指定这两个容器属于默认的docker0网络，那么我们如何让mytomcat03可以ping通mytomcat01呢？   2）首先创建mytomcat03和mytomcat04容器         <img alt="" height="190" src="https://img-blog.csdnimg.cn/20201227143732368.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="932">        <img alt="" height="202" src="https://img-blog.csdnimg.cn/20201227144024547.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="828">        <img alt="" height="312" src="https://img-blog.csdnimg.cn/20201227144042615.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="905">       可以发现它们的网段都不一样：          mytomcat01和mytomcat03属于：192.168.0.x           mytomcat01和mytomcat03属于：172.17.0.x  3)下面我们测试使用mytomcat01去ping通mytomcat03        <img alt="" height="175" src="https://img-blog.csdnimg.cn/20201227143933144.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="976">  4)解决的办法(我们要做的其实是将容器和网络(比如我们自定义的mynet)链接，不是docker0和网络链接)：         命令：docker network connect 网络名词 容器id         例如打通mytomcat03和mynet的网络          <img alt="" height="211" src="https://img-blog.csdnimg.cn/20201227144743908.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1087">            我们在通过docker network inspect mynet查看一下网络情况：          <img alt="" height="330" src="https://img-blog.csdnimg.cn/20201227144902325.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="738">         我们发现mytomcat03在mynet网络中也出现了一个新的ip地址，说明mytomcat03在docker0中有一个ip，在mynet中也有一个ip地址，         这就是一个容器两个ip地址。类似于我们的阿里云服务器有一个公网ip和一个私网ip   5)那么我们再使用mytomcat01去链接一下mytomcat03试一下        <img alt="" height="312" src="https://img-blog.csdnimg.cn/20201227145345110.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="848"></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker之容器互联link</title>
    <url>/2021/07/18/docker%E4%B9%8B%E5%AE%B9%E5%99%A8%E4%BA%92%E8%81%94link/</url>
    <content><![CDATA[<p>title: docker之容器互联link<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker之容器互联link<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. 简介     –link 用于容器直接的互通。1. 我们准备好自己创建的镜像<img alt="" height="145" src="https://img-blog.csdnimg.cn/20201227102350258.png" width="726">1. 使用mytomcat镜像创建两个容器<img alt="" height="299" src="https://img-blog.csdnimg.cn/20201227102622151.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1141">1. 下面我们使用myt1容器去链接myt2容器<img alt="" height="82" src="https://img-blog.csdnimg.cn/20201227103400216.png" width="614">1. 如何解决呢？ 1)我们创建一个myt3容器，使用–link命令          命令：docker run -d -p 9092:8080 –name myt3 –link myt2  mytomcat:v1.0     <img alt="" height="70" src="https://img-blog.csdnimg.cn/20201227104205919.png" width="767"> 2)下面我们使用myt3容器链接myt2     <img alt="" height="237" src="https://img-blog.csdnimg.cn/20201227104445980.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="695"> 3)下面我们再使用myt2容器ping一下myt3试试       <img alt="" height="137" src="https://img-blog.csdnimg.cn/20201227105912403.png" width="617">     发现反向是无法ping通的 4)为什么myt3能够ping通myt2呢？我们查看一下myt3中的/etc/hosts文件       <img alt="" height="264" src="https://img-blog.csdnimg.cn/20201227110827542.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="943">       从以上就可以得出：      –link 就是在我们myt3容器的hosts中增加一个172.17.0.3 myt2 cd1f8468844e       那么我们再查看一下myt2容器的hosts文件        <img alt="" height="186" src="https://img-blog.csdnimg.cn/20201227111118207.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="662">1. 注意：    现在docker中不建议使用–link，一般使用自定义网络，因为docker0是一个官方的网桥，它的很多功能是有局限性的。比如它不支持容器名连接访问</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker案例之制作tomcat镜像</title>
    <url>/2021/07/18/docker%E6%A1%88%E4%BE%8B%E4%B9%8B%E5%88%B6%E4%BD%9Ctomcat%E9%95%9C%E5%83%8F/</url>
    <content><![CDATA[<p>title: docker案例之制作tomcat镜像<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker案例之制作tomcat镜像<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. 进入/opt/tomcat9路径下，上传我们需要的tomcat以及jdk安装包  <img alt="" height="179" src="https://img-blog.csdnimg.cn/20201226174125314.png" width="786"><li>下面我们开始在这个目录下编写Dockerfile文件<img alt="" height="197" src="https://img-blog.csdnimg.cn/20201226175221627.png" width="811"> Dockerfile内容： <pre><code class="language-bash">#基于我们从阿里云下载下来的centos基础镜像<br>FROM centos</p>
<p>#定义维护者的信息<br>MAINTAINER kgf&lt;<a href="mailto:&#x6b;&#x67;&#x66;&#x40;&#x31;&#54;&#51;&#x2e;&#99;&#x6f;&#x6d;">&#x6b;&#x67;&#x66;&#x40;&#x31;&#54;&#51;&#x2e;&#99;&#x6f;&#x6d;</a>&gt;</p>
<p>#把宿主机当前上下文的test1.txt文件拷贝到容器/usr/local/路径下<br>COPY readme.txt /usr/local/readme.txt</p>
<p>#把java与tomcat添加到容器中,使用ADD命令会自动帮我们解压<br>ADD jdk-8u191-linux-x64.tar.gz /usr/local/<br>ADD apache-tomcat-9.0.12.tar.gz /usr/local/</p>
<p>#安装vim编辑器<br>RUN yum -y install vim</p>
<p>#设置工作访问时候的workdir路径，登录落脚点<br>ENV MY_PATH /usr/local<br>WORKDIR $MY_PATH</p>
<p>#配置java与tomcat环境变量<br>ENV JAVA_HOME /usr/local/jdk1.8.0_191<br>ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar<br>ENV CATALINA_HOME /usr/local/apache-tomcat-9.0.12<br>ENV CATALINA_BASE /usr/local/apache-tomcat-9.0.12<br>ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin</p>
<p>#容器运行时监听的端口<br>EXPOSE 8080</p>
<p>#启动时运行tomcat,下面的三种方式随便一种都可以使用<br>#ENTRYPOINT [“/usr/local/apache-tomcat-9.0.12/bin/startup.sh”]<br>#CMD [“/usr/local/apache-tomcat-9.0.12/bin/catalina.sh”,”run”]<br>CMD /usr/local/apache-tomcat-9.0.12/bin/startup.sh &amp;&amp; tail -F /usr/local/apache-tomcat-9.0.12/bin/logs/catalina.out</code></pre>   </li>1. 执行dockerfile文件 命令：docker build -f /opt/tomcat9/Dockerfile -t mytomcat:v1.0 .<img alt="" height="311" src="https://img-blog.csdnimg.cn/20201226183350361.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="701"><img alt="" height="253" src="https://img-blog.csdnimg.cn/20201226183426240.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="593"><li>运行镜像生成镜像的实例容器 命令：     <pre><code class="language-bash">docker run -d -p 9080:8080 --name myt9 <br>-v /opt/tomcat9/test:/usr/local/apache-tomcat-9.0.12/webapps/test <br>-v /opt/tomcat9/logs:/usr/local/apache-tomcat-9.0.12/logs <br>--privileged=true <br>mytomcat:v1.0</p>
<p>#注释:<br>     -d：表示后台运行<br>     -p 宿主机端口号:容器内运行的软件程序端口  —&gt;表示将容器内端口映射到宿主机，对外开放<br>     –name +容器名称  —&gt;为运行启动的容器起一个别名<br>     -v +宿主机路径:容器内路径  —&gt;表示为宿主机和容器添加关联数据卷<br>     –privileged=true   —-&gt;这是为了防止数据卷没有读写权限<br>     mytomcat:v1.0   —-&gt;这个是镜像的名称:版本号</code></pre> <img alt="" height="182" src="https://img-blog.csdnimg.cn/20201226184329432.png" width="702"><img alt="" height="151" src="https://img-blog.csdnimg.cn/20201226184346517.png" width="1200"> </li>1. 查看运行效果：<img alt="" height="372" src="https://img-blog.csdnimg.cn/2020122618455694.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="944">1. 查看本地主机是否同步了容器的数据卷<img alt="" height="355" src="https://img-blog.csdnimg.cn/20201226184801392.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="730">1. 下面在自定义的tomcat9上发布web项目演示 ⑴因为我们在容器内创建关联的数据卷目录是test命令，所以我们就将一个     简单的名称为test的web项目部署到容器内。     a：注意          因为宿主机的test目录是和容器类的test关联目录，所以我们只需要将          项目内文件传递到宿主机内即可。     <img alt="" height="193" src="https://img-blog.csdnimg.cn/20201226194142382.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="833"> b：查看容器内test目录下文件<img alt="" height="171" src="https://img-blog.csdnimg.cn/20201226194239600.png" width="893"> ⑵重新启动运行的容器<img alt="" height="169" src="https://img-blog.csdnimg.cn/20201226194331187.png" width="788"> 效果（完美）：<img alt="" height="257" src="https://img-blog.csdnimg.cn/20201226194406185.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="812"></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker常用的命令</title>
    <url>/2021/07/18/docker%E5%B8%B8%E7%94%A8%E7%9A%84%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>title: docker常用的命令<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker常用的命令<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. 查看docker版本信息  docker version1. 查看docker的详细信息,包括镜像和配置的阿里云加速器以及容器的数量等  docker info1. 镜像相关的命令 1)查看本地主机所有的镜像         docker images 2)查询镜像并且只显示镜像id         docker images -q 3)命令搜索可以下载的镜像        docker search 镜像名称      例如：docker search mysql      <img alt="" height="224" src="https://img-blog.csdnimg.cn/20201217205701441.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1178"> 4)搜索指定条件的镜像(例如：搜索starts在3000以上的)       命令：docker search mysql –filter=STARS=3000      <img alt="" height="117" src="https://img-blog.csdnimg.cn/20201217210110391.png" width="922"> 5)docker下载镜像命令      命令：docker pull 镜像命令 6) 下载指定的镜像版本       命令：docker pull 镜像名称:版本       <img alt="" height="325" src="https://img-blog.csdnimg.cn/20201217211017359.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="684">        注意：mysql的版本必须是docker仓库中存在的，我可以在docker hub中查看：        <img alt="" height="408" src="https://img-blog.csdnimg.cn/20201217211131303.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="640"> 7)删除镜像命令      命令：docker rmi  -f 镜像id       -f : 代表强制删除  8)删除所有的镜像      命令：docker rmi -f $( docker images -aq)      -a : 代表全部      -q : 代表只查镜像id1. 容器相关的命令 docker run [可选参数] image 可选参数如下：        –name=”name”: 为容器指定一个名称        -d: 后台运行容器，并返回容器ID        -i: 以交互模式运行容器，通常与 -t 同时使用       -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用       -P: 为容器指定一个运行的端口，-P 主机端口:容器端口       -p:  为容器随机指定一个运行的端口 1)启动并进入容器命令: docker run -it 镜像  /bin/bash         <img alt="" height="203" src="https://img-blog.csdnimg.cn/20201217220426954.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="676"> 2)查看当前正在运行的容器         docker ps 3)查看正在运行+曾经运行过的容器         docker ps -a 4)只查看容器的编号         docker ps -q 5)退出容器命令         exit : 表示退出并且停止容器         ctrl+p+q : 只退出容器并不停止容器 6)删除容器        docker rm -f 容器id 7)删除所有容器        docker rm -f $( docker ps -aq) 8)启动容器命令        docker start 容器id 9)重启容器        docker restart 容器id  10)停止容器命令        docker stop 容器id 11)杀掉容器命令         docker kill 容器id<li>docker查看日志命令 1)命令格式        <pre><code class="language-bash">$ docker logs [OPTIONS] CONTAINER<br>  Options:<br>        --details        显示更多的信息<br>    -f, --follow         跟踪实时日志<br>        --since string   显示自某个timestamp之后的日志，或相对时间，如42m（即42分钟）<br>        --tail string    从日志末尾显示多少行日志， 默认是all<br>    -t, --timestamps     显示时间戳<br>        --until string   显示自某个timestamp之前的日志，或相对时间，如42m（即42分钟）</code></pre>  2)查看指定时间后的日志，只显示最后100行         <pre><code>$ docker logs -f -t --since=&quot;2018-02-08&quot; --tail=100 CONTAINER_ID</code></pre>  3)查看最近30分钟的日志:      <pre><code>$ docker logs --since 30m CONTAINER_ID</code></pre>  4)查看某时间之后的日志：      <pre><code>$ docker logs -t --since=&quot;2018-02-08T13:23:37&quot; CONTAINER_ID</code></pre>  5) 查看某时间段日志：     <pre><code>$ docker logs -t --since=&quot;2018-02-08T13:23:37&quot; --until &quot;2018-02-09T12:23:37&quot; CONTAINER_ID</code></pre> </li>1. 查看容器中运行的进程信息 语法：    docker top CONTAINER [ps OPTIONS]1. 查看容器内部的细节 命令：docker inspect 容器ID                1. 进入当前正在运行的容器 命令：docker exec -it 容器ID bash  重新进入命令：docker attach 容器ID  区别：          a：attach是直接进入容器启动命令的终端，不会启动新的进程          b：exec是在容器中打开新的终端，并且可以启动新的进程 在容器外面查看容器内的内容：<img alt="" src="https://img-blog.csdnimg.cn/20181028205830489.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70">  1. 从容器内拷贝文件到主机上 命令：docker cp 容器ID:容器内路径 目的主机路径 例如：现在我们在centos容器的/tem目录下存在一个test1文件，现在我们需要将            其拷贝到主机的/opt目录下<img alt="" src="https://img-blog.csdnimg.cn/20181028211352419.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70"><img alt="" src="https://img-blog.csdnimg.cn/20181028211536307.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70"><br>10、删除状态为exited的容器</p>
<p>      命令：docker rm $(docker ps -q -f status=exited)</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker的容器数据卷入门简介</title>
    <url>/2021/07/18/docker%E7%9A%84%E5%AE%B9%E5%99%A8%E6%95%B0%E6%8D%AE%E5%8D%B7%E5%85%A5%E9%97%A8%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>title: docker的容器数据卷入门简介<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker的容器数据卷入门简介<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. 什么是容器数据卷? 命名的容器挂载数据卷，其它容器通过挂载这个（父容器）实现数据共享，挂载数据卷的容器，  称之为数据卷容器 。1. 案例1：用命令来挂载，让主机目录与容器目录数据共享 命令：docker run -it -v 主机目录:容器目录 镜像名称 /bin/bash 1)通过命令运行容器       <img alt="" height="28" src="https://img-blog.csdnimg.cn/20201225204926648.png" width="758"> 2)查看主机的/opt/ceshi目录,该目录下暂时没有东西<img alt="" height="141" src="https://img-blog.csdnimg.cn/20201225205012185.png" width="399"> 3)我们向该目录下新增一个文件      <img alt="" height="224" src="https://img-blog.csdnimg.cn/20201225205148936.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="452"> 4)进入容器的/home目录下看看,可以发现已经同步完成      <img alt="" height="182" src="https://img-blog.csdnimg.cn/20201225205805152.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="713"> 5)我们在容器内创建一个文件       <img alt="" height="295" src="https://img-blog.csdnimg.cn/20201225205942505.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="751"> 6)退出容器,查看主机的/opt/ceshi目录下,发现已经同步       <img alt="" height="234" src="https://img-blog.csdnimg.cn/20201225210251579.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="585"> 7)使用inspect命令查看容器属性       命令：docker inspect 容器id    <img alt="" height="208" src="https://img-blog.csdnimg.cn/2020122521040938.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="748">      <img alt="" height="212" src="https://img-blog.csdnimg.cn/20201225210516892.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="520"><li>案例2：使用Dockerfile创建我们自己的镜像并且完成数据卷挂载 1)首先在/opt目录下创建一个Dockerfile文件      <img alt="" height="233" src="https://img-blog.csdnimg.cn/20201225220922406.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="467">        注意：大小写一定要注意         <pre><code>#表示依赖centos的基础镜像<br>FROM centos</p>
<p>#表示通过匿名的方式创建两个数据挂载卷volume01和volume02<br>VOLUME [“volume01”,”volume02”]</p>
<p>CMD echo “======end===============”</code></pre>  2)使用命令运行Dockerfile去生成自己的镜像      命令：docker build -f /opt/Dockerfile -t kgf/centos:v1.0      -f :指定要使用的Dockerfile路径；      -t :指为新的镜像取名为kgf/centos,版本为v1.0      注意最后有个点，默认使用 “上下文目录（Context）下的名为Dockerfile 的文件作为 Dockerfile”      <img alt="" height="361" src="https://img-blog.csdnimg.cn/20201225220957437.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="809">         <img alt="" height="149" src="https://img-blog.csdnimg.cn/20201225221117351.png" width="620">      3)运行我们的镜像去创建容器          <img alt="" height="371" src="https://img-blog.csdnimg.cn/20201225221456456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="809">           可以发现容器内部存在两个容器卷,我们在里面添加一个文件：           <img alt="" height="135" src="https://img-blog.csdnimg.cn/20201225221714241.png" width="559">       4) 我们到主机查看容器对应的挂载主机目录路径           命令：docker inspect 容器id          <img alt="" height="219" src="https://img-blog.csdnimg.cn/20201225222023966.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="875">            <img alt="" height="396" src="https://img-blog.csdnimg.cn/20201225222053380.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1021">            <img alt="" height="216" src="https://img-blog.csdnimg.cn/20201225222152579.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1053">            可以发现主机的这个挂载目录也同步了容器中的数据文件</li></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker知识点相关笔记一</title>
    <url>/2021/07/18/docker%E7%9F%A5%E8%AF%86%E7%82%B9%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0%E4%B8%80/</url>
    <content><![CDATA[<p>title: docker知识点相关笔记一<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>— </p>
<ol>
<li>  docker images  查询docker下面所有的镜像信息   <img alt="" class="has" height="215" src="https://img-blog.csdn.net/20181021174740132?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="509">        1. docker rmi &lt;image id&gt;     删除镜像信息   <img alt="" class="has" height="272" src="https://img-blog.csdn.net/20181021174953119?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="473">   <img alt="" class="has" height="189" src="https://img-blog.csdn.net/20181021175118660?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="469">1. 当非root用户要运行docker时，需要执行 **sudo usermod -aG docker +用户 **命令  <img alt="" class="has" height="48" src="https://img-blog.csdn.net/20181021181639116?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="496">  其实就是修改用户的组，将这个用户添加到docker的组里面，只要这个用户在docker  组里面，那么我们就不需要root用户，就可以直接运行docker命令。  <img alt="" class="has" height="152" src="https://img-blog.csdn.net/20181021182007275?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="594">1. 如何启动docker，启动的时候出现这个问题：  <img alt="" class="has" height="180" src="https://img-blog.csdn.net/20181021230958758?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="647">  <img alt="" class="has" height="339" src="https://img-blog.csdn.net/20181021232007724?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="651">  解决办法：       查看文件系统 /etc/docker/daemon.json 删除里面内容用空的花括号代替。       {}   保存退出。输入  service docker restart         <img alt="" class="has" height="278" src="https://img-blog.csdn.net/20181021235544697?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="415">1. 搜索相关镜像的版本信息，docker search +镜像名称<img alt="" class="has" height="309" src="https://img-blog.csdn.net/20181022103342178?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="567">  1. ubuntu 下重启网络    命令：sudo service network-manager restart1. 运行nginx，命令：docker run -p 8080:80 -d nginx  -p：是做端口映射的，将docker中nginx本身的80端口映射成本地HOST的8080端口 -d：表示程序时后台运行的 nginx：表示的是启动的程序nginx的名称<img alt="" class="has" height="192" src="https://img-blog.csdn.net/20181023222032634?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="512"> <img alt="" class="has" height="190" src="https://img-blog.csdn.net/20181023222126737?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="581"> 使用我们自定义的index.html，将nginx的index.html页面替换掉命令:docker cp index.html +nginx容器名称://usr/share/nginx/html<img alt="" class="has" height="201" src="https://img-blog.csdn.net/20181023224218558?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="496"> index.html内容如下<img alt="" class="has" height="86" src="https://img-blog.csdn.net/20181023224302281?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="355"> 效果：    <img alt="" class="has" height="132" src="https://img-blog.csdn.net/20181023224402243?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="435"> 但是，我们发现如果我们将nginx重启之后页面的效果又恢复原样了，这是为什么呢？<img alt="" class="has" height="190" src="https://img-blog.csdn.net/20181023222126737?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="581"> 这是因为docker在容器内部所做的改动都是暂时的，如果要永久保存就需要做commit操作。命令：docker commit -m ‘备注信息’ +容器ID或者容器名称<img alt="" class="has" height="85" src="https://img-blog.csdn.net/20181023225814446?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="567"> 查看images发现多了一个，但是没有名字<img alt="" class="has" height="183" src="https://img-blog.csdn.net/20181023230307230?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="549"> 那么我们就将它添加上：docker commit -m ‘备注信息’ +容器ID或者容器名称 +名称:版本<img alt="" class="has" height="245" src="https://img-blog.csdn.net/20181023230508754?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="579">1. 停止容器的命令  命令：docker stop 容器ID或者容器名称  <img alt="" class="has" height="192" src="https://img-blog.csdn.net/20181023225028334?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="544">1. 进入容器内部的命令：  docker exec -it +容器名称/容器ID bash<img alt="" class="has" height="97" src="https://img-blog.csdn.net/20181023230012707?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="530">1. 查询所有的容器信息，不管是当前正在运行的，还是之前运行过并且已经停止了的命令：docker ps -a<img alt="" class="has" height="305" src="https://img-blog.csdn.net/20181023230935475?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="566"><img alt="" class="has" height="246" src="https://img-blog.csdn.net/20181023230956609?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="457"> 如果想要删掉这些信息，使用下面命令：docker rm +容器ID或者容器名称<img alt="" class="has" height="63" src="https://img-blog.csdn.net/20181023231304273?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="510">1. docker的相关网站 docker官网：<a href="http://www.docker.com，注意：这个网站特别慢，因为是国外的网站，有防火墙">http://www.docker.com，注意：这个网站特别慢，因为是国外的网站，有防火墙</a> docker中文网站：<a href="https://www.docker-cn.com1/">https://www.docker-cn.com1</a>. CentOS下Docker的安装  Docker支持以下CentOS版本  <img alt="" class="has" height="178" src="https://img-blog.csdn.net/20181024215249289?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="606"> 案例：Centos7下安装Docker      ⑴查看linux版本          <img alt="" class="has" height="90" src="https://img-blog.csdnimg.cn/20181025211536601.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="416">      ⑵安装gcc，命令：yum -y install gcc           <img alt="" class="has" height="239" src="https://img-blog.csdnimg.cn/20181025212247887.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="479">      ⑶安装gcc- c++，命令：yum -y install gcc- c++         <img alt="" class="has" height="183" src="https://img-blog.csdnimg.cn/20181025212414462.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="348">      ⑷效果：                 <img alt="" class="has" height="252" src="https://img-blog.csdnimg.cn/20181025212521571.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="488">     ⑸如果虚机上存在旧的Docker版本，那么需要先卸载旧版本         <img alt="" class="has" height="315" src="https://img-blog.csdnimg.cn/2018102521374278.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="706">     ⑹安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的          命令：sudo yum install -y yum-utils device-mapper-persistent-data lvm2                     <img alt="" class="has" height="378" src="https://img-blog.csdnimg.cn/20181025224623607.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="490">         ⑺设置yum源,设置stable镜像仓库               命令：sudo yum-config-manager –add-repo <a href="https://download.docker.com/linux/centos/docker-ce.repo">https://download.docker.com/linux/centos/docker-ce.repo</a>               注意：如果我们执行上面的命令可能会出现下面的错误，不是命令的问题，是因为这个命令是需要从官网                          上下载东西，而我们清楚的是官网是国外的，特别慢，所以会时好时坏，出错。                          <img alt="" class="has" height="168" src="https://img-blog.csdnimg.cn/20181025225211858.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="503">              所以我们一般使用下面阿里云的地址：                     命令：sudo yum-config-manager –add-repo <a href="http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo">http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</a>                          <img alt="" class="has" height="159" src="https://img-blog.csdnimg.cn/20181025225603461.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="571">             ⑻更新yum软件包索引                    命令：sudo yum makecache fast                        <img alt="" class="has" height="232" src="https://img-blog.csdnimg.cn/20181025230001583.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="532">            ⑼安装Docker CE                 命令：yum -y install docker-ce                     <img alt="" class="has" height="294" src="https://img-blog.csdnimg.cn/2018102523062872.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="550">                     <img alt="" class="has" height="200" src="https://img-blog.csdnimg.cn/2018102523070298.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="565">            ⑽启动docker                 命令：systemctl start docker                     <img alt="" class="has" height="363" src="https://img-blog.csdnimg.cn/20181025230844666.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="414">           ⑾测试                   命令：下载hello-world镜像                     <img alt="" class="has" height="174" src="https://img-blog.csdnimg.cn/20181025231309981.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="562">                运行helllo-world镜像                     命令：docker run hello-world                    <img alt="" class="has" height="378" src="https://img-blog.csdnimg.cn/20181025231400915.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="531">           ⑿配置镜像加速                 ①在etc下面建立docker目录                        <img alt="" class="has" height="64" src="https://img-blog.csdnimg.cn/2018102523153685.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="306">                ②创建daemon.json文件                      命令：vi /etc/docker/daemon.json                       文件里面可以配置阿里云或者是网易云的链接地址                       <img alt="" class="has" height="227" src="https://img-blog.csdnimg.cn/20181025231842330.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="517">                     下面就是阿里云的，自己注册一个即可：                     <img alt="" class="has" height="498" src="https://img-blog.csdn.net/20181021135224261?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="540">                    这里面我们使用网易云的。                        <img alt="" class="has" height="103" src="https://img-blog.csdnimg.cn/20181025232233333.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="394">                  ③重新加载daemon                       命令:systemctl daemon-reload                       <img alt="" class="has" height="65" src="https://img-blog.csdnimg.cn/20181025232410234.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="306">               ④重新启动一下docker                      命令:systemctl restart docker                          <img alt="" class="has" height="345" src="https://img-blog.csdnimg.cn/20181025232557329.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="377">           ⒀卸载docker命令：                 a：systemctl stop docker                 b：yum -y remove docker-ce                 c：rm -rf /var/lib/docker 1. docker仓库，镜像，容器等相关概念<img alt="" class="has" height="170" src="https://img-blog.csdn.net/20181024224356787?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="735"><img alt="" class="has" height="267" src="https://img-blog.csdn.net/20181024224650568?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="735"></li>
</ol>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p>       </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker知识点相关笔记三</title>
    <url>/2021/07/18/docker%E7%9F%A5%E8%AF%86%E7%82%B9%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0%E4%B8%89/</url>
    <content><![CDATA[<p>title: docker知识点相关笔记三<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—# 一：镜像原理</p>
<p>          1：什么是镜像？                  镜像是一种轻量级，可执行的独立软件包，用来打包软件环境和基于运行环境开发的软件，                  它包含运行某个软件所需的所有内容，包括代码，运行时，库，环境变量和配置文件。            2：什么是UnionFS（联合文件系统）：                   <img alt="" class="has" height="69" src="https://img-blog.csdnimg.cn/20181029202242341.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="629">                        特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载                              会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。            3：docker镜像加载原理                   kernel：表示内核                   <img alt="" class="has" height="159" src="https://img-blog.csdnimg.cn/2018102920290350.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="662">                   <img alt="" class="has" height="120" src="https://img-blog.csdnimg.cn/20181029204145968.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="694">                   <img alt="" class="has" height="150" src="https://img-blog.csdnimg.cn/20181029203215528.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="735">           4：为什么docker镜像要采用这种分层结构呢？                   <img alt="" class="has" height="97" src="https://img-blog.csdnimg.cn/20181029204727527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="627">          5：特点                Docker镜像都是只读的，当容器启动时，一个新的可写层被加载到镜像的顶部。                这一层通常被称作容器层，容器层之下的都叫做镜像层。          6：docker commit操作                ⑴docker commit提交容器副本使之成为一个新的镜像                ⑵docker commit -m “提交的描述信息” -a=”作者” +容器ID +要创建的目标镜像名:[标签名]</p>
<h1 id="二：Docker容器数据卷介绍"><a href="#二：Docker容器数据卷介绍" class="headerlink" title="二：Docker容器数据卷介绍"></a>二：Docker容器数据卷介绍</h1><p>         1：什么是Docker容器数据卷                <img alt="" class="has" height="207" src="https://img-blog.csdnimg.cn/20181030212830897.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="644">               <img alt="" class="has" height="204" src="https://img-blog.csdnimg.cn/20181030213128900.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="653">        2：如何添加数据卷             ⑴直接命令添加                   创建或运行容器的时候，使用<code>-v</code>创建一个数据卷，就是宿主机绝对路径目录                   和容器内目录形成链接。                   命令：docker run -it -v /宿主机绝对路径目录:/容器内目录 +镜像名                  a：例如，我们直接执行下面的命令                        docker run -it -v /myDataVolume:/dataVolumeContainer centos                        注意： myDataVolume是宿主机的目录，可以不创建好，因为执行命令时                                    会自动创建                                    dataVolumeContainer 是镜像centos容器内部的目录，同上可以不先创建。                        <img alt="" class="has" height="211" src="https://img-blog.csdnimg.cn/20181030220152584.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="567">                        <img alt="" class="has" height="289" src="https://img-blog.csdnimg.cn/20181030220121123.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="542">                        通过上图可以发现创建执行命令后，容器内部和主机里都生成了对应的目录。                    b：下面我们查看数据卷是否挂载成功                         我们通过docker inspect +容器ID查看                          <img alt="" class="has" height="145" src="https://img-blog.csdnimg.cn/20181030221104912.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="499">                          <img alt="" class="has" height="129" src="https://img-blog.csdnimg.cn/20181030221550318.png" width="507">                   c：容器和宿主机直接数据共享                          ①首先我们进入到宿主机的数据卷目录下创建一个文件                              <img alt="" class="has" height="187" src="https://img-blog.csdnimg.cn/20181030221933984.png" width="443">                          ②下面我们直接查看容器内的数据卷关联文件                                <img alt="" class="has" height="95" src="https://img-blog.csdnimg.cn/20181030222139909.png" width="422">                           ③同理，如果我们在容器内修改数据卷关联目录下的文件，宿主机下的文件                               也会同步改变，这个数据卷就实现了宿主机关联目录的数据同步问题。</p>
<p>                          ④注意：如果我们容器被停止了，我们对主机上的同步文件进行了修改，                                          那么当容器重新启动之后，容器的管理目录是会自动和宿主机                                          上的关联目录数据同步一次的。                      d：命令（带权限）                              docker run -it -v /myDataVolume2:/dataVolumeContainer2:ro centos                              效果：创建出来的数据卷，宿主机上的关联文件目录是存在读写的权限                                          的，而容器内部的文件目录是没有写的权限的，我们在宿主机上                                          进行写的操作生成的文件数据等都是可以同步到容器内关联的目录                                          下的，而容器内我们是没有写的权限的，无法进行创建文件，修改                                           文件等操作。                              ro：表示read only的含义。              ⑵DockerFile方式添加数据卷                    a：首先我们在根目录下创建mydocker文件夹并且进入                          <img alt="" class="has" height="103" src="https://img-blog.csdnimg.cn/20181031204646552.png" width="293">                    b：可在Dockerfile中使用VOLUME指令来给镜像添加一个或多个数据卷                          <img alt="" class="has" height="123" src="https://img-blog.csdnimg.cn/20181031205041891.png" width="509">                          注释：比如我们在一个主机上创建了一个容器目录，那么当我们需要打包                                     容器到其他机器上时，无法保证其他机器上也有这个与容器关联的                                     宿主机目录，所以可移植行不好，我们无使用上面那种命令方式。                     c：file构建，创建Dockerfile文件                            <img alt="" class="has" height="251" src="https://img-blog.csdnimg.cn/20181031210427252.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="471">                     d：build后生成镜像                             命令：docker build -f +Dockerfile文件路径  -t +名称:版本，如果是当前目录，                                        就是docker build -t +名称:版本 .                                         <img alt="" class="has" height="294" src="https://img-blog.csdnimg.cn/20181031211718117.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="489">                                         <img alt="" class="has" height="94" src="https://img-blog.csdnimg.cn/20181031212027506.png" width="512">                                          那么只要我们运行刚创建的容器，它就会自动给我们创建两个数据卷                                         dataVolumeContainer和dataVolumeContainer2                        e：运行生成的容器卷                                <img alt="" class="has" height="200" src="https://img-blog.csdnimg.cn/20181031212535511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="540">                                我们在容器内的文件夹中创建一个文件test.txt                                 <img alt="" class="has" height="117" src="https://img-blog.csdnimg.cn/20181031212953494.png" width="498">                             那么现在容器内部已经生成了容器卷，宿主机会不会自动生成呢？                            <img alt="" class="has" height="102" src="https://img-blog.csdnimg.cn/20181031213207296.png" width="539">                             <img alt="" class="has" height="228" src="https://img-blog.csdnimg.cn/20181031213447416.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="542">                                 我们查看一下刚刚在容器内dataVolumeContainer目录中创建的test1.txt在宿主机对应的                             目录中有没有：                              <img alt="" class="has" height="136" src="https://img-blog.csdnimg.cn/20181031213655159.png" width="548"></p>
<p> </p>
<p>                                                            </p>
<p>     </p>
<p>                                                      </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker知识点相关笔记二</title>
    <url>/2021/07/18/docker%E7%9F%A5%E8%AF%86%E7%82%B9%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0%E4%BA%8C/</url>
    <content><![CDATA[<p>title: docker知识点相关笔记二<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker知识点相关笔记二<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. 命令：docker info查看docker的详细信息       <img alt="" class="has" height="337" src="https://img-blog.csdnimg.cn/20181028103526197.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="555">1. 命令docker images      <img alt="" class="has" height="153" src="https://img-blog.csdnimg.cn/20181028104939259.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="534">      <img alt="" class="has" height="175" src="https://img-blog.csdnimg.cn/20181028105014801.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="620">1. 命令：docker images -a，这个命令是列出本地所有的镜像（含中间镜像层）1. 命令：docker images -q，这个命令是只显示镜像ID  <img alt="" class="has" height="206" src="https://img-blog.csdnimg.cn/20181028105953733.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="527">1. 命令：docker images –digests，显示镜像的备注信息1. docker images –no-trunc，显示镜像的完整信息  <img alt="" class="has" height="131" src="https://img-blog.csdnimg.cn/20181028110337464.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="692">1. 命令：docker search -s 30 tomcat，表示查询点赞数超出30的版本  <img alt="" class="has" height="195" src="https://img-blog.csdnimg.cn/20181028141906326.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="702">1. 命令：docker rmi -f 镜像ID，删除单个镜像  <img alt="" class="has" height="369" src="https://img-blog.csdnimg.cn/20181028143421943.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="560">1. 命令：docker rmi -f 镜像名1:TAG 镜像名2:TAG，删除多个镜像<img alt="" class="has" height="347" src="https://img-blog.csdnimg.cn/20181028143625893.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="483">1. 命令：docker rmi -f $(docker images -qa)，删除本地所有的镜像  <img alt="" class="has" height="263" src="https://img-blog.csdnimg.cn/2018102814424654.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="569">1. 命令：docker pull centos，下载一个centos镜像   <img alt="" class="has" height="129" src="https://img-blog.csdnimg.cn/20181028171210164.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="528">1. 容器相关命令 ⑴：新建并启动容器        命令：docker run [OPTIONS] IMAGE[:TAG][COMMAND][ARG..]        OPTIONS：说明                <img alt="" class="has" height="310" src="https://img-blog.csdnimg.cn/2018102817160756.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="437">        a：下面我们以交互式模式运行容器，并起一个别名，可以发现我们进入到另外一个终端               命令： docker run -it –name=”mycentos01” 75835a67d134               <img alt="" class="has" height="123" src="https://img-blog.csdnimg.cn/20181028172149498.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="520">              出现上面的情况就说明我们进入了docker中centos容器运行的环境了              <img alt="" class="has" height="92" src="https://img-blog.csdnimg.cn/20181028172522668.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="491">         b：列出当前正在运行所有正在运行的容器               命令：docker ps [OPTIONS]               <img alt="" class="has" height="236" src="https://img-blog.csdnimg.cn/20181028173505876.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="438">               <img alt="" class="has" height="180" src="https://img-blog.csdnimg.cn/20181028174700661.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="548">               <img alt="" class="has" height="98" src="https://img-blog.csdnimg.cn/20181028174720318.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="553">              <img alt="" class="has" height="143" src="https://img-blog.csdnimg.cn/20181028174751869.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="560">               docker ps -lq表示展示最近创建的容器编号               <img alt="" class="has" height="65" src="https://img-blog.csdnimg.cn/20181028174902700.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="388">                     c：退出容器             命令：exit，容器停止并且退出             ctrl+P+Q，容器不停止退出             <img alt="" class="has" height="237" src="https://img-blog.csdnimg.cn/20181028175529696.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="558">     d：启动容器            命令：docker start +容器名称/ID                  e：重启容器           命令:docker restart +容器名称/ID     f：停止容器           命令：docker stop +容器名称/ID           强制停止命令 ：docker kill +容器名称/ID         g：删除容器          删除已经停止容器命令：docker rm +容器名称/ID          强制删除命令（不管容器是否停止） ：docker rm -f +容器名称/ID         h：删除当前运行的或者历史上运行过的所有容器         命令：docker rm -f $(docker ps -a -q)          <img alt="" class="has" height="74" src="https://img-blog.csdnimg.cn/20181028180849376.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="356">1. 命令：docker run -d –name=”mycentos01” centos  <img alt="" class="has" height="205" src="https://img-blog.csdnimg.cn/20181028201018988.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="523"> 这是为什么呢？  <img alt="" class="has" height="218" src="https://img-blog.csdnimg.cn/2018102820131465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="548">1. 查看容器日志 命令：docker logs -f -t –tail 容器ID -f：跟随最新的日志打印 -t：是加入时间戳 –tail 数字：显示最后多少条  <img alt="" class="has" height="308" src="https://img-blog.csdnimg.cn/20181028202308569.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="570">   从上面可以发现，当我们启动docker中centos容器的时候，设置每隔2秒钟打印   hello,这样进程就不会自动停止，最后我们使用查看日志的命令查看最后的几行日志。1. 查看容器内运行的进程  命令：docker top 容器ID  <img alt="" class="has" height="244" src="https://img-blog.csdnimg.cn/20181028203738152.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="569">1. 查看容器内部的细节 命令：docker inspect 容器ID                  1. 进入运行的容器并且以命令交互  命令：docker exec -it 容器ID bash  重新进入命令：docker attach 容器ID  区别：          a：attach是直接进入容器启动命令的终端，不会启动新的进程          b：exec是在容器中打开新的终端，并且可以启动新的进程 在容器外面查看容器内的内容：  <img alt="" class="has" height="359" src="https://img-blog.csdnimg.cn/20181028205830489.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="554"> 进入容器后查看，发现确实是一样的：<img alt="" class="has" height="415" src="https://img-blog.csdnimg.cn/20181028205924204.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="533">1. 从容器内拷贝文件到主机上 命令：docker cp 容器ID:容器内路径 目的主机路径 例如：现在我们在centos容器的/tem目录下存在一个test1文件，现在我们需要将            其拷贝到主机的/opt目录下            <img alt="" class="has" height="116" src="https://img-blog.csdnimg.cn/20181028211352419.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="372">            <img alt="" class="has" height="128" src="https://img-blog.csdnimg.cn/20181028211536307.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_27,color_FFFFFF,t_70" width="466">  
 </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker知识点相关笔记五</title>
    <url>/2021/07/18/docker%E7%9F%A5%E8%AF%86%E7%82%B9%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0%E4%BA%94/</url>
    <content><![CDATA[<p>title: docker知识点相关笔记五<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker知识点相关笔记五<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—<li>创建一个自定义的tomcat9镜像  ⑴创建一个存放dockerfile的目录       <img alt="" class="has" height="109" src="https://img-blog.csdnimg.cn/2018110316462743.png" width="365">  ⑵在这个目录下创建一个test1.txt文件（这个文件是用来演示cp命令的，      完成宿主机到容器的拷贝）      <img alt="" class="has" height="91" src="https://img-blog.csdnimg.cn/20181103164831288.png" width="314">      并且我们在这个目录下准备好jdk和tomcat的压缩包，后面有用     <img alt="" class="has" height="102" src="https://img-blog.csdnimg.cn/20181103172001716.png" width="462"> ⑶下面我们开始在这个目录下编写Dockerfile文件     <img alt="" class="has" height="123" src="https://img-blog.csdnimg.cn/20181103175215340.png" width="467">     dockerfile文件内容：      <pre class="has"><code>#基于我们从阿里云下载下来的centos基础镜像<br>FROM centos</p>
<p>#定义维护者的信息<br>MAINTAINER kgf&lt;<a href="mailto:&#107;&#103;&#x66;&#x40;&#49;&#54;&#51;&#46;&#x63;&#111;&#x6d;">&#107;&#103;&#x66;&#x40;&#49;&#54;&#51;&#46;&#x63;&#111;&#x6d;</a>&gt;</p>
<p>#把宿主机当前上下文的test1.txt文件拷贝到容器/usr/local/路径下<br>COPY test1.txt /usr/local/test1Copytocontainer.txt</p>
<p>#把java与tomcat添加到容器中<br>ADD jdk-8u191-linux-x64.tar.gz /usr/local/<br>ADD apache-tomcat-9.0.12.tar.gz /usr/local/</p>
<p>#安装vim编辑器<br>RUN yum -y install vim</p>
<p>#设置工作访问时候的workdir路径，登录落脚点<br>ENV MY_PATH /usr/local<br>WORKDIR $MY_PATH</p>
<p>#配置java与tomcat环境变量<br>ENV JAVA_HOME /usr/local/jdk1.8.0_191<br>ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar<br>ENV CATALINA_HOME /usr/local/apache-tomcat-9.0.12<br>ENV CATALINA_BASE /usr/local/apache-tomcat-9.0.12<br>ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin</p>
<p>#容器运行时监听的端口<br>EXPOSE 8080</p>
<p>#启动时运行tomcat,下面的三种方式随便一种都可以使用<br>#ENTRYPOINT [“/usr/local/apache-tomcat-9.0.12/bin/startup.sh”]<br>#CMD [“/usr/local/apache-tomcat-9.0.12/bin/catalina.sh”,”run”]<br>CMD /usr/local/apache-tomcat-9.0.12/bin/startup.sh &amp;&amp; tail -F /usr/local/apache-tomcat-9.0.12/bin/logs/catalina.out<br></code></pre>  ⑷执行dockerfile文件      命令：docker build -f /tmp/kgf/tomcat9/Dockerfile -t kgftomcat9:1.1 .      <img alt="" class="has" height="299" src="https://img-blog.csdnimg.cn/20181103180408356.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="536">      <img alt="" class="has" height="158" src="https://img-blog.csdnimg.cn/20181103180456939.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="542"> ⑸运行镜像生成镜像的实例容器     命令如下： <pre class="has"><code class="language-java">docker run -d -p 9080:8080 --name myt9<br>-v /tmp/kgf/tomcat9/test:/usr/local/apache-tomcat-9.0.12/webapps/test<br>-v /tmp/kgf/tomcat9/tomcat9logs:/usr/local/apache-tomcat-9.0.12/logs<br>--privileged=true<br>kgftomcat9:1.1</p>
<p>#注释:<br>     -d：表示后台运行<br>     -p 宿主机端口号:容器内运行的软件程序端口  —&gt;表示将容器内端口映射到宿主机，对外开放<br>     –name +容器名称  —&gt;为运行启动的容器起一个别名<br>     -v +宿主机路径:容器内路径  —&gt;表示为宿主机和容器添加关联数据卷<br>     –privileged=true   —-&gt;这是为了防止数据卷没有读写权限<br>     kgftomcat9   —-&gt;这个是镜像的名称<br>       </code></pre> <img alt="" class="has" height="160" src="https://img-blog.csdnimg.cn/20181103210630651.png" width="800"> 查看运行效果：    <img alt="" class="has" height="365" src="https://img-blog.csdnimg.cn/20181103210825440.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="838">  我们可以在外面查看容器类的目录：   <img alt="" class="has" height="403" src="https://img-blog.csdnimg.cn/20181103211230721.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="856">   <img alt="" class="has" height="333" src="https://img-blog.csdnimg.cn/20181103211552558.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="664">   <img alt="" class="has" height="145" src="https://img-blog.csdnimg.cn/20181103211744927.png" width="586">   </li>1.  下面在自定义的tomcat9上发布web项目演示 ⑴因为我们在容器内创建关联的数据卷目录是test命令，所以我们就将一个     简单的名称为test的web项目部署到容器内。     a：注意          因为宿主机的test目录是和容器类的test关联目录，所以我们只需要将          项目内文件传递到宿主机内即可。          <img alt="" class="has" height="157" src="https://img-blog.csdnimg.cn/20181103214844512.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="646">   b：查看容器内test目录下文件        <img alt="" class="has" height="177" src="https://img-blog.csdnimg.cn/20181103215334189.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="655"> ⑵重新启动运行的容器     <img alt="" class="has" height="137" src="https://img-blog.csdnimg.cn/20181103215653600.png" width="630">   效果（完美）：      <img alt="" class="has" height="213" src="https://img-blog.csdnimg.cn/20181103215714154.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="648"> <li> docker上安装mysql   ⑴从阿里云上拉取5.6版本mysql         命令：docker pull mysql:5.6         <img alt="" class="has" height="159" src="https://img-blog.csdnimg.cn/20181104090814422.png" width="622">    ⑵使用镜像运行容器         命令： <pre class="has"><code class="language-java">docker run -p 12345:3306 --name mysql<br>-v /tmp/mysql/conf:/etc/mysql/conf.d<br>-v /tmp/mysql/logs:/logs<br>-v /tmp/mysql/data:/var/lib/mysql<br>-e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.6</p>
<p>命令说明：<br>-p 12345:3306 ：  将主机的12345端口映射到docker容器的3306端口<br>–name mysql ：自定义运行服务的名字<br>-v /tmp/mysql/conf:/etc/mysql/conf.d ：将主机/tmp/mysql/conf目录挂载到容器的/etc/mysql/conf.d<br>-v /tmp/mysql/logs:/logs ：将主机/tmp/mysql/logs目录挂载到容器的/logs<br>-v /tmp/mysql/data:/var/lib/mysql ：将主机/tmp/mysql/data目录挂载到容器的/var/lib/mysql<br>-e MYSQL_ROOT_PASSWORD=123456 ：初始化root用户的密码<br>-d mysql:5.6 后台运行mysql5.6程序</code></pre>   ⑶执行效果:      <img alt="" class="has" height="231" src="https://img-blog.csdnimg.cn/20181104092326376.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="698">    ⑷进入容器         <img alt="" class="has" height="303" src="https://img-blog.csdnimg.cn/2018110409272143.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="591">    ⑸下面我们同宿主机上的工具链接一下试试        <img alt="" class="has" height="389" src="https://img-blog.csdnimg.cn/20181104093117859.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="372"> </li>1.  将我们的镜像提交到阿里云上  ⑴查看镜像      <img alt="" class="has" height="163" src="https://img-blog.csdnimg.cn/20181104094851343.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="585"> ⑵首先运行mycentos镜像容器，并且提交一个新的版本       <img alt="" class="has" height="308" src="https://img-blog.csdnimg.cn/20181104100419368.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="613"> ⑶首先登陆到阿里云服务器上        <img alt="" class="has" height="333" src="https://img-blog.csdnimg.cn/20181104101854763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="674"> ⑷创建镜像仓库       <img alt="" class="has" height="159" src="https://img-blog.csdnimg.cn/20181104103732446.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="589">      <img alt="" class="has" height="404" src="https://img-blog.csdnimg.cn/20181104103916572.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="550">     <img alt="" class="has" height="238" src="https://img-blog.csdnimg.cn/20181104104057629.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="576">    <img alt="" class="has" height="114" src="https://img-blog.csdnimg.cn/2018110410412917.png" width="596"> ⑸下面我们需要将镜像推送到阿里云      <img alt="" class="has" height="128" src="https://img-blog.csdnimg.cn/20181104104238801.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="567">      <img alt="" class="has" height="241" src="https://img-blog.csdnimg.cn/20181104104325780.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="617">      a：首先我们链接登陆阿里云          <img alt="" class="has" height="274" src="https://img-blog.csdnimg.cn/2018110411242920.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="541">      b：对上传到阿里云上标签的处理            <img alt="" class="has" height="153" src="https://img-blog.csdnimg.cn/20181104112900369.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="536">     c：下面就是向阿里云上push了            <img alt="" class="has" height="164" src="https://img-blog.csdnimg.cn/20181104113841958.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="497">     d：下面我们可以到阿里云上去搜索一下            <img alt="" class="has" height="168" src="https://img-blog.csdnimg.cn/20181104114100444.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="539">    e：可以到阿里云官网直接搜索，因为是公开的,这里我们就不演示了,可以直接搜索kgfbuy/mycebtos     1.  那么我们再演示一下如何从阿里云下载下来  a：首先我们先把本地的删除        <img alt="" class="has" height="300" src="https://img-blog.csdnimg.cn/20181104115137229.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="682">              b：下载下来        命令：docker pull registry.cn-qingdao.aliyuncs.com/kgfbuy/mycentos:1.2.1          <img alt="" class="has" height="241" src="https://img-blog.csdnimg.cn/20181104115504240.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="661">           </p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker知识点相关笔记四</title>
    <url>/2021/07/18/docker%E7%9F%A5%E8%AF%86%E7%82%B9%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0%E5%9B%9B/</url>
    <content><![CDATA[<p>title: docker知识点相关笔记四<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker知识点相关笔记四<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. 什么叫做数据卷容器？  命名的容器挂载数据卷，其它容器通过挂载这个（父容器）实现数据共享，挂载数据卷的容器，  称之为数据卷容器 。1. 下面我们基于之前创建的镜像kgf/centos去创建3个容器，名称分别为dc01,dc02和dc03，这三个  容器的关系是dc02和dc03都继承与dc01，下面我们通过实例操作试一下。   ⑴创建dc01的容器，命令：docker run -it –name dc01 kgf/centos       <img alt="" class="has" height="244" src="https://img-blog.csdnimg.cn/20181101215806230.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="571">       上面的dataVolumeContainer2和dataVolumeContainer目录是之前创建kgf/centos镜像        时建立的据数卷。那么现在我们在dataVolumeContainer2中创建一个文件。        <img alt="" class="has" height="137" src="https://img-blog.csdnimg.cn/20181101220127190.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="628">   ⑵创建dc01的容器，继承dc01容器       命令：docker run -it –name dc02 –volumes-from dc01 kgf/centos       <img alt="" class="has" height="197" src="https://img-blog.csdnimg.cn/20181101220646727.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="638">    ⑶创建dc03的容器，继承dc01容器       命令：docker run -it –name dc03 –volumes-from dc01 kgf/centos       <img alt="" class="has" height="223" src="https://img-blog.csdnimg.cn/20181101221236249.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="601">  ⑷下面我们分别查看dc01，dc02中的数据卷情况。       <img alt="" class="has" height="299" src="https://img-blog.csdnimg.cn/20181101221455562.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="566">       通过上面我们可以发现，我们创建的dc01,dc02和dc03它们之间的关联数据卷中的       数据是可以数据共享的，不管是哪个容器的数据发成了变化，那么其它的两个容器       的数据也将会发生同样的改变。1. 那么基于上面我们创建的dc01，dc02和dc033个容器，如果我们将dc01删除掉，再去 修改dc02，那么dc03会不会发生数据同步呢？能不能获取到dc02修改后的数据呢？ ⑴首先删除掉dc01容器     <img alt="" class="has" height="99" src="https://img-blog.csdnimg.cn/20181101222244856.png" width="598">       <img alt="" class="has" height="301" src="https://img-blog.csdnimg.cn/20181101222921658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="522">     由上图可以发现我们删除了dc01这个父容器后，对dc02和dc03的文件没有产生     影响，文件都还存在。 ⑵我们在dc02上新增一个文件试试      <img alt="" class="has" height="277" src="https://img-blog.csdnimg.cn/2018110122400323.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="521"> ⑶结论：      容器之间的配置信息的传递，数据卷的生命周期一直会持续到没有容器为止。       这就叫做容器卷传递共享（–volumes-from）       1. 什么是Dockerfile？  Dockerfile是用来构建docker镜像的构建文件，是由一系列命令和参数构成的脚本。1. 构建Dockerfile的三步骤：  a：编写Dockerfile文件  b：docker build去执行文件  c：docker run去运行生产的镜像1. Dockerfile的构建过程解析  ⑴DockerFile内容基础知识       a：每条保留字指令都必须为大写字母且后面要跟随至少一个参数       b：指令按照从上到下，顺序执行       c：#表示注释       d：每条指令都会创建一个新的镜像层，并对镜像进行提交  ⑵Docker执行Dockerfile的大致流程       a：dcoker从基础镜像运行一个容器       b：执行一条指令并对容器做出修改       c：执行类似docker commit的操作提交一个新的镜像层       d：docker再基于刚提交的镜像运行一个新容器       e：执行dockerfile中的下一条指令直到所有指令都执行完成  ⑶dockerfile的体系结构（保留字指令）       ①FROM：表示基础镜像，当前新镜像是基于哪个镜像的。              例如：FROM tomcat  —–》就是基于tomcat作为基础镜像的       ②MAINTAINER：表示镜像维护者的姓名和邮箱地址                  例如：MAINTAINER The Centos Project &lt;<a href="mailto:&#x63;&#108;&#111;&#117;&#x64;&#45;&#111;&#x70;&#115;&#x40;&#x63;&#x65;&#110;&#x74;&#x6f;&#x73;&#x2e;&#x6f;&#x72;&#x67;">&#x63;&#108;&#111;&#117;&#x64;&#45;&#111;&#x70;&#115;&#x40;&#x63;&#x65;&#110;&#x74;&#x6f;&#x73;&#x2e;&#x6f;&#x72;&#x67;</a>&gt;       ③RUN：表示容器构建时需要运行的命令       ④EXPOSE：表示构建的容器启动后对外暴露的端口号              例如：EXPOSE 6379       ⑤WORKDIR：表示指定在容器创建后，终端默认登录进来的工作目录，一个落脚点                    例如：WORKDIR /data   表示当我们进入容器后默认就在/data这个目录下       ⑥ENV：用来在构建镜像过程中设置环境变量              例如：ENV MY_PATH /usr/mytest   表示我们设置一个环境变量名称为MY_PATH，                         值为/usr/mytest，那么我们后面就可以引用这个环境变量。比如我们在设置                         落脚点的时候，WORKDIR $MY_PATH，那么登录进来后直接就是在/usr/mytest                         目录下。       ⑦ADD： 将宿主机目录下的文件拷贝进镜像并且ADD命令会自动处理URL和解压tar压缩包                   例如：ADD centos-7-docker.tar.xz /       ⑧COPY：类似ADD，拷贝文件和目录到镜像中。将从构建上下文目录中&lt;源路径&gt;的文件/目录                        复制到新的一层镜像内的&lt;目标路径&gt;位置。              例如：COPY src dest 或者 COPY [“src”,”dest”]       ⑨VOLUME：容器数据卷，用于数据保存和持久化工作       ⑩CMD：               a：表示指定一个容器启动时要运行的命令                     <img alt="" class="has" height="159" src="https://img-blog.csdnimg.cn/20181103103647354.png" width="572">               b：Dockerfile中可以有多个CMD指令，但只有最后一个生效，CMD会被docker run 之后                     的参数替代。       ENTRYPOINT：表示指定一个容器启动时要运行的命令，ENTRYPOINT的目的和CMD一样，                                  都是在指定容器启动程序及参数。       ONBUILD：表示当构建一个被继承的Dockerfile时运行命令，父镜像在被子继承后父镜像的                           onbuild被触发。1. 基于上面保留字的案例  ⑴Base镜像（scratch）        Docker Hub中99%的镜像都是通过在base镜像中安装和配置需要的软件构建出来的。  ⑵自定义镜像mycentos        ①我们现在可以看看我们从网上下载下载的centos镜像原本是什么样子的              <img alt="" class="has" height="323" src="https://img-blog.csdnimg.cn/20181103134447707.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="547">        ②下面我们编写我们的Dockerfile文件              a：在/tmp/mydocker目录下创建Dockerfile文件                   <img alt="" class="has" height="146" src="https://img-blog.csdnimg.cn/20181103140755811.png" width="394">             b：编写文件内容                  <img alt="" class="has" height="413" src="https://img-blog.csdnimg.cn/2018110314090794.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="381">            c：使用dockerfile文件构建新的镜像                 命令：docker build -f /tmp/mydocker/Dockerfile -t mycentos:1.1 .                 <img alt="" class="has" height="314" src="https://img-blog.csdnimg.cn/20181103141819974.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="436">                 <img alt="" class="has" height="113" src="https://img-blog.csdnimg.cn/2018110314192873.png" width="522">           d：下面我们运行新建的镜像                  命令：docker run -it mycentos:1.1                  <img alt="" class="has" height="132" src="https://img-blog.csdnimg.cn/20181103142152857.png" width="451">                  <img alt="" class="has" height="248" src="https://img-blog.csdnimg.cn/20181103142350154.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="429">                  <img alt="" class="has" height="109" src="https://img-blog.csdnimg.cn/20181103142447753.png" width="426">             e：使用docker history +镜像ID 查看镜像详细信息                 <img alt="" class="has" height="296" src="https://img-blog.csdnimg.cn/20181103142826822.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="610">1. ONBUILD命令案例   ⑴简介        当构建一个被继承的Dockerfile时运行命令，父镜像在被子继承后，父镜像的onbuild被触发。    ⑵简单案例：        <img alt="" class="has" height="272" src="https://img-blog.csdnimg.cn/20181103161931606.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="654">           <img alt="" class="has" height="547" src="https://img-blog.csdnimg.cn/20181103162024270.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="642">     </p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker网络简介</title>
    <url>/2021/07/18/docker%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>title: docker网络简介<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker网络简介<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—|Host|容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。<br>|Bridge|此模式会为每一个容器分配、设置IP等，并将容器连接到一个docker0虚拟网桥，通过docker0网桥以及Iptables nat表配置与宿主机通信。<br>|None|该模式关闭了容器的网络功能。<br>|Container|创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围。<br>|自定义网络|略</p>
<h2 id="一、默认网络"><a href="#一、默认网络" class="headerlink" title="一、默认网络"></a>一、默认网络</h2><p><strong>当你安装Docker时，它会自动创建三个网络。你可以使用以下docker network ls命令列出这些网络：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@server1 ~]# docker network ls</span><br><span class="line">NETWORK ID          NAME                DRIVER              SCOPE</span><br><span class="line">0147b8d16c64        bridge              bridge              local</span><br><span class="line">2da931af3f0b        host                host                local</span><br><span class="line">63d31338bcd9        none                null                local</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20190702223222117.png"></p>
<p><strong>Docker内置这三个网络，运行容器时，你可以使用该–network标志来指定容器应连接到哪些网络。</strong></p>
<p><strong>该bridge网络代表docker0所有Docker安装中存在的网络。除非你使用该docker run –network=选项指定，否则Docker守护程序默认将容器连接到此网络。</strong></p>
<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20190702223920623.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21lbHRzbm93,size_16,color_FFFFFF,t_70">

<p><strong>我们在使用docker run创建Docker容器时，可以用 –net 选项指定容器的网络模式，Docker可以有以下4种网络模式：</strong></p>
<ul>
<li>host模式：使用 –net=host 指定。- none模式：使用 –net=none 指定。- bridge模式：使用 –net=bridge 指定，默认设置。- container模式：使用 –net=container:NAME_or_ID 指定。</li>
</ul>
<p><strong>下面分别介绍一下Docker的各个网络模式。</strong></p>
<p><strong>1.1 Host模式</strong></p>
<p><strong>相当于Vmware中的桥接模式，与宿主机在同一个网络中，但没有独立IP地址。</strong></p>
<p><strong>众所周知，Docker使用了Linux的Namespaces技术来进行资源隔离，如PID Namespace隔离进程，Mount Namespace隔离文件系统，Network Namespace隔离网络等。</strong></p>
<p><strong>一个Network Namespace提供了一份独立的网络环境，包括网卡、路由、Iptable规则等都与其他的Network Namespace隔离。一个Docker容器一般会分配一个独立的Network Namespace。但如果启动容器的时候使用host模式，那么这个容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。</strong></p>
<p><strong>例如，我们在172.25.6.1/24的机器上用host模式启动一个ubuntu容器</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@server1 ~]# docker run -it --network=host ubuntu</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>可以看到，容器的网络使用的时宿主机的网络，但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。</strong></p>
<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20190702225446117.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21lbHRzbm93,size_16,color_FFFFFF,t_70">

<p><strong>1.2 Container模式</strong></p>
<p><strong>在理解了host模式后，这个模式也就好理解了。这个模式指定新创建的容器和已经存在的一个容器共享一个Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过lo网卡设备通信。</strong></p>
<p><strong>1.3 None模式</strong></p>
<p><strong>该模式将容器放置在它自己的网络栈中，但是并不进行任何配置。实际上，该模式关闭了容器的网络功能，在以下两种情况下是有用的：容器并不需要网络（例如只需要写磁盘卷的批处理任务）。</strong></p>
<p>overlay</p>
<p><strong>在docker1.7代码进行了重构，单独把网络部分独立出来编写，所以在docker1.8新加入的一个overlay网络模式。Docker对于网络访问的控制也是在逐渐完善的。</strong></p>
<p><strong>1.4 Bridge模式</strong></p>
<p><strong>相当于Vmware中的Nat模式，容器使用独立network Namespace，并连接到docker0虚拟网卡（默认模式）。通过docker0网桥以及Iptables nat表配置与宿主机通信；bridge模式是Docker默认的网络设置，此模式会为每一个容器分配Network Namespace、设置IP等，并将一个主机上的Docker容器连接到一个虚拟网桥上。下面着重介绍一下此模式。</strong></p>
<h2 id="二、Bridge模式"><a href="#二、Bridge模式" class="headerlink" title="二、Bridge模式"></a>二、Bridge模式</h2><p><strong>2.1 Bridge模式的拓扑</strong></p>
<p><strong>当Docker server启动时，会在主机上创建一个名为docker0的虚拟网桥，此主机上启动的Docker容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。接下来就要为容器分配IP了，Docker会从RFC1918所定义的私有IP网段中，选择一个和宿主机不同的IP地址和子网分配给docker0，连接到docker0的容器就从这个子网中选择一个未占用的IP使用。如一般Docker会使用172.17.0.0/16这个网段，并将172.17.0.1/16分配给docker0网桥（在主机上使用ifconfig命令是可以看到docker0的，可以认为它是网桥的管理接口，在宿主机上作为一块虚拟网卡使用）。单机环境下的网络拓扑如下，主机地址为10.10.0.186/24。</strong></p>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20190702230627173.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21lbHRzbm93,size_16,color_FFFFFF,t_70">  </p>
<p><strong>2.2 Docker：网络模式详解</strong></p>
<p><strong>Docker完成以上网络配置的过程大致是这样的：</strong></p>
<p><strong>（1）在主机上创建一对虚拟网卡veth pair设备。veth设备总是成对出现的，它们组成了一个数据的通道，数据从一个设备进入，就会从另一个设备出来。因此，veth设备常用来连接两个网络设备。</strong></p>
<p><strong>（2）Docker将veth pair设备的一端放在新创建的容器中，并命名为eth0。另一端放在主机中，以veth65f9这样类似的名字命名，并将这个网络设备加入到docker0网桥中，可以通过brctl show命令查看。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">brctl show</span><br><span class="line">bridge name     bridge id               STP enabled     interfaces</span><br><span class="line">docker0         8000.02425f21c208       no</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>（3）从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。</strong></p>
<p><strong>运行容器：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run --name=nginx_bridge --net=bridge -p 80:80 -d nginx        </span><br><span class="line">9582dbec7981085ab1f159edcc4bf35e2ee8d5a03984d214bce32a30eab4921a</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>查看容器：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker ps</span><br><span class="line">CONTAINER ID        IMAGE          COMMAND                  CREATED             STATUS              PORTS                NAMES</span><br><span class="line">9582dbec7981        nginx          &quot;nginx -g &#x27;daemon ...&quot;   3 seconds ago       Up 2 seconds        0.0.0.0:80-&amp;gt;80/tcp   nginx_bridge</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 查看容器网络;</span><br><span class="line">docker inspect 9582dbec7981</span><br><span class="line">&quot;Networks&quot;: &#123;</span><br><span class="line">    &quot;bridge&quot;: &#123;</span><br><span class="line">        &quot;IPAMConfig&quot;: null,</span><br><span class="line">        &quot;Links&quot;: null,</span><br><span class="line">        &quot;Aliases&quot;: null,</span><br><span class="line">        &quot;NetworkID&quot;: &quot;9e017f5d4724039f24acc8aec634c8d2af3a9024f67585fce0a0d2b3cb470059&quot;,</span><br><span class="line">        &quot;EndpointID&quot;: &quot;81b94c1b57de26f9c6690942cd78689041d6c27a564e079d7b1f603ecc104b3b&quot;,</span><br><span class="line">        &quot;Gateway&quot;: &quot;172.17.0.1&quot;,</span><br><span class="line">        &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,</span><br><span class="line">        &quot;IPPrefixLen&quot;: 16,</span><br><span class="line">        &quot;IPv6Gateway&quot;: &quot;&quot;,</span><br><span class="line">        &quot;GlobalIPv6Address&quot;: &quot;&quot;,</span><br><span class="line">        &quot;GlobalIPv6PrefixLen&quot;: 0,</span><br><span class="line">        &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">docker network inspect bridge</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Name&quot;: &quot;bridge&quot;,</span><br><span class="line">        &quot;Id&quot;: &quot;9e017f5d4724039f24acc8aec634c8d2af3a9024f67585fce0a0d2b3cb470059&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2019-06-09T23:20:28.061678042-04:00&quot;,</span><br><span class="line">        &quot;Scope&quot;: &quot;local&quot;,</span><br><span class="line">        &quot;Driver&quot;: &quot;bridge&quot;,</span><br><span class="line">        &quot;EnableIPv6&quot;: false,</span><br><span class="line">        &quot;IPAM&quot;: &#123;</span><br><span class="line">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class="line">            &quot;Options&quot;: null,</span><br><span class="line">            &quot;Config&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Internal&quot;: false,</span><br><span class="line">        &quot;Attachable&quot;: false,</span><br><span class="line">        &quot;Ingress&quot;: false,</span><br><span class="line">        &quot;Containers&quot;: &#123;</span><br><span class="line">            &quot;9582dbec7981085ab1f159edcc4bf35e2ee8d5a03984d214bce32a30eab4921a&quot;: &#123;</span><br><span class="line">                &quot;Name&quot;: &quot;nginx_bridge&quot;,</span><br><span class="line">                &quot;EndpointID&quot;: &quot;81b94c1b57de26f9c6690942cd78689041d6c27a564e079d7b1f603ecc104b3b&quot;,</span><br><span class="line">                &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;,</span><br><span class="line">                &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;,</span><br><span class="line">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Options&quot;: &#123;</span><br><span class="line">            &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;,</span><br><span class="line">            &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;,</span><br><span class="line">            &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,</span><br><span class="line">            &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;,</span><br><span class="line">            &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;,</span><br><span class="line">            &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>网络拓扑介绍完后，接着介绍一下bridge模式下容器是如何通信的。</p>
<p><strong>2.3 bridge模式下容器的通信</strong></p>
<p><strong>在bridge模式下，连在同一网桥上的容器可以相互通信（若出于安全考虑，也可以禁止它们之间通信，方法是在DOCKER_OPTS变量中设置–icc=false，这样只有使用–link才能使两个容器通信）。</strong></p>
<p><strong>Docker可以开启容器间通信（意味着默认配置–icc=true），也就是说，宿主机上的所有容器可以不受任何限制地相互通信，这可能导致拒绝服务攻击。进一步地，Docker可以通过–ip_forward和–iptables两个选项控制容器间、容器和外部世界的通信。</strong></p>
<p><strong>容器也可以与外部通信，我们看一下主机上的Iptable规则，可以看到这么一条</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>这条规则会将源地址为172.17.0.0/16的包（也就是从Docker容器产生的包），并且不是从docker0网卡发出的，进行源地址转换，转换成主机网卡的地址。这么说可能不太好理解，举一个例子说明一下。假设主机有一块网卡为eth0，IP地址为10.10.101.105/24，网关为10.10.101.254。从主机上一个IP为172.17.0.1/16的容器中ping百度（180.76.3.151）。IP包首先从容器发往自己的默认网关docker0，包到达docker0后，也就到达了主机上。然后会查询主机的路由表，发现包应该从主机的eth0发往主机的网关10.10.105.254/24。接着包会转发给eth0，并从eth0发出去（主机的ip_forward转发应该已经打开）。这时候，上面的Iptable规则就会起作用，对包做SNAT转换，将源地址换为eth0的地址。这样，在外界看来，这个包就是从10.10.101.105上发出来的，Docker容器对外是不可见的。</strong></p>
<p><strong>那么，外面的机器是如何访问Docker容器的服务呢？我们首先用下面命令创建一个含有web应用的容器，将容器的80端口映射到主机的80端口。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run --name=nginx_bridge --net=bridge -p 80:80 -d nginx</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>然后查看Iptable规则的变化，发现多了这样一条规则：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-A DOCKER ! -i docker0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 172.17.0.2:80</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>此条规则就是对主机eth0收到的目的端口为80的tcp流量进行DNAT转换，将流量发往172.17.0.2:80，也就是我们上面创建的Docker容器。所以，外界只需访问10.10.101.105:80就可以访问到容器中的服务。</strong></p>
<p><strong>除此之外，我们还可以自定义Docker使用的IP地址、DNS等信息，甚至使用自己定义的网桥，但是其工作方式还是一样的。</strong></p>
<h2 id="三、自定义网络"><a href="#三、自定义网络" class="headerlink" title="三、自定义网络"></a>三、自定义网络</h2><p><strong>建议使用自定义的网桥来控制哪些容器可以相互通信，还可以自动DNS解析容器名称到IP地址。Docker提供了创建这些网络的默认网络驱动程序，你可以创建一个新的Bridge网络，Overlay或Macvlan网络。你还可以创建一个网络插件或远程网络进行完整的自定义和控制。</strong></p>
<p><strong>你可以根据需要创建任意数量的网络，并且可以在任何给定时间将容器连接到这些网络中的零个或多个网络。此外，您可以连接并断开网络中的运行容器，而无需重新启动容器。当容器连接到多个网络时，其外部连接通过第一个非内部网络以词法顺序提供。</strong></p>
<p><strong>接下来介绍Docker的内置网络驱动程序。</strong></p>
<p><strong>3.1 bridge</strong></p>
<p><strong>一个bridge网络是Docker中最常用的网络类型。桥接网络类似于默认bridge网络，但添加一些新功能并删除一些旧的能力。以下示例创建一些桥接网络，并对这些网络上的容器执行一些实验。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker network create --driver bridge new_bridge</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>创建网络后，可以看到新增加了一个网桥（172.18.0.1）。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ifconfig</span><br><span class="line">br-f677ada3003c: flags=4099&amp;lt;UP,BROADCAST,MULTICAST&amp;gt;  mtu 1500</span><br><span class="line">        inet 172.18.0.1  netmask 255.255.0.0  broadcast 0.0.0.0</span><br><span class="line">        ether 02:42:2f:c1:db:5a  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 4001976  bytes 526995216 (502.5 MiB)</span><br><span class="line">        RX errors 0  dropped 35  overruns 0  frame 0</span><br><span class="line">        TX packets 1424063  bytes 186928741 (178.2 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">docker0: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt;  mtu 1500</span><br><span class="line">        inet 172.17.0.1  netmask 255.255.0.0  broadcast 0.0.0.0</span><br><span class="line">        inet6 fe80::42:5fff:fe21:c208  prefixlen 64  scopeid 0x20&amp;lt;link&amp;gt;</span><br><span class="line">        ether 02:42:5f:21:c2:08  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 12  bytes 2132 (2.0 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 24  bytes 2633 (2.5 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>3.2 Macvlan</strong></p>
<p><strong>Macvlan是一个新的尝试，是真正的网络虚拟化技术的转折点。Linux实现非常轻量级，因为与传统的Linux Bridge隔离相比，它们只是简单地与一个Linux以太网接口或子接口相关联，以实现网络之间的分离和与物理网络的连接。</strong></p>
<p><strong>Macvlan提供了许多独特的功能，并有充足的空间进一步创新与各种模式。这些方法的两个高级优点是绕过Linux网桥的正面性能以及移动部件少的简单性。删除传统上驻留在Docker主机NIC和容器接口之间的网桥留下了一个非常简单的设置，包括容器接口，直接连接到Docker主机接口。由于在这些情况下没有端口映射，因此可以轻松访问外部服务。</strong></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>docker简介</title>
    <url>/2021/07/18/docker%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>title: docker简介<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker简介<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. 什么是docker?  Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中,然后发布到任何流行的机器上,也可以实现虚拟化,  容器是完全使用沙箱机制,相互之间不会有任何接口。  <img alt="" src="https://img-blog.csdn.net/20181016204647520?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">1. docker的基本组成<img alt="" height="423" src="https://img-blog.csdnimg.cn/20201215220208243.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="792"> 镜像(Images)：          docker镜像可以理解为一个模板，我们可以来创建容器服务，我们可以通过一个模板创建多个容器。          并且我们的项目服务最终都是运行在容器中的，例如我们springboot项目,mysql,redis等. 容器(Containers)：          <img alt="" src="https://img-blog.csdn.net/20181016230900110?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"> 仓库(Registry)：          <img alt="" src="https://img-blog.csdn.net/20181016231010989?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>git常用的相关操作命令</title>
    <url>/2021/07/18/git%E5%B8%B8%E7%94%A8%E7%9A%84%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>title: git常用的相关操作命令<br>categories:</p>
<ul>
<li>git</li>
</ul>
<p>—title: git常用的相关操作命令<br>categories:</p>
<ul>
<li>git</li>
</ul>
<p>—1.   命令：git rm -r –cached 文件路径 1.    </p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
  </entry>
  <entry>
    <title>hadoop之快照管理,回收站</title>
    <url>/2021/07/18/hadoop%E4%B9%8B%E5%BF%AB%E7%85%A7%E7%AE%A1%E7%90%86,%E5%9B%9E%E6%94%B6%E7%AB%99/</url>
    <content><![CDATA[<p>title: hadoop之快照管理,回收站<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：快照管理</p>
<ol>
<li>简介       快照相当于对目录做一个备份。并不会立即复制所有文件，而是指向同一个文件。当写入发生时，才会产生新文件。1.   基本语法如下      <img alt="" class="has" height="342" src="https://img-blog.csdnimg.cn/2019072521270446.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="527">1.  案例实操     ⑴开启/禁用指定目录的快照功能                <img alt="" class="has" height="147" src="https://img-blog.csdnimg.cn/20190725213117140.png" width="590">     ⑵ 列出当前用户所有可快照目录                <img alt="" class="has" height="95" src="https://img-blog.csdnimg.cn/20190725213247981.png" width="657">         ⑶对指定目录创建快照，将快照放在/user/kgf/input/.snapshot/s20190725-213524.180这个目录下             <img alt="" class="has" height="131" src="https://img-blog.csdnimg.cn/20190725213538808.png" width="563">           注意：生成的是隐藏文件，浏览器上看不到，但是可以直接访问。          <img alt="" class="has" height="229" src="https://img-blog.csdnimg.cn/20190725213907297.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="542">    ⑷重命名快照          <img alt="" class="has" height="141" src="https://img-blog.csdnimg.cn/20190725214235569.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="624">          <img alt="" class="has" height="269" src="https://img-blog.csdnimg.cn/20190725214258523.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="623">      ⑸比较两个快照目录的不同之处           a：创建过快照的目录下的一些文件                 <img alt="" class="has" height="207" src="https://img-blog.csdnimg.cn/20190725215155901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="495">          b：删掉创建过快照的目录下的一些文件，并且新增一些其它文件                <img alt="" class="has" height="213" src="https://img-blog.csdnimg.cn/20190725215403106.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="517">          c：使用命令比较这个目录和之前创建的快照区别               <img alt="" class="has" height="143" src="https://img-blog.csdnimg.cn/20190725215722279.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="525">               就是说快照里面比现在的目录多了一个wait.sh,少了一个README.txt        <h1 id="二：回收站"><a href="#二：回收站" class="headerlink" title="二：回收站"></a>二：回收站</h1></li>
<li>默认回收站，一般公司里，防止误删数据会保存一周时间      <img alt="" class="has" height="144" src="https://img-blog.csdnimg.cn/20190725221204854.png" width="750">1.  启用回收站并且修改访问垃圾回收站用户名称（进入垃圾回收站用户名称，默认是 dr.who）  ⑴进入namenode的/opt/module/hadoop-2.7.2/etc/hadoop目录下在core-site.xml中修改       <img alt="" class="has" height="283" src="https://img-blog.csdnimg.cn/20190725221945370.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="406">    ⑵将修改后的文件分发到集群的各个服务器上          <img alt="" class="has" height="274" src="https://img-blog.csdnimg.cn/20190725222402894.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="409">1.  重新启动集群，并且删除hdfs上一个文件    <img alt="" class="has" height="92" src="https://img-blog.csdnimg.cn/20190725223236997.png" width="823">           可以发现删除的文件进入回收站hdfs://hadoop102:9000/user/kgf/.Trash/Current目录下，一分钟后自动删除    <img alt="" class="has" height="228" src="https://img-blog.csdnimg.cn/20190725223339934.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="651">1. 注意：  <img alt="" class="has" height="104" src="https://img-blog.csdnimg.cn/20190725223844497.png" width="582"></li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>docker镜像原理</title>
    <url>/2021/07/18/docker%E9%95%9C%E5%83%8F%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>title: docker镜像原理<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—title: docker镜像原理<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—1. 镜像是什么? 形象说法：镜像就像千层饼，一层套一层 官方：镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容包括代码、运行时、库、环境变量和配置文件。1. 什么是UnionFS（联合文件系统）         UnionFS(联合文件系统): Union文件系统(UnionFS)是一种分层、轻量级并且高性能的文件系统，它支持<strong>对文件系统的修改作为一次提交来一层层的叠加</strong>，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。Union文件系统是Docker镜像的基础。镜像可以通过分层来进行继承, 基于基础镜像(没有父镜像)， 可以制作各种具体的应用镜像。 特性: 一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录        我们在下载某个镜像的时候，可能会看到下载了一层一层的多个镜像。    <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200820173232156.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwODM3MzEw,size_16,color_FFFFFF,t_70#pic_center">1. docker镜像加载原理 1)docker镜像实际上是由一层层的文件系统组成，这种层级文件系统就是联合文件系统。 2)bootfs（boot file system,用于系统引导的文件系统）主要包含BootLoader和kernel，BootLoader主要负责引导加载kernel，Linux刚启动时会加载bootfs文件系统来引导内核的加载，     Docker镜像的最底层就是bootfs。这一层与我们典 型的unix系统是一样的，包含boot引导器和内核，当boot加载完成后整个内核就在内存中了，此时内存的使用权已经由bootfs转交给内核，     此时系统会卸载bootfs。 3)rootfs（root file system,根文件系统）在bootfs之上，包含的就是典型的unix系统的/dev、 /proc、 /etc等标准目录和文件和一些命令，rootfs就是不同unix系统的发行版，比如Ubuntu、centos等。 4)我们平时安装的虚拟机centos镜像好几个G，Docker安装的才200多m，因为对于一个精简的OS，rootfs可以很小，只需包含最基本的命令，工具和程序库就行了，因为底层直接使用宿主机的内核，    自己只需提供rootfs（相当于操作内核的客户端）就可以，由此可见不同发行版的bootfs基本是一致的，roorfs有差别，因此不同的发行版可以公有bootfs。<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200820180619143.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwODM3MzEw,size_16,color_FFFFFF,t_70#pic_center"> 第一个图仅仅是bootfs+rootfs，然后如果要制作一个emacs环境的镜像，就在这个基础上新加一层emacs镜像，如图二。如果要在添加一个Apache环境，那就再图二基础上加一个apache镜像。如图三。图中的每一层镜像都能进行复用。 比如：上面的redis镜像。使用docker inspect redis镜像的ID 命令查看镜像的元信息，找到layer信息。<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200820174106623.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwODM3MzEw,size_16,color_FFFFFF,t_70#pic_center"> 由上图可以看到下载的redis镜像是由6个镜像一层层组成的。<img alt="在这里插入图片描述" height="444" src="https://img-blog.csdnimg.cn/20200820174621185.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwODM3MzEw,size_16,color_FFFFFF,t_70#pic_center" width="462"> 这些镜像都是一个个独立可复用的镜像，如果下载其他镜像是，某一层镜像是已经存在本地的了，就不用在下载，直接复用该镜像，节省空间。比如上面下载redis镜像时，提示某个镜像已经存在。<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200820174801540.png#pic_center"> 注意： Docker镜像都是只读的，用镜像创建容器启动时，实际上是在原本的镜像上新建了一层可写层到原本镜像的顶部，这一层我们叫作容器层，容器层之下的叫作镜像层。<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200820181518835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwODM3MzEw,size_16,color_FFFFFF,t_70#pic_center"> 如上图，使用Tomcat镜像创建容器后，会在Tomcat镜像的基础上新建一个可写层，容器的写入是在可写层进行记录，然后使用commit命令把该容器创建一个新的镜像，实际上新的镜像是tomcat镜像+可写层镜像，以tomcat镜像为基础。通过下面介绍使用容器构建镜像，可以更好地理解。1. 分层理解<img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20200813125712686.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FscGhy,size_16,color_FFFFFF,t_70#pic_center"></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>hadoop入门之概述</title>
    <url>/2021/07/18/hadoop%E5%85%A5%E9%97%A8%E4%B9%8B%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p>title: hadoop入门之概述<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：什么是Hadoop?</p>
<ol>
<li>Hadoop 是一个由 Apache 基金会所开发的分布式系统基础架构1. 主要解决，海量数据的存储和海量数据的分析计算问题。1. 广义上来说，HADOOP 通常是指一个更广泛的概念——HADOOP 生态圈         1. Hadoop 三大发行版本: Apache、Cloudera、Hortonworks。  a:Apache 版本最原始（最基础）的版本，对于入门学习最好。  b:Cloudera 在大型互联网企业中用的较多  c:Hortonworks 文档较好。<h1 id="二：Hadoop-的优势"><a href="#二：Hadoop-的优势" class="headerlink" title="二：Hadoop 的优势"></a>二：Hadoop 的优势</h1></li>
<li>高可靠性      因为 Hadoop 假设计算元素和存储会出现故障，因为它维护多个工作数据副本，在出现故障时可以对失败的节点重新分布处理1. 高扩展性      在集群间分配任务数据，可方便的扩展数以千计的节点1.  高效性       在 MapReduce 的思想下，Hadoop 是并行工作的，以加快任务处理速度1.  高容错性       自动保存多份副本数据，并且能够自动将失败的任务重新分配    <h1 id="三：Hadoop-组成"><a href="#三：Hadoop-组成" class="headerlink" title="三：Hadoop  组成"></a>三：Hadoop  组成</h1></li>
<li> Hadoop HDFS      一个高可靠、高吞吐量的分布式文件系统。1. Hadoop MapReduce      一个分布式的离线并行计算框架1. Hadoop YARN     作业调度与集群资源管理的框架。1. Hadoop Common     支持其他模块的工具模块（Configuration、RPC、序列化机制、日志 操作）。     <h1 id="四：HDFS-架构-概述"><a href="#四：HDFS-架构-概述" class="headerlink" title="四：HDFS  架构 概述"></a>四：HDFS  架构 概述</h1></li>
<li>NameNode（nn）     存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。1. DataNode(dn)     在本地文件系统存储文件块数据，以及块数据的校验和。1. Secondary NameNode(2nn)      用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照     <h1 id="五：YARN-Yet-Another-Resource-Negotiator-架构"><a href="#五：YARN-Yet-Another-Resource-Negotiator-架构" class="headerlink" title="五：YARN(Yet Another Resource Negotiator)  架构"></a>五：YARN(Yet Another Resource Negotiator)  架构</h1></li>
<li>ResourceManager(rm)      处理客户端请求、启动/监控 ApplicationMaster、监控 NodeManager、资源分配与调度1. NodeManager(nm)      单个节点上的资源管理、处理来自 ResourceManager 的命令、处理来自 ApplicationMaster 的命令。 它会定时地向RM汇报本节点上的资源使用情况和各个Container的运行状态；同时会接收并处理来自AM 的Container 启动/停止等请求。1. ApplicationMaster      数据切分、为应用程序申请资源，并分配给内部任务、任务监控与容错。 用户提交的应用程序均包含一个AM，负责应用的监控，跟踪应用执行状态，重启失败任务等。ApplicationMaster 是应用框架，它负责向ResourceManager协调资源，并且与NodeManager协同工作完成Task的执行和监控。1. Container      对任务运行环境的抽象，封装了 CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息 。 Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当AM向RM 申请资源时，RM为AM返回的资源便是用Container 表示的。 YARN会为每个任务分配一个Container且该任务只能 使用该Container中描述的资源。1. 简介（detail）     YARN（Yet Another Resource Negotiator）是一个<strong>通用</strong>的资源管理平台，可为各类计算框架提供资源的管理和调度。 其核心出发点是为了分离资源管理与作业调度/监控，实现分离的做法是拥有一个全局的资源管理器。以及每个应用程序 对应一个的应用管理器（ApplicationMaster，AM）。1. 架构如下：     <img alt="" class="has" height="408" src="https://img-blog.csdnimg.cn/20190630220652270.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="642">   </li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>hashCode的作用</title>
    <url>/2021/07/18/hashCode%E7%9A%84%E4%BD%9C%E7%94%A8/</url>
    <content><![CDATA[<p>title: hashCode的作用<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—<strong>1、hashCoed 的特性：</strong></p>
<p>（1）HashCode的存在主要是用于查找的快捷性，如Hashtable，HashMap等，HashCode经常用于确定对象的存储地址；</p>
<p>（2）如果两个对象相同， equals方法一定返回true，并且这两个对象的HashCode一定相同；</p>
<p>（3）两个对象的HashCode相同，并不一定表示两个对象就相同，即equals()不一定为true，只能够说明这两个对象在一个散列存储结构中。</p>
<p>（4）如果对象的equals方法被重写，那么对象的HashCode也尽量重写。</p>
<p>有关equals 与hashCode 方法可以参考这篇文章：</p>
<p> </p>
<p><strong>2、hashCode 的作用：</strong></p>
<p>Java中的集合有两类，一类是List，再有一类是Set。前者集合内的元素是有序的，元素可以重复；后者元素无序，但元素不可重复。 equals方法可用于保证元素不重复，但如果每增加一个元素就检查一次，若集合中现在已经有1000个元素，那么第1001个元素加入集合时，就要调用1000次equals方法。这显然会大大降低效率。 于是，Java采用了哈希表的原理。</p>
<p>哈希算法也称为散列算法，是将数据依特定算法直接指定到一个地址上。这样一来，当集合要添加新的元素时，先调用这个元素的HashCode方法，就一下子能定位到它应该放置的物理位置上。</p>
<p>（1）如果这个位置上没有元素，它就可以直接存储在这个位置上，不用再进行任何比较了；</p>
<p>（2）如果这个位置上已经有元素了，就调用它的equals方法与新元素进行比较，相同的话就不存了；</p>
<p>（3）不相同的话，也就是发生了Hash key相同导致冲突的情况，那么就在这个Hash key的地方产生一个链表，将所有产生相同HashCode的对象放到这个单链表上去，串在一起。这样一来实际调用equals方法的次数就大大降低了。 </p>
<p> 所以hashCode在上面扮演的角色为寻域（寻找某个对象在集合中区域位置）。hashCode可以将集合分成若干个区域，每个对象都可以计算出他们的hash码，可以将hash码分组，每个分组对应着某个存储区域，根据一个对象的hash码就可以确定该对象所存储区域，这样就大大减少查询匹配元素的数量，提高了查询效率。  </p>
<p><strong>3、hashCode实践：</strong></p>
<p>hashCode是用于查找使用的，而equals是用于比较两个对象是否相等的。</p>
<p>（1）例如内存中有这样的位置 ：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0  1  2  3  4  5  6  7    </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>而我有个类，这个类有个字段叫ID，我要把这个类存放在以上8个位置之一，如果不用HashCode而任意存放，那么当查找时就需要到这八个位置里挨个去找，或者用二分法一类的算法。   但以上问题如果用HashCode就会使效率提高很多。  定义我们的HashCode为ID％8，比如我们的ID为9，9除8的余数为1，那么我们就把该类存在1这个位置，如果ID是13，求得的余数是5，那么我们就把该类放在5这个位置。依此类推。  </p>
<p>（2）但是如果两个类有相同的HashCode，例如9除以8和17除以8的余数都是1，也就是说，我们先通过 HashCode来判断两个类是否存放某个桶里，但这个桶里可能有很多类，那么我们就需要再通过equals在这个桶里找到我们要的类。    </p>
<p>请看下面这个例子 ：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public class HashTest &#123;  </span><br><span class="line">    private int i;  </span><br><span class="line">  </span><br><span class="line">    public int getI() &#123;  </span><br><span class="line">        return i;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    public void setI(int i) &#123;  </span><br><span class="line">        this.i = i;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    public int hashCode() &#123;  </span><br><span class="line">        return i % 10;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    public final static void main(String[] args) &#123;  </span><br><span class="line">        HashTest a = new HashTest();  </span><br><span class="line">        HashTest b = new HashTest();  </span><br><span class="line">        a.setI(1);  </span><br><span class="line">        b.setI(1);  </span><br><span class="line">        Set&amp;lt;HashTest&amp;gt; set = new HashSet&amp;lt;HashTest&amp;gt;();  </span><br><span class="line">        set.add(a);  </span><br><span class="line">        set.add(b);  </span><br><span class="line">        System.out.println(a.hashCode() == b.hashCode());  </span><br><span class="line">        System.out.println(a.equals(b));  </span><br><span class="line">        System.out.println(set);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>输出结果为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">true</span><br><span class="line">false</span><br><span class="line">[HashTest@1, HashTest@1]</span><br></pre></td></tr></table></figure>

<p>以上这个示例，我们只是重写了HashCode方法，从上面的结果可以看出，虽然两个对象的HashCode相等，但是实际上两个对象并不是相等，因为我们没有重写equals方法，那么就会调用Object默认的equals方法，Object的equals方法调用的是 == 进行比较两个对象，显示这是两个不同的对象。</p>
<p>这里我们将生成的对象放到了HashSet中，而HashSet中只能够存放唯一的对象，也就是相同的（适用于equals方法）的对象只会存放一个，但是这里实际上是两个对象ab都被放到了HashSet中，这样HashSet就失去了他本身的意义了。</p>
<p>下面我们继续重写equals方法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public class HashTest &#123;  </span><br><span class="line">    private int i;  </span><br><span class="line">  </span><br><span class="line">    public int getI() &#123;  </span><br><span class="line">        return i;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    public void setI(int i) &#123;  </span><br><span class="line">        this.i = i;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    public boolean equals(Object object) &#123;  </span><br><span class="line">        if (object == null) &#123;  </span><br><span class="line">            return false;  </span><br><span class="line">        &#125;  </span><br><span class="line">        if (object == this) &#123;  </span><br><span class="line">            return true;  </span><br><span class="line">        &#125;  </span><br><span class="line">        if (!(object instanceof HashTest)) &#123;  </span><br><span class="line">            return false;  </span><br><span class="line">        &#125;  </span><br><span class="line">        HashTest other = (HashTest) object;  </span><br><span class="line">        if (other.getI() == this.getI()) &#123;  </span><br><span class="line">            return true;  </span><br><span class="line">        &#125;  </span><br><span class="line">        return false;  </span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    public int hashCode() &#123;  </span><br><span class="line">        return i % 10;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    public final static void main(String[] args) &#123;  </span><br><span class="line">        HashTest a = new HashTest();  </span><br><span class="line">        HashTest b = new HashTest();  </span><br><span class="line">        a.setI(1);  </span><br><span class="line">        b.setI(1);  </span><br><span class="line">        Set&amp;lt;HashTest&amp;gt; set = new HashSet&amp;lt;HashTest&amp;gt;();  </span><br><span class="line">        set.add(a);  </span><br><span class="line">        set.add(b);  </span><br><span class="line">        System.out.println(a.hashCode() == b.hashCode());  </span><br><span class="line">        System.out.println(a.equals(b));  </span><br><span class="line">        System.out.println(set);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>输出结果如下所示:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">true</span><br><span class="line">true</span><br><span class="line">[HashTest@1]</span><br></pre></td></tr></table></figure>

<p>从结果我们可以看出，现在两个对象就完全相等了，HashSet中也只存放了一份对象。</p>
<p>原文地址：</p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>ClickHouse数据查询</title>
    <url>/2021/07/18/ClickHouse%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2/</url>
    <content><![CDATA[<p>title: ClickHouse数据查询<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—### 1.查询语法</p>
<blockquote>
 <pre><code class="language-sql">[WITH expr_list|(subquery)]
SELECT [DISTINCT] expr_list
[FROM [db.]table | (subquery) | table_function] [FINAL]
[SAMPLE sample_coeff]
[ARRAY JOIN ...]
[GLOBAL] [ANY|ALL|ASOF] [INNER|LEFT|RIGHT|FULL|CROSS] [OUTER|SEMI|ANTI] JOIN (subquery)|table (ON &lt;expr_list&gt;)|(USING &lt;column_list&gt;)
[PREWHERE expr]
[WHERE expr]
[GROUP BY expr_list] [WITH TOTALS]
[HAVING expr]
[ORDER BY expr_list] [WITH FILL] [FROM expr] [TO expr] [STEP expr]
[LIMIT [offset_value, ]n BY columns]
[LIMIT [n, ]m] [WITH TIES]
[UNION ALL ...]
[INTO OUTFILE filename]
[FORMAT format]
</blockquote>
<p></code></pre><br> 可以看到ClickHouse的SELECT语句的语法和通用的SQL的SELECT语句非常类似，包括： </p>
<ul>
<li>SELECT: 指定返回结果字段- DISTINCT：去重- FROM: 指定要查询的表或子查询- JOIN：表连接，支持内连接和外连接、左连接和右连接- WHERE：筛选条件- GROUP BY：分组，和聚合函数一起使用- HAVING：分组后筛选- ORDER BY：排序- LIMIT：限制返回记录数- UNION ALL：并集；ClickHouse目前只支持UNION ALL，还不支持UNION<br>ClickHouse的SELECT语句中也有一些特殊的用法： </li>
<li>WITH: 设置查询中要用到的变量- SAMPLE: 数据取样，类似Pandas库的sample()函数- PREWHERE: 预筛选，起到提升性能作用- ARRAY JOIN：数组连接，用来展开数组或嵌套字段，一行变多行- LIMIT BY: 分组，再从每组中取前n条记录- INTO OUTFILE: 导出表数据到文件，再用FORMAT指定文件格式</li>
</ul>
<h3 id="2-WITH子句"><a href="#2-WITH子句" class="headerlink" title="2.WITH子句"></a>2.WITH子句</h3><blockquote>
 <pre><code class="language-sql">-- 在WITH子句中定义一个变量并赋值，然后在SELECT子句中通过别名使用该变量
with '2014-03-17' as dt \
select count(1) from hits_v1 where EventDate = dt;
</blockquote>
<p>– 在WITH子句中定义一个函数，然后在SELECT子句中通过别名使用该函数<br>with round(Duration / 60)as duration_minutes <br>select StartDate, max(duration_minutes) as max_duration_minutes from visits_v1 <br>group by StartDate, Duration <br>order by max_duration_minutes desc <br>limit 10;</p>
<p>– 在WITH子句中定义一个子查询，然后在SELECT子句中通过别名使用该子查询<br>– 该子查询只能返回一行数据<br>with ( <br>  select sum(Duration) from visits_v1 <br>) as total_duration <br>select StartDate, sum(Duration) / total_duration as duration_percentage from visits_v1 <br>group by StartDate, Duration <br>limit 10;</p>
<p></code></pre><br> <h3> </h3> </p>
<h3 id="3-SAMPLE子句"><a href="#3-SAMPLE子句" class="headerlink" title="3.SAMPLE子句"></a>3.SAMPLE子句</h3><blockquote>
<p> 对使用了MergeTree表引擎的表，并且设置了SAMPLE BY的表，可以使用SAMPLE子句来对数据进行抽样。<br> 表例子：<br> <pre><code class="language-sql">CREATE TABLE tutorial.hits_v1 \<br>(<br>  ...<br>)<br>ENGINE = MergeTree() \<br>PARTITION BY toYYYYMM(EventDate) \<br>ORDER BY (CounterID, EventDate, intHash32(UserID)) \<br>SAMPLE BY intHash32(UserID) \<br>SETTINGS index_granularity = 8192;</p>
</blockquote>
<p></code></pre><br> hits_v1表使用MergeTree表引擎，并且SAMPLE BY为将UserID转换成32位的Hash值。<br> <img alt="" height="276" src="https://img-blog.csdnimg.cn/20210428212535801.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"><br> SAMPLE子句示例：<br> <pre><code class="language-sql">-- 按比例采样<br>-- 采样结果记录数<br>select count(1) from hits_v1 sample 0.1<br>-- 采样数据，默认限制返回10000条<br>select CounterID, UserID, EventDate, EventTime  from hits_v1 sample 0.1<br>-- 采样数据，限制返回10条<br>select CounterID, UserID, EventDate, EventTime  from hits_v1 sample 0.1 limit 10</p>
<p>– 按记录数采样<br>– 采样记录数较小时，采样结果数据为0条<br>select count(1) from hits_v1 sample 100<br>– 采样记录数大过索引粒度时，采样结果数据记录数接近采样记录数<br>elect count(1) from hits_v1 sample 10000<br>– 采样数据，默认限制返回10000条<br>select CounterID, UserID, EventDate, EventTime  from hits_v1 sample 20000<br>– 采样数据，限制返回10条<br>select CounterID, UserID, EventDate, EventTime  from hits_v1 sample 20000 limit 10</p>
<p>– 按比例和偏移量采样，类似于按比例采样<br>select CounterID, UserID, EventDate, EventTime  from hits_v1 sample 0.1 offset 0.3 limit 10<br></code></pre><br> SAMPLE子句数据采样具有幂等性和近似性的特点： </p>
<ul>
<li>幂等性：采样条件不变时，两次采样的结果<strong>可能</strong>一样- 近似性：采样范围和采样结果不保证精确</li>
</ul>
<h3 id="4-PREWHERE子句"><a href="#4-PREWHERE子句" class="headerlink" title="4.PREWHERE子句"></a>4.PREWHERE子句</h3><blockquote>
<p> 只有MergeTree表引擎的表才能使用PREWHERE子句，可以将PREWHERE看作是ClickHouse对WHERE子句的优化。<br> ClickHouse默认将WHERE自动优化为PREWHERE:<br> <pre><code class="language-sql">-- optimize_move_to_prewhere为1时，表示开始PREWHERE自动优化<br>select name, value from system.settings where name like '%prewhere%'<br></code></pre> 
   </p>
</blockquote>
<h3 id="5-ARRAY-JOIN子句"><a href="#5-ARRAY-JOIN子句" class="headerlink" title="5.ARRAY JOIN子句"></a>5.ARRAY JOIN子句</h3><blockquote>
<p> 可以用ARRAY JOIN子句来对数组（Array）或嵌套（Nested）类型做链接查询，可以将一行数组展成多行。<br> ARRAY JOIN数组示例：<br> <pre><code class="language-sql">-- 不使用ARRAY JOIN<br>select WatchID, RefererCategories from hits_v1 where WatchID = 4944118417295196513</p>
</blockquote>
<p>– 结果：<br>┌─────────────WatchID─┬─RefererCategories─┐<br>│ 4944118417295196513 │ [6,98,456,8586]   │<br>└─────────────────────┴───────────────────┘</p>
<p>– 使用ARRAY JOIN<br>select WatchID, RefererCategories <br>from hits_v1 <br>array join RefererCategories <br>where WatchID = 4944118417295196513;</p>
<p>– 结果：<br>─────────────WatchID─┬─RefererCategories─┐<br>│ 4944118417295196513 │                 6 │<br>│ 4944118417295196513 │                98 │<br>│ 4944118417295196513 │               456 │<br>│ 4944118417295196513 │              8586 │<br>└─────────────────────┴───────────────────┘</p>
<p></code></pre><br> ARRAY JOIN嵌套类型示例：<br> <pre><code class="language-sql">-- 不使用ARRAY JOIN<br>select WatchID, ParsedParams.Key1, ParsedParams.Key2 from hits_v1 where WatchID = 5024825574842900819</p>
<p>– 结果：<br>┌─────────────WatchID─┬─ParsedParams.Key1───────────┬─ParsedParams.Key2───┐<br>│ 5024825574842900819 │ [‘gen_timestamp’,’Toolbar’] │ [‘group’,’true” /‘] │<br>└─────────────────────┴─────────────────────────────┴─────────────────────┘</p>
<p>– 使用ARRAY JOIN<br>select WatchID, ParsedParams.Key1, ParsedParams.Key2 <br>from hits_v1 <br>array join ParsedParams <br>where WatchID = 5024825574842900819;</p>
<p>– 结果：<br>┌─────────────WatchID─┬─ParsedParams.Key1─┬─ParsedParams.Key2─┐<br>│ 5024825574842900819 │ gen_timestamp     │ group             │<br>│ 5024825574842900819 │ Toolbar           │ true” /           │<br>└─────────────────────┴───────────────────┴───────────────────┘</p>
<p></code></pre><br> ARRAY JOIN也支持左连接接<code>LEFT ARRAY JOIN</code>。 </p>
<h3 id="6-LIMIT-BY子句"><a href="#6-LIMIT-BY子句" class="headerlink" title="6.LIMIT BY子句"></a>6.LIMIT BY子句</h3><blockquote>
<p> LIMIT BY子句不同于通用SQL的LIMIT子句。<br> <code>LIMIT n BY expression</code> 对SELECT结果先按expression分组，再在每组里选出前n个，类似分类排行榜的概念。<br> 示例：<br> <pre><code class="language-sql">CREATE TABLE limit_by(id Int, val Int) ENGINE = Memory;<br>INSERT INTO limit_by VALUES (1, 10), (1, 11), (1, 12), (2, 20), (2, 21), (2, 22), (3, 31);<br></code></pre><br> <pre><code class="language-sql">-- 排序<br>SELECT * FROM limit_by ORDER BY id, val</p>
</blockquote>
<p>┌─id─┬─val─┐<br>│  1 │  10 │<br>│  1 │  11 │<br>│  1 │  12 │<br>│  2 │  20 │<br>│  2 │  21 │<br>│  2 │  22 │<br>│  3 │  31 │<br>└────┴─────┘</p>
<p>– 分类排序，再在每个分组内取前2条记录<br>SELECT * FROM limit_by ORDER BY id, val LIMIT 2 BY id</p>
<p>┌─id─┬─val─┐<br>│  1 │  10 │<br>│  1 │  11 │<br>│  2 │  20 │<br>│  2 │  21 │<br>│  3 │  31 │<br>└────┴─────┘</p>
<p>– 注意，与LIMIT 2的不同<br>SELECT * FROM limit_by ORDER BY id, val LIMIT 2</p>
<p>┌─id─┬─val─┐<br>│  1 │  10 │<br>│  1 │  11 │<br>└────┴─────┘</p>
<p></code></pre><br> LIMIT BY子句也支持偏移量：<code>LIMIT n OFFSET m BY exression</code> </p>
<h3 id="7-INTO-OUTFILE子句"><a href="#7-INTO-OUTFILE子句" class="headerlink" title="7.INTO OUTFILE子句"></a>7.INTO OUTFILE子句</h3><blockquote>
<p> ClickHouse的INTO OUTFILE子句与MySQL的INTO OUTFILE子句类似。<br> <pre><code class="language-sql">-- 输出到当前目录<br>-- 默认格式为TSV<br>-- 注意文件名必须用单引号来括起来，且不能用双引号括起来，否则会报错：Expected string literal<br>-- 目录下不能存在同名文件，否则会报错<br>select WatchID, JavaEnable, EventDate  from hits_v1 limit 10 into outfile 'test.tsv'</p>
</blockquote>
<p>– 设置格式为CSV，CSV需要为全大小<br>select WatchID, JavaEnable, EventDate  from hits_v1 limit 10 into outfile ‘out.csv’ format CSV<br></code></pre> 
   </p>
<h3 id="8-执行计划"><a href="#8-执行计划" class="headerlink" title="8.执行计划"></a>8.执行计划</h3><blockquote>
 <h3>查看执行计划</h3> 
 可以通过以下方式查看执行计划： 
 <ol>- 直接查看执行计划： ch --send_logs_level=trace &lt;&lt;&lt; 'select * from tutorial.hits_v1' &gt; /dev/null <li>可以将以下内容保持到一个脚本文件，比如`chx.sh`中： <pre><code class="language-bash">#!/bin/bash
</blockquote>
<p>clickhouse-client –send_logs_level=trace &lt;&lt;&lt; “$1” &gt; /dev/null<br></code></pre> 再通过<code>bash chi.sh &quot;select * from tutorial.hits_v1&quot;</code> 来查看执行计划。 </li>- 也可以在clickhouse-client执行sql同时，用<code>tail -f clickhouse-server.log</code> 查看clickhouse-server的日志。</ol><br> <h3>执行计划示例</h3><br> <code>select * from tutorial.hits_v1</code>的执行计划日志示例：<br> <pre><code class="language-bash">&lt;Debug&gt; tutorial.hits_v1 (SelectExecutor): Key condition: unknown<br>&lt;Debug&gt; tutorial.hits_v1 (SelectExecutor): MinMax index condition: unknown<br>&lt;Debug&gt; tutorial.hits_v1 (SelectExecutor): Selected 9 parts by date, 9 parts by key, 1094 marks to read from 9 ranges<br>&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_1_6_1, approx. 1900000 rows starting from 0<br>&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_7_12_1, approx. 1900000 rows starting from 0<br>&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_13_18_1, approx. 1800000 rows starting from 0<br>&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_19_24_1, approx. 1800000 rows starting from 0<br>&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_25_25_0, approx. 303104 rows starting from 0<br>&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_26_26_0, approx. 303104 rows starting from 0<br>&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_27_27_0, approx. 303104 rows starting from 0<br>&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_28_28_0, approx. 303104 rows starting from 0<br>&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_29_29_0, approx. 278528 rows starting from 0<br>&lt;Trace&gt; InterpreterSelectQuery: FetchColumns -&gt; Complete<br>&lt;Information&gt; executeQuery: Read 8873898 rows, 7.88 GiB in 47.964 sec., 185011 rows/sec., 168.22 MiB/sec.<br>&lt;Debug&gt; MemoryTracker: Peak memory usage (for query): 204.54 MiB.<br></code></pre><br> <strong>说明：</strong> </p>
<ul>
<li><strong>Key condition: unknown：没有使用主键索引。</strong>- <strong>MinMax index condition: unknown： 没有使用分区索引。</strong>- <strong>Selected 9 parts by date, 9 parts by key, 1094 marks to read from 9 ranges： 共扫描了9个分区，共1094个mark。</strong>- <strong>Read 8873898 rows, 7.88 GiB in 47.964 sec., 185011 rows/sec., 168.22 MiB/sec.: 读取了8873898行数据，数据大小为7.88GB，用时47.964秒。</strong>- <strong>Peak memory usage (for query): 204.54 MiB.: 内存峰值（最大内存使用量）为204.54MB。</strong><br>将SQL改为只返回一个字段<code>select WatchID from tutorial.hits_v1</code>，再来看执行计划： <pre><code class="language-sql">&lt;Debug&gt; tutorial.hits_v1 (SelectExecutor): Key condition: unknown
&lt;Debug&gt; tutorial.hits_v1 (SelectExecutor): MinMax index condition: unknown
&lt;Debug&gt; tutorial.hits_v1 (SelectExecutor): Selected 9 parts by date, 9 parts by key, 1094 marks to read from 9 ranges
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_1_6_1, approx. 1900000 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_7_12_1, approx. 1900000 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_13_18_1, approx. 1800000 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_19_24_1, approx. 1800000 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_25_25_0, approx. 303104 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_26_26_0, approx. 303104 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_27_27_0, approx. 303104 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_28_28_0, approx. 303104 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 1 ranges from part 201403_29_29_0, approx. 278528 rows starting from 0
&lt;Trace&gt; InterpreterSelectQuery: FetchColumns -&gt; Complete
&lt;Information&gt; executeQuery: Read 8873898 rows, 67.70 MiB in 0.318 sec., 27892532 rows/sec., 212.80 MiB/sec.
&lt;Debug&gt; MemoryTracker: Peak memory usage (for query): 12.32 MiB.
</code></pre> 
几个变化： </li>
<li>Read 8873898 rows, 67.70 MiB in 0.318 sec., 27892532 rows/sec., 212.80 MiB/sec.: 数据大小从7.88GB减小到67.70MB，用时从47.964秒减小到0.318秒。- Peak memory usage (for query): 12.32 MiB.: 内存峰值从204.54MB减小到12.32MB。<br>再将SQL改为指定分区查询： <pre><code class="language-sql">select WatchID from tutorial.hits_v1 where EventDate = '2014-03-17'
</code></pre> 
执行计划日志：  <pre><code class="language-bash">&lt;Debug&gt; executeQuery: (from 127.0.0.1:48102) SELECT WatchID FROM tutorial.hits_v1 WHERE EventDate = '2014-03-17'
&lt;Debug&gt; InterpreterSelectQuery: MergeTreeWhereOptimizer: condition "EventDate = '2014-03-17'" moved to PREWHERE
&lt;Trace&gt; ContextAccess (default): Access granted: SELECT(WatchID, EventDate) ON tutorial.hits_v1
&lt;Debug&gt; tutorial.hits_v1 (SelectExecutor): Key condition: (column 1 in [16146, 16146])
&lt;Debug&gt; tutorial.hits_v1 (SelectExecutor): MinMax index condition: (column 0 in [16146, 16146])
&lt;Debug&gt; tutorial.hits_v1 (SelectExecutor): Selected 9 parts by date, 9 parts by key, 833 marks to read from 72 ranges
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 14 ranges from part 201403_1_6_1, approx. 818656, up to 818656 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 14 ranges from part 201403_7_12_1, approx. 1621472, up to 1621472 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 15 ranges from part 201403_13_18_1, approx. 1349440, up to 1349440 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 14 ranges from part 201403_19_24_1, approx. 1619776, up to 1619776 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 4 ranges from part 201403_25_25_0, approx. 278528, up to 278528 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 3 ranges from part 201403_26_26_0, approx. 286720, up to 286720 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 2 ranges from part 201403_27_27_0, approx. 294912, up to 294912 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 3 ranges from part 201403_28_28_0, approx. 229376, up to 229376 rows starting from 0
&lt;Trace&gt; MergeTreeSelectProcessor: Reading 3 ranges from part 201403_29_29_0, approx. 253952, up to 253952 rows starting from 0
&lt;Trace&gt; InterpreterSelectQuery: FetchColumns -&gt; Complete
&lt;Information&gt; executeQuery: Read 6735786 rows, 61.49 MiB in 0.097 sec., 69655325 rows/sec., 635.86 MiB/sec.
&lt;Debug&gt; MemoryTracker: Peak memory usage (for query): 16.32 MiB.
</code></pre> </li>
</ul>
<p> <strong>说明：</strong> </p>
<ul>
<li>MergeTreeWhereOptimizer: condition “EventDate = ‘2014-03-17’” moved to PREWHERE： 启动了PREWHERE优化。- Key condition: (column 1 in [16146, 16146])： 用了主键索引。- MinMax index condition: (column 0 in [16146, 16146])： 用了分区索引。- Selected 9 parts by date, 9 parts by key, 833 marks to read from 72 ranges：从1094 marks减少到833 marks。- Read 6735786 rows, 61.49 MiB in 0.097 sec., 69655325 rows/sec., 635.86 MiB/sec.： 数据大小从67.70MB变为61.49MB，用时从0.318秒减少到0.097秒。</li>
</ul>
<h3 id="执行计划示例"><a href="#执行计划示例" class="headerlink" title="执行计划示例"></a>执行计划示例</h3>]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>Docker容器相关知识点总结</title>
    <url>/2021/07/18/Docker%E5%AE%B9%E5%99%A8%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>title: Docker容器相关知识点总结<br>categories:</p>
<ul>
<li>docker</li>
</ul>
<p>—# 一：简介</p>
<p>       1：什么是docker?                <img alt="" class="has" height="362" src="https://img-blog.csdn.net/20181016204647520?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="625">                <img alt="" class="has" height="235" src="https://img-blog.csdn.net/20181016205211455?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="610">        2：docker解决了什么问题？              <strong>Docker解决了运行环境和配置问题，方便发布，也就方便做持续集成</strong>。        </p>
<p>       3：docker的生命周期               Docker的生命周期包含三个部分，镜像，容器，仓库，我们可以把镜像，               容器想像成java的类和对象，即容器是由镜像实例化而来的。也就是说我                们想使用装有相关软件的镜像，首先要把镜像创建成容器。</p>
<p>      4：什么是docker镜像？              <img alt="" class="has" height="295" src="https://img-blog.csdn.net/20181016230820975?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="484"></p>
<p>      5：什么是docker容器？              <img alt="" class="has" height="298" src="https://img-blog.csdn.net/20181016230900110?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="547">        6：什么是docker仓库？             <img alt="" class="has" height="239" src="https://img-blog.csdn.net/20181016231010989?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="545">              <img alt="" class="has" height="195" src="https://img-blog.csdn.net/20181017203507706?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="312"></p>
<h1 id="二：Windows系统上安装Docker"><a href="#二：Windows系统上安装Docker" class="headerlink" title="二：Windows系统上安装Docker"></a>二：Windows系统上安装Docker</h1><p>       1：下载地址                <img alt="" class="has" height="203" src="https://img-blog.csdn.net/20181017203712503?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="595">               我们这里是在国内网站下载的，速度比较快                    Docker Toolbox for Win7下载地址：                                                  <img alt="" class="has" height="347" src="https://img-blog.csdn.net/20181017205207991?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="467">                        <img alt="" class="has" height="108" src="https://img-blog.csdn.net/20181017205256736?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="334">         2：安装                 ⑴下载完成后，双击下载文件                 ⑵ 一路Next，接受所有默认安装 。注意：在安装过程中，会出现几个其他的安装过程，                      如Ocracle Corporation等系列软件，全部选择安装即可。                 ⑶整个安装过程非常简单，安装完成后，可以在桌面得到如下的三个图标：                       <img alt="è¿éåå¾çæè¿°" class="has" src="https://img-blog.csdn.net/20160517175511388">                ⑷点击Docker Quickstart Terminal图标，从而打开一个Docker Toolbox terminal                       <img alt="è¿éåå¾çæè¿°" class="has" height="176" src="https://img-blog.csdn.net/20160517175602919" width="355">                       打开terminal后，terminal会自动进行一些设置，需要点时间，全部完成后，会出现如下的结果                        <img alt="" class="has" height="258" src="https://img-blog.csdn.net/20181017211540464?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="543">                      查看docker的版本信息：docker info                        <img alt="" class="has" height="373" src="https://img-blog.csdn.net/20181017211927234?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="411"></p>
<h1 id="三：Linux上安装Docker"><a href="#三：Linux上安装Docker" class="headerlink" title="三：Linux上安装Docker"></a>三：Linux上安装Docker</h1><p>        <img alt="" class="has" height="214" src="https://img-blog.csdn.net/20181017214429547?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="373">         就是说必须要是64位的，内核版本要大于3.10，还有就是docker本身是在Ubuntu         系统上开发的，所以它对Ubuntu系统的支持是最好的，所以推荐使用Ubuntu系统         进行学习。        1：查看一下系统的内核版本：命令：uname -r   版本为4.15.0              <img alt="" class="has" height="101" src="https://img-blog.csdn.net/20181019230726238?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="339">        2：保证我们的apt-get是最新版本的：命令：apt-get update                 <img alt="" class="has" height="264" src="https://img-blog.csdn.net/20181019231928292?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="476">       3：安装Docker,最新版本的 Docker 安装包命令：curl -s <a href="https://get.docker.com|sh/">https://get.docker.com|sh</a>               问题：curl command not found                   <img alt="" class="has" height="139" src="https://img-blog.csdn.net/20181019232709244?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="512">                解决：                   <img alt="" class="has" height="173" src="https://img-blog.csdn.net/20181019232854291?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="404">                再次执行安装Docker命令：                    <img alt="" class="has" height="260" src="https://img-blog.csdn.net/20181019233732246?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="488">                安装完成后有个提示：                    <img alt="" class="has" height="77" src="https://img-blog.csdn.net/20181019233931211?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="610">                 当要以非root用户可以直接运行docker时，需要执行 **sudo usermod -aG docker +用户 **命令，                 然后重新登陆，否则会有如下报错：                    <img alt="" class="has" src="http://www.runoob.com/wp-content/uploads/2016/05/docker06.png">           4：使用docker version命令查看是否安装成功                  <img alt="" class="has" height="333" src="https://img-blog.csdn.net/20181019234358577?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="432">           5：启动docker后台服务命令：sudo service docker start，                下面存在Server就说明Docker服务端已经启动                  <img alt="" class="has" height="333" src="https://img-blog.csdn.net/20181019234358577?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="432">                   </p>
<h1 id="四：Docker镜像"><a href="#四：Docker镜像" class="headerlink" title="四：Docker镜像"></a>四：Docker镜像</h1><p>        1：相关命令               ⑴docker pull [OPTIONS] NAME[:TAG]：                       这条命令是用来拉取镜像的，它会从docker远程仓库拉取一个镜像到我们本地。               ⑵docker images [OPTIONS] [REPOSITORY[:TAG]]                       这条命令是用来查看我们本机都存在哪些镜像，也可以用来验证我们pull镜像是否成功了。         2：操作我们上面安装好的docker               ⑴查看一下我们本地镜像                     <img alt="" class="has" height="153" src="https://img-blog.csdn.net/20181020114442883?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="609">        3：我们使用命令去docker的一个公共img仓库拉取hello world镜像，在官网上可以查到docker有哪些镜像                <img alt="" class="has" height="125" src="https://img-blog.csdn.net/2018102011571711?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="591">                <img alt="" class="has" height="138" src="https://img-blog.csdn.net/20181020115941529?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="640"></p>
<h1 id="五：Docker容器"><a href="#五：Docker容器" class="headerlink" title="五：Docker容器"></a>五：Docker容器</h1><p>      1：运行镜像               docker run [OPTIONS] IMAGE[:TAG][COMMAND][ARG..]               <img alt="" class="has" height="303" src="https://img-blog.csdn.net/20181020142521906?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="497">               出现上面的效果说明hello-world镜像运行结束。</p>
<h1 id="六：Docker运行Nginx"><a href="#六：Docker运行Nginx" class="headerlink" title="六：Docker运行Nginx"></a>六：Docker运行Nginx</h1><p>        1：前往网易云蜂巢镜像中心：                 <img alt="" class="has" height="256" src="https://img-blog.csdn.net/2018102014523129?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="530">         2:查找到nginx镜像 ，这里使用docker同步的nginx镜像               <img alt="" class="has" height="135" src="https://img-blog.csdn.net/2018102014531188?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="462">        3：进入复制下载地址               <img alt="" class="has" height="78" src="https://img-blog.csdn.net/20181020145358328?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="605">       4： 在服务器中粘贴执行该下载镜像               <img alt="" class="has" height="148" src="https://img-blog.csdn.net/20181020145725314?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="582">              <img alt="" class="has" height="155" src="https://img-blog.csdn.net/20181020145917718?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="567">       5：后台启动nginx服务,命令是docker run -d +服务名称              <img alt="" class="has" height="176" src="https://img-blog.csdn.net/20181020150337334?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="560">               <img alt="" class="has" height="116" src="https://img-blog.csdn.net/20181020150510133?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="557">        6：进入到容器内部，命令：docker exec -it +容器名称 +bash               <img alt="" class="has" height="120" src="https://img-blog.csdn.net/20181020152214946?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="563">               可以发现进入容器内部后，就像是进入了一个新的电脑一样                <img alt="" class="has" height="75" src="https://img-blog.csdn.net/20181020152321630?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="523">                 <img alt="" class="has" height="168" src="https://img-blog.csdn.net/201810201525019?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="466">        7：如何让外部访问到容器中的nginx              ⑴首先我们将容器停掉，命令：docker stop +服务名称                   <img alt="" class="has" height="154" src="https://img-blog.csdn.net/20181020161059739?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="542">              ⑵nginx 的默认启动端口是80，8080:80  将外部主机8080端口映射到容器的80端口。                   <img alt="" class="has" height="244" src="https://img-blog.csdn.net/20181020161509916?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="575">                  命令：docker run -d -p 8080:80 +镜像名称                  <img alt="" class="has" height="99" src="https://img-blog.csdn.net/20181020161733514?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="595">                 效果：说明已经OK了。                   <img alt="" class="has" height="236" src="https://img-blog.csdn.net/2018102016194610?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="674">              8：我们也可以随意开辟一个端口去映射nginx的80端口                   <img alt="" class="has" height="243" src="https://img-blog.csdn.net/20181020162508162?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="577">                   命令：docker run -d -P +镜像名称                   从上面可以发现，随机分配了一个32768的端口去映射80端口。                    <img alt="" class="has" height="205" src="https://img-blog.csdn.net/20181020162701144?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="568">                    完美！</p>
<h1 id="七：简单的java-web应用"><a href="#七：简单的java-web应用" class="headerlink" title="七：简单的java web应用"></a>七：简单的java web应用</h1><p>       1：制作自己的镜像              ⑴什么是Dockerfile？                     Dockerfile就是用来告诉Docker，我们要怎么制作一个镜像，                     我们制作镜像的每一步操作是什么。              ⑵什么是docker build？                     当Dockerfile写好之后，我们使用docker build命令来执行Dockerfile                     里面我们编写的代码，最终把docker镜像给构建出来。        2：开始制作Dockerfile               <img alt="" class="has" height="156" src="https://img-blog.csdn.net/20181020211609396?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="653">                  ⑴那么我们需要如何制作java web端的镜像呢？                    ①我们的镜像是要运行在tomcat中的。一般创建镜像，第一步是要继承一个基础镜像。                        那么我们就去网易蜂巢去找一个tomcat镜像，作为一个基础镜像                       <img alt="" class="has" height="124" src="https://img-blog.csdn.net/20181020212635912?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="640">                        我们将tomcat下载下来，注意：这个tomcat是包含JDK的，所以我们不用担心JDK问题。                      <img alt="" class="has" height="260" src="https://img-blog.csdn.net/20181020213441170?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="553">                      <img alt="" class="has" height="153" src="https://img-blog.csdn.net/20181020213616168?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="547">                   ②编写Dockerfile，以tomcat作为基础镜像，这个位置是镜像中的位置                        <img alt="" class="has" height="283" src="https://img-blog.csdn.net/20181020215557979?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="599">                        <img alt="" class="has" height="435" src="https://img-blog.csdn.net/20181020220057227?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="525">                        <img alt="" class="has" height="120" src="https://img-blog.csdn.net/20181020220951896?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="469">            3：使用docker build执行Dockerfile文件                    命令：docker build -t +名称:版本 +Dockerfile文件路径，如果是当前目录，                               就是docker build -t +名称:版本 .                         <img alt="" class="has" height="256" src="https://img-blog.csdn.net/20181020221932148?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="508">                         <img alt="" class="has" height="244" src="https://img-blog.csdn.net/2018102022222666?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="593">               4：运行自己的容器                      ⑴运行命令                            <img alt="" class="has" height="293" src="https://img-blog.csdn.net/20181020222949107?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="528">                             <img alt="" class="has" height="96" src="https://img-blog.csdn.net/20181020223114385?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="477">                    ⑵访问端口                          <img alt="" class="has" height="259" src="https://img-blog.csdn.net/20181020223243837?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="551">                   ⑶访问我们的应用程序                         <img alt="" class="has" height="208" src="https://img-blog.csdn.net/2018102022355978?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="648"></p>
<p>                                                         </p>
<p> </p>
<p>        </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>Elasticsearch之Request Body查询</title>
    <url>/2021/07/18/Elasticsearch%E4%B9%8BRequest%20Body%E6%9F%A5%E8%AF%A2/</url>
    <content><![CDATA[<p>title: Elasticsearch之Request Body查询<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、term查询简介</p>
<blockquote>
<p> term是表达语义的最小单位，在搜索的时候基本都要使用到term。 term查询的种类有：Term Query、Range Query等。 在ES中，Term查询不会对输入进行分词处理，将输入作为一个整体，在倒排索引中查找准确的词项。 我们也可以使用 Constant Score 将查询转换为一个filter,避免算分，利用缓存，提高查询的效 率。 </p>
</blockquote>
<h3 id="2、term与terms"><a href="#2、term与terms" class="headerlink" title="2、term与terms"></a>2、term与terms</h3><blockquote>
<p> 查询电影名字中包含有 beautiful 这个单词的所有的电影，用于查询的单词不会进行分词的处理<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “term”: {<!-- -->             “title”: {<!-- -->                 “value”: “beautiful”             }         }     } }<br> 查询电影名字中包含有 beautiful 或者 mind 这两个单词的所有的电影，用于查询的单词不会进行 分词的处理<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “terms”: {<!-- -->             “title”: [                 “beautiful”,                 “mind”             ]         }     } } </p>
</blockquote>
<h3 id="3、range"><a href="#3、range" class="headerlink" title="3、range"></a>3、range</h3><blockquote>
<p> 查询上映在2016到2018年的所有的电影，再根据上映时间的倒序进行排序<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “range”: {<!-- -->             “year”: {<!-- -->                 “gte”: 2016,                 “lte”: 2018             }          }     },     “sort”: [         {<!-- -->             “year”: {<!-- -->                 “order”: “desc”             }         }     ] } </p>
</blockquote>
<h3 id="4、Constant-Score"><a href="#4、Constant-Score" class="headerlink" title="4、Constant Score"></a>4、Constant Score</h3><blockquote>
<p> 查询title中包含有beautiful的所有的电影，不进行相关性算分，查询的数据进行缓存，提高效率<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “constant_score”: {<!-- -->             “filter”: {<!-- -->                 “term”: {<!-- -->                     “title”: “beautiful”                 }             }         }     } } </p>
</blockquote>
<h3 id="5、全文查询"><a href="#5、全文查询" class="headerlink" title="5、全文查询"></a>5、全文查询</h3><blockquote>
<p> 全文查询的种类有: Match Query、Match Phrase Query、Query String Query等 索引和搜索的时候都会进行分词，在查询的时候，会对输入进行分词，然后每个词项会逐个到底层进行 查询，将最终的结果进行合并 </p>
</blockquote>
<h3 id="6、match"><a href="#6、match" class="headerlink" title="6、match"></a>6、match</h3><blockquote>
<p> 查询电影名字中包含有beautiful的所有电影，每页十条，取第二页的数据<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “match”: {<!-- -->             “title”: “beautiful”         }     },     “from”: 10,     “size”: 10 }<br> 查询电影名字中包含有 beautiful 或者 mind 的所有的数据，但是只查询title和id两个属性<br> GET movies/_search {<!-- -->     “_source”: [“title”, “id”],         “query”: {<!-- -->             “match”: {<!-- -->                 “title”: “beautiful mind”             }         } } </p>
</blockquote>
<h3 id="7、match-phrase"><a href="#7、match-phrase" class="headerlink" title="7、match_phrase"></a>7、match_phrase</h3><blockquote>
<p> 查询电影名字中包含有 “beautiful mind” 这个短语的所有的数据<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “match_phrase”: {<!-- -->             “title”: “beautiful mind”         }     } }<br> 注意：match_phrase和term区别<br> term是将传入的文本原封不动地（不分词）拿去查询。 match会对输入进行分词处理后再去查询，部分命中的结果也会按照评分由高到低显示出来。 match_phrase是按短语查询，只有存在这个短语的文档才会被显示出来。<br> 也就是说，term和match_phrase都可以用于精确匹配，而match用于模糊匹配。<br> 上面说的也不是很准确：<br> match_phrase总结如下： </p>
</blockquote>
<ul>
<li>match_phrase还是分词后去搜的- 目标文档需要包含分词后的所有词- 目标文档还要保持这些词的相对顺序和文档中的一致</li>
</ul>
<h3 id="8、multi-match"><a href="#8、multi-match" class="headerlink" title="8、multi_match"></a>8、multi_match</h3><blockquote>
<p> 查询 title 或 genre 中包含有 beautiful 或者 Adventure 的所有的数据<br> GET movies/_search     {<!-- -->     “query”: {<!-- -->         “multi_match”: {<!-- -->             “query”: “beautiful Adventure”,             “fields”: [“title”, “genre”]         }     } }   </p>
</blockquote>
<h3 id="9、match-all"><a href="#9、match-all" class="headerlink" title="9、match_all"></a>9、match_all</h3><blockquote>
<p> 查询所有的数据<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “match_all”: {}     } } </p>
</blockquote>
<h3 id="10、query-string"><a href="#10、query-string" class="headerlink" title="10、query_string"></a>10、query_string</h3><blockquote>
<p> 查询 title 中包含有 beautiful 和 mind 的所有的电影<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “query_string”: {<!-- -->             “default_field”: “title”,             “query”: “mind AND beautiful”         }     } } 或者<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “query_string”: {<!-- -->             “default_field”: “title”,             “query”: “mind beautiful”,             “default_operator”: “AND”         }     } }   </p>
</blockquote>
<h3 id="11、simple-query-string"><a href="#11、simple-query-string" class="headerlink" title="11、simple_query_string"></a>11、simple_query_string</h3><blockquote>
<p> simple_query_string 覆盖了很多其他查询的用法。<br> 查询 title 中包含有 beautiful 和 mind 的所有的电影<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “simple_query_string”: {<!-- -->             “query”: “beautiful + mind”,             “fields”: [“title”]         }     } }<br> 或者<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “simple_query_string”: {<!-- -->             “query”: “beautiful mind”,             “fields”: [“title”],             “default_operator”: “AND”         }     } }<br> 查询title中包含 “beautiful mind” 这个短语的所有的电影 (用法和match_phrase类似)<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “simple_query_string”: {<!-- -->             “query”: “&quot;beautiful mind&quot;“,             “fields”: [“title”]         }     } }<br> 查询title或genre中包含有 beautiful mind romance 这个三个单词的所有的电影 （与multi_match类似）<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “simple_query_string”: {<!-- -->             “query”: “beautiful mind Romance”,             “fields”: [“title”, “genre”]         }     } }<br> 查询title中包含 “beautiful mind” 或者 “Modern Romance” 这两个短语的所有的电影<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “simple_query_string”: {<!-- -->             “query”: “&quot;beautiful mind&quot; | &quot;Modern Romance&quot;“,             “fields”: [“title”]         }     } }<br> 查询title或者genre中包含有 beautiful + mind 这个两个词，或者Comedy + Romance + Musical + Drama + Children 这个五个词的所有的数据<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “simple_query_string”: {<!-- -->             “query”: “(beautiful + mind) | (Comedy + Romance + Musical + Drama + Children)”,             “fields”: [“title”,”genre”]         }     } }<br> 查询 title 中包含 beautiful 和 people 但是不包含 Animals 的所有的数据<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “simple_query_string”: {<!-- -->             “query”: “beautiful + people + -Animals”,             “fields”: [“title”]         }     } } </p>
</blockquote>
<h3 id="12、模糊搜索"><a href="#12、模糊搜索" class="headerlink" title="12、模糊搜索"></a>12、模糊搜索</h3><blockquote>
<p> 查询title中从第6个字母开始只要最多纠正一次，就与 neverendign 匹配的所有的数据<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “fuzzy”: {<!-- -->             “title”: {<!-- -->                 “value”: “neverendign”,                 “fuzziness”: 1,                 “prefix_length”: 5             }         }     } } </p>
</blockquote>
<h3 id="13、多条件查询"><a href="#13、多条件查询" class="headerlink" title="13、多条件查询"></a>13、多条件查询</h3><blockquote>
<p> 查询title中包含有beautiful或者mind单词，并且上映时间在2016<del>1018年的所有的电影<br> GET movies/_search {<!-- -->     “query”: {<!-- -->         “bool”: {<!-- -->             “must”: [                 {<!-- -->                     “simple_query_string”: {<!-- -->                         “query”: “beautiful mind”,                         “fields”: [“title”]                     }                 },                 {<!-- -->                     “range”: {<!-- -->                         “year”: {<!-- -->                             “gte”: 2016,                             “lte”: 2018                         }                     }                 }             ]         }     } }<br> 查询 title 中包含有 beautiful 这个单词，并且上映年份在2016</del>2018年间的所有电影，但是不 进行相关性的算分 </p>
</blockquote>
<h1 id="filter不会进行相关性的算分，并且会将查出来的结果进行缓存，效率上比-query-高-GET-movies-search-“query”-“bool”-“filter”-“term”-“title”-“beautiful”-“range”-“year”-“gte”-2016-“lte”-2018"><a href="#filter不会进行相关性的算分，并且会将查出来的结果进行缓存，效率上比-query-高-GET-movies-search-“query”-“bool”-“filter”-“term”-“title”-“beautiful”-“range”-“year”-“gte”-2016-“lte”-2018" class="headerlink" title="filter不会进行相关性的算分，并且会将查出来的结果进行缓存，效率上比 query 高 GET movies/_search {     “query”: {         “bool”: {             “filter”: [                 {                     “term”: {                         “title”: “beautiful”                     }                 },                 {                     “range”: {                         “year”: {                             “gte”: 2016,                             “lte”: 2018                         }                     }                 }             ]         }     } }"></a>filter不会进行相关性的算分，并且会将查出来的结果进行缓存，效率上比 query 高 GET movies/_search {<!-- -->     “query”: {<!-- -->         “bool”: {<!-- -->             “filter”: [                 {<!-- -->                     “term”: {<!-- -->                         “title”: “beautiful”                     }                 },                 {<!-- -->                     “range”: {<!-- -->                         “year”: {<!-- -->                             “gte”: 2016,                             “lte”: 2018                         }                     }                 }             ]         }     } }</h1><h3 id="14、Mapping"><a href="#14、Mapping" class="headerlink" title="14、Mapping"></a>14、Mapping</h3><blockquote>
<p> mapping类似于数据库中的schema，作用如下:<br>         1. 定义索引中的字段类型；<br>         2. 定义字段的数据类型，例如：布尔、字符串、数字、日期…..<br>         3. 字段倒排索引的设置<br> 数据类型<img alt="" height="315" src="https://img-blog.csdnimg.cn/20210703130327728.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="753"><br> Mapping的定义语法如下：<br> PUT users {<!-- -->     “mappings”: {<!-- -->         // define your mappings here     } }<br> 定义mapping的建议方式: 写入一个样本文档到临时索引中，ES会自动生成mapping信息，通过访问 mapping信息的api查询mapping的定义，修改自动生成的mapping成为我们需要方式，创建索引，删 除临时索引，简而言之就是 “卸磨杀驴” 。 </p>
</blockquote>
<h3 id="15、常见参数"><a href="#15、常见参数" class="headerlink" title="15、常见参数"></a>15、常见参数</h3><blockquote>
<p> 1）index<br>       可以给属性添加一个 布尔类型的index属性，标识该属性是否能被倒排索引，也就是说是否能通过 该字段进行搜索。<br> 2) null_value<br> 在数据索引进ES的时候，当某些数据为 null 的时候，该数据是不能被搜索的，可以使用 null_value 属性指定一个值，当属性的值为 null 的时候，转换为一个通过 null_value 指 定的值。 null_value属性只能用于Keyword类型的属性 </p>
</blockquote>
<h3 id="16、聚合查询"><a href="#16、聚合查询" class="headerlink" title="16、聚合查询"></a>16、聚合查询</h3><blockquote>
<p> 1）聚合搜索的语法格式如下：<br> GET indexName/_search {<!-- -->     “aggs”: {<!-- -->         “aggs_name”: { #聚合分析的名字是由用户自定义的             “aggs_type”: {<!-- -->                 // aggregation body             }         }     } } 2）给users索引创建mapping信息<br> <img alt="" height="507" src="https://img-blog.csdnimg.cn/20210703165950461.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="406"><br> 3）往 users 索引中写入数据<br> <pre><code class="language-html">PUT employee/_bulk<br>&#123;"index": &#123;"_id": 1&#125;&#125;<br>&#123;"id": 1, "name": "Bob", "job": "java", "age": 21, "sal": 8000, "gender": "female"&#125;<br>&#123;"index": &#123;"_id": 2&#125;&#125;<br>&#123;"id": 2, "name": "Rod", "job": "html", "age": 31, "sal": 18000, "gender": "female"&#125;<br>&#123;"index": &#123;"_id": 3&#125;&#125;<br>&#123;"id": 3, "name": "Gaving", "job": "java", "age": 24, "sal": 12000, "gender": "male"&#125;<br>&#123;"index": &#123;"_id": 4&#125;&#125;<br>&#123;"id": 4, "name": "King", "job": "dba", "age": 26, "sal": 15000, "gender": "female"&#125;<br>&#123;"index": &#123;"_id": 5&#125;&#125;<br>&#123;"id": 5, "name": "Jonhson", "job": "dba", "age": 29, "sal": 16000, "gender": "male"&#125;<br>&#123;"index": &#123;"_id": 6&#125;&#125;<br>&#123;"id": 6, "name": "Douge", "job": "java", "age": 41, "sal": 20000, "gender": "female"&#125;<br>&#123;"index": &#123;"_id": 7&#125;&#125;<br>&#123;"id": 7, "name": "cutting", "job": "dba", "age": 27, "sal": 7000, "gender": "male"&#125;<br>&#123;"index": &#123;"_id": 8&#125;&#125;<br>&#123;"id": 8, "name": "Bona", "job": "html", "age": 22, "sal": 14000, "gender": "female"&#125;<br>&#123;"index": &#123;"_id": 9&#125;&#125;<br>&#123;"id": 9, "name": "Shyon", "job": "dba", "age": 20, "sal": 19000, "gender": "female"&#125;<br>&#123;"index": &#123;"_id": 10&#125;&#125;<br>&#123;"id": 10, "name": "James", "job": "html", "age": 18, "sal": 22000, "gender": "male"&#125;<br>&#123;"index": &#123;"_id": 11&#125;&#125;<br>&#123;"id": 11, "name": "Golsling", "job": "java", "age": 32, "sal": 23000, "gender":<br>"female"&#125;<br>&#123;"index": &#123;"_id": 12&#125;&#125;<br>&#123;"id": 12, "name": "Lily", "job": "java", "age": 24, "sal": 2000, "gender": "male"&#125;<br>&#123;"index": &#123;"_id": 13&#125;&#125;<br>&#123;"id": 13, "name": "Jack", "job": "html", "age": 23, "sal": 3000, "gender": "female"&#125;<br>&#123;"index": &#123;"_id": 14&#125;&#125;<br>&#123;"id": 14, "name": "Rose", "job": "java", "age": 36, "sal": 6000, "gender": "female"&#125;<br>&#123;"index": &#123;"_id": 15&#125;&#125;<br>&#123;"id": 15, "name": "Will", "job": "dba", "age": 38, "sal": 4500, "gender": "male"&#125;<br>&#123;"index": &#123;"_id": 16&#125;&#125;<br>&#123;"id": 16, "name": "smith", "job": "java", "age": 32, "sal": 23000, "gender": "male"&#125;</code></pre><br> 4）单值的输出，ES中大多数的数学计算只输出一个值，如：min、max、sum、avg、cardinalit<br>     4.1）查询工资的总和<br>           <img alt="" height="254" src="https://img-blog.csdnimg.cn/20210703170233150.png" width="292"><br>     4.2）查询员工的平均工资<br>           <img alt="" height="257" src="https://img-blog.csdnimg.cn/20210703170322424.png" width="290"><br>     4.3）查询总共有多少个岗位, cardinality的值类似于sql中的 count distinct,即去重统计总数<br>            <img alt="" height="264" src="https://img-blog.csdnimg.cn/20210703170347326.png" width="298"><br>     4.4）查询航班票价的最高值、平均值、最低值<br>            <img alt="" height="483" src="https://img-blog.csdnimg.cn/20210703170430932.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="447"><br> 5）多值的输出,ES还有些函数，可以一次性输出很多个统计的数据: terms、stats<br>      5.1）查询工资的信息<br>             <img alt="" height="250" src="https://img-blog.csdnimg.cn/20210703170608578.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="316"><br>      5.2）查询到达不同城市的航班数量<br>             <img alt="" height="260" src="https://img-blog.csdnimg.cn/20210703170635852.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="368"><br>      5.3）查询每个岗位有多少人<br>             <img alt="" height="260" src="https://img-blog.csdnimg.cn/20210703170720626.png" width="279"><br>      5.4）查询目标地的航班次数以及天气信息<br>             <img alt="" height="417" src="https://img-blog.csdnimg.cn/20210703170751309.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="427"><br>      5.5）查询每个岗位下工资的信息(平均工资、最高工资、最少工资等)<br>             <img alt="" height="542" src="https://img-blog.csdnimg.cn/20210703170929821.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="493"><br>      5.6）查询不同工种的男女员工数量、然后统计不同工种下男女员工的工资信息<br>               <img alt="" height="572" src="https://img-blog.csdnimg.cn/20210703171012471.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="408"><br>      5.7）查询年龄最大的两位员工的信息<br>           <img alt="" height="543" src="https://img-blog.csdnimg.cn/20210703171105176.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="382"><br>      5.8）查询不同区间员工工资的统计信息<br>           <img alt="" height="645" src="https://img-blog.csdnimg.cn/2021070317114435.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="442"><br>     5.9）以直方图的方式以每5000元为一个区间查看工资信息<br>          <img alt="" height="431" src="https://img-blog.csdnimg.cn/20210703171304558.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="553"><br>     5.10）查询平均工资最低的工种<br>          <img alt="" height="525" src="https://img-blog.csdnimg.cn/20210703171412288.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="490"><br>     5.11）求工资和工种的信息<br>          <img alt="" height="375" src="https://img-blog.csdnimg.cn/20210703171444218.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="351"><br>     5.12）查询年龄大于30岁的员工的平均工资<br>        <img alt="" height="423" src="https://img-blog.csdnimg.cn/20210703171518293.png" width="282"><br>     5.13）查询Java员工的平均工资<br>          <img alt="" height="488" src="https://img-blog.csdnimg.cn/20210703171556873.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="303"><br>     5.14）求30岁以上的员工的平均工资和所有员工的平均工资<br>        <img alt="" height="757" src="https://img-blog.csdnimg.cn/20210703171629367.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="367"> </p>
</blockquote>
<h3 id="17、推荐搜索"><a href="#17、推荐搜索" class="headerlink" title="17、推荐搜索"></a>17、推荐搜索</h3><blockquote>
<p> 在搜索过程中，因为单词的拼写错误，没有得到任何的结果，希望ES能够给我们一个推荐搜索。<br> <img alt="" height="456" src="https://img-blog.csdnimg.cn/20210703175229434.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="596"> </p>
</blockquote>
<h3 id="18、自动补全"><a href="#18、自动补全" class="headerlink" title="18、自动补全"></a>18、自动补全</h3><blockquote>
<p> 自动补全应该是我们在日常的开发过程中最常见的搜索方式了，如百度搜索和京东商品搜索。<br> <img alt="" height="382" src="https://img-blog.csdnimg.cn/20210703175338116.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="750"><br> <img alt="" height="671" src="https://img-blog.csdnimg.cn/20210703175400630.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="753"><br> 定义mapping：<br> <img alt="" height="824" src="https://img-blog.csdnimg.cn/20210703175531835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="519"><br> <img alt="" height="314" src="https://img-blog.csdnimg.cn/20210703175551768.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="462"><br> 前缀搜索<br> <img alt="" height="330" src="https://img-blog.csdnimg.cn/20210703175642732.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="366"><br> <img alt="" height="804" src="https://img-blog.csdnimg.cn/20210703175715675.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> </p>
</blockquote>
<h3 id="19、高亮显示"><a href="#19、高亮显示" class="headerlink" title="19、高亮显示"></a>19、高亮显示</h3><blockquote>
<p> 高亮显示在实际的应用中也会碰到很多，如下给出了百度和极客时间的两个高亮搜索的案例：<br> <img alt="" height="825" src="https://img-blog.csdnimg.cn/20210703180705816.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="925"><br> <img alt="" height="657" src="https://img-blog.csdnimg.cn/2021070318072243.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="960"><br> 将所有的包含有 beautiful 的单词高亮显示<br> <img alt="" height="631" src="https://img-blog.csdnimg.cn/20210703180807646.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="551"><br> <img alt="" height="636" src="https://img-blog.csdnimg.cn/20210703180825496.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1200"> </p>
</blockquote>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>HDFS的数据流以及Namenode工作机制</title>
    <url>/2021/07/18/HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81%E4%BB%A5%E5%8F%8ANamenode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<p>title: HDFS的数据流以及Namenode工作机制<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：通过IO流操作HDFS</p>
<ol>
<li>HDFS文件上传      <img alt="" class="has" height="395" src="https://img-blog.csdnimg.cn/20190720090731704.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="547">     效果：     <img alt="" class="has" height="226" src="https://img-blog.csdnimg.cn/20190720090802700.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="543">1. HDFS文件下载  <img alt="" class="has" height="317" src="https://img-blog.csdnimg.cn/20190720093258845.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="514">1. 定位文件读取       ⑴下面的文件总共有188.5M，它是分在两块Block存储的，我们如何分块读取呢      <img alt="" class="has" height="164" src="https://img-blog.csdnimg.cn/20190720094556179.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="629">      <img alt="" class="has" height="328" src="https://img-blog.csdnimg.cn/20190720094627331.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="313">   ⑵我们指定每次读取的文件大小即可，第一次读取128M，后面再读取60.5M就读取完整了       <img alt="" class="has" height="390" src="https://img-blog.csdnimg.cn/20190720095202534.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="555">      效果：      <img alt="" class="has" height="108" src="https://img-blog.csdnimg.cn/20190720095233507.png" width="315">     下面我们再读取第二块：      <img alt="" class="has" height="359" src="https://img-blog.csdnimg.cn/20190720095709972.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="505">      效果：      <img alt="" class="has" height="96" src="https://img-blog.csdnimg.cn/20190720095852842.png" width="512">     我们可以将第二块的文件通过cmd上命令内容追加到第一块文件上，验证是否正确      <img alt="" class="has" height="184" src="https://img-blog.csdnimg.cn/20190720100126750.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="617">      <img alt="" class="has" height="112" src="https://img-blog.csdnimg.cn/20190720100236590.png" width="632"><h1 id="二：HDFS写数据流程"><a href="#二：HDFS写数据流程" class="headerlink" title="二：HDFS写数据流程"></a>二：HDFS写数据流程</h1></li>
<li>剖析文件写入   <img alt="" class="has" height="497" src="https://img-blog.csdnimg.cn/20190720125256764.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="609">1.  网络拓扑的概念  <img alt="" class="has" height="191" src="https://img-blog.csdnimg.cn/20190720125829474.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="518">  <img alt="" class="has" height="465" src="https://img-blog.csdnimg.cn/20190720130440345.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="600">1.  机架感知<img alt="" class="has" height="403" src="https://img-blog.csdnimg.cn/20190720144503947.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="571"><img alt="" class="has" height="391" src="https://img-blog.csdnimg.cn/20190720144709457.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="519"><img alt="" class="has" height="90" src="https://img-blog.csdnimg.cn/20190720145500612.png" width="504">      <h1 id="三：HDFS读数据流程"><a href="#三：HDFS读数据流程" class="headerlink" title="三：HDFS读数据流程"></a>三：HDFS读数据流程</h1></li>
</ol>
<p>         <img alt="" class="has" height="430" src="https://img-blog.csdnimg.cn/20190720145850721.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="554"></p>
<h1 id="四：NameNode工作机制"><a href="#四：NameNode工作机制" class="headerlink" title="四：NameNode工作机制"></a>四：NameNode工作机制</h1><ol>
<li>如下图<img alt="" class="has" height="430" src="https://img-blog.csdnimg.cn/20190720153511862.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="631">1. 详情如下  ⑴第一阶段：namenode启动             a：第一次启动 namenode 格式化后，创建 fsimage 和 edits 文件。如果不是第一次启                   动，直接加载编辑日志和镜像文件到内存。             b：当客户端对元数据进行增删改的请求的时候，namenode 记录操作日志，更新滚动日志                   namenode 在内存中对数据进行增删改查  ⑵第二阶段：Secondary NameNode 工作            a：Secondary NameNode 询问 namenode 是否需要 checkpoint。直接带回 namenode 是                  否检查结果            b：Secondary NameNode 请求执行 checkpoint           c：namenode 滚动正在写的 edits 日志。           d：将滚动前的编辑日志和镜像文件拷贝到 Secondary NameNode           e：Secondary NameNode 加载编辑日志和镜像文件到内存，并合并           f：生成新的镜像文件 fsimage.chkpoint           g：拷贝 fsimage.chkpoint 到 namenode，namenode 将 fsimage.chkpoint 重新命名成 fsimage1. namenode简介  ⑴namenode主要负责三个功能：          a：管理元数据          b：维护目录树          c：响应客户请求  ⑵详情如下          <img alt="" class="has" height="324" src="https://img-blog.csdnimg.cn/20190720160107465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="543">          <img alt="" class="has" height="339" src="https://img-blog.csdnimg.cn/20190720160248837.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="608">         <img alt="" class="has" height="272" src="https://img-blog.csdnimg.cn/20190720160406633.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="697">            <h1 id="五：镜像文件和编辑日志文件"><a href="#五：镜像文件和编辑日志文件" class="headerlink" title="五：镜像文件和编辑日志文件"></a>五：镜像文件和编辑日志文件</h1></li>
<li> 简介        namenode被格式化之后，将在/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current目录中产生如下文件        <img alt="" class="has" height="331" src="https://img-blog.csdnimg.cn/2019072016440785.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="504">       <img alt="" class="has" height="485" src="https://img-blog.csdnimg.cn/20190720165933192.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="549">  ⑴Fsimage 文件：HDFS 文件系统元数据的一个永久性的检查点，其中包含 HDFS文件系统的所有目录和     文件 idnode 的序列化信息。 ⑵Edits 文件：存放 HDFS 文件系统的所有更新操作的路径，文件系统客户端执行     的所有写操作首先会被记录到 edits 文件中。 ⑶seen_txid 文件保存的是一个数字，就是最后一个 edits_的数字 ⑷每次次 Namenode 启动的时候都会将 fsimage 文件读入内存，并从 00001 开始     到 seen_txid 中记录的数字依次执行每个 edits 里面的更新操作，保证内存中的元数据信息    是最新的、同步的，可以看成 Namenode 启动的时候就将 fsimage 和 edits 文件进行了合    并。1. 使用oiv查看Fsimage文件  ⑴基本语法：        hdfs oiv -p 文件类型 -i 镜像文件 -o 转换后文件输出路径  ⑵案例：        <img alt="" class="has" height="345" src="https://img-blog.csdnimg.cn/20190720170724543.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="574">      将文件下载到本地格式化看一下：        <img alt="" class="has" height="439" src="https://img-blog.csdnimg.cn/20190720171144829.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="505">1.  使用oev命令查看edits文件   ⑴基本语法         hdfs oev -p 文件类型 -i 编辑日志 -o 转换后文件输出路径           ⑵案例        <img alt="" class="has" height="336" src="https://img-blog.csdnimg.cn/20190720212156658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="468">         将文件下载到本地格式化看一下：        <img alt="" class="has" height="193" src="https://img-blog.csdnimg.cn/20190720212830715.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="374">       发现这个日志中没有什么东西，那么我们上传一个文件，试试：       <img alt="" class="has" height="63" src="https://img-blog.csdnimg.cn/20190720213618676.png" width="516">       <img alt="" class="has" height="58" src="https://img-blog.csdnimg.cn/20190720213718300.png" width="724">      查看xml内容：     <img alt="" class="has" height="359" src="https://img-blog.csdnimg.cn/20190720213854379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="407"><h1 id="六：滚动编辑日志"><a href="#六：滚动编辑日志" class="headerlink" title="六：滚动编辑日志"></a>六：滚动编辑日志</h1></li>
<li>简介       正常情况 HDFS 文件系统有更新操作时，就会滚动编辑日志。也可以用命令强制滚动编辑日志。1.  滚动编辑日志（前提必须启动集群）  命令：hdfs dfsadmin -rollEdits       <h1 id="七：chkpoint-检查-时间-参数"><a href="#七：chkpoint-检查-时间-参数" class="headerlink" title="七：chkpoint  检查 时间 参数"></a>七：chkpoint  检查 时间 参数</h1></li>
<li>通常情况下，SecondaryNameNode 每隔一小时执行一次。配置是在hdfs-site.xml中添加<img alt="" class="has" height="140" src="https://img-blog.csdnimg.cn/20190720222713915.png" width="558">         1. 一分钟检查一次操作次数，当操作次数达到 1 百万时，SecondaryNameNode 执行一次。<img alt="" class="has" height="320" src="https://img-blog.csdnimg.cn/20190720222746874.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="488">     <h1 id="八：SecondaryNameNode-目录结构"><a href="#八：SecondaryNameNode-目录结构" class="headerlink" title="八：SecondaryNameNode  目录结构"></a>八：SecondaryNameNode  目录结构</h1></li>
<li> 进入SecondaryNameNode服务器的目录，/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary/current  <img alt="" class="has" height="361" src="https://img-blog.csdnimg.cn/20190721102534154.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="523">  SecondaryNameNode 的 namesecondary/current 目录和主 namenode 的 current 目录的布局相同。 好 处 ： 在 主 namenode 发 生 故 障 时 （ 假 设 没 有 及 时 备 份 数 据 ） ， 可 以 从SecondaryNameNode 恢复数据。     <h1 id="九：NameNode故障处理方法"><a href="#九：NameNode故障处理方法" class="headerlink" title="九：NameNode故障处理方法"></a>九：NameNode故障处理方法</h1></li>
<li>Namenode 故障后，可以采用如下两种方法恢复数据。   方法一：将 SecondaryNameNode 中数据拷贝到 namenode 存储数据的目录；   方 法 二 ：使 用 -importCheckpoint 选 项 启 动 namenode 守 护 进 程 ， 从 而 将SecondaryNameNode 中                     数据拷贝到 namenode 目录中。1.  案例一：使用手动拷贝 SecondaryNameNode  数据解决问题   ⑴kill -9 namenode 进程           <img alt="" class="has" height="211" src="https://img-blog.csdnimg.cn/20190721104854927.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="489">   ⑵删除 namenode 存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）            <img alt="" class="has" height="194" src="https://img-blog.csdnimg.cn/20190721105154463.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="474">   ⑶拷贝104服务器 SecondaryNameNode 中数据到102服务器的原 namenode 存储数据目录        <img alt="" class="has" height="404" src="https://img-blog.csdnimg.cn/20190721110541295.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="520">    ⑷单独重新启动 namenode，这个我们最好使用单节点启动         <img alt="" class="has" height="215" src="https://img-blog.csdnimg.cn/20190721110910948.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="649">     ⑸效果，发现数据回来了         <img alt="" class="has" height="349" src="https://img-blog.csdnimg.cn/20190721111541274.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="494">1.   案例二：采用 importCheckpoint  命令贝 拷贝 SecondaryNameNode   ⑴修改 hdfs-site.xml 中的配置         <img alt="" class="has" height="342" src="https://img-blog.csdnimg.cn/20190721115756609.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="676">  ⑵kill -9 namenode 进程          <img alt="" class="has" height="225" src="https://img-blog.csdnimg.cn/20190721120200675.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="390">  ⑶删除 namenode 存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）         <img alt="" class="has" height="145" src="https://img-blog.csdnimg.cn/20190721120404664.png" width="469">  ⑷ 如 果 SecondaryNameNode 不 和 Namenode 在 一 个 主 机 节 点 上 ， 需 要 将SecondaryNameNode      存储数据的目录拷贝到 Namenode 存储数据的平级目录，并删除in_use.lock 文件      a：拷贝到下面这个目录下：           <img alt="" class="has" height="162" src="https://img-blog.csdnimg.cn/20190721120620362.png" width="541">     b：拷贝文件，并删除lock文件           <img alt="" class="has" height="118" src="https://img-blog.csdnimg.cn/20190721120926592.png" width="701">           <img alt="" class="has" height="252" src="https://img-blog.csdnimg.cn/20190721121040805.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="476">   ⑸导入检查点数据（等待一会 ctrl+c 结束掉，时间有点长，需要等一下），到指定的目录下：       <img alt="" class="has" height="289" src="https://img-blog.csdnimg.cn/20190721140843982.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="490">             查看namenode的目录：发现数据已经同步回来了：      <img alt="" class="has" height="175" src="https://img-blog.csdnimg.cn/20190721141014184.png" width="589">  ⑹启动 namenode      <img alt="" class="has" height="141" src="https://img-blog.csdnimg.cn/20190721141117690.png" width="634">  ⑺效果：数据回来了      <img alt="" class="has" height="385" src="https://img-blog.csdnimg.cn/20190721141149205.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="561">     <h1 id="十：集群安全-模式-操作"><a href="#十：集群安全-模式-操作" class="headerlink" title="十：集群安全 模式 操作"></a>十：集群安全 模式 操作</h1></li>
<li> 简介      Namenode 启动时，首先将映像文件（fsimage）载入内存，并执行编辑日志（edits）中 的各项操作。一旦在内存中成功建立文件系统元数据的映像，则创建一个新的 fsimage 文件 和一个空的编辑日志。此时，namenode 开始监听 datanode 请求。但是此刻，namenode 运行 在安全模式，即 namenode 的文件系统对于客户端来说是只读的。系统中的数据块的位置并不是 由 namenode 维护的，而是以块列表的形式存储在datanode 中。在系统的正常操作期间， namenode 会在内存中保留所有块位置的映射信息。在安全模式下，各个 datanode 会向 namenode 发送最新的块列表信息，namenode 了解到足够多的块位置信息之后，即可高效运行文件系统。          如果满足“最小副本条件”，namenode 会在 30 秒钟之后就退出安全模式。所谓的最小副 本 条 件 指 的 是 在 整 个 文 件 系 统 中 99.9% 的 块 满 足 最 小 副 本 级 别 （ 默 认 值 ： dfs.replication.min=1）。在启动一个刚刚格式化的 HDFS 集群时，因为系统中还没有任何块， 所以 namenode 不会进入安全模式。           总之一句话，就是需要等待namenode和datanode完全建立链接之后，才会退出安全模式， 我们才能对集群进行操作。           集群处于安全模式，不能执行重要操作（写操作）。集群启动完成后，自动退出安全模式。1. 基本语法 （1）bin/hdfs dfsadmin -safemode get （功能描述：查看安全模式状态） （2）bin/hdfs dfsadmin -safemode enter （功能描述：进入安全模式状态） （3）bin/hdfs dfsadmin -safemode leave  （功能描述：离开安全模式状态） （4）bin/hdfs dfsadmin -safemode wait  （功能描述：等待安全模式状态）1.  案例    ⑴查看安全模式状态            <img alt="" class="has" height="121" src="https://img-blog.csdnimg.cn/20190721163354661.png" width="472">    ⑵进入安全模式           <img alt="" class="has" height="99" src="https://img-blog.csdnimg.cn/20190721163453808.png" width="604">    ⑶在安全模式在我们上传一个文件试试           <img alt="" class="has" height="174" src="https://img-blog.csdnimg.cn/20190721163815488.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="510">    ⑷离开安全模式          <img alt="" class="has" height="170" src="https://img-blog.csdnimg.cn/20190721163935781.png" width="637">  1.  等待安全模式状态案例   a：需求           大数据中一般我们都是在晚上进行跑批的操作，跑批的时候系统是不能进行其他任何操作的，需要         进入安全模式，那么有些操作就要等待，等待系统一旦离开安全模式就会立即进行其他的操作，这里         我们可以通过脚本实现。   ⑴首先进入安全模式             <img alt="" class="has" height="132" src="https://img-blog.csdnimg.cn/20190721164757555.png" width="510">      ⑵创建一个脚本wait.sh,就是等待安全模式一结束就上传文件             <img alt="" class="has" height="122" src="https://img-blog.csdnimg.cn/2019072116514518.png" width="478">    ⑶执行脚本              <img alt="" class="has" height="329" src="https://img-blog.csdnimg.cn/20190721165648182.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="352">            ⑷重新打开一个窗口，将安全模式退出              <img alt="" class="has" height="294" src="https://img-blog.csdnimg.cn/20190721165953353.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="489"><h1 id="十一：Namenode-多目录配置"><a href="#十一：Namenode-多目录配置" class="headerlink" title="十一：Namenode 多目录配置"></a>十一：Namenode 多目录配置</h1></li>
<li> 简介        众所周知，namenode很重要，它一旦挂掉，将会很麻烦，虽然有SecondaryNameNode进行数据  恢复，但也比较麻烦。所以namenode 的本地目录可以配置成多个，且每个目录存放内容相同，增加了可靠性。1.  具体配置如下    ⑴首先格式化集群，删除数据，回到初始状态           a：103服务器执行sbin/stop-yarn.sh           b：102服务器执行sbin/stop-dfs.sh           c：102，103，104服务器执行删除数据操作：rm -rf data/ logs/           d：格式化102服务器的namenode                  bin/hdfs namenode -format                  后面出现的data再次删除掉。    ⑵配置 hdfs-site.xml，进行多目录配置         <img alt="" class="has" height="256" src="https://img-blog.csdnimg.cn/20190721173830229.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="498">         注意：这个${hadoop.tmp.dir}是在core-site.xml中配置的指定hadoop运行时产生文件的存储目录        <img alt="" class="has" height="111" src="https://img-blog.csdnimg.cn/20190721174053149.png" width="507">  ⑶将 hdfs-site.xml同步到集群的各个服务器上       <img alt="" class="has" height="45" src="https://img-blog.csdnimg.cn/20190721174736248.png" width="457">   ⑷需要对102服务器再次格式化一下：bin/hdfs namenode -format   ⑸最后启动集群   ⑹效果：          <img alt="" class="has" height="198" src="https://img-blog.csdnimg.cn/20190721190001501.png" width="579">       发现name1和name2中数据一致：       <img alt="" class="has" height="384" src="https://img-blog.csdnimg.cn/20190721190214655.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="668">       也就是说当我们进行数据操作的时候，信息会同时保存到这两个namenode当中。增强了保护性。         </li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hbase入门知识点入门学习二</title>
    <url>/2021/07/18/Hbase%E5%85%A5%E9%97%A8%E7%9F%A5%E8%AF%86%E7%82%B9%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%BA%8C/</url>
    <content><![CDATA[<p>title: Hbase入门知识点入门学习二<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：Hbase读写流程</p>
<ol>
<li>读流程       ⑴client访问Zookeeper中，找到ROOT表的Region所在的RegionServer信息；       ⑵client连接RegionServer访问ROOT表查询.meta表的region位置信息       ⑶再去连接.meta表的region所在的regionserver然后访问meta表，找到目标数据在哪个region上           及region所在的regionserver位置信息       ⑷然后去访问目标数据所在的regionserver中的region,先在memstore中查询数据，memstore中不存在则在           BlockCache中读数据，           BlockCache中还是不存在的话就最后在storefile中读数据，并且将读取到的数据先写入到BlockCache中，然后再返回给客户端      <img alt="" class="has" height="413" src="https://img-blog.csdnimg.cn/20190925225120501.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="811">1. 写流程               ⑴Client访问Zookeeper集群，查询ROOT表region所在的regionserver地址信息，比如rs1      ⑵client连接rs1，访问ROOT表，根据写入信息查询.meta表的region位于哪些regionserver上，将得到的结果返回给client；      ⑶client去连接相应的rs，访问.meta表，根据写入的namespace、表名和rowkey找到对应的region信息         ⑷client连接最终的rs，为了持久化和恢复，将数据先写到Hlog（write ahead log）中;      ⑸再将数据写入到memstore中，当memstore达到预设阈值后，就会创建一个新的memstore，而老的memstore就会加入flush队         列，由单独的线程flush到磁盘上，形成一个storefile；      ⑹与此同时，系统会在Zookeeper记录一个checkpoint，表示这个时刻之前的数据变更已经持久化了，当系统出现意外可能导致           memstore中的数据丢失，就可以通过hlog来恢复checkpoint之后的数据；      ⑺每次flush就会形成一个storefile文件，而storefile文件是只读的，一旦创建之后就不可修改，因此hbase的更新就是不断追加的            操作；      ⑻随着storefile的数量不断增多，当达到设定阈值后就会触发compact合并操作，将多个storefile合并成一个大的storefile，同时进           行版本合并和数据删除；      ⑼当store中的单个storefile文件的大小超过阈值的时候，触发split操作，regionserver把当前的region split成2个新的region      ⑽父region就会下线，新split出的2个region就会被hmaster分配到两个regionserver上，实现负载均衡，使得原先一个region的压           力分流到两个region上。<img alt="" class="has" height="432" src="https://img-blog.csdnimg.cn/20190925225942751.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1131">1.  <h1 id="二：Hbase中-meta简介"><a href="#二：Hbase中-meta简介" class="headerlink" title="二：Hbase中.meta简介"></a>二：Hbase中.meta简介</h1></li>
<li> 简介        当我们在对HBase的读写操作时，都需要提前知道我们需要操作的region的所在位置，即是存在于哪个HRegionServer上，  因此在HBase中存在一张表元数据表.meta表（属于Hbase的内置表）专门存储了表的元数据信息，以及region位于哪个  regionserver上。.meta表的结构类似于下图：  <img alt="" class="has" height="276" src="https://img-blog.csdnimg.cn/20190925224043792.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="759">  .meta表的RowKey由三部分组成：TableName（表名）、StartKey（起始键）、TimeStamp(时间戳)，rowkey存储的内容又称为  region的Name（扩展：用来存放Region的文件夹的名字为RegionName的hash值，因为某些RegionName包含某些非法字符，而 RegionName为什么会包含非法字符是因为startkey是允许包含任何值的）。将组成rowkey的三个部分用逗号隔开组成了整个完整的 rowkey。TimeStamp使用十进制的数字字符串来表示。 .meta表的info为表中最主要的列簇，含有三个column：regioninfo、server、serverstartcode。regioninfo存储的是region的详细信  息，包括startkey、endkey、以及每个family信息。server存储的是管理这个region的regionserver地址。 由于.meta存储的是region的信息，如果当hbase中表的数据非常大会被分成很多个region，那么此时在.meta中所占的空间也会变大，而.meta本身也是一张表，在存储数据非常大的情况下，也会被分割成多个region存储于不同的regionserver上，此时要是想把.meta表的region位置信息存储在zookeeper集群中就不太现实，.meta表region的位置信息是会发生变化的。因此，此时我们可以通过另外一张表来存储.meta表的元数据信息，即-ROOT-(根数据表)，hbase认为这张表不会太大，因此-ROOT-只会有一个region，这个region的信息存在于hbase中，而管理-ROOT-表的位置信息（regionserver地址）存储在Zookeeper中。 所以综上所述要想对HBase进行读写首先去访问Zookeeper集群，获得ROOT表的所在regionserver地址信息。          <h1 id="三：JAVA-api操作Hbase"><a href="#三：JAVA-api操作Hbase" class="headerlink" title="三：JAVA api操作Hbase"></a>三：JAVA api操作Hbase</h1></li>
<li>在maven项目中添加依赖  <img alt="" class="has" height="485" src="https://img-blog.csdnimg.cn/20190928215702389.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="355">  配置文件：  <img alt="" class="has" height="126" src="https://img-blog.csdnimg.cn/20190928220100582.png" width="273">1. HbaseDemo.java类       ⑴判断表是否存在       <img alt="" class="has" height="433" src="https://img-blog.csdnimg.cn/20190928220535888.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="605">   ⑵创建表        <img alt="" class="has" height="345" src="https://img-blog.csdnimg.cn/20190928220620412.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="727">       <img alt="" class="has" height="134" src="https://img-blog.csdnimg.cn/20190928220853511.png" width="613">    ⑶删除表        <img alt="" class="has" height="373" src="https://img-blog.csdnimg.cn/20190928221359776.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="596">  ⑷添加一行数据        <img alt="" class="has" height="320" src="https://img-blog.csdnimg.cn/2019092822232898.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="645">    ⑸删除一行数据       <img alt="" class="has" height="269" src="https://img-blog.csdnimg.cn/20190928223800513.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="568">  ⑹删除多行数据        <img alt="" class="has" height="395" src="https://img-blog.csdnimg.cn/20190928224100873.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="572">  ⑺扫描数据         <img alt="" class="has" height="332" src="https://img-blog.csdnimg.cn/20190928225338999.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="696">           ⑻获取一个列簇的数据         <img alt="" class="has" height="344" src="https://img-blog.csdnimg.cn/20190928230225808.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="686">
 </li>
</ol>
<h1 id="四：MapReduce"><a href="#四：MapReduce" class="headerlink" title="四：MapReduce"></a>四：MapReduce</h1><ol>
<li> 简介        通过 HBase 的相关 JavaAPI，我们可以实现伴随 HBase 操作的 MapReduce 过程，比如使用 MapReduce 将数据从本地文件系统导入到 HBase 的表中，比如我们从 HBase 中读取一些原始数 据后使用 MapReduce 做数据分析。   1.  查看 HBase 的 MapReduce 任务所需的依赖  <img alt="" class="has" height="258" src="https://img-blog.csdnimg.cn/20191001113529507.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="644">1. 执行环境变量的导入   <img alt="" class="has" height="229" src="https://img-blog.csdnimg.cn/20191001113933475.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="820">1. 运行官方的 MapReduce 任务 ，统计 Student 表中有多少行数据   <img alt="" class="has" height="186" src="https://img-blog.csdnimg.cn/20191001115537753.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="779">   <img alt="" class="has" height="355" src="https://img-blog.csdnimg.cn/20191001115607426.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="526">1.  让环境变量永久生效，修改**/etc/profile**配置文件  <img alt="" class="has" height="72" src="https://img-blog.csdnimg.cn/20191001145150761.png" width="784"><h1 id="五：-案例一：使用-MapReduce-将本地数据导入到-HBase"><a href="#五：-案例一：使用-MapReduce-将本地数据导入到-HBase" class="headerlink" title="五： 案例一：使用 MapReduce 将本地数据导入到 HBase"></a>五： 案例一：使用 MapReduce 将本地数据导入到 HBase</h1></li>
<li>在本地创建一个 tsv 格式的文件：fruit.tsv   <img alt="" class="has" height="286" src="https://img-blog.csdnimg.cn/20191001123400511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="949">  <img alt="" class="has" height="293" src="https://img-blog.csdnimg.cn/20191001123430916.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="551">1.   在 HDFS 中创建 input_fruit 文件夹并上传 fruit.tsv 文件   <img alt="" class="has" height="271" src="https://img-blog.csdnimg.cn/20191001140033849.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="662">  <img alt="" class="has" height="256" src="https://img-blog.csdnimg.cn/20191001140415572.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="717">1. 创建 HBase 的fruit表  <img alt="" class="has" height="335" src="https://img-blog.csdnimg.cn/20191001140746465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="522">1. 执行 MapReduce 到 HBase 的 fruit 表中    <img alt="" class="has" height="210" src="https://img-blog.csdnimg.cn/20191001141233513.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1022">  <img alt="" class="has" height="333" src="https://img-blog.csdnimg.cn/20191001145023335.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="900">1.   进入hbase,查看fruit表  <img alt="" class="has" height="403" src="https://img-blog.csdnimg.cn/20191001145335178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="701">  <h1 id="六：自定义-HBase-MapReduce1"><a href="#六：自定义-HBase-MapReduce1" class="headerlink" title="六：自定义 HBase-MapReduce1"></a>六：自定义 HBase-MapReduce1</h1></li>
<li>需求  目标：将 fruit 表中的一部分数据，通过 MR 迁入到 fruit_mr 表中。 1.  创建MAVEN项目  <img alt="" class="has" height="391" src="https://img-blog.csdnimg.cn/20191001160346800.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="342">  <img alt="" class="has" height="590" src="https://img-blog.csdnimg.cn/20191001160359509.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="868"><li>创建ReadFruitMapper.java类   <pre class="has"><code class="language-java">package com.kgf.mr1;</li>
</ol>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.hbase.Cell;<br>import org.apache.hadoop.hbase.CellUtil;<br>import org.apache.hadoop.hbase.client.Put;<br>import org.apache.hadoop.hbase.client.Result;<br>import org.apache.hadoop.hbase.io.ImmutableBytesWritable;<br>import org.apache.hadoop.hbase.mapreduce.TableMapper;<br>import org.apache.hadoop.hbase.util.Bytes;<br>import org.apache.hadoop.mapreduce.Mapper;</p>
<p>/***</p>
<ul>
<li>创建mapper类，读数据</li>
<li>ImmutableBytesWritable：可以看做是rowkey,代表一行数据</li>
<li>Put:这里面封装了一条一条数据</li>
<li>@author KGF</li>
<li></li>
<li>/<br>public class ReadFruitMapper extends TableMapper&lt;ImmutableBytesWritable,Put&gt; &#123;  /***<ul>
<li>map方法处理数据</li>
<li>/<br>@Override<br>protected void map(ImmutableBytesWritable key, Result value,<pre><code>  Mapper&amp;lt;ImmutableBytesWritable, Result, ImmutableBytesWritable, Put&amp;gt;.Context context)
  throws IOException, InterruptedException &#123;
</code></pre>
  //读取数据，使用Put封装数据<br>  Put put = new Put(key.get());<br>  //遍历column<br>  for (Cell cell : value.rawCells()) {<pre><code>  //筛选，我们只需要info列簇的数据
  if(&quot;info&quot;.equals(Bytes.toString(CellUtil.cloneFamily(cell)))) &#123;
      //我们只要列名为name的数据
      if(&quot;name&quot;.equals(Bytes.toString(CellUtil.cloneQualifier(cell)))) &#123;
          //将数据添加到put中
          put.add(cell);
      &#125;
  &#125;
</code></pre>
  }<br>  //将数据写出<br>  context.write(key, put);<br>}</li>
</ul>
</li>
</ul>
<p>}<br></code></pre>   </li><li> 创建WriteFruitMRReducer.java类   <pre class="has"><code class="language-java">package com.kgf.mr1;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.hbase.client.Mutation;<br>import org.apache.hadoop.hbase.client.Put;<br>import org.apache.hadoop.hbase.io.ImmutableBytesWritable;<br>import org.apache.hadoop.hbase.mapreduce.TableReducer;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.mapreduce.Reducer;</p>
<p>/***</p>
<ul>
<li><p>创建reducer类</p>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class WriteFruitMRReducer extends TableReducer&lt;ImmutableBytesWritable, Put,NullWritable&gt;&#123;</p>
<p>  @Override<br>  protected void reduce(ImmutableBytesWritable key, Iterable&lt;Put&gt; values,</p>
<pre><code>      Reducer&amp;lt;ImmutableBytesWritable, Put, NullWritable, Mutation&amp;gt;.Context context)
      throws IOException, InterruptedException &#123;
  for (Put put : values) &#123;
      context.write(NullWritable.get(),put);
  &#125;
</code></pre>
<p>  }<br>}<br></code></pre>   </li><li> 创建Fruit2FruitMRRunner.java类   <pre class="has"><code class="language-java">package com.kgf.mr1;</p>
</li>
</ul>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.hbase.HBaseConfiguration;<br>import org.apache.hadoop.hbase.client.Put;<br>import org.apache.hadoop.hbase.client.Scan;<br>import org.apache.hadoop.hbase.io.ImmutableBytesWritable;<br>import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.util.Tool;<br>import org.apache.hadoop.util.ToolRunner;</p>
<p>/***</p>
<ul>
<li><p>创建Runner</p>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class Fruit2FruitMRRunner implements Tool &#123;</p>
<p>  private Configuration conf;</p>
<p>  public void setConf(Configuration conf) &#123;</p>
<pre><code>  //创建hbase的conf
  this.conf = HBaseConfiguration.create();
</code></pre>
<p>  }</p>
<p>  public Configuration getConf() {</p>
<pre><code>  return this.conf;
</code></pre>
<p>  }</p>
<p>  public int run(String[] args) throws Exception {</p>
<pre><code>  //创建Job
  Job job = Job.getInstance();
  //设置入口jar
  job.setJarByClass(Fruit2FruitMRRunner.class);
  //配置job
  Scan scan = new Scan();
  //设置mapper
  TableMapReduceUtil.initTableMapperJob(&quot;fruit&quot;, 
          scan, 
          ReadFruitMapper.class,ImmutableBytesWritable.class, 
          Put.class, job);
  //设置reducer
  TableMapReduceUtil.initTableReducerJob(&quot;fruit_mr&quot;,WriteFruitMRReducer.class, job);
  job.setNumReduceTasks(1);
  boolean result = job.waitForCompletion(true);
  return result?0:1;
</code></pre>
<p>  }</p>
<p>  public static void main(String[] args) {</p>
<pre><code>  try &#123;
      int status = ToolRunner.run(new Fruit2FruitMRRunner(), args);
      System.out.println(status);
  &#125; catch (Exception e) &#123;
      e.printStackTrace();
  &#125;
</code></pre>
<p>  }</p>
</li>
</ul>
<p>}<br></code></pre>   </li>1.  打成jar包，上传Linux  <img alt="" class="has" height="226" src="https://img-blog.csdnimg.cn/20191001160600622.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="347">1.   在Hbase上创建fruit_mr表  <img alt="" class="has" height="355" src="https://img-blog.csdnimg.cn/20191001160742374.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="584">1.   执行jar包  <img alt="" class="has" height="140" src="https://img-blog.csdnimg.cn/20191001160912374.png" width="1200">  <img alt="" class="has" height="378" src="https://img-blog.csdnimg.cn/20191001162033873.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="649">1.  效果，数据成功导入  <img alt="" class="has" height="269" src="https://img-blog.csdnimg.cn/20191001162201361.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1077"></p>
<h1 id="七：自定义-HBase-MapReduce2"><a href="#七：自定义-HBase-MapReduce2" class="headerlink" title="七：自定义 HBase-MapReduce2"></a>七：自定义 HBase-MapReduce2</h1><ol>
<li>需求：实现将 HDFS 中的数据(fruit.tsv)写入到 HBase 表中(先将fruit表数据清空)。 <li>创建ReadFruitFromHDFSMapper.java类   <pre class="has"><code class="language-java">package com.kgf.mr2;</li>
</ol>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.hbase.client.Put;<br>import org.apache.hadoop.hbase.io.ImmutableBytesWritable;<br>import org.apache.hadoop.hbase.util.Bytes;<br>import org.apache.hadoop.io.LongWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;</p>
<p>/**</p>
<ul>
<li><p>创建mapper类，因为我们是从HDFS上读取数据，所以我们继承的是普通的mapper,</p>
</li>
<li><p>我们读取数据向HBASE中写所以使用ImmutableBytesWritable,Put写出,</p>
</li>
<li><p>读取HDFS上的fruit.tsv中的数据</p>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class ReadFruitFromHDFSMapper extends Mapper&lt;LongWritable, Text, ImmutableBytesWritable,Put&gt; &#123;</p>
<p>  @Override<br>  protected void map(LongWritable key, Text value,</p>
<pre><code>      Mapper&amp;lt;LongWritable, Text, ImmutableBytesWritable, Put&amp;gt;.Context context)
      throws IOException, InterruptedException &#123;
  //读取一行数据
  String[] split = value.toString().split(&quot;\t&quot;);
  byte[] rowkey = Bytes.toBytes(split[0]);
  byte[] name = Bytes.toBytes(split[1]);
  byte[] color = Bytes.toBytes(split[2]);
  //创建Put对象
  Put put = new Put(rowkey);
  //为指定的列族，列添加数据
  put.addColumn(Bytes.toBytes(&quot;info&quot;), Bytes.toBytes(&quot;name&quot;), name);
  put.addColumn(Bytes.toBytes(&quot;info&quot;), Bytes.toBytes(&quot;color&quot;),color);
  
  //写出
  context.write(new ImmutableBytesWritable(rowkey),put);
</code></pre>
<p>  }</p>
</li>
</ul>
<p>}<br></code></pre>   </li><li> 创建Writer2HbaseReducer.java类   <pre class="has"><code class="language-java">package com.kgf.mr2;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.hbase.client.Mutation;<br>import org.apache.hadoop.hbase.client.Put;<br>import org.apache.hadoop.hbase.io.ImmutableBytesWritable;<br>import org.apache.hadoop.hbase.mapreduce.TableReducer;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.mapreduce.Reducer;</p>
<p>public class Writer2HbaseReducer extends TableReducer&lt;ImmutableBytesWritable, Put,NullWritable&gt;&#123;</p>
<pre><code>@Override
protected void reduce(ImmutableBytesWritable key, Iterable&amp;lt;Put&amp;gt; values,
        Reducer&amp;lt;ImmutableBytesWritable, Put, NullWritable, Mutation&amp;gt;.Context context)
        throws IOException, InterruptedException &#123;
    for (Put put : values) &#123;
        context.write(NullWritable.get(),put);
    &#125;
&#125;
</code></pre>
<p>}<br></code></pre>   </li><li>创建HDFS2HbaseRunner.java   <pre class="has"><code class="language-java">package com.kgf.mr2;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.hbase.HBaseConfiguration;<br>import org.apache.hadoop.hbase.client.Put;<br>import org.apache.hadoop.hbase.client.Scan;<br>import org.apache.hadoop.hbase.io.ImmutableBytesWritable;<br>import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.util.Tool;<br>import org.apache.hadoop.util.ToolRunner;</p>
<p>import com.kgf.mr1.Fruit2FruitMRRunner;</p>
<p>public class HDFS2HbaseRunner implements Tool &#123;</p>
<pre><code>private Configuration conf;

public void setConf(Configuration conf) &#123;
    //创建hbase的conf
    this.conf = HBaseConfiguration.create();
&#125;

public Configuration getConf() &#123;
    return this.conf;
&#125;

public int run(String[] args) throws Exception &#123;
    //创建Job
    Job job = Job.getInstance();
    //设置入口jar
    job.setJarByClass(HDFS2HbaseRunner.class);
    //设置mapper
    job.setMapperClass(ReadFruitFromHDFSMapper.class);
    job.setMapOutputKeyClass(ImmutableBytesWritable.class);
    job.setMapOutputValueClass(Put.class);
    
    //设置reducer,OutPutFormat
    TableMapReduceUtil.initTableReducerJob(&quot;fruit&quot;,Writer2HbaseReducer.class, job);
    
    //设置FileInputFormat
    FileInputFormat.addInputPath(job, new Path(&quot;/input_fruit/&quot;));
    job.setNumReduceTasks(1);
    boolean result = job.waitForCompletion(true);
    return result?0:1;
&#125;

public static void main(String[] args) &#123;
    try &#123;
        int status = ToolRunner.run(new Fruit2FruitMRRunner(), args);
        System.out.println(status);
    &#125; catch (Exception e) &#123;
        e.printStackTrace();
    &#125;
&#125;
</code></pre>
<p>}<br></code></pre>   </li>1. 打成jar包，上传Linux  <img alt="" class="has" height="260" src="https://img-blog.csdnimg.cn/20191006231143621.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="732">1. 进入/usr/local/module/hadoop-2.7.2目录下执行jar包  <img alt="" class="has" height="169" src="https://img-blog.csdnimg.cn/2019100623144363.png" width="1110"><img alt="" class="has" height="347" src="https://img-blog.csdnimg.cn/20191007094918730.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="861"> 1. 查看fruit表信息  <img alt="" class="has" height="275" src="https://img-blog.csdnimg.cn/20191007100122765.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1028">       </p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hive知识点入门学习五</title>
    <url>/2021/07/18/Hive%E7%9F%A5%E8%AF%86%E7%82%B9%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%BA%94/</url>
    <content><![CDATA[<p>title: Hive知识点入门学习五<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：函数 </p>
<p>      <img alt="" class="has" height="257" src="https://img-blog.csdnimg.cn/20190825215121162.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="427">       <img alt="" class="has" height="314" src="https://img-blog.csdnimg.cn/20190825215231991.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="627">       <img alt="" class="has" height="277" src="https://img-blog.csdnimg.cn/20190825215259467.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="534">       <img alt="" class="has" height="401" src="https://img-blog.csdnimg.cn/20190825215350821.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="536">       <img alt="" class="has" height="309" src="https://img-blog.csdnimg.cn/20190825215423162.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="563">       <img alt="" class="has" height="405" src="https://img-blog.csdnimg.cn/20190825215500629.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="554"></p>
<h1 id="二：行转列"><a href="#二：行转列" class="headerlink" title="二：行转列"></a>二：行转列</h1><ol>
<li>表结构如下：  <img alt="" class="has" height="190" src="https://img-blog.csdnimg.cn/20190829215916927.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="647">1. 需求：把星座和血型一样的人归类到一起 ，效果如下  <img alt="" class="has" height="81" src="https://img-blog.csdnimg.cn/20190829220254118.png" width="295">1. sql步骤如下  <img alt="" class="has" height="196" src="https://img-blog.csdnimg.cn/20190829221220361.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="711">           sql:        select              t1.base,              concat_ws(‘|’, collect_set(t1.name)) name         from (                    select                           name,                           concat(constellation,’,’,blood_type) as base                    from  person_info                  ) t1 group by t1.base<img alt="" class="has" height="202" src="https://img-blog.csdnimg.cn/20190829221438842.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="507">  <img alt="" class="has" height="418" src="https://img-blog.csdnimg.cn/20190829221644867.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="671">  <img alt="" class="has" height="294" src="https://img-blog.csdnimg.cn/20190829221815775.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="567"><h1 id="三：列转行"><a href="#三：列转行" class="headerlink" title="三：列转行"></a>三：列转行</h1></li>
<li>表结构  <img alt="" class="has" height="189" src="https://img-blog.csdnimg.cn/20190831215607885.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="688">1.  创建表   <img alt="" class="has" height="159" src="https://img-blog.csdnimg.cn/20190831220314536.png" width="520">1. 导入数据   <img alt="" class="has" height="131" src="https://img-blog.csdnimg.cn/20190831220512348.png" width="434">  <img alt="" class="has" height="215" src="https://img-blog.csdnimg.cn/201908312206423.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="710">1. 将数组展开  <img alt="" class="has" height="89" src="https://img-blog.csdnimg.cn/20190831220853427.png" width="759">           sql如下：  <strong>select movie,category_name from movie_info lateral view explode(category) table_temp as category_name;</strong>  <img alt="" class="has" height="282" src="https://img-blog.csdnimg.cn/20190831221355527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="695">1. 数组等相关简介  <img alt="" class="has" height="121" src="https://img-blog.csdnimg.cn/20190831221557350.png" width="889">  <img alt="" class="has" height="412" src="https://img-blog.csdnimg.cn/20190831221629324.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="636">  <img alt="" class="has" height="179" src="https://img-blog.csdnimg.cn/20190831222953324.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="690"> <h1 id="四：youtube项目实战"><a href="#四：youtube项目实战" class="headerlink" title="四：youtube项目实战"></a>四：youtube项目实战</h1></li>
<li>表结构  a：视频表结构相关字段          <img alt="" class="has" height="168" src="https://img-blog.csdnimg.cn/2019090109262326.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="625">  b：用户表         <img alt="" class="has" height="145" src="https://img-blog.csdnimg.cn/20190901092523720.png" width="588">1. 相关原始数据脚本  a：视频数据文件          <img alt="" class="has" height="170" src="https://img-blog.csdnimg.cn/20190901092742237.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="651">  b：用户数据文件          <img alt="" class="has" height="226" src="https://img-blog.csdnimg.cn/20190901092822641.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="377"><li>对原始数据进行ETL编码清洗   通过观察原始数据形式，可以发现，视频可以有多个所属分类，每个所属分类用&amp;符号分割， 且分割的两边有空格字符，同时相关视频也是可以有多个元素，多个相关视频又用“\t”进 行分割。为了分析数据时方便对存在多个子元素的数据进行操作，我们首先进行数据重组清 洗操作。即：将所有的类别用“&amp;”分割，同时去掉两边空格，多个相关视频 id 也使用“&amp;” 进行分割。 ⑴项目：       <img alt="" class="has" height="292" src="https://img-blog.csdnimg.cn/20190901124134443.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="264">  ⑵pom.xml文件          <pre class="has"><code class="language-html">&lt;project xmlns="<a href="http://maven.apache.org/POM/4.0.0&quot;">http://maven.apache.org/POM/4.0.0&quot;</a> xmlns:xsi="<a href="http://www.w3.org/2001/XMLSchema-instance&quot;">http://www.w3.org/2001/XMLSchema-instance&quot;</a> xsi:schemaLocation="<a href="http://maven.apache.org/POM/4.0.0">http://maven.apache.org/POM/4.0.0</a> <a href="http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;">http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</a>&gt;<br>&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;<br>&lt;groupId&gt;com.kgf&lt;/groupId&gt;<br>&lt;artifactId&gt;youtube&lt;/artifactId&gt;<br>&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;</li>
</ol>
<p>  &lt;properties&gt;<br>      &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;<br>  &lt;/properties&gt;</p>
<p>  &lt;dependencies&gt;<br>      &lt;!–引入hadoop依赖  –&gt;<br>      &lt;dependency&gt;<br>       &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;<br>       &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;<br>       &lt;version&gt;2.7.2&lt;/version&gt;<br>      &lt;/dependency&gt;<br>      &lt;dependency&gt;<br>           &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;<br>         &lt;artifactId&gt;hadoop-yarn-server-resourcemanager&lt;/artifactId&gt;<br>         &lt;version&gt;2.7.2&lt;/version&gt;<br>      &lt;/dependency&gt;<br>  &lt;/dependencies&gt;<br>&lt;/project&gt;</code></pre> ⑶ETLUtil工具类 <pre class="has"><code class="language-java">package com.kgf.youtube.utils;</p>
<p>/**</p>
<ul>
<li>对数据文件中的一行数据进行处理</li>
<li>@author KGF</li>
<li></li>
<li>/<br>public class ETLUtil &#123;<br>  //RX24KLBhwMI    lemonette    697    People &amp; Blogs    512    24149    4.22    315    474    t60tW0WevkE    WZgoejVDZlo<br>  public static String getEtlString(String ori) &#123;<pre><code>  StringBuilder sb = new StringBuilder();
  //对数据进行切割
  String[] splitArray = ori.split(&quot;\t&quot;);
  //一行数据中相关视频可以没有，其它相关数据必须存在，否则该条数据作废
  if(splitArray.length&amp;lt;9)return null;
  //因为视频类别是以&amp;amp;连接，我们将中间空格去掉，变成如下效果
  //RX24KLBhwMI    lemonette    697    People&amp;amp;Blogs    512    24149    4.22    315    474    t60tW0WevkE    WZgoejVDZlo
  splitArray[3] = splitArray[3].replaceAll(&quot; &quot;,&quot;&quot;);
  //拼接数据
  for (int i = 0; i &amp;lt; splitArray.length; i++) &#123;
      sb.append(splitArray[i]);
      if(i&amp;lt;9) &#123;
          if(i!=splitArray.length-1) &#123;
              sb.append(&quot;\t&quot;);
          &#125;
      &#125;else &#123;
          if(i!=splitArray.length-1) &#123;
              sb.append(&quot;&amp;amp;&quot;);//这里对相关视频进行特殊处理，使用&amp;amp;连接
          &#125;
      &#125;
  &#125;
  //RX24KLBhwMI    lemonette    697    People&amp;amp;Blogs    512    24149    4.22    315    474    t60tW0WevkE&amp;amp;WZgoejVDZlo
  return sb.toString();
</code></pre>
  }<br>}<br></code></pre> ⑷VideoEtlMapper.java类 <pre class="has"><code class="language-java">package com.kgf.youtube.etl;</li>
</ul>
<p>import java.io.IOException;</p>
<p>import org.apache.commons.lang.StringUtils;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;<br>import com.kgf.youtube.utils.ETLUtil;<br>/**</p>
<ul>
<li><p>读取一行对数据进行处理</p>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class VideoEtlMapper extends Mapper&lt;Object,Text, NullWritable, Text&gt; &#123;</p>
<p>  Text k = new Text();</p>
<p>  @Override<br>  protected void map(Object key, Text value, Mapper&lt;Object, Text, NullWritable, Text&gt;.Context context)</p>
<pre><code>      throws IOException, InterruptedException &#123;
  //对读取的一行数据进行处理
  String etlString = ETLUtil.getEtlString(value.toString());
  if(StringUtils.isNotBlank(etlString)) &#123;
      k.set(etlString);
      context.write(NullWritable.get(),k);
  &#125;
</code></pre>
<p>  }<br>}<br></code></pre> ⑸VideoEtlRunner.java类 <pre class="has"><code class="language-java">package com.kgf.youtube.etl;</p>
</li>
</ul>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.FileSystem;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;<br>import org.apache.hadoop.util.Tool;<br>import org.apache.hadoop.util.ToolRunner;</p>
<p>public class VideoEtlRunner implements Tool &#123;</p>
<pre><code>private Configuration conf = null;

@Override
public void setConf(Configuration conf) &#123;
    this.conf = conf;//使用集群中的conf赋值
&#125;

@Override
public Configuration getConf() &#123;
    return this.conf;
&#125;

@Override
public int run(String[] args) throws Exception &#123;
    //将路径存入conf中
    conf.set(&quot;inpath&quot;,args[0]);
    conf.set(&quot;outpath&quot;,args[1]);
    //获取job对象
    Job job = Job.getInstance(conf);
    //设置jar
    job.setJarByClass(VideoEtlRunner.class);
    //设置mapper
    job.setMapperClass(VideoEtlMapper.class);
    job.setMapOutputKeyClass(NullWritable.class);
    job.setMapOutputValueClass(Text.class);
    //设置reduce
    job.setNumReduceTasks(0);
    //设置输入，输出路径
    initInputJobPath(job);
    initOutputJobPath(job);
    boolean result = job.waitForCompletion(true);
    return result?1:-1;
&#125;

private void initOutputJobPath(Job job) &#123;
    try &#123;
        Configuration conf = job.getConfiguration();
        String outPath = conf.get(&quot;outpath&quot;);//获取conf中的输出路径
        FileSystem fs = FileSystem.get(conf);//获取文件系统对象
        Path path = new Path(outPath);
        if(fs.exists(path))&#123;
            fs.delete(path, true);//删除文件夹，包括子目录
        &#125;
        FileOutputFormat.setOutputPath(job, path);
    &#125; catch (Exception e) &#123;
        e.printStackTrace();
    &#125;
&#125;

private void initInputJobPath(Job job) &#123;
    try &#123;
        Configuration conf = job.getConfiguration();
        String inPath = conf.get(&quot;inpath&quot;);//获取conf中的输出路径
        FileSystem fs = FileSystem.get(conf);//获取文件系统对象
        Path path = new Path(inPath);
        if(fs.exists(path))&#123;
            FileInputFormat.setInputPaths(job, path);
        &#125;else &#123;
            throw new Exception(&quot;inPath not exists&quot;);
        &#125;
    &#125; catch (Exception e) &#123;
        e.printStackTrace();
    &#125;
&#125;

public static void main(String[] args) throws Exception &#123;
    //调用run方法
    int resultCode = ToolRunner.run(new VideoEtlRunner(), args);
    System.out.println(resultCode);
&#125;
</code></pre>
<p>}<br></code></pre> ⑹将代码打成jar上传到集群       <img alt="" class="has" height="208" src="https://img-blog.csdnimg.cn/20190901124457905.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="594">  ⑺将原始数据文件video.txt上传到集群/youtube/video/2008路径下      <img alt="" class="has" height="186" src="https://img-blog.csdnimg.cn/20190901124619827.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="561"> ⑻执行jar生成文件      a：进入到/opt/module/hadoop-2.7.2目录下      b：执行如下命令           hadoop jar ../jars/youtube-0.0.1-SNAPSHOT.jar com.kgf.youtube.etl.VideoEtlRunner           /youtube/video/2008 /youtube/video/output          <img alt="" class="has" height="305" src="https://img-blog.csdnimg.cn/20190901124850213.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="604"> </li>1. 效果  <img alt="" class="has" height="285" src="https://img-blog.csdnimg.cn/20190901124927461.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="589">  <img alt="" class="has" height="279" src="https://img-blog.csdnimg.cn/20190901125028770.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="752"><li>创建表    <img alt="" class="has" height="292" src="https://img-blog.csdnimg.cn/20190901173330821.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="364"><img alt="" class="has" height="174" src="https://img-blog.csdnimg.cn/20190901173428254.png" width="427">  <img alt="" class="has" height="277" src="https://img-blog.csdnimg.cn/2019090117352126.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="450">  <img alt="" class="has" height="179" src="https://img-blog.csdnimg.cn/20190901173547731.png" width="432">   <pre class="has"><code class="language-sql">create table youtube_ori(<br>    videoId string,<br>    uploader string,<br>    age int,<br>    category array&lt;string&gt;,<br>    length int,<br>    views int,<br>    rate float,<br>    ratings int,<br>    comments int,<br>    relatedId array&lt;string&gt;<br>)<br>row format delimited<br>fields terminated by "\t"<br>collection items terminated by "&amp;"<br>stored as textfile; </p>
<p>create table youtube_user_ori(<br>    uploader string,<br>    videos int,<br>    friends int)<br>clustered by (uploader) into 24 buckets<br>row format delimited<br>fields terminated by “\t”<br>stored as textfile;</p>
<p>create table youtube_orc(<br>    videoId string,<br>    uploader string,<br>    age int,<br>    category array&lt;string&gt;,<br>    length int,<br>    views int,<br>    rate float,<br>    ratings int,<br>    comments int,<br>    relatedId array&lt;string&gt;)<br>clustered by (uploader) into 8 buckets<br>row format delimited fields terminated by “\t”<br>collection items terminated by “&amp;”<br>stored as orc;</p>
<p>create table youtube_user_orc(<br>    uploader string,<br>    videos int,<br>    friends int)<br>clustered by (uploader) into 24 buckets<br>row format delimited<br>fields terminated by “\t”<br>stored as orc; </code></pre> <img alt="" class="has" height="50" src="https://img-blog.csdnimg.cn/20190901173813131.png" width="829"><img alt="" class="has" height="232" src="https://img-blog.csdnimg.cn/20190901173855528.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="619"><img alt="" class="has" height="53" src="https://img-blog.csdnimg.cn/20190901173909838.png" width="426"> </li>1. 导入 ETL 后的数据到ori表中  <img alt="" class="has" height="329" src="https://img-blog.csdnimg.cn/20190901174937582.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="787"><img alt="" class="has" height="256" src="https://img-blog.csdnimg.cn/20190901175123561.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="788">1. 向 ORC 表插入数据  a：insert into table youtube_orc select * from youtube_ori;   b：insert into table youtube_user_orc select * from youtube_user_ori;  1. 需求1：统计视频观看数 Top10   SQL:<strong>select videoId,category,views from  youtube_orc order by views desc limit 10;</strong>  <img alt="" class="has" height="353" src="https://img-blog.csdnimg.cn/20190901181041639.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="768">1. 需求2：统计视频类别热度 Top10   <img alt="" class="has" height="233" src="https://img-blog.csdnimg.cn/2019090118113433.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="765">  <img alt="" class="has" height="294" src="https://img-blog.csdnimg.cn/20190901182646488.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="621">  <img alt="" class="has" height="322" src="https://img-blog.csdnimg.cn/20190901182737120.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="574">1. 需求3：统计出视频观看数最高的 20 个视频的所属类别以及类别包含 这 Top20 视频的个数 <img alt="" class="has" height="357" src="https://img-blog.csdnimg.cn/20190901210611997.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="716"><img alt="" class="has" height="283" src="https://img-blog.csdnimg.cn/20190901210707215.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="609">1. 统计视频观看数 Top50 所关联视频的所属类别的热度排名   <img alt="" class="has" height="373" src="https://img-blog.csdnimg.cn/20190901212411101.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="437">  <img alt="" class="has" height="237" src="https://img-blog.csdnimg.cn/20190901212538808.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="569"></p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>Hive知识点入门学习四</title>
    <url>/2021/07/18/Hive%E7%9F%A5%E8%AF%86%E7%82%B9%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E5%9B%9B/</url>
    <content><![CDATA[<p>title: Hive知识点入门学习四<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：分区表 </p>
<ol>
<li>简介  <img alt="" class="has" height="198" src="https://img-blog.csdnimg.cn/20190823212951784.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="745">1. 创建分区表语法   <img alt="" class="has" height="234" src="https://img-blog.csdnimg.cn/20190823213522674.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="601">1.  加载数据到分区表中   <img alt="" class="has" height="282" src="https://img-blog.csdnimg.cn/2019082321412080.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="758">   <img alt="" class="has" height="283" src="https://img-blog.csdnimg.cn/20190823214201146.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="736">1. 查询分区表中数据   <img alt="" class="has" height="317" src="https://img-blog.csdnimg.cn/20190823214419960.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="647">1.  多分区联合查询   <img alt="" class="has" height="230" src="https://img-blog.csdnimg.cn/20190823214530409.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="631">1. 增加分区   ⑴创建单个分区      <img alt="" class="has" height="114" src="https://img-blog.csdnimg.cn/2019082321493483.png" width="585">      <img alt="" class="has" height="207" src="https://img-blog.csdnimg.cn/20190823214954441.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="591"> ⑵同时创建多个分区       <img alt="" class="has" height="91" src="https://img-blog.csdnimg.cn/20190823215112591.png" width="749"> 1. 查看分区表有多少分区   <img alt="" class="has" height="244" src="https://img-blog.csdnimg.cn/20190823215259130.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="557">1.   删除分区   a：删除单个分区        <img alt="" class="has" height="326" src="https://img-blog.csdnimg.cn/20190823215609913.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="608">  b：删除多个分区        <img alt="" class="has" height="346" src="https://img-blog.csdnimg.cn/20190823215700431.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="655"> 1. 创建二级分区表   <img alt="" class="has" height="247" src="https://img-blog.csdnimg.cn/2019082322024328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="585">1.   导入数据  <img alt="" class="has" height="268" src="https://img-blog.csdnimg.cn/20190823220401984.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="743">     <img alt="" class="has" height="308" src="https://img-blog.csdnimg.cn/20190823220433743.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="718"><h1 id="二：把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式"><a href="#二：把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式" class="headerlink" title="二：把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式"></a>二：把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式</h1></li>
<li>方式一：上传数据后修复   ⑴创建目录        <img alt="" class="has" height="125" src="https://img-blog.csdnimg.cn/20190824211553599.png" width="683">        <img alt="" class="has" height="228" src="https://img-blog.csdnimg.cn/20190824211630627.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="586">  ⑵上传数据        <img alt="" class="has" height="124" src="https://img-blog.csdnimg.cn/20190824211752784.png" width="699">        <img alt="" class="has" height="220" src="https://img-blog.csdnimg.cn/20190824211811832.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="652">  ⑶查询数据，发现刚刚上传的20190824没有数据         <img alt="" class="has" height="206" src="https://img-blog.csdnimg.cn/20190824211926590.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="551">  ⑷执行修复命令：msck repair table dept_partition2;       <img alt="" class="has" height="283" src="https://img-blog.csdnimg.cn/20190824212109823.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="572">1. 方式二：上传数据后添加分区    ⑴上传数据         <img alt="" class="has" height="157" src="https://img-blog.csdnimg.cn/20190824212316551.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="726">           <img alt="" class="has" height="210" src="https://img-blog.csdnimg.cn/20190824212340738.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="591">    ⑵执行添加分区         <img alt="" class="has" height="159" src="https://img-blog.csdnimg.cn/20190824212529214.png" width="776">     ⑶查询数据          <img alt="" class="has" height="276" src="https://img-blog.csdnimg.cn/20190824212616933.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="650">1. 方式三：上传数据后 load 数据到分区          ⑴ 创建目录，上传数据             <img alt="" class="has" height="201" src="https://img-blog.csdnimg.cn/20190824212818598.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="793">         ⑵查询数据             <img alt="" class="has" height="300" src="https://img-blog.csdnimg.cn/20190824212924424.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="607"><h1 id="三：修改表"><a href="#三：修改表" class="headerlink" title="三：修改表"></a>三：修改表</h1></li>
<li>重命名表   <img alt="" class="has" height="206" src="https://img-blog.csdnimg.cn/20190824214216327.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="705">1. 增加/修改/替换列信息   <img alt="" class="has" height="409" src="https://img-blog.csdnimg.cn/20190824214406119.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="530">     <h1 id="四：数据导入"><a href="#四：数据导入" class="headerlink" title="四：数据导入"></a>四：数据导入</h1></li>
<li>向表中装载数据（Load）   ⑴语法：load data [local] inpath ‘/opt/module/datas/student.txt’ [overwrite] into table student [partition (partcol1=val1,…)];       <img alt="" class="has" height="260" src="https://img-blog.csdnimg.cn/20190824220523291.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="583"> ⑵实操案例        a：创建一张表              <img alt="" class="has" height="168" src="https://img-blog.csdnimg.cn/20190824220737161.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="687">        b：加载本地文件到 hive               <img alt="" class="has" height="248" src="https://img-blog.csdnimg.cn/20190824221040184.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="683">        c： 上传文件到 HDFS ，加载 HDFS 上数据                <img alt="" class="has" height="298" src="https://img-blog.csdnimg.cn/20190824221324500.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="563">               <img alt="" class="has" height="331" src="https://img-blog.csdnimg.cn/20190824221432772.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="601">       d：加载数据覆盖表中已有的数据             <img alt="" class="has" height="272" src="https://img-blog.csdnimg.cn/20190824221552622.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="628">1.  通过查询语句向表中插入数据（Insert）   <img alt="" class="has" height="379" src="https://img-blog.csdnimg.cn/20190824224156549.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="718">        <img alt="" class="has" height="154" src="https://img-blog.csdnimg.cn/20190824224218340.png" width="653">   <h1 id="五：数据导出"><a href="#五：数据导出" class="headerlink" title="五：数据导出"></a>五：数据导出</h1></li>
<li>将查询的结果格式化导出到本地     命令：insert overwrite local directory ‘/opt/module/datas/export/student’             row format delimited fields terminated by ‘\t’ select * from student ;   <img alt="" class="has" height="321" src="https://img-blog.csdnimg.cn/20190825130935356.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="690">    <img alt="" class="has" height="218" src="https://img-blog.csdnimg.cn/20190825131402981.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="537">   1. 将查询的结果导出到 HDFS 上(没有 local)   命令：insert overwrite directory ‘/user/kgf/student’ row format delimited fields terminated by ‘\t’ select * from student；  <img alt="" class="has" height="350" src="https://img-blog.csdnimg.cn/20190825131553463.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="679">   <img alt="" class="has" height="334" src="https://img-blog.csdnimg.cn/20190825131631583.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="657">1. Hadoop 命令导出到本地   命令：dfs -get /user/hive/warehouse/dept_partition2/month=201907/day=23 /opt/module/datas/export/;  <img alt="" class="has" height="307" src="https://img-blog.csdnimg.cn/20190825132150261.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="660">  <img alt="" class="has" height="280" src="https://img-blog.csdnimg.cn/20190825132221332.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="576">1.  Hive Shell 命令导出   <img alt="" class="has" height="135" src="https://img-blog.csdnimg.cn/20190825132534284.png" width="784">1.  Export 导出到 HDFS 上    <img alt="" class="has" height="59" src="https://img-blog.csdnimg.cn/20190825132710154.png" width="758">1. 清除表中数据（Truncate）   <img alt="" class="has" height="97" src="https://img-blog.csdnimg.cn/20190825133323839.png" width="630"><h1 id="六：每个-MapReduce-内部排序（Sort-By）"><a href="#六：每个-MapReduce-内部排序（Sort-By）" class="headerlink" title="六：每个 MapReduce 内部排序（Sort By）"></a>六：每个 MapReduce 内部排序（Sort By）</h1></li>
</ol>
<p>     <img alt="" class="has" height="376" src="https://img-blog.csdnimg.cn/20190825140241161.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="705"></p>
<h1 id="七：分区排序（Distribute-By）"><a href="#七：分区排序（Distribute-By）" class="headerlink" title="七：分区排序（Distribute By）"></a>七：分区排序（Distribute By）</h1><p>      <img alt="" class="has" height="174" src="https://img-blog.csdnimg.cn/20190825141106860.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="742">       <img alt="" class="has" height="94" src="https://img-blog.csdnimg.cn/20190825141136668.png" width="631">       <img alt="" class="has" height="116" src="https://img-blog.csdnimg.cn/20190825141157763.png" width="689">      </p>
<h1 id="八：-Cluster-By"><a href="#八：-Cluster-By" class="headerlink" title="八： Cluster By"></a>八： Cluster By</h1><p>       <img alt="" class="has" height="285" src="https://img-blog.csdnimg.cn/20190825141251326.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="667"></p>
<h1 id="九：分桶及抽样查询"><a href="#九：分桶及抽样查询" class="headerlink" title="九：分桶及抽样查询"></a>九：分桶及抽样查询</h1><ol>
<li>分桶表数据存储简介  <img alt="" class="has" height="170" src="https://img-blog.csdnimg.cn/20190825144141196.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="772">1. 数据准备  <img alt="" class="has" height="349" src="https://img-blog.csdnimg.cn/20190825162434915.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="434">  1. 创建分桶表   <img alt="" class="has" height="173" src="https://img-blog.csdnimg.cn/2019082516353533.png" width="560">  创建的表以id进行分区和排序，并且分为4桶。  <img alt="" class="has" height="330" src="https://img-blog.csdnimg.cn/20190825163854806.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="403">1. 数据通过子查询的方式导入到分桶表中 （<strong>直接导入没有效果</strong>）  a：先建一个普通的 stu 表 ，向普通的 stu 表中导入数据          <img alt="" class="has" height="185" src="https://img-blog.csdnimg.cn/2019082516440926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="571">        <img alt="" class="has" height="411" src="https://img-blog.csdnimg.cn/20190825164607253.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="622">  b：设置一个属性 ，打开分桶        <img alt="" class="has" height="219" src="https://img-blog.csdnimg.cn/20190825165330800.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="476">  c：通过子查询导入        命令：insert into table stu_buck select id,name from stu;         <img alt="" class="has" height="321" src="https://img-blog.csdnimg.cn/20190825165803884.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="650">1. 分桶抽样查询    <img alt="" class="has" height="312" src="https://img-blog.csdnimg.cn/20190825170452928.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="622">   <img alt="" class="has" height="142" src="https://img-blog.csdnimg.cn/20190825170522678.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="619">   <img alt="" class="has" height="193" src="https://img-blog.csdnimg.cn/20190825170723319.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="640">1. 数据块抽样   <img alt="" class="has" height="230" src="https://img-blog.csdnimg.cn/20190825170903313.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="691"></li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>MapReduce之Hadoop序列化,MapTask  工作机制，CombineTextInputFormat 切片机制，Partition 分区，WritableComparable 排序</title>
    <url>/2021/07/18/MapReduce%E4%B9%8BHadoop%E5%BA%8F%E5%88%97%E5%8C%96,MapTask%20%C2%A0%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%EF%BC%8CCombineTextInputFormat%20%E5%88%87%E7%89%87%E6%9C%BA%E5%88%B6%EF%BC%8CPartition%20%E5%88%86%E5%8C%BA%EF%BC%8CWritableComparable%20%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<p>title: MapReduce之Hadoop序列化,MapTask  工作机制，CombineTextInputFormat 切片机制，Partition 分区，WritableComparable 排序<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：Hadoop序列化</p>
<ol>
<li>为什么要序列化？  <img alt="" class="has" height="144" src="https://img-blog.csdnimg.cn/20190727221421643.png" width="701">1. 什么是序列化？  <img alt="" class="has" height="166" src="https://img-blog.csdnimg.cn/20190727221450619.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="668"> 1.  为什么不用 Java ？  <img alt="" class="has" height="137" src="https://img-blog.csdnimg.cn/20190727221518294.png" width="711">1.   为什么序列化对 Hadoop  很重要？  <img alt="" class="has" height="374" src="https://img-blog.csdnimg.cn/20190727221546511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="587">1.  常用数据序列化类型  <img alt="" class="has" height="283" src="https://img-blog.csdnimg.cn/20190727221638148.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="550">1.   自定义 bean  对象 实现序列化接口（Writable ）  ⑴自定义 bean 对象要想序列化传输，必须实现序列化接口，需要注意以下 7 项：         a：必须实现 Writable 接口         b：反序列化时，需要反射调用空参构造函数，所以必须有空参构造。         c：重写序列化方法         d：重写反序列化方法         e：注意反序列化的顺序和序列化的顺序完全一致         f：要想把结果显示在文件中，需要重写 toString()，可用”\t”分开，方便后续用         g：如果需要将自定义的 bean 放在 key 中传输，则还需要实现 comparable 接口，因为               mapreduce 框中的 shuffle 过程一定会对 key 进行排序。<li>  案例之流量汇总   ⑴需求：           统计每一个手机号耗费的总上行流量、下行流量、总流量(序列化)   ⑵数据准备(phone_data.txt)，数据格式如下，现在我们只知道每一行倒数第二个是下行流量，       倒数第三个是上行流量，总流量需要自己去算，第二个是手机号。           <img alt="" class="has" height="316" src="https://img-blog.csdnimg.cn/20190727223341939.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="557">   ⑶最后输出的数据格式大概如下：         <img alt="" class="has" height="120" src="https://img-blog.csdnimg.cn/20190727223727598.png" width="475">   ⑷基本思路分析如下：         ①Map 阶段                 <img alt="" class="has" height="79" src="https://img-blog.csdnimg.cn/20190727224459494.png" width="426">         ②Reduce 阶段                <img alt="" class="has" height="111" src="https://img-blog.csdnimg.cn/20190727224612980.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="474">                <img alt="" class="has" height="84" src="https://img-blog.csdnimg.cn/20190727224638661.png" width="474">   ⑸代码实现如下：          ①首先定义一个bean序列化对象                 <pre class="has"><code class="language-java">package com.kgf.mapreduce.flowsum;</li>
</ol>
<p>import java.io.DataInput;<br>import java.io.DataOutput;<br>import java.io.IOException;<br>import org.apache.hadoop.io.Writable;</p>
<p>/**</p>
<ul>
<li><p>首先我们需要实现序列化接口Writable</p>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class FlowBean implements Writable&#123;</p>
<p>  /<strong>上行流量</strong>/<br>  private long upFlow;<br>  /<strong>下行流量</strong>/<br>  private long downFlow;<br>  /<strong>总流量</strong>/<br>  private long sumFlow;<br>  /**</p>
<ul>
<li>必须要有无参构造方法</li>
<li>反序列化时，需要反射调用空参构造函数，所以必须有空参构造</li>
<li>/<br>public FlowBean() &#123;<br>  super();<br>&#125;</li>
</ul>
<p>  public void setFlowBean(long upFlow, long downFlow) &#123;</p>
<pre><code>  this.upFlow = upFlow;
  this.downFlow = downFlow;
  this.sumFlow = upFlow+downFlow;//总流量等于上行流量加上下行流量
</code></pre>
<p>  }</p>
<p>  public FlowBean(long upFlow, long downFlow) {</p>
<pre><code>  this.upFlow = upFlow;
  this.downFlow = downFlow;
  this.sumFlow = upFlow+downFlow;//总流量等于上行流量加上下行流量
</code></pre>
<p>  }</p>
<p>  /***</p>
<ul>
<li>这个是序列化方法:这个方法其实就是mapper阶段向Reduce阶段写数据的过程</li>
<li>/<br>@Override<br>public void write(DataOutput out) throws IOException {<br>  //按照顺序依次将数据写入<br>  out.writeLong(upFlow);<br>  out.writeLong(downFlow);<br>  out.writeLong(sumFlow);<br>}</li>
</ul>
<p>  /**</p>
<ul>
<li>这个是反序列化方法</li>
<li>/<br>@Override<br>public void readFields(DataInput in) throws IOException {<br>  //这个反序列化顺序要和上面序列化顺序保持一致<br>  this.upFlow = in.readLong();<br>  this.downFlow = in.readLong();<br>  this.sumFlow = in.readLong();<br>}</li>
</ul>
<p>  @Override<br>  public String toString() {</p>
<pre><code>  return upFlow + &quot;\t&quot; + downFlow + &quot;\t&quot; + sumFlow;//可用”\t”分开，方便后续用
</code></pre>
<p>  }</p>
<p>  public long getUpFlow() {</p>
<pre><code>  return upFlow;
</code></pre>
<p>  }</p>
<p>  public void setUpFlow(long upFlow) {</p>
<pre><code>  this.upFlow = upFlow;
</code></pre>
<p>  }</p>
<p>  public long getDownFlow() {</p>
<pre><code>  return downFlow;
</code></pre>
<p>  }</p>
<p>  public void setDownFlow(long downFlow) {</p>
<pre><code>  this.downFlow = downFlow;
</code></pre>
<p>  }</p>
<p>  public long getSumFlow() {</p>
<pre><code>  return sumFlow;
</code></pre>
<p>  }</p>
<p>  public void setSumFlow(long sumFlow) {</p>
<pre><code>  this.sumFlow = sumFlow;
</code></pre>
<p>  }</p>
</li>
</ul>
<p>}<br></code></pre>     ⑵自定义mapper对象 <pre class="has"><code class="language-java">package com.kgf.mapreduce.flowsum;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.io.LongWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;</p>
<p>/**</p>
<ul>
<li><p>继承Mapper接口：定义输入和输出参数</p>
</li>
<li><p>输入参数：第一个是数据行号，第二个是一行数据</p>
</li>
<li><p>输出参数：第一个是手机号，第二个是自定义的实体对象</p>
</li>
<li><p>@author kgf</p>
</li>
<li></li>
<li><p>/<br>public class FlowMapper extends Mapper&lt;LongWritable,Text, Text,FlowBean&gt;&#123;</p>
<p>  //定义输出参数<br>  Text k = new Text();<br>  FlowBean v = new FlowBean();</p>
<p>  @Override<br>  protected void map(LongWritable key, Text value,Context context)</p>
<pre><code>      throws IOException, InterruptedException &#123;
  
  //1:获取一行数据
  String line = value.toString();
  //2:对数据进行切割，这里数据间的是以制表符分割的，就是tab
  String[] fields = line.split(&quot;\t&quot;);
  //3:获取我们需要的数据
  String phoneNum = fields[1];//手机号
  long upFlow = Long.parseLong(fields[fields.length-3]);//上行流量
  long downFlow = Long.parseLong(fields[fields.length-2]);//下行流量
  //封装数据
  v.setFlowBean(upFlow,downFlow);
  k.set(phoneNum);
  
  //写出数据
  context.write(k, v);
</code></pre>
<p>  }</p>
</li>
</ul>
<p>}<br></code></pre>    ⑶自定义FlowReducer <pre class="has"><code class="language-java">package com.kgf.mapreduce.flowsum;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Reducer;</p>
<p>/**</p>
<ul>
<li><p>继承Reducer接口：</p>
</li>
<li><p>输入参数：手机号–&gt;自定义bean对象</p>
</li>
<li><p>输出参数：手机号–&gt;自定义bean对象</p>
</li>
<li><p>@author 86136</p>
</li>
<li></li>
<li><p>/<br>public class FlowReducer extends Reducer&lt;Text, FlowBean, Text, FlowBean&gt;&#123;</p>
<p>  @Override<br>  protected void reduce(Text key, Iterable&lt;FlowBean&gt; values,Context context)</p>
<pre><code>      throws IOException, InterruptedException &#123;
  //1：因为可能存在多条相同的手机号码，所以我们需要对相同的key数据进行数据汇总
  long sum_upFlow = 0;
  long sum_downFlow =0;
  
  //2:求和累加
  for (FlowBean flowBean : values) &#123;
      sum_upFlow+=flowBean.getUpFlow();
      sum_downFlow+=flowBean.getDownFlow();
  &#125;
  
  FlowBean flowBean = new FlowBean(sum_upFlow,sum_downFlow);
  //3：输出数据
  context.write(key, flowBean);
</code></pre>
<p>  }</p>
</li>
</ul>
<p>}<br></code></pre>   ⑷自定义FlowDriver <pre class="has"><code class="language-java">package com.kgf.mapreduce.flowsum;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</p>
<p>public class FlowDriver &#123;</p>
<pre><code>public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123;
    //1:获取job对象
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf);
    
    //2:设置jar包路径
    job.setJarByClass(FlowDriver.class);
    
    //3:管理自定义的Mapper和Reducer类
    job.setMapperClass(FlowMapper.class);
    job.setReducerClass(FlowReducer.class);
    
    //4:Mapper输出类型
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(FlowBean.class);
    
    //5：Reducer输出类型
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(FlowBean.class);
    
    //6：设置输出路径
    FileInputFormat.setInputPaths(job,new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    //7：提交
    boolean result = job.waitForCompletion(true);
    System.exit(result?0:1);
&#125;
</code></pre>
<p>}<br></code></pre> ⑸本地测试      a：设置运行的环境变量             <img alt="" class="has" height="163" src="https://img-blog.csdnimg.cn/20190728001704387.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="263">              在输入目录下数据文件已经准备好。               <img alt="" class="has" height="196" src="https://img-blog.csdnimg.cn/20190728001720271.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="428">       b：效果（具体结果自己可以校验一下）             <img alt="" class="has" height="138" src="https://img-blog.csdnimg.cn/20190728001818909.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="301">             <img alt="" class="has" height="313" src="https://img-blog.csdnimg.cn/20190728001908764.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="387">    </li></p>
<h1 id="二：MapTask-工作机制"><a href="#二：MapTask-工作机制" class="headerlink" title="二：MapTask  工作机制"></a>二：MapTask  工作机制</h1><ol>
<li> 简介         maptask 的并行度决定 map 阶段的任务处理并发度，进而影响到整个 job 的处理速度。 一个 job 的 map 阶段 MapTask 并行度（个数），由客户端提交 job 时的切片个数决定1.  MapTask 并行度决定机制         <img alt="" class="has" height="428" src="https://img-blog.csdnimg.cn/2019072808544236.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="528">     <h1 id="三：CombineTextInputFormat-切片机制"><a href="#三：CombineTextInputFormat-切片机制" class="headerlink" title="三：CombineTextInputFormat 切片机制"></a>三：CombineTextInputFormat 切片机制</h1></li>
<li>关于大量小文件的优化策略       <img alt="" class="has" height="113" src="https://img-blog.csdnimg.cn/20190728101550887.png" width="598">1. 优化策略        <img alt="" class="has" height="296" src="https://img-blog.csdnimg.cn/20190728101655451.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="535">1. 案例之大量小文件的切片优化   ⑴现在我们就使用之前的WordCount案例来测试，我们在输入路径下放入多个很小的文件，来使用WordCount       去计算，我们看看默认的切片机制，以及创建了几个maptask？        <img alt="" class="has" height="222" src="https://img-blog.csdnimg.cn/20190728103453328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="604">       看运行结果和日志：       <img alt="" class="has" height="215" src="https://img-blog.csdnimg.cn/20190728103622869.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="674">      通过上面的日志可以发现，6个很小的文件在计算的时候却分为6个切片，开了6个maptask，肯定是      不太好的，处理效率极其低下，那么我们如何将其合为一个切片呢？    ⑵解决方案，在 WordcountDriver 中增加如下代码         <img alt="" class="has" height="333" src="https://img-blog.csdnimg.cn/20190728105228277.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="347">         效果（可以发现只分了一个切片，只开了一个maptask）：         <img alt="" class="has" height="195" src="https://img-blog.csdnimg.cn/2019072810530220.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="504">          <h1 id="四：Partition-分区"><a href="#四：Partition-分区" class="headerlink" title="四：Partition 分区"></a>四：Partition 分区</h1></li>
<li>要求将统计结果按照条件输出到不同文件中（分区）。比如：将统计结果按照手机归属地不同省份输出到不同文件中（分区）。1. 默认分区     <img alt="" class="has" height="226" src="https://img-blog.csdnimg.cn/2019072811064097.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="566">1. 自定义 Partitioner 分区   <img alt="" class="has" height="364" src="https://img-blog.csdnimg.cn/20190728131935896.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="442">1.  在 job 驱动中，设置自定义 partitioner   <img alt="" class="has" height="378" src="https://img-blog.csdnimg.cn/20190728132941914.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="395">   注意：   <img alt="" class="has" height="334" src="https://img-blog.csdnimg.cn/20190728133023471.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="515">1.   运行效果   <img alt="" class="has" height="271" src="https://img-blog.csdnimg.cn/20190728133157912.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="375">         如下：第一个分区都是136的，后面都是根据不同手机号在不同的分区。   <img alt="" class="has" height="189" src="https://img-blog.csdnimg.cn/20190728133232505.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="485"><h1 id="五：WritableComparable-排序"><a href="#五：WritableComparable-排序" class="headerlink" title="五：WritableComparable 排序"></a>五：WritableComparable 排序</h1></li>
<li>简介        排序是 MapReduce 框架中最重要的操作之一。Map Task 和 Reduce Task 均会对数据（按照 key）进行排序。 该操作属于 Hadoop 的默认行为。任何应用程序中的数据均会被排序，而不管逻辑上是否需要。默认排序是按照字 典顺序排序，且实现该排序的方法是快速排序。        对于 Map Task，它会将处理的结果暂时放到一个缓冲区中，当缓冲区使用率达到一定阈值后，再对缓冲区中的 数据进行一次排序，并将这些有序数据写到磁盘上，而当数据处理完毕后，它会对磁盘上所有文件进行一次合并， 以将这些文件合并成一个大的有序文件。        对于 Reduce Task，它从每个 Map Task 上远程拷贝相应的数据文件，如果文件大小超过一定阈值，则放到磁盘上， 否则放到内存中。如果磁盘上文件数目达到一定阈值，则进行一次合并以生成一个更大文件；如果内存中文件大小或者 数目超过一定阈值，则进行一次合并后将数据写到磁盘上。当所有数据拷贝完毕后，Reduce Task 统一对内存和磁盘上 的所有数据进行一次合并。1.  排序的分类      ⑴部分排序                 MapReduce 根据输入记录的键对数据集排序。保证输出的每个文件内部排序。      ⑵全排序                 <img alt="" class="has" height="229" src="https://img-blog.csdnimg.cn/20190728144810792.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="524">       ⑶辅助排序：（GroupingComparator 分组）                <img alt="" class="has" height="152" src="https://img-blog.csdnimg.cn/2019072814493740.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="517">       ⑷二次排序                在自定义排序过程中，如果 compareTo 中的判断条件为两个即为二次排序。       ⑸自定义排序 WritableComparable            bean 对象实现 WritableComparable 接口重写 compareTo 方法，就可以实现排序 <li>案例之手机流量按总流量进行倒序排序       ⑴数据准备               <img alt="" class="has" height="313" src="https://img-blog.csdnimg.cn/20190728154515743.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="415">       ⑵自定义Bean对象实现WritableComparable接口，重写 compareTo 方法 <pre class="has"><code class="language-java">package com.kgf.mapreduce.flowsort;</li>
</ol>
<p>import java.io.DataInput;<br>import java.io.DataOutput;<br>import java.io.IOException;<br>import org.apache.hadoop.io.WritableComparable;</p>
<p>public class FlowSortBean implements WritableComparable&lt;FlowSortBean&gt;&#123;</p>
<pre><code>/**上行流量**/
private long upFlow;
/**下行流量**/
private long downFlow;
/**总流量**/
private long sumFlow;
/**
 * 必须要有无参构造方法
 * 反序列化时，需要反射调用空参构造函数，所以必须有空参构造
 */
public FlowSortBean() &#123;
    super();
&#125;

public void setFlowSortBean(long upFlow, long downFlow) &#123;
    this.upFlow = upFlow;
    this.downFlow = downFlow;
    this.sumFlow = upFlow+downFlow;//总流量等于上行流量加上下行流量
&#125;

public FlowSortBean(long upFlow, long downFlow) &#123;
    this.upFlow = upFlow;
    this.downFlow = downFlow;
    this.sumFlow = upFlow+downFlow;//总流量等于上行流量加上下行流量
&#125;

/***
 * 这个是序列化方法:这个方法其实就是mapper阶段向Reduce阶段写数据的过程
 */
@Override
public void write(DataOutput out) throws IOException &#123;
    //按照顺序依次将数据写入
    out.writeLong(upFlow);
    out.writeLong(downFlow);
    out.writeLong(sumFlow);
&#125;

/**
 * 这个是反序列化方法
 */
@Override
public void readFields(DataInput in) throws IOException &#123;
    //这个反序列化顺序要和上面序列化顺序保持一致
    this.upFlow = in.readLong();
    this.downFlow = in.readLong();
    this.sumFlow = in.readLong();
&#125;

@Override
public String toString() &#123;
    return upFlow + &quot;\t&quot; + downFlow + &quot;\t&quot; + sumFlow;//可用”\t”分开，方便后续用
&#125;

public long getUpFlow() &#123;
    return upFlow;
&#125;

public void setUpFlow(long upFlow) &#123;
    this.upFlow = upFlow;
&#125;

public long getDownFlow() &#123;
    return downFlow;
&#125;

public void setDownFlow(long downFlow) &#123;
    this.downFlow = downFlow;
&#125;

public long getSumFlow() &#123;
    return sumFlow;
&#125;

public void setSumFlow(long sumFlow) &#123;
    this.sumFlow = sumFlow;
&#125;

/**
 * 按照总流量的倒序排序
 */
@Override
public int compareTo(FlowSortBean o) &#123;
    return (int) (this.sumFlow-o.getSumFlow());
&#125;
</code></pre>
<p>}<br></code></pre>   ⑶自定义Mapper类 <pre class="has"><code class="language-java">package com.kgf.mapreduce.flowsort;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.io.LongWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;</p>
<p>/**</p>
<ul>
<li><p>我们需要将排序的参数作为KEY</p>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class FlowSortMapper extends Mapper&lt;LongWritable,Text,FlowSortBean,Text&gt;&#123;</p>
<p>  FlowSortBean k = new FlowSortBean();<br>  Text v = new Text();</p>
<p>  @Override<br>  protected void map(LongWritable key, Text value,Context context)</p>
<pre><code>      throws IOException, InterruptedException &#123;
  //1：获取一行数据
  String line = value.toString();
  //2:切割数据
  String[] fields = line.split(&quot;\t&quot;);
  //3:封装对象
  long upFlow = Long.parseLong(fields[1]);//上行流量
  long downFlow = Long.parseLong(fields[2]);//下行流量
  
  k.setFlowSortBean(upFlow, downFlow);
  v.set(fields[0]);
  
  //4：将数据写出
  context.write(k, v);
</code></pre>
<p>  }</p>
</li>
</ul>
<p>}<br></code></pre>   ⑷自定义Reducer类        <img alt="" class="has" height="259" src="https://img-blog.csdnimg.cn/2019072816005613.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="429">    ⑸自定义Driver类 <pre class="has"><code class="language-java">package com.kgf.mapreduce.flowsort;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</p>
<p>public class FlowSortDriver &#123;</p>
<pre><code>public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123;
    //1:获取job对象
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf);
    
    //2:设置jar包路径
    job.setJarByClass(FlowSortDriver.class);
    
    //3:设置自定义的mapper和Reducer类
    job.setMapperClass(FlowSortMapper.class);
    job.setReducerClass(FlowSortReducer.class);
    
    //4:设置mapper输出的k,v类型
    job.setMapOutputKeyClass(FlowSortBean.class);
    job.setMapOutputValueClass(Text.class);
    
    //5:设置reducer的输出类型
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(FlowSortBean.class);
    
    //6：设置输入输出路径
    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job,new Path(args[1]));
    
    //7:提交
    boolean result = job.waitForCompletion(true);
    System.exit(result?0:1);
&#125;
</code></pre>
<p>}<br></code></pre>   ⑹运行效果         <img alt="" class="has" height="235" src="https://img-blog.csdnimg.cn/20190728160205523.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="460">        <img alt="" class="has" height="365" src="https://img-blog.csdnimg.cn/20190728160235175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="488"> </li>1.  在上面排序的基础上，将不同省份的手机号输出到不同的文件中，并且内部排序    ⑴增加分区类           <img alt="" class="has" height="297" src="https://img-blog.csdnimg.cn/20190728162325650.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="377">             ⑵在Driver中引入自定义的分区          <img alt="" class="has" height="365" src="https://img-blog.csdnimg.cn/20190728162411687.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="361">   ⑶效果：         <img alt="" class="has" height="209" src="https://img-blog.csdnimg.cn/20190728162438778.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="407">        里面的每个文件内容都排了序：        <img alt="" class="has" height="258" src="https://img-blog.csdnimg.cn/20190728162529395.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="538"></p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>MapReduce之Shuffle机制以及小文件处理案例（自定义 InputFormat），OutputFormat 案例</title>
    <url>/2021/07/18/MapReduce%E4%B9%8BShuffle%E6%9C%BA%E5%88%B6%E4%BB%A5%E5%8F%8A%E5%B0%8F%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B%EF%BC%88%E8%87%AA%E5%AE%9A%E4%B9%89%20InputFormat%EF%BC%89%EF%BC%8COutputFormat%20%E6%A1%88%E4%BE%8B/</url>
    <content><![CDATA[<p>title: MapReduce之Shuffle机制以及小文件处理案例（自定义 InputFormat），OutputFormat 案例<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：Shuffle机制</p>
<ol>
<li>简介        Mapreduce 确保每个 reducer 的输入都是按键排序的。系统执行排序的过程（即将 map 输出作为输入传给 reducer）称为 shuffle。   <img alt="" class="has" height="298" src="https://img-blog.csdnimg.cn/20190801211802997.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="511">1.  详细流程如下：  <img alt="" class="has" height="350" src="https://img-blog.csdnimg.cn/20190801213915875.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="415">          <h1 id="二：小文件处理案例（自定义-InputFormat）"><a href="#二：小文件处理案例（自定义-InputFormat）" class="headerlink" title="二：小文件处理案例（自定义 InputFormat）"></a>二：小文件处理案例（自定义 InputFormat）</h1></li>
<li>需求：      无论 hdfs 还是 mapreduce，对于小文件都有损效率，实践中，又难免面临处理大量小文 件的场景，此时，就需要有相应解决方案。将多个小文件合并成一个文件 SequenceFile， SequenceFile 里面存储着多个文件，存储的形式为文件路径+名称为 key，文件内容为 value。1. 分析，小文件的优化无非以下几种方式：   a：在数据采集的时候，就将小文件或小批数据合成大文件再上传 HDFS   b：在业务处理之前，在 HDFS 上使用 mapreduce 程序对小文件进行合并   c：在 mapreduce 处理时，可采用 CombineTextInputFormat 提高效率 <img alt="" class="has" height="295" src="https://img-blog.csdnimg.cn/2019080122024881.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="477">1.  数据准备（准备如下三个小文件）：  <img alt="" class="has" height="205" src="https://img-blog.csdnimg.cn/20190804081453104.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="392"><li>具体实现如下：   ⑴自定义 InputFromat             <pre class="has"><code class="language-java">package com.kgf.mapreduce.inputformat;</li>
</ol>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.BytesWritable;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.mapreduce.InputSplit;<br>import org.apache.hadoop.mapreduce.JobContext;<br>import org.apache.hadoop.mapreduce.RecordReader;<br>import org.apache.hadoop.mapreduce.TaskAttemptContext;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</p>
<p>/**</p>
<ul>
<li>自定义WholeFileInputformat,主要是在自定义的mapper读取数据之前对数据进行处理，然后传给mapper：</li>
<li>这里我们的key是NullWritable，因为我们每次读取的是一个小文件，不需要关注行号等等。</li>
<li>value是BytesWritable，字节数组，代表的是我们每次读取的一个小文件，然后将这个文件内容传递给mapper</li>
<li>@author KGF</li>
<li></li>
<li>/<br>public class WholeFileInputformat extends FileInputFormat&lt;NullWritable,BytesWritable&gt;&#123;<br>  /***<ul>
<li>设置每个小文件不可分片,保证一个小文件生成一个key-value键值对</li>
<li>/<br>@Override<br>protected boolean isSplitable(JobContext context, Path filename) &#123;<br>  return false;<br>&#125;<br>/**</li>
<li>自定义需重写父类RecordReader方法，自定义读取文件的方式</li>
<li>split：表示的是我们每次读取一个小文件时的切片信息</li>
<li>context：代表上下文信息</li>
<li>/<br>@Override<br>public RecordReader&lt;NullWritable, BytesWritable&gt; createRecordReader(InputSplit split,<pre><code>  TaskAttemptContext context)
  throws IOException, InterruptedException &#123;
</code></pre>
  //创建自定义的RecordReader对象<br>  WholeFileRecordReader record = new WholeFileRecordReader();<br>  //初始化record中的方法<br>  record.initialize(split, context);<br>  return record;<br>}</li>
</ul>
</li>
</ul>
<p>}<br></code></pre> ⑵自定义WholeFileRecordReader <pre class="has"><code class="language-java">package com.kgf.mapreduce.inputformat;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.FSDataInputStream;<br>import org.apache.hadoop.fs.FileSystem;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.BytesWritable;<br>import org.apache.hadoop.io.IOUtils;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.mapreduce.InputSplit;<br>import org.apache.hadoop.mapreduce.RecordReader;<br>import org.apache.hadoop.mapreduce.TaskAttemptContext;<br>import org.apache.hadoop.mapreduce.lib.input.FileSplit;</p>
<p>/***</p>
<ul>
<li><p>该类主要用来读取每个小文件内容</p>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class WholeFileRecordReader extends RecordReader&lt;NullWritable, BytesWritable&gt;&#123;<br>  //创建返回结果对象<br>  BytesWritable v = new BytesWritable();<br>  //当前读取进度，默认没有读<br>  boolean isProgress = false;<br>  FileSplit fileSplit;<br>  Configuration conf;<br>  /***</p>
<ul>
<li>初始化方法：</li>
<li>split:表示传递过来的文件切片</li>
<li>/<br>@Override<br>public void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException &#123;<br>  //1：首先我们需要将切片转换为FileSplit<br>  this.fileSplit = (FileSplit) split;<br>  //2:获取上下文配置信息<br>  conf = context.getConfiguration();<br>&#125;</li>
</ul>
<p>  /***</p>
<ul>
<li>读取一个一个文件</li>
<li>/<br>@Override<br>public boolean nextKeyValue() throws IOException, InterruptedException &#123;<br>  //开始读取文件，我们有三个小文件，所以它要读取3次<br>  FileSystem fs = null;<br>  FSDataInputStream fis = null;<br>  if(!isProgress) &#123;//判断状态，程序没有读取文件时，我们就可以开始读了<pre><code>  try &#123;
      //定义一个缓冲区对象，大小就是一个小文件的大小
      byte[] buf = new byte[(int) fileSplit.getLength()];
      //获取文件路径
      Path path = this.fileSplit.getPath();
      //获取文件系统对象
      fs = path.getFileSystem(conf);
      //打开文件输入流
      fis = fs.open(path);
      //流的拷贝,将读取的文件拷贝到缓冲区中
      IOUtils.readFully(fis, buf, 0, buf.length);
      //最后我们将缓冲区的数据拷贝到最终输出的对象中
      v.set(buf, 0, buf.length);
      //是否继续读文件，防止重复读,当下一个小文件进来时，这里的变量就会重新初始化为false
      isProgress = true;
      return true;
  &#125; catch (Exception e) &#123;
      e.printStackTrace();
  &#125;finally &#123;
      IOUtils.closeStream(fs);
      IOUtils.closeStream(fis);
  &#125;
</code></pre>
  }<br>  return false;<br>}<br>/**</li>
<li>获取key,我们这里没有key，所以直接是NullWritable</li>
<li>/<br>@Override<br>public NullWritable getCurrentKey() throws IOException, InterruptedException {<br>  return NullWritable.get();<br>}<br>/***</li>
<li>这个是获取当前的value值方法</li>
<li>/<br>@Override<br>public BytesWritable getCurrentValue() throws IOException, InterruptedException {<br>  return v;<br>}<br>/**</li>
<li>获取当前进度的方法</li>
<li>/<br>@Override<br>public float getProgress() throws IOException, InterruptedException {<br>  //正在读返回1，否则返回0，通过这个方法别人可以知道我们是否正在读取文件<br>  return isProgress?1:0;<br>}</li>
</ul>
<p>  @Override<br>  public void close() throws IOException {</p>
<p>  }</p>
</li>
</ul>
<p>}<br></code></pre> ⑶创建SequenseFileMapper.java类 <pre class="has"><code class="language-java">package com.kgf.mapreduce.inputformat;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.BytesWritable;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;<br>import org.apache.hadoop.mapreduce.lib.input.FileSplit;</p>
<p>/***</p>
<ul>
<li>创建自定义的mapper，前两个参数就是WholeFileInputformat处理数据后的输出参数，</li>
<li>后面两个参数，一个是key-&gt;是文件路径加上名称拼接而成。一个是value，就是小文件内容</li>
<li>@author KGF</li>
<li></li>
<li>/<br>public class SequenseFileMapper extends Mapper&lt;NullWritable, BytesWritable, Text, BytesWritable&gt;&#123;  Text k = new Text();  /***<ul>
<li>该方法是主要用来获取文件路径和名称,程序运行会先进入这个setup方法，再进入我们自定义的WholeFileInputformat类中的方法，</li>
<li>然后再回来进入map方法</li>
<li>/<br>@Override<br>protected void setup(Mapper&lt;NullWritable, BytesWritable, Text, BytesWritable&gt;.Context context)<pre><code>  throws IOException, InterruptedException &#123;
</code></pre>
  //1:获取上下文切片信息<br>  FileSplit split = (FileSplit) context.getInputSplit();<br>  Path path = split.getPath();<br>  k.set(path.toString());<br>}<br>/***</li>
<li>map方法是对数据进行处理，并且写出到下一阶段，这里是每次写一个小文件</li>
<li>/<br>@Override<br>protected void map(NullWritable key, BytesWritable value,<pre><code>  Mapper&amp;lt;NullWritable, BytesWritable, Text, BytesWritable&amp;gt;.Context context)
  throws IOException, InterruptedException &#123;
</code></pre>
  context.write(k, value);<br>}<br>}<br></code></pre> ⑷自定义SequenseFileReducer      <img alt="" class="has" height="289" src="https://img-blog.csdnimg.cn/20190804100533568.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="406"> ⑸创建SequenseFileDriver <pre class="has"><code class="language-java">package com.kgf.mapreduce.inputformat;</li>
</ul>
</li>
</ul>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.BytesWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;</p>
<p>public class SequenseFileDriver &#123;</p>
<pre><code>public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123;
    //1:获取job对象
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf);
    
    //2:设置jar路径
    job.setJarByClass(SequenseFileDriver.class);
    
    //3：关联自定义的mapper和reducer
    job.setMapperClass(SequenseFileMapper.class);
    job.setReducerClass(SequenseFileReducer.class);
    
    //4:设置我们自定义的WholeFileInputformat对象,输出为SequenceFileOutputFormat
    job.setInputFormatClass(WholeFileInputformat.class);
    job.setOutputFormatClass(SequenceFileOutputFormat.class);
    
    //5：设置mapper的输出类型
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(BytesWritable.class);
    
    //6:设置reducer的输出类型
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(BytesWritable.class);
    
    //7：设置文件的输入输出路径
    FileInputFormat.setInputPaths(job,new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    
    //8：提交
    boolean result = job.waitForCompletion(true);
    System.exit(result?0:1);
&#125;
</code></pre>
<p>}<br></code></pre> ⑹效果：       <img alt="" class="has" height="211" src="https://img-blog.csdnimg.cn/20190804102313326.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="454">       <img alt="" class="has" height="154" src="https://img-blog.csdnimg.cn/20190804102445966.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="543">         </li></p>
<h1 id="三：OutputFormat-接口实现"><a href="#三：OutputFormat-接口实现" class="headerlink" title="三：OutputFormat 接口实现"></a>三：OutputFormat 接口实现</h1><ol>
<li>简介        OutputFormat 是 MapReduce 输出的基类，所有实现 MapReduce 输出都实现了  OutputFormat 接口。下面我们介绍几种常见的 OutputFormat 实现类。 <img alt="" class="has" height="265" src="https://img-blog.csdnimg.cn/20190804113214875.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="655">1. 自定义 OutputFormat   <img alt="" class="has" height="227" src="https://img-blog.csdnimg.cn/2019080411325760.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="765"><li> 案例：过滤日志及自定义日志输出路径案例（自定义 OutputFormat）   ⑴需求：过滤输入的log日志中是否包含topcheer，包含topcheer的行输出到e:/topcheer.log,否则                 输出到e:/other.log文件中。        <img alt="" class="has" height="268" src="https://img-blog.csdnimg.cn/20190804114012540.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="390">   ⑵创建FilterOutputFormat.java用来自定义文件输出         <img alt="" class="has" height="269" src="https://img-blog.csdnimg.cn/20190804120644666.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="374">  ⑶创建FilterRecordWriter.java,对输出的数据进行自定义处理          <pre class="has"><code class="language-java">package com.kgf.mapreduce.outputformat;</li>
</ol>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.FSDataOutputStream;<br>import org.apache.hadoop.fs.FileSystem;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.RecordWriter;<br>import org.apache.hadoop.mapreduce.TaskAttemptContext;</p>
<p>/**</p>
<ul>
<li><p>自定义RecordWriter实现类，对输出的数据进行自定义处理</p>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class FilterRecordWriter extends RecordWriter&lt;Text, NullWritable&gt; &#123;</p>
<p>  private Configuration conf = null;</p>
<p>  FSDataOutputStream topcheerFos = null;</p>
<p>  FSDataOutputStream otherFos = null;<br>  /**</p>
<ul>
<li><p>用来创建输出流相关配置</p>
</li>
<li><p>@param context</p>
</li>
<li><p>@throws IOException</p>
</li>
<li><p>/<br>public FilterRecordWriter(TaskAttemptContext context) throws IOException &#123;<br>  try &#123;</p>
<pre><code>  //1：获取配置信息
  conf = context.getConfiguration();
  //2：获取文件输出流，分别输出到两个不同的路径文件用
  FileSystem fs = FileSystem.get(conf);
  //3:创建两个不同路径的输出流
  topcheerFos = fs.create(new Path(&quot;e:/topcheer.log&quot;));
  otherFos = fs.create(new Path(&quot;e:/other.log&quot;));
</code></pre>
<p>  } catch (Exception e) {</p>
<pre><code>  e.printStackTrace();
</code></pre>
<p>  }<br>}<br>/**</p>
</li>
<li><p>根据输入参数key的内容去判断数据要输出到那个文件路径中</p>
</li>
<li><p>/<br>@Override<br>public void write(Text key, NullWritable arg1) throws IOException, InterruptedException {</p>
<p>  //判断key中是否包含topcheer<br>  if(key.toString().contains(“topcheer”)) {</p>
<pre><code>  topcheerFos.write(key.getBytes());
</code></pre>
<p>  }else {</p>
<pre><code>  otherFos.write(key.getBytes());
</code></pre>
<p>  }<br>}<br>/**</p>
</li>
<li><p>最后我们需要将流关闭</p>
</li>
<li><p>/<br>@Override<br>public void close(TaskAttemptContext arg0) throws IOException, InterruptedException {<br>  //关闭资源<br>  if(topcheerFos!=null) {</p>
<pre><code>  topcheerFos.close();
</code></pre>
<p>  }<br>  if(otherFos!=null) {</p>
<pre><code>  otherFos.close();
</code></pre>
<p>  }<br>}<br>}<br></code></pre> ⑷自定义mapper阶段类FilterMapper        <img alt="" class="has" height="331" src="https://img-blog.csdnimg.cn/20190804121243957.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="406">     ⑸自定义reducer类        <img alt="" class="has" height="221" src="https://img-blog.csdnimg.cn/20190804121702752.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="465">   ⑹自定义FilterDriver         <pre class="has"><code class="language-java">package com.kgf.mapreduce.outputformat;</p>
</li>
</ul>
</li>
</ul>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</p>
<p>public class FilterDriver &#123;</p>
<pre><code>public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123;
    //1:获取job对象
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf);
    
    //2:设置jar
    job.setJarByClass(FilterDriver.class);
    
    //3:关联自定义的mapper和reducer
    job.setMapperClass(FilterMapper.class);
    job.setReducerClass(FilterReducer.class);
    
    //4:设置mapper输出参数类型
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(NullWritable.class);
    
    //5:设置Reducer输出类型
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(NullWritable.class);
    
    //6:将自定义的输出outputFormat设置进来
    job.setOutputFormatClass(FilterOutputFormat.class);
    
    //7：设置输出路径，虽然我们自定义了 outputformat，但是因为我们的 outputformat 继承自 fileoutputformat， 
    //而 fileoutputformat 要输出一个_SUCCESS 文件，所以，在这还得指定一个输 出目录 .
    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    
    //8：提交
    boolean result = job.waitForCompletion(true);
    System.exit(result?0:1);
&#125;
</code></pre>
<p>}<br></code></pre> ⑺效果：       <img alt="" class="has" height="138" src="https://img-blog.csdnimg.cn/20190804123037268.png" width="575">       <img alt="" class="has" height="151" src="https://img-blog.csdnimg.cn/20190804123049492.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="280">       <img alt="" class="has" height="130" src="https://img-blog.csdnimg.cn/20190804123720268.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="378">  ⑻具体流程：       数据–&gt;FilterMapper-&gt;FilterOutputFormat-&gt;FilterRecordWriter中构造方法初始化全局对象—&gt;FilterReducer中接受FilterMapper中       传递的每一行数据并且在输出的时候调用FilterRecordWriter中的write方法，将数据写入到指定的路径下。        </li></p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>MapReduce之数据清洗(ETL)案例,倒排索引案例,ReduceTask 工作机制,Hadoop 数据压缩简介</title>
    <url>/2021/07/18/MapReduce%E4%B9%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97(ETL)%E6%A1%88%E4%BE%8B,%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E6%A1%88%E4%BE%8B,ReduceTask%20%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6,Hadoop%20%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>title: MapReduce之数据清洗(ETL)案例,倒排索引案例,ReduceTask 工作机制,Hadoop 数据压缩简介<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：简介</p>
<p>             在运行核心业务 Mapreduce 程序之前，往往要先对数据进行清洗，清理掉不符合用户要求的数据。       清理的过程往往只需要运行 mapper 程序，不需要运行 reduce 程序。</p>
<h1 id="二：日志清洗案例之简单解析版"><a href="#二：日志清洗案例之简单解析版" class="headerlink" title="二：日志清洗案例之简单解析版"></a>二：日志清洗案例之简单解析版</h1><ol>
<li> 需求：去除日志中字段长度小于等于11的日志(每一行按照空格切割，切割后数组长度小于11的日志不要)1.  数据如下：   <img alt="" class="has" height="154" src="https://img-blog.csdnimg.cn/20190808213958907.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="455"><li>代码实现如下：  ⑴创建mapper类：           <pre class="has"><code class="language-java">package com.kgf.mapreduce.weblog;</li>
</ol>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.io.LongWritable;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;</p>
<p>public class LogMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</p>
<pre><code>Text k = new Text();

@Override
protected void map(LongWritable key, Text value,Context context)
        throws IOException, InterruptedException &#123;
    
    //1:获取一行
    String line = value.toString();
    
    //2：解析一行数据
    boolean result = parseLog(line);
    
    if(!result) &#123;
        return;
    &#125;
    k.set(line);
    context.write(k, NullWritable.get());
&#125;

private boolean parseLog(String line) &#123;
    String[] fields = line.split(&quot; &quot;);
    if(fields.length&amp;gt;11) &#123;
        return true;
    &#125;
    return false;
&#125;
</code></pre>
<p>}<br></code></pre> ⑵创建Driver: <pre class="has"><code class="language-java">package com.kgf.mapreduce.weblog;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</p>
<p>public class LogDriver &#123;</p>
<pre><code>public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123;
    //1：获取Job对象
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf);
    
    //2：设置jar对象
    job.setJarByClass(LogDriver.class);
    
    //3:设置关联Mapper
    job.setMapperClass(LogMapper.class);
    
    //4：设置mapper输出类型
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(NullWritable.class);
    
    //5:设置reduce task为0
    job.setNumReduceTasks(0);
    
    //6：设置最终输出参数
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(NullWritable.class);
    
    //7：设置文件输入输出路径
    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    
    //8：提交
    boolean result = job.waitForCompletion(true);
    System.exit(result?0:1);
&#125;
</code></pre>
<p>}<br></code></pre>   </li>1.   效果：  ⑴日志清理前数据有如下数量：           <img alt="" class="has" height="120" src="https://img-blog.csdnimg.cn/20190808221608218.png" width="413">         ⑵清理后：            <img alt="" class="has" height="175" src="https://img-blog.csdnimg.cn/20190808221642199.png" width="474">   ⑶程序运行日志如下：           <img alt="" class="has" height="276" src="https://img-blog.csdnimg.cn/201908082218109.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="512">1. 计数器应用   ⑴简介：            Hadoop 为每个作业维护若干内置计数器，以描述多项指标。例如，某些计数器记录已      处理的字节数和记录数，使用户可监控已处理的输入数据量和已产生的输出数据量。   ⑵计数器方式如下：          <img alt="" class="has" height="274" src="https://img-blog.csdnimg.cn/20190808223125431.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="462">  ⑶案例，我们可以在上面的日志清洗案例中加上计数器组应用：代码如下：         <img alt="" class="has" height="349" src="https://img-blog.csdnimg.cn/2019080822352462.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="427">      效果如下（可以发现控制台出现了下面的日志内容，可以帮助我们定位问题）：         <img alt="" class="has" height="322" src="https://img-blog.csdnimg.cn/20190808223631620.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="431"></p>
<h1 id="三：倒排索引案例"><a href="#三：倒排索引案例" class="headerlink" title="三：倒排索引案例"></a>三：倒排索引案例</h1><ol>
<li>现在有三个文件a.txt,b.txt,c.txt,现在我们需要将文件里面的单词汇总 ⑴文件如下：         <img alt="" class="has" height="67" src="https://img-blog.csdnimg.cn/20190809224946281.png" width="106"><img alt="" class="has" height="66" src="https://img-blog.csdnimg.cn/20190809224958271.png" width="156"><img alt="" class="has" height="65" src="https://img-blog.csdnimg.cn/2019080922501325.png" width="208"> ⑵最后要求的结果（汇总每个单词所在的文件中个数）：       <img alt="" class="has" height="117" src="https://img-blog.csdnimg.cn/20190809225058159.png" width="514"><li> 代码实现如下：  ⑴建立bean对象         <pre class="has"><code class="language-java">package com.kgf.mapreduce.index;</li>
</ol>
<p>import java.io.DataInput;<br>import java.io.DataOutput;<br>import java.io.IOException;</p>
<p>import org.apache.hadoop.io.Writable;</p>
<p>public class IndexVo implements Writable&#123;</p>
<pre><code>private String word;

private String file;

private int num;

public IndexVo(String word, String file, int num) &#123;
    super();
    this.word = word;
    this.file = file;
    this.num = num;
&#125;

public IndexVo() &#123;
    super();
&#125;

@Override
public void readFields(DataInput in) throws IOException &#123;
    this.word = in.readUTF();
    this.file = in.readUTF();
    this.num = in.readInt();
&#125;

@Override
public void write(DataOutput out) throws IOException &#123;
    out.writeUTF(word);
    out.writeUTF(file);
    out.writeInt(num);
&#125;

public String getWord() &#123;
    return word;
&#125;

public void setWord(String word) &#123;
    this.word = word;
&#125;

public String getFile() &#123;
    return file;
&#125;

public void setFile(String file) &#123;
    this.file = file;
&#125;

public int getNum() &#123;
    return num;
&#125;

public void setNum(int num) &#123;
    this.num = num;
&#125;

@Override
public String toString() &#123;
    return word + &quot;\t&quot; + file + &quot;\t&quot; + num;
&#125;
</code></pre>
<p>}<br></code></pre>  ⑵建立mapper对象         <pre class="has"><code class="language-java">package com.kgf.mapreduce.index;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.io.LongWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;<br>import org.apache.hadoop.mapreduce.lib.input.FileSplit;</p>
<p>public class IndexMapper extends Mapper&lt;LongWritable, Text, Text, IndexVo&gt;&#123;</p>
<pre><code>private String fileName = null;

Text k = new Text();

IndexVo v = new IndexVo();

@Override
protected void setup(Context context)
        throws IOException, InterruptedException &#123;
    //1：获取文件切片信息
    FileSplit splitFile = (FileSplit) context.getInputSplit();
    fileName = splitFile.getPath().getName();
&#125;

@Override
protected void map(LongWritable key, Text value,Context context)
        throws IOException, InterruptedException &#123;
    
    //1:获取一行数据
    String line = value.toString();
    //2:切割数据
    String[] fields = line.split(&quot;\t&quot;);
    for (String field : fields) &#123;
        k.set(field);
        v.setWord(field);
        v.setFile(fileName);
        v.setNum(1);
        context.write(k, v);
    &#125;
&#125;
</code></pre>
<p>}<br></code></pre> ⑶建立reducer对象       <pre class="has"><code class="language-java">package com.kgf.mapreduce.index;</p>
<p>import java.io.IOException;<br>import java.util.HashMap;<br>import java.util.Map;<br>import java.util.Set;</p>
<p>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Reducer;</p>
<p>public class IndexReducer extends Reducer&lt;Text, IndexVo, Text, NullWritable&gt; &#123;</p>
<pre><code>Text k = new Text();

@Override
protected void reduce(Text key, Iterable&amp;lt;IndexVo&amp;gt; values,Context context)
        throws IOException, InterruptedException &#123;
    
    Map&amp;lt;String,Integer&amp;gt; map = new HashMap&amp;lt;String,Integer&amp;gt;();
    
    for (IndexVo indexVo : values) &#123;
        String name = indexVo.getFile();
        if(map.containsKey(name)) &#123;
            map.put(name, map.get(name)+indexVo.getNum());
        &#125;else &#123;
            map.put(name, indexVo.getNum());
        &#125;
    &#125;
    
    String result = key.toString()+&quot;\t&quot;;
    for (String fileName : map.keySet()) &#123;
        result+=(fileName+&quot;\t&quot;+map.get(fileName))+&quot;\t&quot;;
    &#125;
    k.set(result);
    context.write(k, NullWritable.get());
&#125;
</code></pre>
<p>}<br></code></pre> ⑷建立Driver对象       <pre class="has"><code class="language-java">package com.kgf.mapreduce.index;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</p>
<p>public class IndexDriver &#123;</p>
<pre><code>public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123;
    //1：获取job对象
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf);
    
    //2：设置jar
    job.setJarByClass(IndexDriver.class);
    
    //3:关联mapper和reducer
    job.setMapperClass(IndexMapper.class);
    job.setReducerClass(IndexReducer.class);
    
    //4:设置mapper输出参数
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(IndexVo.class);
    
    //5:设置最终输出参数
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(NullWritable.class);
    
    //6：设置数据输入输出路径
    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    
    //7：提交
    boolean rsult = job.waitForCompletion(true);
    System.exit(rsult?0:1);
&#125;
</code></pre>
<p>}<br></code></pre>         </li></p>
<h1 id="四：-ReduceTask-工作机制"><a href="#四：-ReduceTask-工作机制" class="headerlink" title="四： ReduceTask 工作机制"></a>四： ReduceTask 工作机制</h1><ol>
<li>ReduceTask有如下特点：  <img alt="" class="has" height="381" src="https://img-blog.csdnimg.cn/20190810091911354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="529">1.  流程图如下：  <img alt="" class="has" height="461" src="https://img-blog.csdnimg.cn/20190810092256618.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="595">  ⑴Copy阶段：          ReduceTask 从各个 MapTask 上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，     则写到磁盘上，否则直接放到内存中。  ⑵Merge 阶段：           在远程拷贝数据的同时，ReduceTask 启动了两个后台线程对内存和磁盘上的文件进行合并，     以防止内存使用过多或磁盘上文件过多。   ⑶Sort 阶段：           按照 MapReduce 语义，用户编写 reduce()函数输入数据是按 key 进行聚集的一组数据。     为了将 key 相同的数据聚在一起，Hadoop 采用了基于排序的策略。由于各个 MapTask 已经     实现对自己的处理结果进行了局部排序，因此，ReduceTask 只需对所有数据进行一次归并排序即可。   ⑷Reduce 阶段：            reduce()函数将计算结果写到 HDFS 上。 <h1 id="五：-Hadoop-数据压缩"><a href="#五：-Hadoop-数据压缩" class="headerlink" title="五： Hadoop 数据压缩"></a>五： Hadoop 数据压缩</h1></li>
<li>简介     压缩技术能够有效减少底层存储系统（HDFS）读写字节数。压缩提高了网络带宽和磁盘空间的效率。 在 Hadoop 下，尤其是数据规模很大和工作负载密集的情况下，使用数据压缩显得非常重要。在这种情况下， I/O 操作和网络数据传输要花大量的时间。还有，Shuffle与 Merge 过程同样也面临着巨大的 I/O 压力。     鉴于磁盘 I/O 和网络带宽是 Hadoop 的宝贵资源，数据压缩对于节省资源、最小化磁盘 I/O 和网络传输非常有帮助。不过，尽管压缩与解压操作的 CPU 开销不高，其性能的提升和 资源的节省并非没有代价。      如果磁盘 I/O 和网络带宽影响了 MapReduce 作业性能，在任意 MapReduce 阶段启用压 缩都可以改善端到端处理时间并减少 I/O 和网络流量。       压缩 Mapreduce 的一种优化策略：通过压缩编码对 Mapper 或者 Reducer 的输出进行 压缩，以减少磁盘 IO，提高 MR 程序运行速度（但相应增加了 cpu 运算负担）。       <img alt="" class="has" height="201" src="https://img-blog.csdnimg.cn/20190810095228924.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="562">1. MR支持的压缩编码     <img alt="" class="has" height="372" src="https://img-blog.csdnimg.cn/20190810095333486.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="422">    <img alt="" class="has" height="277" src="https://img-blog.csdnimg.cn/2019081009535852.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="583">1.  压缩性能的比较     <img alt="" class="has" height="297" src="https://img-blog.csdnimg.cn/20190810095427226.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="629">1.  压缩方式选择       ⑴Gzip 压缩           <img alt="" class="has" height="291" src="https://img-blog.csdnimg.cn/20190810105343262.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="518">   ⑵ Bzip2 压缩           <img alt="" class="has" height="310" src="https://img-blog.csdnimg.cn/20190810105413209.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="581">    ⑶Lzo 压缩           <img alt="" class="has" height="210" src="https://img-blog.csdnimg.cn/20190810105518675.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="548">          <img alt="" class="has" height="76" src="https://img-blog.csdnimg.cn/20190810105535471.png" width="549">    ⑷Snappy 压缩           <img alt="" class="has" height="205" src="https://img-blog.csdnimg.cn/20190810105618682.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="559">1. 压缩位置选择   压缩可以在 MapReduce 作用的任意阶段启用。   <img alt="" class="has" height="651" src="https://img-blog.csdnimg.cn/20190810105756931.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="754">1. 压缩配置参数   <img alt="" class="has" height="352" src="https://img-blog.csdnimg.cn/20190810105926815.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="683">  <img alt="" class="has" height="369" src="https://img-blog.csdnimg.cn/20190810105950851.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="680">  <img alt="" class="has" height="376" src="https://img-blog.csdnimg.cn/20190810110017564.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="680">  <img alt="" class="has" height="336" src="https://img-blog.csdnimg.cn/20190810110042410.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="677"></li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>MapReduce，MapTask工作流程，Combiner 合并以及二次排序GroupingComparator</title>
    <url>/2021/07/18/MapReduce%EF%BC%8CMapTask%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%EF%BC%8CCombiner%20%E5%90%88%E5%B9%B6%E4%BB%A5%E5%8F%8A%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8FGroupingComparator/</url>
    <content><![CDATA[<p>title: MapReduce，MapTask工作流程，Combiner 合并以及二次排序GroupingComparator<br>categories:</p>
<ul>
<li>BigData</li>
</ul>
<p>—# 一：MapTask工作流程</p>
<ol>
<li>简介      <img alt="" class="has" height="337" src="https://img-blog.csdnimg.cn/20190728221249534.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="539">1.  详细流程如下    ⑴Read阶段：              Map Task 通过用户编写的 RecordReader，从输入 InputSplit 中解析出一个个 key/value。    ⑵Map 阶段：               该节点主要是将解析出的 key/value 交给用户编写 map()函数处理，并产生一系列新的 key/value。    ⑶Collect 收集阶段：               在用户编写 map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。       在该函数内部，它会将生成的 key/value 分区（调用Partitioner），并写入一个环形内存缓冲区中。    ⑷Spill 阶段：                即“溢写”，当环形缓冲区满后，MapReduce 会将数据写到本地磁盘上，生成一个临时文件。        需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进        行合并、压缩等操作。                溢写阶段详情：                         a：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号partition                               进行排序，然后按照 key 进行排序。这样，经过排序后，数据以分区为单位聚集在一起，                               且同一分区内所有数据按照 key 有序。                         b：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件                               output/spillN.out（N 表示当前溢写次数）中。如果用户设置了 Combiner，则写入文件之                                前，对每个分区中的数据进行一次聚集操作。                         c：将分区数据的元信息写到内存索引数据结构 SpillRecord 中，其中每个分区的元信息包括                              在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过                              1MB，则将内存索引写到文件 output/spillN.out.index 中。    ⑸Combine 阶段：             当所有数据处理完成后，MapTask 对所有临时文件进行一次合并以确保最终只会生成一个数据文件。             当所有数据处理完后，MapTask 会将所有临时文件合并成一个大文件，并保存到文件output/file.out 中，        同时生成相应的索引文件 output/file.out.index。              在进行文件合并过程中，MapTask 以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的        方式。每轮合并 io.sort.factor（默认 100）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，        重复以上过程，直到最终得到一个大文件。              让每个 MapTask 最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机        读取带来的开销。         <h1 id="二：MapReduce-工作流程"><a href="#二：MapReduce-工作流程" class="headerlink" title="二：MapReduce  工作流程"></a>二：MapReduce  工作流程</h1></li>
<li>流程示意图如下：      <img alt="" class="has" height="335" src="https://img-blog.csdnimg.cn/20190728223420512.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="508">      <img alt="" class="has" height="345" src="https://img-blog.csdnimg.cn/20190728223526161.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="504">1.  流程详解如下：  ⑴maptask 收集我们的 map()方法输出的 kv 对，放到内存缓冲区中  ⑵从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件  ⑶多个溢出文件会被合并成大的溢出文件  ⑷在溢出过程中，及合并的过程中，都要调用 partitioner 进行分区和针对 key 进行排序  ⑸reducetask 根据自己的分区号，去各个 maptask 机器上取相应的结果分区数据 。  ⑹reducetask 会取到同一个分区的来自不同 maptask 的结果文件，reducetask 会将这些      文件再进行合并（归并排序）  ⑺合并成大文件后，shuffle 的过程也就结束了，后面进入 reducetask 的逻辑运算过程          （从文件中取出一个一个的键值对 group，调用用户自定义的 reduce()方法）   注意：         Shuffle 中的缓冲区大小会影响到 mapreduce 程序的执行效率，原则上说，缓冲区越大，  磁盘 io 的次数越少，执行速度就越快。缓冲区的大小可以通过参数调整，参数：io.sort.mb 默认 100M。<h1 id="三：Combiner-合并"><a href="#三：Combiner-合并" class="headerlink" title="三：Combiner 合并"></a>三：Combiner 合并</h1></li>
<li>简介       <img alt="" class="has" height="300" src="https://img-blog.csdnimg.cn/20190729220522148.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="583">       <img alt="" class="has" height="116" src="https://img-blog.csdnimg.cn/20190729220719373.png" width="635">1.  案例：我们在wordcount案例中使用Conbiner    ⑴数据准备            <img alt="" class="has" height="215" src="https://img-blog.csdnimg.cn/2019072922243974.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="469">    ⑵使用原本的wordcount代码看看日志           <img alt="" class="has" height="265" src="https://img-blog.csdnimg.cn/20190729222738153.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="363">    ⑶自定义一个 combiner 继承 Reducer，重写 reduce 方法           <img alt="" class="has" height="300" src="https://img-blog.csdnimg.cn/20190729222824707.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="413">     ⑷在 job 驱动类中设置：          <img alt="" class="has" height="347" src="https://img-blog.csdnimg.cn/20190729223022718.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="358">     ⑸效果：         <img alt="" class="has" height="263" src="https://img-blog.csdnimg.cn/20190729223311563.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="339">               ⑹其实我们可以发现Combiner的代码和Reducer的代码一样，只不过执行的位置不同：          <img alt="" class="has" height="331" src="https://img-blog.csdnimg.cn/20190729223603934.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="440">          所以我们直接在Driver中将Combiner指定reducer也可以：          <img alt="" class="has" height="355" src="https://img-blog.csdnimg.cn/20190729223745619.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="344"><h1 id="四：辅助-排序和二次排序案例（GroupingComparator）"><a href="#四：辅助-排序和二次排序案例（GroupingComparator）" class="headerlink" title="四：辅助 排序和二次排序案例（GroupingComparator）"></a>四：辅助 排序和二次排序案例（GroupingComparator）</h1></li>
<li> 需求：     <img alt="" class="has" height="277" src="https://img-blog.csdnimg.cn/20190730213326408.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="521">1. 数据准备：    <img alt="" class="has" height="114" src="https://img-blog.csdnimg.cn/20190731223724507.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="274"><img alt="" class="has" height="111" src="https://img-blog.csdnimg.cn/20190731223812489.png" width="322">1.  思路分析   ⑴在Mapper中处理的事情：         a：获取每一行输入的数据         b：对数据进行切割，只需要订单号，金额         c：将切割好的数据分装到自定义的bean当中，并且对订单号以及金额进行排序，都是从大到小。               因为在后面定义分组的时候，只会传递一个key给reducer,这时候我们取最大金额的订单。    ⑵自定义分区，从mapper端传递过来的数据，只要订单号一样我们就分到一个分区之中，最后         3中编号的订单分到3个分区文件中。    ⑶自定义groupingcomparator分组，获取相同订单号的数据，并且取第一个订单号数据发送给reducer.    ⑷最后reducer分别把不同订单号的第一条金额最大的数据写出。<li>代码实现如下：   ⑴自定义bean，并且实现订单号以及金额排序           <pre class="has"><code class="language-java">package com.kgf.mapreduce.order;</li>
</ol>
<p>import java.io.DataInput;<br>import java.io.DataOutput;<br>import java.io.IOException;<br>import org.apache.hadoop.io.WritableComparable;</p>
<p>/***</p>
<ul>
<li><p>序列化排序自定义的bean对象</p>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class OrderBean implements WritableComparable&lt;OrderBean&gt;&#123;</p>
<p>  /<strong>订单号</strong>/<br>  private int orderId;<br>  /<strong>价格</strong>/<br>  private double price;</p>
<p>  public OrderBean(int orderId, double price) &#123;</p>
<pre><code>  super();
  this.orderId = orderId;
  this.price = price;
</code></pre>
<p>  }<br>  public OrderBean() {</p>
<pre><code>  super();
</code></pre>
<p>  }<br>  /***</p>
<ul>
<li>反序列化操作</li>
<li>/<br>@Override<br>public void readFields(DataInput input) throws IOException {<br>  this.orderId = input.readInt();<br>  this.price = input.readDouble();<br>}<br>/***</li>
<li>序列化操作</li>
<li>/<br>@Override<br>public void write(DataOutput output) throws IOException {<br>  output.writeInt(orderId);<br>  output.writeDouble(price);<br>}<br>public int getOrderId() {<br>  return orderId;<br>}<br>public void setOrderId(int orderId) {<br>  this.orderId = orderId;<br>}<br>public double getPrice() {<br>  return price;<br>}<br>public void setPrice(double price) {<br>  this.price = price;<br>}<br>@Override<br>public String toString() {<br>  return orderId + “\t” + price;<br>}<br>@Override<br>public int compareTo(OrderBean o) {<br>  int result = 0;<br>  if(this.orderId&gt;o.getOrderId()) {<pre><code>  result = 1;
</code></pre>
  }else if(this.orderId&lt;o.getOrderId()) {<pre><code>  result = -1;
</code></pre>
  }else {<pre><code>  if(this.price&amp;gt;o.getPrice()) &#123;
      result = -1;
  &#125;else if(this.price&amp;lt;o.getPrice()) &#123;
      result = 1;
  &#125;
</code></pre>
  }<br>  return result;<br>}<br>}<br></code></pre> ⑵自定义OrderMapper对数据进行切割 <pre class="has"><code class="language-java">package com.kgf.mapreduce.order;</li>
</ul>
</li>
</ul>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.io.LongWritable;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Mapper;<br>/***</p>
<ul>
<li><p>继承Mapper接口,对读取的文件数据进行切割</p>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class OrderMapper extends Mapper&lt;LongWritable, Text, OrderBean, NullWritable&gt;&#123;</p>
<p>  OrderBean k = new OrderBean();</p>
<p>  @Override<br>  protected void map(LongWritable key, Text value,Context context)</p>
<pre><code>      throws IOException, InterruptedException &#123;
  System.out.println(&quot;===========OrderMapper BEGIN=============&quot;);
  //获取一行数据
  String line = value.toString();
  //切割数据
  String[] fields = line.split(&quot;\t&quot;);
  System.out.println(&quot;[fields:]&quot;+fields);
  //封装数据对象
  k.setOrderId(Integer.valueOf(fields[0]));
  k.setPrice(Double.parseDouble(fields[2]));
  //输出
  context.write(k, NullWritable.get());
  System.out.println(&quot;===========OrderMapper END=============&quot;);
</code></pre>
<p>  }<br>}<br></code></pre>  ⑶自定义分区，将不同订单号的数据写入到不同分区 <pre class="has"><code class="language-java">package com.kgf.mapreduce.order;</p>
</li>
</ul>
<p>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.mapreduce.Partitioner;</p>
<p>/***</p>
<ul>
<li><p>继承分区函数，分为多个区</p>
</li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class OrderPartitioner extends Partitioner&lt;OrderBean,NullWritable&gt;&#123;</p>
<p>  /**</p>
<ul>
<li>注意：这个numberPartitions就是Driver中job.setNumReduceTasks(3);</li>
<li>/<br>@Override<br>public int getPartition(OrderBean key, NullWritable value, int numberPartitions) &#123;<br>  return (key.getOrderId() &amp; Integer.MAX_VALUE) % numberPartitions;<br>&#125;</li>
</ul>
</li>
</ul>
<p>&#125;<br></code></pre> ⑷自定义分组，将相同订单号的第一条金额最大的数据写入到reducer中 <pre class="has"><code class="language-java">package com.kgf.mapreduce.order;</p>
<p>import org.apache.hadoop.io.WritableComparable;<br>import org.apache.hadoop.io.WritableComparator;</p>
<p>/***</p>
<ul>
<li>自定义GroupingComparator进行分组,WritableComparator是一个类 这个类是用于mapreduce编程模型中的比较 排序 .</li>
<li>mapreduce中有两次排序 一次是 在环形缓冲区域之中进行分区 排序,还有一次是数据在reduce端获取文件之后进行分组</li>
<li>它是用来给Key分组的,</li>
<li>@author kgf</li>
<li></li>
<li>/<br>public class OrderGroupingComparator extends WritableComparator&#123;<br>   /***<pre><code>           * 无参构造子 必须调用父类的构造子 不然会报空指针 未初始化 buffer
*/
</code></pre>
  public OrderGroupingComparator() {<pre><code>  super(OrderBean.class,true);
</code></pre>
  }<br>  /**<ul>
<li>我们这里通过比较orderId分组，相同的一组</li>
<li>/<br>@SuppressWarnings(“rawtypes”)<br>@Override<br>public int compare(WritableComparable a, WritableComparable b) {<br>  System.out.println(“======OrderGroupingComparator begin=======”);<br>  OrderBean aBean = (OrderBean) a;<br>  OrderBean bBean = (OrderBean) b;<br>  System.out.println(“[aBean:]”+aBean);<br>  System.out.println(“[bBean:]”+bBean);<br>  int result = 0;<br>  if(bBean.getOrderId()&gt;aBean.getOrderId()) {<pre><code>  result = 1;
</code></pre>
  }else if(bBean.getOrderId()&lt;aBean.getOrderId()) {<pre><code>  result = -1;
</code></pre>
  }else {<pre><code>  result = 0;
</code></pre>
  }<br>  System.out.println(“======OrderGroupingComparator end=======”);<br>  return result;<br>}<br>}<br></code></pre>  ⑸自定义reducer，写出不同订单号的金额最大的数据 <pre class="has"><code class="language-java">package com.kgf.mapreduce.order;</li>
</ul>
</li>
</ul>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.mapreduce.Reducer;</p>
<p>/***</p>
<ul>
<li></li>
<li><p>@author KGF</p>
</li>
<li></li>
<li><p>/<br>public class OrderReducer extends Reducer&lt;OrderBean, NullWritable, OrderBean, NullWritable&gt;&#123;</p>
<p>  @Override<br>  protected void reduce(OrderBean key, Iterable&lt;NullWritable&gt; value,Context context)</p>
<pre><code>      throws IOException, InterruptedException &#123;
  System.out.println(&quot;=========OrderReducer=====begin=========&quot;);
  context.write(key, NullWritable.get());
  System.out.println(&quot;=========OrderReducer=====END=========&quot;);
</code></pre>
<p>  }</p>
</li>
</ul>
<p>}<br></code></pre> ⑹OrderDriver启动服务类 <pre class="has"><code class="language-java">package com.kgf.mapreduce.order;</p>
<p>import java.io.IOException;</p>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</p>
<p>public class OrderDriver &#123;</p>
<pre><code>public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123;
    
    //1：获取job配置信息
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf);
    //2:设置jar包加载路径
    job.setJarByClass(OrderDriver.class);
    //3:加载自定义的mapper和reducer
    job.setMapperClass(OrderMapper.class);
    job.setReducerClass(OrderReducer.class);
    //4:设置mapper的输出类型
    job.setMapOutputKeyClass(OrderBean.class);
    job.setMapOutputValueClass(NullWritable.class);
    //5：设置reducer的输出类型
    job.setOutputKeyClass(OrderBean.class);
    job.setOutputValueClass(NullWritable.class);
    //6:设置文件输入和输出路径
    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job,new Path(args[1]));
    
    //8：设置分区
    job.setPartitionerClass(OrderPartitioner.class);
    job.setNumReduceTasks(3);
    
    //9:设置自定义分组
    job.setGroupingComparatorClass(OrderGroupingComparator.class);
    
    //7:提交
    boolean result = job.waitForCompletion(true);
    System.exit(result?0:-1);
&#125;
</code></pre>
<p>}<br></code></pre>   </li>1. OVER</p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
  </entry>
  <entry>
    <title>clickhouse副本同步与高可用功能验证,分布式表与集群配置,数据副本与复制表,ZooKeeper整合,创建复制表,副本同步机制,数据原子写入与去重,负载平衡策略,案例</title>
    <url>/2021/07/18/clickhouse%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E4%B8%8E%E9%AB%98%E5%8F%AF%E7%94%A8%E5%8A%9F%E8%83%BD%E9%AA%8C%E8%AF%81,%E5%88%86%E5%B8%83%E5%BC%8F%E8%A1%A8%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE,%E6%95%B0%E6%8D%AE%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%A4%8D%E5%88%B6%E8%A1%A8,ZooKeeper%E6%95%B4%E5%90%88,%E5%88%9B%E5%BB%BA%E5%A4%8D%E5%88%B6%E8%A1%A8,%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6,%E6%95%B0%E6%8D%AE%E5%8E%9F%E5%AD%90%E5%86%99%E5%85%A5%E4%B8%8E%E5%8E%BB%E9%87%8D,%E8%B4%9F%E8%BD%BD%E5%B9%B3%E8%A1%A1%E7%AD%96%E7%95%A5,%E6%A1%88%E4%BE%8B/</url>
    <content><![CDATA[<p>title: clickhouse副本同步与高可用功能验证,分布式表与集群配置,数据副本与复制表,ZooKeeper整合,创建复制表,副本同步机制,数据原子写入与去重,负载平衡策略,案例<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—### 1.分布式表与集群配置</p>
<blockquote>
</blockquote>
<ul>
<li>分布式表基于Distributed引擎创建，在多个分片上运行分布式查询。- 读取是自动并行化的，可使用远程服务器上的索引（如果有）。- 数据在请求的本地服务器上尽可能地被部分处理。例如，对于GROUP BY查询，数据将在远程服务器 上聚合，聚合函数的中间状态将发送到请求服务器，然后数据将进一步聚合。<br>创建分布式表： <pre><code class="language-sql">ENGINE = Distributed(cluster_name, db_name, table_name[, sharding_key[, policy_name]])
</code></pre> </li>
</ul>
<p> <strong>参数：</strong> </p>
<ul>
<li><strong>cluster_name:集群名称。</strong>- <strong>db_name:数据库名称，可使用常量表达式：currentDatabase()。</strong>- <strong>table_name: 各分片上的表名称。</strong>- <strong>sharding_key: (可选)分片的key，可设置为rand()。</strong>- <strong>policy_name: (可选）策略名称，用于存储异步发送的临时文件。</strong><br>例如下面的/etc/metrika.xml的一部分内容： <pre><code class="language-XML">&lt;remote_servers&gt;
 &lt;logs&gt;
     &lt;shard&gt;
         &lt;weight&gt;1&lt;/weight&gt;
         &lt;internal_replication&gt;false&lt;/internal_replication&gt;
         &lt;replica&gt;
             &lt;host&gt;example01-01-1&lt;/host&gt;
             &lt;port&gt;9000&lt;/port&gt;
         &lt;/replica&gt;
         &lt;replica&gt;
             &lt;host&gt;example01-01-2&lt;/host&gt;
             &lt;port&gt;9000&lt;/port&gt;
         &lt;/replica&gt;
     &lt;/shard&gt;
     &lt;shard&gt;
         &lt;weight&gt;2&lt;/weight&gt;
         &lt;internal_replication&gt;false&lt;/internal_replication&gt;
         &lt;replica&gt;
             &lt;host&gt;example01-02-1&lt;/host&gt;
             &lt;port&gt;9000&lt;/port&gt;
         &lt;/replica&gt;
         &lt;replica&gt;
             &lt;host&gt;example01-02-2&lt;/host&gt;
             &lt;secure&gt;1&lt;/secure&gt;
             &lt;port&gt;9000&lt;/port&gt;
         &lt;/replica&gt;
     &lt;/shard&gt;
 &lt;/logs&gt;
&lt;/remote_servers&gt;
</code></pre> 
这里定义了一个名为logs的集群名称，它有两个分片（shard）组成，每个分片包含两个副本（replica）。<br>分片是包含数据的不同服务器（要读取所有数据，必须访问所有分片）。<br>副本是存储复制数据的服务器（要读取所有数据，访问该分片上的任意一个副本上的数据即可）。 </li>
</ul>
<p> 1.weight : 可选，写入数据时分片的权重，建议忽略该配置。 2.internal_repliacation : 可选，同一时刻是否只将数据写入其中一个副本。默认值：false（将数据写入所有副本），建议设置为true。写一个即可。避免重复写。 3.副本配置：配置每个Server的信息，必须参数:host和port，可选参数：user、password、secure和compression。 （1）、host ： 远程服务器地址。支持IPv4和IPv6。也可指定域名，更改域名解析需 重启服务。 （2）、port ： 消息传递的TCP端口。配置文件的tcp_port指定的端口，通常设置为 9000。 （3）、user ： 用于连接到服务的用户名称。默认值：true。在users.xml文件中配置 了访问权限。 （4）、password：用于连接到远程服务的密码。默认值：空字符串。 （5）、secure ： 使用ssl进行连接，通常还应该定义port=9440。 （6）、compression ： 使用数据压缩。默认值：true。 </p>
<h3 id="2-数据副本与复制表"><a href="#2-数据副本与复制表" class="headerlink" title="2.数据副本与复制表"></a>2.数据副本与复制表</h3><blockquote>
</blockquote>
<ul>
<li>只有MergeTree系列引擎支持数据副本，支持副本的引擎是在MergeTree引擎名称的前面加上前缀 Replicated。- 副本是表级别的而不是整个服务器级别的，因此服务器可以同时存储复制表和非复制表。- 副本不依赖于分片，每个分片都有自己独立的副本。</li>
</ul>
<p> <strong>副本表如：</strong> </p>
<ul>
<li><strong>ReplicatedMergeTree</strong>- <strong>ReplicatedSummingMergeTree</strong>- <strong>ReplicatedReplacingMergeTree</strong>- <strong>ReplicatedAggregatingMergeTree</strong>- <strong>ReplicatedCollapsingMergeTree</strong>- <strong>ReplicatedVersionedCollapsingMergeTree</strong>- <strong>ReplicatedGraphiteMergeTree</strong></li>
</ul>
<h3 id="3-ZooKeeper整合"><a href="#3-ZooKeeper整合" class="headerlink" title="3.ZooKeeper整合"></a>3.ZooKeeper整合</h3><blockquote>
<p> ClickHouse使用Apache ZooKeeper来存储副本元信息, 在配置文件设置 zookeeper相关的参数。 ClickHouse在创建复制表的时候指定Zookeeper的目录，指定的目录会在建 表时自动创建。 如果ClickHouse的配置文件未配置ZooKeeper， 则无法创建复制表， 并且 任何存量的复制表都将是只读的。 对本地复制表的查询，不会使用ZooKeeper， 其查询速度和非复制表一样快。<br> 本地复制表的数据插入，针对每个数据块（一个块最多有 max_insert_block_size = 1048576条记录），会通过几个事务将大约十个条目添加到Zookeeper。因此，与非复制表相比， 复制表的INSERT操作等 待时间稍长。<br> <pre><code class="language-XML">&lt;zookeeper&gt;<br>    &lt;node index="1"&gt;<br>        &lt;host&gt;example1&lt;/host&gt;<br>        &lt;port&gt;2181&lt;/port&gt;<br>    &lt;/node&gt;<br>    &lt;node index="2"&gt;<br>        &lt;host&gt;example2&lt;/host&gt;<br>        &lt;port&gt;2181&lt;/port&gt;<br>    &lt;/node&gt;<br>    &lt;node index="3"&gt;<br>        &lt;host&gt;example3&lt;/host&gt;<br>        &lt;port&gt;2181&lt;/port&gt;<br>    &lt;/node&gt;<br>&lt;/zookeeper&gt;<br></code></pre> 
   </p>
</blockquote>
<h3 id="4-创建复制表"><a href="#4-创建复制表" class="headerlink" title="4.创建复制表"></a>4.创建复制表</h3><blockquote>
<p> 复制表的引擎要以Replicated为前缀，例如：ReplicatedMergeTree。<br> <pre><code class="language-sql">CREATE TABLE table_name<br>(<br>    EventDate DateTime,<br>    CounterID UInt32,<br>    UserID UInt32<br>) ENGINE = ReplicatedMergeTree('/clickhouse/tables/&#123;layer&#125;-&#123;shard&#125;/table_name', '&#123;replica&#125;')<br>PARTITION BY toYYYYMM(EventDate)<br>ORDER BY (CounterID, EventDate, intHash32(UserID))<br>SAMPLE BY intHash32(UserID);<br></code></pre><br> 引擎参数包含了变量，这些变量是在配置文件的”macros”部分配置的，例如：<br> <pre><code class="language-XML">&lt;macros&gt;<br>    &lt;layer&gt;05&lt;/layer&gt;<br>    &lt;shard&gt;02&lt;/shard&gt;<br>    &lt;replica&gt;clickhouse1&lt;/replica&gt;<br>&lt;/macros&gt;<br></code></pre><br> <strong>Replicated*MergeTree引擎参数：</strong> zoo_path : ZooKeeper中表的路径。 replica_name : ZooKeeper中的副本名称。<br> 1.第一个参数ZooKeeper路径组成： （1）、通用前缀：/clickhouse/tables/,建议复制表都使用类似这样的前缀。 （2）、分片标识符：{layer}-{shard},在本示例中，分片标识符有两部分组成，只要保证分片标识符能唯一标识一个分片即可。 （3）、ZooKeeper节点名称：table_name。节点名称最好与表名相同，节点名称在定义后不会更改，即使执行表的重命名操作。<strong>2.第二个参数是副本名称，用于标识同一个分片的不同副本。副本名称只需要在每个shard中唯一即可。</strong><br> 上面的示例中，复制引擎的参数使用了变量替换。ClickHouse也支持使用显示的参数。在这种情况下，不能使用分布式的DDL查询（ON CLUSTER）。建议使用变量替换的方式传入参数，<br> 降低出错概率。<br> 在每个副本服务器上运行CREATE TABLE语句，如果该分片的表在其他节点已经创建且有数据，则该新副本自动同步其他副本的数据。 </p>
</blockquote>
<h3 id="5-副本同步机制"><a href="#5-副本同步机制" class="headerlink" title="5.副本同步机制"></a>5.副本同步机制</h3><blockquote>
</blockquote>
<ul>
<li>复制是多主异步的。- INSERT语句（以及ALTER）可在任意可用的服务器上执行。数据首先插入到本地的服务器 （即运行查询的服务器），然后数据被复制到其他服务器。- 由于复制是异步的，所以最近插入的数据出现在其他副本上会有一定的延迟。- 如果部分副本不可用，则在它们可用时写入数据。- 如果副本可用， 则等待的时间是通过网络传输压缩数据块所耗费的时间。- 默认情况下， INSERT操作只需等待一个副本写入成功后返回。如果仅将数据成功写入一个 副本，并且该副本的服务器不再存在， 则存储的数据将丢失。要启动来自多个副本的写入确 认机制，使用insert_quorum选项。</li>
</ul>
<h3 id="6-数据原子写入与去重"><a href="#6-数据原子写入与去重" class="headerlink" title="6.数据原子写入与去重"></a>6.数据原子写入与去重</h3><blockquote>
</blockquote>
<ul>
<li>INSERT查询按照数据块插入数据，每个数据块最多max_insert_block_size(默认 max_insert_block_size = 1048576)条记录。换言之， 如果INSERT插入少于1048576条记 录，则插入操作是原子的。单个数据块的写入是原子的。- 数据块是去重的。 对于同一数据块的多次写入（相同大小的的数据块，包含相同的行以及相 同的顺序），该块仅写入一次。在出现网口故障等异常情况下， 客户端应用程序不知道数据 是否已将数据成功写入数据库，因此可以简单地重复执行INSERT查询。相同的数据发送到哪 个副本进行插入并不重要，INSERT是幂等的。数据去重可通过参数 insert_deduplicate控 制，默认为0(开启去重)。- 在复制过程中， 只有插入的源数据通过网络传输。进一步的数据转换（合并）会在所有副本 上以相同的方式进行处理。 这样可以最大限度减少网络带宽占用，这意味着当副本位于不同 的数据中心时，复制的效果也很好。- ClickHouse内部监控副本的数据同步，并能够在发生故障后恢复。故障转义是自动的（对于数据的微小差异）或半自动的（当数据的差异太大时，这可能表示配置错误）。- ClickHouse内部监控副本上的数据同步，并能够在发生故障后恢复。故障转移是自动的（对于数据的微小差异）或半自动的（当数据差异太大时，这可能表示配置错误）。</li>
</ul>
<h3 id="7-负载平衡策略"><a href="#7-负载平衡策略" class="headerlink" title="7.负载平衡策略"></a>7.负载平衡策略</h3><blockquote>
<p> 执行分布式查询时，首先计算分片的每个副本的错误数，然后将查询发送至最少错误的副本。如果没有错误或者错误数相同，则按如下的策略查询数据： 1.random(默认) ： 将查询发送至任意一个副本。 2.nearest_hostname : 将查询发送至主机名最相似的副本。 3.in_order : 将查询按配置文件中的配置顺序发送至副本。 4.first_or_random : 选择第一个副本，如果第一个副本不可用，随机选择一个可用的副本。<br> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/202012162320232.png#pic_center"><br> <strong>设置策略的方式：</strong><br> <pre><code class="language-sql">set load_balancing = 'first_or_random';<br></code></pre> 
   </p>
</blockquote>
<h3 id="8-案例"><a href="#8-案例" class="headerlink" title="8.案例"></a>8.案例</h3><blockquote>
<p> <strong>1.在所有节点执行如下语句：</strong><br> **     **创建本地复制表：<br> <pre><code class="language-sql">CREATE TABLE table_local on cluster mycluster<br>(<br>    EventDate DateTime,<br>    CounterID UInt32,<br>    UserID UInt32<br>) ENGINE = ReplicatedMergeTree('/clickhouse/tables/&#123;layer&#125;-&#123;shard&#125;/table_local', '&#123;replica&#125;')<br>PARTITION BY toYYYYMM(EventDate)<br>ORDER BY (CounterID, EventDate, intHash32(UserID))<br>SAMPLE BY intHash32(UserID);<br></code></pre><br> <strong>执行效果图： 在docker01-node节点执行的效果图如下：</strong><br> <img alt="" height="669" src="https://img-blog.csdnimg.cn/20210424154112568.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1074"> <br> <strong>在docker02-node上执行后的效果如下（提示已经存在了）：</strong><br> <pre><code class="language-sql">docker02-node :) CREATE TABLE table_local on cluster mycluster<br>:-] (<br>:-]     EventDate DateTime,<br>:-]     CounterID UInt32,<br>:-]     UserID UInt32<br>:-] ) ENGINE = ReplicatedMergeTree('/clickhouse/tables/&#123;layer&#125;-&#123;shard&#125;/table_local', '&#123;replica&#125;')<br>:-] PARTITION BY toYYYYMM(EventDate)<br>:-] ORDER BY (CounterID, EventDate, intHash32(UserID))<br>:-] SAMPLE BY intHash32(UserID);</p>
</blockquote>
<p>CREATE TABLE table_local ON CLUSTER mycluster<br>(<br>    <code>EventDate</code> DateTime,<br>    <code>CounterID</code> UInt32,<br>    <code>UserID</code> UInt32<br>)<br>ENGINE = ReplicatedMergeTree(‘/clickhouse/tables/{layer}-{shard}/table_local’, ‘{replica}’)<br>PARTITION BY toYYYYMM(EventDate)<br>ORDER BY (CounterID, EventDate, intHash32(UserID))<br>SAMPLE BY intHash32(UserID)</p>
<p>┌─host──────────┬─port─┬─status─┬─error─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬─num_hosts_remaining─┬─num_hosts_active─┐<br>│ 192.168.56.13 │ 9000 │     57 │ Code: 57, e.displayText() = DB::Exception: Table default.table_local already exists. (version 20.1.4.14 (official build)) │                   3 │                1 │<br>│ 192.168.56.11 │ 9000 │     57 │ Code: 57, e.displayText() = DB::Exception: Table default.table_local already exists. (version 20.1.4.14 (official build)) │                   2 │                1 │<br>│ 192.168.56.10 │ 9000 │     57 │ Code: 57, e.displayText() = DB::Exception: Table default.table_local already exists. (version 20.1.4.14 (official build)) │                   1 │                1 │<br>└───────────────┴──────┴────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────┴──────────────────┘<br>┌─host──────────┬─port─┬─status─┬─error─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬─num_hosts_remaining─┬─num_hosts_active─┐<br>│ 192.168.56.12 │ 9000 │     57 │ Code: 57, e.displayText() = DB::Exception: Table default.table_local already exists. (version 20.1.4.14 (official build)) │                   0 │                0 │<br>└───────────────┴──────┴────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────┴──────────────────┘<br>↓ Progress: 0.00 rows, 0.00 B (0.00 rows/s., 0.00 B/s.)                                                                                                                                0%Received exception from server (version 20.1.4):<br>Code: 57. DB::Exception: Received from 192.168.56.11:9000. DB::Exception: There was an error on [192.168.56.13:9000]: Code: 57, e.displayText() = DB::Exception: Table default.table_local already exists. (version 20.1.4.14 (official build)).</p>
<p>4 rows in set. Elapsed: 0.617 sec.</p>
<p>docker02-node :)</code></pre><br> 通过上面的案例可以知道，只要在一个节点上创建了副本表之后，在其它节点上也已经存在了。<br> <strong>创建分布式表(每个节点都要创建)：</strong><br> <pre><code class="language-sql">CREATE TABLE table_distributed as table_local ENGINE = Distributed(mycluster, default, table_local, rand());<br></code></pre><br> <strong>2.验证副本的复制****在clickhouse1上，对本地表操作。</strong><br> <img alt="" height="505" src="https://img-blog.csdnimg.cn/20210424154842225.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="903"><br> <strong>在docker02-node上（docker02-node的分片副本节点）上，验证数据是否同步：</strong><br> <img alt="" height="335" src="https://img-blog.csdnimg.cn/20210424154940833.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="961"><br> <strong>在docker03-node和docker04-node上执行（即shard2上）。发现查询不到结果，效果如下：</strong><br> <img alt="" height="218" src="https://img-blog.csdnimg.cn/20210424155132498.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="558"><br> <img alt="" height="250" src="https://img-blog.csdnimg.cn/20210424155146647.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="557"><br> 3.<strong>验证集群的功能</strong><br> 在任意节点查看分布式表的数据（都将出现下面的效果）。<br> <img alt="" height="277" src="https://img-blog.csdnimg.cn/20210424155259421.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="738"><br> 在任意一个节点往分布式表里面插入5条数据：<br> <pre><code class="language-sql">insert into table_distributed values('2020-03-11 12:12:31', 21, 1);    docker04-node上执行<br>insert into table_distributed values('2020-03-12 12:12:32', 22, 2);    docker04-node上执行<br>insert into table_distributed values('2020-03-13 12:12:33', 23, 3);    docker03-node上执行<br>insert into table_distributed values('2020-03-14 12:12:34', 24, 4);    docker03-node上执行<br>insert into table_distributed values('2020-03-15 12:12:35', 25, 5);    docker02-node上执行<br></code></pre><br> 然后在任意一台机器上执行：<br> <pre><code class="language-sql">select * from table_distributed;<br></code></pre><br> 都可以看到：<br> <pre><code class="language-sql">docker02-node :) select * from table_distributed;</p>
<p>SELECT *<br>FROM table_distributed</p>
<p>┌───────────EventDate─┬─CounterID─┬─UserID─┐<br>│ 2020-03-11 12:12:33 │        22 │     37 │<br>└─────────────────────┴───────────┴────────┘<br>┌───────────EventDate─┬─CounterID─┬─UserID─┐<br>│ 2020-03-12 12:12:32 │        22 │      2 │<br>└─────────────────────┴───────────┴────────┘<br>┌───────────EventDate─┬─CounterID─┬─UserID─┐<br>│ 2020-03-11 12:12:31 │        21 │      1 │<br>└─────────────────────┴───────────┴────────┘<br>┌───────────EventDate─┬─CounterID─┬─UserID─┐<br>│ 2020-03-14 12:12:34 │        24 │      4 │<br>└─────────────────────┴───────────┴────────┘<br>┌───────────EventDate─┬─CounterID─┬─UserID─┐<br>│ 2020-03-13 12:12:33 │        23 │      3 │<br>└─────────────────────┴───────────┴────────┘<br>┌───────────EventDate─┬─CounterID─┬─UserID─┐<br>│ 2020-03-15 12:12:35 │        25 │      5 │<br>└─────────────────────┴───────────┴────────┘</p>
<p>6 rows in set. Elapsed: 0.007 sec.</p>
<p>docker02-node :)</code></pre><br> 然后，分别在两个分片的主机上查询本地表：<strong>在docker01-node上（shard1）发现的效果是：</strong><br> <img alt="" height="445" src="https://img-blog.csdnimg.cn/2021042416000130.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="555"><br> <strong>在docker03-node上（shard2）发现的效果是：</strong><br> <img alt="" height="340" src="https://img-blog.csdnimg.cn/20210424160051386.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="564"><br> 可以看到，使用分布式表插入数据，数据分散到不同分片（shard）的本地表。 </p>
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>Elasticsearch之JAVA API操作</title>
    <url>/2021/07/18/Elasticsearch%E4%B9%8BJAVA%20API%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<p>title: Elasticsearch之JAVA API操作<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、JavaAPI-环境准备</p>
<blockquote>
<p> 1.1、创建一个springboot项目<br>       <img alt="" height="300" src="https://img-blog.csdnimg.cn/2021062012261018.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="477">      pom的依赖如下：<br> <pre><code class="language-html">&lt;?xml version="1.0" encoding="UTF-8"?&gt;<br>&lt;project xmlns="<a href="http://maven.apache.org/POM/4.0.0&quot;">http://maven.apache.org/POM/4.0.0&quot;</a><br>         xmlns:xsi="<a href="http://www.w3.org/2001/XMLSchema-instance&quot;">http://www.w3.org/2001/XMLSchema-instance&quot;</a><br>         xsi:schemaLocation="<a href="http://maven.apache.org/POM/4.0.0">http://maven.apache.org/POM/4.0.0</a> <a href="http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;">http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</a>&gt;<br>    &lt;parent&gt;<br>        &lt;artifactId&gt;kgf-java-learning&lt;/artifactId&gt;<br>        &lt;groupId&gt;com.kgf.learning&lt;/groupId&gt;<br>        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;<br>        &lt;relativePath&gt;../kgf-java-learning/pom.xml&lt;/relativePath&gt;<br>    &lt;/parent&gt;<br>    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</p>
</blockquote>
<pre><code>&amp;lt;groupId&amp;gt;com.kgf.es7.8&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;kgf-es7.8-api&amp;lt;/artifactId&amp;gt;
&amp;lt;properties&amp;gt;
    &amp;lt;!--自定义elasticsearch版本--&amp;gt;
    &amp;lt;elasticsearch.version&amp;gt;7.8.0&amp;lt;/elasticsearch.version&amp;gt;
    &amp;lt;lombok.version&amp;gt;1.18.16&amp;lt;/lombok.version&amp;gt;
    &amp;lt;fastjson.version&amp;gt;1.2.75&amp;lt;/fastjson.version&amp;gt;
&amp;lt;/properties&amp;gt;
&amp;lt;dependencies&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;com.alibaba&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;fastjson&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;$&#123;fastjson.version&#125;&amp;lt;/version&amp;gt;
    &amp;lt;/dependency&amp;gt;
    &amp;lt;!--引入lombok依赖--&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.projectlombok&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;lombok&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;$&#123;lombok.version&#125;&amp;lt;/version&amp;gt;
    &amp;lt;/dependency&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-data-elasticsearch&amp;lt;/artifactId&amp;gt;
    &amp;lt;/dependency&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
    &amp;lt;/dependency&amp;gt;
    &amp;lt;!--引入Juntil单元测试 --&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt;
    &amp;lt;/dependency&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-configuration-processor&amp;lt;/artifactId&amp;gt;
        &amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;
    &amp;lt;/dependency&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-thymeleaf&amp;lt;/artifactId&amp;gt;
    &amp;lt;/dependency&amp;gt;
    &amp;lt;!--jsoup解析网页，tiks解析视频音乐--&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.jsoup&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;jsoup&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;1.10.2&amp;lt;/version&amp;gt;
    &amp;lt;/dependency&amp;gt;
&amp;lt;/dependencies&amp;gt;
&amp;lt;build&amp;gt;
    &amp;lt;plugins&amp;gt;
        &amp;lt;plugin&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;2.2.11.RELEASE&amp;lt;/version&amp;gt;
        &amp;lt;/plugin&amp;gt;
        &amp;lt;plugin&amp;gt;
            &amp;lt;artifactId&amp;gt;maven-compiler-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;configuration&amp;gt;
                &amp;lt;source&amp;gt;1.8&amp;lt;/source&amp;gt;
                &amp;lt;target&amp;gt;1.8&amp;lt;/target&amp;gt;
            &amp;lt;/configuration&amp;gt;
        &amp;lt;/plugin&amp;gt;
    &amp;lt;/plugins&amp;gt;
&amp;lt;/build&amp;gt;
</code></pre>
<p>&lt;/project&gt;</code></pre><br> <pre><code>ElasticConfig.java如下：</code></pre><br> <pre><code class="language-java">package com.kgf.es.config;</p>
<p>import org.apache.http.HttpHost;<br>import org.elasticsearch.client.RestClient;<br>import org.elasticsearch.client.RestHighLevelClient;<br>import org.springframework.context.annotation.Bean;<br>import org.springframework.context.annotation.Configuration;</p>
<p>@Configuration<br>public class ElasticConfig &#123;</p>
<pre><code>@Bean
public RestHighLevelClient restHighLevelClient()&#123;
    RestHighLevelClient client = new RestHighLevelClient(
            RestClient.builder(new HttpHost(&quot;127.0.0.1&quot;, 9200, &quot;http&quot;))
    );
    return client;
&#125;
</code></pre>
<p>}<br></code></pre><br> 1.2、ESApplication.java如下<br> <pre><code class="language-java">package com.kgf.es;</p>
<p>import org.springframework.boot.SpringApplication;<br>import org.springframework.boot.autoconfigure.SpringBootApplication;</p>
<p>@SpringBootApplication<br>public class ESApplication &#123;</p>
<pre><code>public static void main(String[] args) &#123;

    SpringApplication.run(ESApplication.class,args);

&#125;
</code></pre>
<p>}<br></code></pre> 
   </p>
<h3 id="2、JavaAPI-索引-创建"><a href="#2、JavaAPI-索引-创建" class="headerlink" title="2、JavaAPI-索引-创建"></a>2、JavaAPI-索引-创建</h3><blockquote>
<p> 2.1、在一个Junit测试类创建索引<br> <pre><code class="language-java">package es7;</p>
</blockquote>
<p>import com.kgf.es.ESApplication;<br>import org.elasticsearch.client.RequestOptions;<br>import org.elasticsearch.client.RestHighLevelClient;<br>import org.elasticsearch.client.indices.CreateIndexRequest;<br>import org.elasticsearch.client.indices.CreateIndexResponse;<br>import org.junit.Test;<br>import org.junit.runner.RunWith;<br>import org.springframework.boot.test.context.SpringBootTest;<br>import org.springframework.test.context.junit4.SpringRunner;</p>
<p>import javax.annotation.Resource;<br>import java.io.IOException;</p>
<p>@RunWith(SpringRunner.class)<br>@SpringBootTest(classes = ESApplication.class,webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)<br>public class EsApplicationTest &#123;</p>
<pre><code>@Resource
private RestHighLevelClient restHighLevelClient;

/***
 * 创建索引
 */
@Test
public void createIndexTest()&#123;
    try &#123;
        //创建索引对象
        CreateIndexRequest indexRequest = new CreateIndexRequest(&quot;user&quot;);
        //客户端执行请求
        CreateIndexResponse response = restHighLevelClient.indices().create(indexRequest, RequestOptions.DEFAULT);

        boolean acknowledged = response.isAcknowledged();
        // 响应状态
        System.out.println(&quot;操作状态 = &quot; + acknowledged);
    &#125; catch (IOException e) &#123;
        e.printStackTrace();
    &#125;
&#125;
</code></pre>
<p>}<br></code></pre><br> 执行：<br> <img alt="" height="245" src="https://img-blog.csdnimg.cn/20210620123925330.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="724"><br> 查看索引：<br> <img alt="" height="503" src="https://img-blog.csdnimg.cn/20210620124000441.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="1100"> </p>
<h3 id="3、索引-查询-amp-删除"><a href="#3、索引-查询-amp-删除" class="headerlink" title="3、索引-查询 &amp; 删除"></a>3、索引-查询 &amp; 删除</h3><blockquote>
<p> <strong>3.1、查询</strong><br> <pre><code class="language-java">   /***<br>     * 查询索引<br>     */<br>    @Test<br>    public void getIndexTest()&#123;<br>        try &#123;<br>            // 查询索引 - 请求对象<br>            GetIndexRequest request = new GetIndexRequest("user");<br>            // 发送请求，获取响应<br>            GetIndexResponse response = restHighLevelClient.indices().get(request,<br>                    RequestOptions.DEFAULT);</p>
</blockquote>
<pre><code>        System.out.println(&quot;aliases:&quot;+response.getAliases());
        System.out.println(&quot;mappings:&quot;+response.getMappings());
        System.out.println(&quot;settings:&quot;+response.getSettings());
    &#125; catch (IOException e) &#123;
        e.printStackTrace();
    &#125;
&#125;&lt;/code&gt;&lt;/pre&gt; 
</code></pre>
<p> 后台打印：<br> <pre><code class="language-java">aliases:&#123;user=[]&#125;<br>mappings:&#123;user=org.elasticsearch.cluster.metadata.MappingMetadata@872c984c&#125;<br>settings:&#123;user=&#123;"index.creation_date":"1624163950299","index.number_of_replicas":"1","index.number_of_shards":"1","index.provided_name":"user","index.uuid":"XvPUSw3rR7CjmrGk0BtdCw","index.version.created":"7080099"&#125;&#125;<br></code></pre><br> <strong>3.2、删除</strong><br> <pre><code class="language-java"> /***<br>     * 删除索引<br>     */<br>    @Test<br>    public void DelIndexTest()&#123;<br>        try &#123;<br>            // 删除索引 - 请求对象<br>            DeleteIndexRequest request = new DeleteIndexRequest("user");<br>            // 发送请求，获取响应<br>            AcknowledgedResponse response = restHighLevelClient.indices().delete(request,RequestOptions.DEFAULT);<br>            // 操作结果<br>            System.out.println("操作结果 ： " + response.isAcknowledged());<br>        &#125; catch (IOException e) &#123;<br>            e.printStackTrace();<br>        &#125;<br>    &#125;</code></pre><br> 后台打印：<br> <pre><code>操作结果 ： true<br></code></pre> 
   </p>
<h3 id="4、JavaAPI-文档-新增-amp-修改"><a href="#4、JavaAPI-文档-新增-amp-修改" class="headerlink" title="4、JavaAPI-文档-新增 &amp; 修改"></a>4、JavaAPI-文档-新增 &amp; 修改</h3><blockquote>
<p> <strong>4.1、新增</strong><br> <pre><code class="language-java">/***<br>     * 添加文档<br>     */<br>    @Test<br>    public void addDocumentTest()&#123;<br>        try &#123;<br>            // 新增文档 - 请求对象<br>            IndexRequest request = new IndexRequest();<br>            // 设置索引及唯一性标识<br>            request.index("user").id("1001");</p>
</blockquote>
<pre><code>        // 创建数据对象
        User user = new User();
        user.setName(&quot;zhangsan&quot;);
        user.setAge(30);
        user.setSex(&quot;男&quot;);

        ObjectMapper objectMapper = new ObjectMapper();
        String productJson = objectMapper.writeValueAsString(user);
        // 添加文档数据，数据格式为 JSON 格式
        request.source(productJson, XContentType.JSON);
        // 客户端发送请求，获取响应对象
        IndexResponse response = restHighLevelClient.index(request, RequestOptions.DEFAULT);
        //打印结果信息
        System.out.println(&quot;_index:&quot; + response.getIndex());
        System.out.println(&quot;_id:&quot; + response.getId());
        System.out.println(&quot;_result:&quot; + response.getResult());
    &#125; catch (IOException e) &#123;
        e.printStackTrace();
    &#125;
&#125;&lt;/code&gt;&lt;/pre&gt; 
</code></pre>
<p> 后台打印：<br> <img alt="" height="210" src="https://img-blog.csdnimg.cn/20210620172914512.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tfNTIwX1c=,size_16,color_FFFFFF,t_70" width="668"><br> <strong>4.2、修改</strong><br> <pre><code class="language-java">/***<br>     * 修改文档信息<br>     */<br>    @Test<br>    public void updateDocument()&#123;<br>        try &#123;<br>            // 修改文档 - 请求对象<br>            UpdateRequest request = new UpdateRequest();<br>            // 配置修改参数<br>            request.index("user").id("1001");<br>            // 设置请求体，对数据进行修改<br>            request.doc(XContentType.JSON, "sex", "女");<br>            // 客户端发送请求，获取响应对象<br>            UpdateResponse response = restHighLevelClient.update(request, RequestOptions.DEFAULT);<br>            System.out.println("_index:" + response.getIndex());<br>            System.out.println("_id:" + response.getId());<br>            System.out.println("_result:" + response.getResult());<br>        &#125; catch (Exception e) &#123;<br>            e.printStackTrace();<br>        &#125;<br>    &#125;</code></pre><br> 后台打印：<br> <img alt="" height="188" src="https://img-blog.csdnimg.cn/20210620173126639.png" width="699"> </p>
<h3 id="5、文档-查询-amp-删除"><a href="#5、文档-查询-amp-删除" class="headerlink" title="5、文档-查询 &amp; 删除"></a>5、文档-查询 &amp; 删除</h3><blockquote>
<p> <strong>5.1、查询文档</strong><br> <pre><code class="language-java"> /***<br>     * 查询文档信息<br>     */<br>    @Test<br>    public void queryDocument()&#123;<br>        try &#123;<br>            //1.创建请求对象<br>            GetRequest request = new GetRequest().index("user").id("1001");<br>            //2.客户端发送请求，获取响应对象<br>            GetResponse response = restHighLevelClient.get(request, RequestOptions.DEFAULT);<br>            //打印结果信息<br>            System.out.println("_index:" + response.getIndex());<br>            System.out.println("_type:" + response.getType());<br>            System.out.println("_id:" + response.getId());<br>            System.out.println("source:" + response.getSourceAsString());<br>        &#125; catch (Exception e) &#123;<br>            e.printStackTrace();<br>        &#125;<br>    &#125;</code></pre><br> 后台打印：<br> <pre><code class="language-java">_index:user<br>_type:_doc<br>_id:1001<br>source:&#123;"name":"zhangsan","age":30,"sex":"男"&#125;</p>
</blockquote>
<p>Process finished with exit code 0<br></code></pre><br> <strong>5.2、删除</strong><br> <pre><code class="language-java"> /***<br>     * 删除文档操作<br>     * @throws IOException<br>     */<br>    @Test<br>    public void delDocumentTest() throws IOException &#123;<br>        //创建请求对象<br>        DeleteRequest request = new DeleteRequest().index("user").id("1001");<br>        //客户端发送请求，获取响应对象<br>        DeleteResponse response = restHighLevelClient.delete(request, RequestOptions.DEFAULT);<br>        //打印信息<br>        System.out.println(response.toString());<br>    &#125;</code></pre><br> 后台打印：<br> <pre><code class="language-java">DeleteResponse[index=user,type=_doc,id=1001,version=16,result=deleted,shards=ShardInfo&#123;total=2, successful=1, failures=[]&#125;]</p>
<p>Process finished with exit code 0<br></code></pre> 
   </p>
<h3 id="6、文档-批量新增-amp-批量删除"><a href="#6、文档-批量新增-amp-批量删除" class="headerlink" title="6、文档-批量新增 &amp; 批量删除"></a>6、文档-批量新增 &amp; 批量删除</h3><blockquote>
<p> <strong>6.1、批量新增</strong><br> <pre><code class="language-java"> /***<br>     * 测试批量插入操作<br>     * @throws IOException<br>     */<br>    @Test<br>    public void bulkInsertRequestTest() throws IOException &#123;<br>        //创建批量新增请求对象<br>        BulkRequest request = new BulkRequest();<br>        request.add(new<br>                IndexRequest().index("user").id("1001").source(XContentType.JSON, "name",<br>                "zhangsan"));<br>        request.add(new<br>                IndexRequest().index("user").id("1002").source(XContentType.JSON, "name",<br>                "lisi"));<br>        request.add(new<br>                IndexRequest().index("user").id("1003").source(XContentType.JSON, "name",<br>                "wangwu"));<br>        //客户端发送请求，获取响应对象<br>        BulkResponse responses = restHighLevelClient.bulk(request, RequestOptions.DEFAULT);<br>        //打印结果信息<br>        System.out.println("took:" + responses.getTook());<br>        System.out.println("items:" + responses.getItems());<br>    &#125;</code></pre><br> 后台打印<br> <pre><code class="language-java">took:294ms<br>items:[Lorg.elasticsearch.action.bulk.BulkItemResponse;@2beee7ff</p>
</blockquote>
<p>Process finished with exit code 0<br></code></pre><br> <strong>6.2、批量删除</strong><br> <pre><code class="language-java">  /***<br>     * 测试批量插入操作<br>     * @throws IOException<br>     */<br>    @Test<br>    public void bulkDeleteRequestTest() throws IOException &#123;<br>        //创建批量删除请求对象<br>        BulkRequest request = new BulkRequest();<br>        request.add(new DeleteRequest().index("user").id("1001"));<br>        request.add(new DeleteRequest().index("user").id("1002"));<br>        request.add(new DeleteRequest().index("user").id("1003"));<br>        //客户端发送请求，获取响应对象<br>        BulkResponse responses = restHighLevelClient.bulk(request, RequestOptions.DEFAULT);<br>        //打印结果信息<br>        System.out.println("took:" + responses.getTook());<br>        System.out.println("items:" + responses.getItems());<br>    &#125;</code></pre><br> 后台打印<br> <pre><code class="language-java">took:108ms<br>items:[Lorg.elasticsearch.action.bulk.BulkItemResponse;@7b02881e</p>
<p>Process finished with exit code 0</p>
<p></code></pre> 
   </p>
<h3 id="7、文档-高级查询-全量查询"><a href="#7、文档-高级查询-全量查询" class="headerlink" title="7、文档-高级查询-全量查询"></a>7、文档-高级查询-全量查询</h3><blockquote>
<p> 7.1、先批量增加数据<br> <pre><code class="language-java"> /***<br>     * 测试批量插入操作<br>     * @throws IOException<br>     */<br>    @Test<br>    public void bulkInsertRequestTest() throws IOException &#123;<br>        //创建批量新增请求对象<br>        BulkRequest request = new BulkRequest();<br>        request.add(new IndexRequest().index("user").id("1001").source(XContentType.JSON, "name", "zhangsan", "age", "10", "sex","女"));<br>        request.add(new IndexRequest().index("user").id("1002").source(XContentType.JSON, "name", "lisi", "age", "30", "sex","女"));<br>        request.add(new IndexRequest().index("user").id("1003").source(XContentType.JSON, "name", "wangwu1", "age", "40", "sex","男"));<br>        request.add(new IndexRequest().index("user").id("1004").source(XContentType.JSON, "name", "wangwu2", "age", "20", "sex","女"));<br>        request.add(new IndexRequest().index("user").id("1005").source(XContentType.JSON, "name", "wangwu3", "age", "50", "sex","男"));<br>        request.add(new IndexRequest().index("user").id("1006").source(XContentType.JSON, "name", "wangwu4", "age", "20", "sex","男"));<br>        //客户端发送请求，获取响应对象<br>        BulkResponse responses = restHighLevelClient.bulk(request, RequestOptions.DEFAULT);<br>        //打印结果信息<br>        System.out.println("took:" + responses.getTook());<br>        System.out.println("items:" + responses.getItems());<br>    &#125;</code></pre><br> 后台打印<br> <pre><code class="language-java">took:168ms<br>items:[Lorg.elasticsearch.action.bulk.BulkItemResponse;@2beee7ff</p>
</blockquote>
<p>Process finished with exit code 0<br></code></pre><br> <strong>查询所有索引数据</strong><br> <pre><code class="language-java">/***<br>     * 查询所有索引数据<br>     * @throws IOException<br>     */<br>    @Test<br>    public void searchRequestTest() throws IOException &#123;<br>        // 创建搜索请求对象<br>        SearchRequest request = new SearchRequest();<br>        request.indices("user");<br>        // 构建查询的请求体<br>        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();<br>        // 查询所有数据<br>        sourceBuilder.query(QueryBuilders.matchAllQuery());<br>        request.source(sourceBuilder);<br>        SearchResponse response = restHighLevelClient.search(request, RequestOptions.DEFAULT);<br>        // 查询匹配<br>        SearchHits hits = response.getHits();<br>        System.out.println("took:" + response.getTook());<br>        System.out.println("timeout:" + response.isTimedOut());<br>        System.out.println("total:" + hits.getTotalHits());<br>        System.out.println("MaxScore:" + hits.getMaxScore());<br>        System.out.println("hits========&gt;&gt;");<br>        for (SearchHit hit : hits) &#123;<br>            //输出每条查询的结果信息<br>            System.out.println(hit.getSourceAsString());<br>        &#125;<br>        System.out.println("&lt;&lt;========");<br>    &#125;</code></pre><br> 后台打印<br> <pre><code class="language-java">took:2ms<br>timeout:false<br>total:6 hits<br>MaxScore:1.0<br>hits========&gt;&gt;<br>&#123;"name":"zhangsan","age":"10","sex":"女"&#125;<br>&#123;"name":"lisi","age":"30","sex":"女"&#125;<br>&#123;"name":"wangwu1","age":"40","sex":"男"&#125;<br>&#123;"name":"wangwu2","age":"20","sex":"女"&#125;<br>&#123;"name":"wangwu3","age":"50","sex":"男"&#125;<br>&#123;"name":"wangwu4","age":"20","sex":"男"&#125;<br>&lt;&lt;========</p>
<p>Process finished with exit code 0<br></code></pre> 
   </p>
<h3 id="8、文档-高级查询-分页查询-amp-条件查询-amp-查询排序"><a href="#8、文档-高级查询-分页查询-amp-条件查询-amp-查询排序" class="headerlink" title="8、文档-高级查询-分页查询 &amp; 条件查询 &amp; 查询排序"></a>8、文档-高级查询-分页查询 &amp; 条件查询 &amp; 查询排序</h3><blockquote>
<p> <strong>8.1、条件查询</strong><br> <pre><code class="language-java"> /***<br>     * 条件查询<br>     * @throws IOException<br>     */<br>    @Test<br>    public void queryByConditiontest() throws IOException &#123;<br>        // 创建搜索请求对象<br>        SearchRequest request = new SearchRequest();<br>        request.indices("user");<br>        // 构建查询的请求体<br>        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();<br>        sourceBuilder.query(QueryBuilders.termQuery("age", "30"));<br>        request.source(sourceBuilder);<br>        SearchResponse response = restHighLevelClient.search(request, RequestOptions.DEFAULT);<br>        // 查询匹配<br>        SearchHits hits = response.getHits();<br>        System.out.println("took:" + response.getTook());<br>        System.out.println("timeout:" + response.isTimedOut());<br>        System.out.println("total:" + hits.getTotalHits());<br>        System.out.println("MaxScore:" + hits.getMaxScore());<br>        System.out.println("hits========&gt;&gt;");<br>        for (SearchHit hit : hits) &#123;<br>            //输出每条查询的结果信息<br>            System.out.println(hit.getSourceAsString());<br>        &#125;<br>        System.out.println("&lt;&lt;========");<br>    &#125;</code></pre><br> 后台打印<br> <pre><code class="language-java">took:1ms<br>timeout:false<br>total:1 hits<br>MaxScore:1.0<br>hits========&gt;&gt;<br>&#123;"name":"lisi","age":"30","sex":"女"&#125;<br>&lt;&lt;========<br></code></pre><br> <strong>8.2、分页查询</strong> </p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/***</span><br><span class="line">     * 条件查询</span><br><span class="line">     * @throws IOException</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void queryByPagetest() throws IOException &#123;</span><br><span class="line">        // 创建搜索请求对象</span><br><span class="line">        SearchRequest request = new SearchRequest();</span><br><span class="line">        request.indices(&quot;user&quot;);</span><br><span class="line">        // 构建查询的请求体</span><br><span class="line">        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();</span><br><span class="line">        sourceBuilder.query(QueryBuilders.matchAllQuery());</span><br><span class="line">        // 分页查询</span><br><span class="line">        // 当前页其实索引(第一条数据的顺序号)， from</span><br><span class="line">        sourceBuilder.from(0);</span><br><span class="line"></span><br><span class="line">        // 每页显示多少条 size</span><br><span class="line">        sourceBuilder.size(2);</span><br><span class="line">        request.source(sourceBuilder);</span><br><span class="line">        SearchResponse response = restHighLevelClient.search(request, RequestOptions.DEFAULT);</span><br><span class="line">        // 查询匹配</span><br><span class="line">        SearchHits hits = response.getHits();</span><br><span class="line">        System.out.println(&quot;took:&quot; + response.getTook());</span><br><span class="line">        System.out.println(&quot;timeout:&quot; + response.isTimedOut());</span><br><span class="line">        System.out.println(&quot;total:&quot; + hits.getTotalHits());</span><br><span class="line">        System.out.println(&quot;MaxScore:&quot; + hits.getMaxScore());</span><br><span class="line">        System.out.println(&quot;hits========&amp;gt;&amp;gt;&quot;);</span><br><span class="line">        for (SearchHit hit : hits) &#123;</span><br><span class="line">            //输出每条查询的结果信息</span><br><span class="line">            System.out.println(hit.getSourceAsString());</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(&quot;&amp;lt;&amp;lt;========&quot;);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>后台打印</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">took:1ms</span><br><span class="line">timeout:false</span><br><span class="line">total:6 hits</span><br><span class="line">MaxScore:1.0</span><br><span class="line">hits========&amp;gt;&amp;gt;</span><br><span class="line">&#123;&quot;name&quot;:&quot;zhangsan&quot;,&quot;age&quot;:&quot;10&quot;,&quot;sex&quot;:&quot;女&quot;&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lisi&quot;,&quot;age&quot;:&quot;30&quot;,&quot;sex&quot;:&quot;女&quot;&#125;</span><br><span class="line">&amp;lt;&amp;lt;========</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="8-3、查询排序"><a href="#8-3、查询排序" class="headerlink" title="8.3、查询排序"></a>8.3、查询排序</h3><blockquote>
 <pre><code class="language-java">/***
     * 条件查询
     * @throws IOException
     */
    @Test
    public void queryByOrdertest() throws IOException &#123;
        // 创建搜索请求对象
        SearchRequest request = new SearchRequest();
        request.indices("user");
</blockquote>
<pre><code>    // 构建查询的请求体
    SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
    sourceBuilder.query(QueryBuilders.matchAllQuery());
    // 排序
    sourceBuilder.sort(&quot;age&quot;, SortOrder.ASC);
    request.source(sourceBuilder);
    SearchResponse response = restHighLevelClient.search(request, RequestOptions.DEFAULT);
    // 查询匹配
    SearchHits hits = response.getHits();
    System.out.println(&quot;took:&quot; + response.getTook());
    System.out.println(&quot;timeout:&quot; + response.isTimedOut());
    System.out.println(&quot;total:&quot; + hits.getTotalHits());
    System.out.println(&quot;MaxScore:&quot; + hits.getMaxScore());
    System.out.println(&quot;hits========&amp;gt;&amp;gt;&quot;);
    for (SearchHit hit : hits) &#123;
        //输出每条查询的结果信息
        System.out.println(hit.getSourceAsString());
    &#125;
    System.out.println(&quot;&amp;lt;&amp;lt;========&quot;);
&#125;&lt;/code&gt;&lt;/pre&gt; 
</code></pre>
<p> 后台打印<br> <pre><code class="language-java">took:1ms<br>timeout:false<br>total:6 hits<br>MaxScore:NaN<br>hits========&gt;&gt;<br>&#123;"name":"zhangsan","age":"10","sex":"女"&#125;<br>&#123;"name":"wangwu2","age":"20","sex":"女"&#125;<br>&#123;"name":"wangwu4","age":"20","sex":"男"&#125;<br>&#123;"name":"lisi","age":"30","sex":"女"&#125;<br>&#123;"name":"wangwu1","age":"40","sex":"男"&#125;<br>&#123;"name":"wangwu3","age":"50","sex":"男"&#125;<br>&lt;&lt;========<br></code></pre> 
   </p>
<h3 id="9、高级查询-组合查询-amp-范围查询"><a href="#9、高级查询-组合查询-amp-范围查询" class="headerlink" title="9、高级查询-组合查询 &amp; 范围查询"></a>9、高级查询-组合查询 &amp; 范围查询</h3><blockquote>
 <h3>9.1、组合查询</h3> 
 <pre><code class="language-java"> /***
     * 条件查询
     * @throws IOException
     */
    @Test
    public void queryByCombinattest() throws IOException &#123;
        // 创建搜索请求对象
        SearchRequest request = new SearchRequest();
        request.indices("user");
        // 构建查询的请求体
        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
        BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
        // 必须包含
        boolQueryBuilder.must(QueryBuilders.matchQuery("age", "30"));
        // 一定不含
        boolQueryBuilder.mustNot(QueryBuilders.matchQuery("name", "zhangsan"));
        // 可能包含
        boolQueryBuilder.should(QueryBuilders.matchQuery("sex", "男"));
        sourceBuilder.query(boolQueryBuilder);
        request.source(sourceBuilder);
        SearchResponse response = restHighLevelClient.search(request, RequestOptions.DEFAULT);
        // 查询匹配
        SearchHits hits = response.getHits();
        System.out.println("took:" + response.getTook());
        System.out.println("timeout:" + response.isTimedOut());
        System.out.println("total:" + hits.getTotalHits());
        System.out.println("MaxScore:" + hits.getMaxScore());
        System.out.println("hits========&gt;&gt;");
        for (SearchHit hit : hits) &#123;
            //输出每条查询的结果信息
            System.out.println(hit.getSourceAsString());
        &#125;
        System.out.println("&lt;&lt;========");
    &#125;</code></pre> 
 后台打印 
 <pre><code class="language-java">took:28ms
timeout:false
total:1 hits
MaxScore:1.0
hits========&gt;&gt;
&#123;"name":"lisi","age":"30","sex":"女"&#125;
&lt;&lt;========
</blockquote>
<p>Process finished with exit code 0<br></code></pre><br> <strong>9.2、范围查询</strong><br> <pre><code class="language-java">import com.lun.elasticsearch.hello.ConnectElasticsearch;<br>import com.lun.elasticsearch.hello.ElasticsearchTask;<br>import org.elasticsearch.action.search.SearchRequest;<br>import org.elasticsearch.action.search.SearchResponse;<br>import org.elasticsearch.client.RequestOptions;<br>import org.elasticsearch.index.query.BoolQueryBuilder;<br>import org.elasticsearch.index.query.QueryBuilders;<br>import org.elasticsearch.index.query.RangeQueryBuilder;<br>import org.elasticsearch.search.SearchHit;<br>import org.elasticsearch.search.SearchHits;<br>import org.elasticsearch.search.builder.SearchSourceBuilder;<br>import org.elasticsearch.search.sort.SortOrder;</p>
<p>public class QueryDoc &#123;</p>
<pre><code>public static final ElasticsearchTask SEARCH_BY_RANGE = client -&amp;gt; &#123;
    // 创建搜索请求对象
    SearchRequest request = new SearchRequest();
    request.indices(&quot;user&quot;);
    // 构建查询的请求体
    SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
    RangeQueryBuilder rangeQuery = QueryBuilders.rangeQuery(&quot;age&quot;);
    // 大于等于
    //rangeQuery.gte(&quot;30&quot;);
    // 小于等于
    rangeQuery.lte(&quot;40&quot;);
    sourceBuilder.query(rangeQuery);
    request.source(sourceBuilder);
    SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    // 查询匹配
    SearchHits hits = response.getHits();
    System.out.println(&quot;took:&quot; + response.getTook());
    System.out.println(&quot;timeout:&quot; + response.isTimedOut());
    System.out.println(&quot;total:&quot; + hits.getTotalHits());
    System.out.println(&quot;MaxScore:&quot; + hits.getMaxScore());
    System.out.println(&quot;hits========&amp;gt;&amp;gt;&quot;);
    for (SearchHit hit : hits) &#123;
    //输出每条查询的结果信息
        System.out.println(hit.getSourceAsString());
    &#125;
    System.out.println(&quot;&amp;lt;&amp;lt;========&quot;);
&#125;;

public static void main(String[] args) &#123;
    ConnectElasticsearch.connect(SEARCH_BY_RANGE);
&#125;
</code></pre>
<p>}</p>
<p></code></pre><br> 后台打印<br> <pre><code class="language-java">took:1ms<br>timeout:false<br>total:5 hits<br>MaxScore:1.0<br>hits========&gt;&gt;<br>&#123;"name":"zhangsan","age":"10","sex":"女"&#125;<br>&#123;"name":"lisi","age":"30","sex":"女"&#125;<br>&#123;"name":"wangwu1","age":"40","sex":"男"&#125;<br>&#123;"name":"wangwu2","age":"20","sex":"女"&#125;<br>&#123;"name":"wangwu4","age":"20","sex":"男"&#125;<br>&lt;&lt;========</p>
<p>Process finished with exit code 0<br></code></pre> </p>
<h3 id="10、高级查询-模糊查询-amp-高亮查询"><a href="#10、高级查询-模糊查询-amp-高亮查询" class="headerlink" title="10、高级查询-模糊查询 &amp; 高亮查询"></a><strong>10、</strong>高级查询-模糊查询 &amp; 高亮查询</h3><blockquote>
<p> <strong>10.1、模糊查询</strong><br> <pre><code class="language-java">import com.lun.elasticsearch.hello.ConnectElasticsearch;<br>import com.lun.elasticsearch.hello.ElasticsearchTask;<br>import org.elasticsearch.action.search.SearchRequest;<br>import org.elasticsearch.action.search.SearchResponse;<br>import org.elasticsearch.client.RequestOptions;<br>import org.elasticsearch.common.unit.Fuzziness;<br>import org.elasticsearch.index.query.BoolQueryBuilder;<br>import org.elasticsearch.index.query.QueryBuilders;<br>import org.elasticsearch.index.query.RangeQueryBuilder;<br>import org.elasticsearch.search.SearchHit;<br>import org.elasticsearch.search.SearchHits;<br>import org.elasticsearch.search.builder.SearchSourceBuilder;<br>import org.elasticsearch.search.sort.SortOrder;</p>
</blockquote>
<p>public class QueryDoc &#123;</p>
<pre><code>public static final ElasticsearchTask SEARCH_BY_FUZZY_CONDITION = client -&amp;gt; &#123;
    // 创建搜索请求对象
    SearchRequest request = new SearchRequest();
    request.indices(&quot;user&quot;);
    // 构建查询的请求体
    SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
    sourceBuilder.query(QueryBuilders.fuzzyQuery(&quot;name&quot;,&quot;wangwu&quot;).fuzziness(Fuzziness.ONE));
    request.source(sourceBuilder);
    SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    // 查询匹配
    SearchHits hits = response.getHits();
    System.out.println(&quot;took:&quot; + response.getTook());
    System.out.println(&quot;timeout:&quot; + response.isTimedOut());
    System.out.println(&quot;total:&quot; + hits.getTotalHits());
    System.out.println(&quot;MaxScore:&quot; + hits.getMaxScore());
    System.out.println(&quot;hits========&amp;gt;&amp;gt;&quot;);
    for (SearchHit hit : hits) &#123;
        //输出每条查询的结果信息
        System.out.println(hit.getSourceAsString());
    &#125;
    System.out.println(&quot;&amp;lt;&amp;lt;========&quot;);
&#125;;


public static void main(String[] args) &#123;
</code></pre>
<p>//        ConnectElasticsearch.connect(SEARCH_ALL);<br>//        ConnectElasticsearch.connect(SEARCH_BY_CONDITION);<br>//        ConnectElasticsearch.connect(SEARCH_BY_PAGING);<br>//        ConnectElasticsearch.connect(SEARCH_WITH_ORDER);<br>//        ConnectElasticsearch.connect(SEARCH_BY_BOOL_CONDITION);<br>//        ConnectElasticsearch.connect(SEARCH_BY_RANGE);<br>        ConnectElasticsearch.connect(SEARCH_BY_FUZZY_CONDITION);<br>    }</p>
<p>}<br></code></pre><br> 后台打印<br> <pre><code class="language-java">took:152ms<br>timeout:false<br>total:4 hits<br>MaxScore:1.2837042<br>hits========&gt;&gt;<br>&#123;"name":"wangwu1","age":"40","sex":"男"&#125;<br>&#123;"name":"wangwu2","age":"20","sex":"女"&#125;<br>&#123;"name":"wangwu3","age":"50","sex":"男"&#125;<br>&#123;"name":"wangwu4","age":"20","sex":"男"&#125;<br>&lt;&lt;========</p>
<p>Process finished with exit code 0<br></code></pre><br> <strong>10.2、高亮查询</strong><br> <pre><code class="language-java">import com.lun.elasticsearch.hello.ConnectElasticsearch;<br>import com.lun.elasticsearch.hello.ElasticsearchTask;<br>import org.elasticsearch.action.search.SearchRequest;<br>import org.elasticsearch.action.search.SearchResponse;<br>import org.elasticsearch.client.RequestOptions;<br>import org.elasticsearch.common.unit.Fuzziness;<br>import org.elasticsearch.index.query.BoolQueryBuilder;<br>import org.elasticsearch.index.query.QueryBuilders;<br>import org.elasticsearch.index.query.RangeQueryBuilder;<br>import org.elasticsearch.index.query.TermsQueryBuilder;<br>import org.elasticsearch.search.SearchHit;<br>import org.elasticsearch.search.SearchHits;<br>import org.elasticsearch.search.builder.SearchSourceBuilder;<br>import org.elasticsearch.search.fetch.subphase.highlight.HighlightBuilder;<br>import org.elasticsearch.search.fetch.subphase.highlight.HighlightField;<br>import org.elasticsearch.search.sort.SortOrder;</p>
<p>import java.util.Map;</p>
<p>public class QueryDoc &#123;</p>
<pre><code>public static final ElasticsearchTask SEARCH_WITH_HIGHLIGHT = client -&amp;gt; &#123;
    // 高亮查询
    SearchRequest request = new SearchRequest().indices(&quot;user&quot;);
    //2.创建查询请求体构建器
    SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
    //构建查询方式：高亮查询
    TermsQueryBuilder termsQueryBuilder =
            QueryBuilders.termsQuery(&quot;name&quot;,&quot;zhangsan&quot;);
    //设置查询方式
    sourceBuilder.query(termsQueryBuilder);
    //构建高亮字段
    HighlightBuilder highlightBuilder = new HighlightBuilder();
    highlightBuilder.preTags(&quot;&amp;lt;font color=&#39;red&#39;&amp;gt;&quot;);//设置标签前缀
    highlightBuilder.postTags(&quot;&amp;lt;/font&amp;gt;&quot;);//设置标签后缀
    highlightBuilder.field(&quot;name&quot;);//设置高亮字段
    //设置高亮构建对象
    sourceBuilder.highlighter(highlightBuilder);
    //设置请求体
    request.source(sourceBuilder);
    //3.客户端发送请求，获取响应对象
    SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    //4.打印响应结果
    SearchHits hits = response.getHits();
    System.out.println(&quot;took::&quot;+response.getTook());
    System.out.println(&quot;time_out::&quot;+response.isTimedOut());
    System.out.println(&quot;total::&quot;+hits.getTotalHits());
    System.out.println(&quot;max_score::&quot;+hits.getMaxScore());
    System.out.println(&quot;hits::::&amp;gt;&amp;gt;&quot;);
    for (SearchHit hit : hits) &#123;
        String sourceAsString = hit.getSourceAsString();
        System.out.println(sourceAsString);
        //打印高亮结果
        Map&amp;lt;String, HighlightField&amp;gt; highlightFields = hit.getHighlightFields();
        System.out.println(highlightFields);
    &#125;
    System.out.println(&quot;&amp;lt;&amp;lt;::::&quot;);
&#125;;


public static void main(String[] args) &#123;
    ConnectElasticsearch.connect(SEARCH_WITH_HIGHLIGHT);
&#125;
</code></pre>
<p>}<br></code></pre><br> 后台打印<br> <pre><code class="language-java">took::672ms<br>time_out::false<br>total::1 hits<br>max_score::1.0<br>hits::::&gt;&gt;<br>&#123;"name":"zhangsan","age":"10","sex":"女"&#125;<br>&#123;name=[name], fragments[[&lt;font color='red'&gt;zhangsan&lt;/font&gt;]]&#125;<br>&lt;&lt;::::</p>
<p>Process finished with exit code 0<br></code></pre> 
   </p>
<h3 id="11、高级查询-最大值查询-amp-分组查询"><a href="#11、高级查询-最大值查询-amp-分组查询" class="headerlink" title="11、高级查询-最大值查询 &amp; 分组查询"></a>11、高级查询-最大值查询 &amp; 分组查询</h3><blockquote>
<p> <strong>1、最大值查询</strong><br> <pre><code class="language-java">import com.lun.elasticsearch.hello.ConnectElasticsearch;<br>import com.lun.elasticsearch.hello.ElasticsearchTask;<br>import org.elasticsearch.action.search.SearchRequest;<br>import org.elasticsearch.action.search.SearchResponse;<br>import org.elasticsearch.client.RequestOptions;<br>import org.elasticsearch.common.unit.Fuzziness;<br>import org.elasticsearch.index.query.BoolQueryBuilder;<br>import org.elasticsearch.index.query.QueryBuilders;<br>import org.elasticsearch.index.query.RangeQueryBuilder;<br>import org.elasticsearch.index.query.TermsQueryBuilder;<br>import org.elasticsearch.search.SearchHit;<br>import org.elasticsearch.search.SearchHits;<br>import org.elasticsearch.search.aggregations.AggregationBuilders;<br>import org.elasticsearch.search.builder.SearchSourceBuilder;<br>import org.elasticsearch.search.fetch.subphase.highlight.HighlightBuilder;<br>import org.elasticsearch.search.fetch.subphase.highlight.HighlightField;<br>import org.elasticsearch.search.sort.SortOrder;</p>
</blockquote>
<p>import java.util.Map;</p>
<p>public class QueryDoc &#123;</p>
<pre><code>public static final ElasticsearchTask SEARCH_WITH_MAX = client -&amp;gt; &#123;
    // 高亮查询
    SearchRequest request = new SearchRequest().indices(&quot;user&quot;);
    SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
    sourceBuilder.aggregation(AggregationBuilders.max(&quot;maxAge&quot;).field(&quot;age&quot;));
    //设置请求体
    request.source(sourceBuilder);
    //3.客户端发送请求，获取响应对象
    SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    //4.打印响应结果
    SearchHits hits = response.getHits();
    System.out.println(response);
&#125;;

public static void main(String[] args) &#123;
    ConnectElasticsearch.connect(SEARCH_WITH_MAX);
&#125;
</code></pre>
<p>}<br></code></pre><br> 后台打印<br> <pre><code>&#123;"took":16,"timed_out":false,"_shards":&#123;"total":1,"successful":1,"skipped":0,"failed":0&#125;,"hits":&#123;"total":&#123;"value":6,"relation":"eq"&#125;,"max_score":1.0,"hits":[&#123;"_index":"user","_type":"_doc","_id":"1001","_score":1.0,"_source":&#123;"name":"zhangsan","age":"10","sex":"女"&#125;&#125;,&#123;"_index":"user","_type":"_doc","_id":"1002","_score":1.0,"_source":&#123;"name":"lisi","age":"30","sex":"女"&#125;&#125;,&#123;"_index":"user","_type":"_doc","_id":"1003","_score":1.0,"_source":&#123;"name":"wangwu1","age":"40","sex":"男"&#125;&#125;,&#123;"_index":"user","_type":"_doc","_id":"1004","_score":1.0,"_source":&#123;"name":"wangwu2","age":"20","sex":"女"&#125;&#125;,&#123;"_index":"user","_type":"_doc","_id":"1005","_score":1.0,"_source":&#123;"name":"wangwu3","age":"50","sex":"男"&#125;&#125;,&#123;"_index":"user","_type":"_doc","_id":"1006","_score":1.0,"_source":&#123;"name":"wangwu4","age":"20","sex":"男"&#125;&#125;]&#125;,"aggregations":&#123;"max#maxAge":&#123;"value":50.0&#125;&#125;&#125;</p>
<p>Process finished with exit code 0<br></code></pre><br> <h3>分组查询</h3><br> <pre><code class="language-java">import com.lun.elasticsearch.hello.ConnectElasticsearch;<br>import com.lun.elasticsearch.hello.ElasticsearchTask;<br>import org.elasticsearch.action.search.SearchRequest;<br>import org.elasticsearch.action.search.SearchResponse;<br>import org.elasticsearch.client.RequestOptions;<br>import org.elasticsearch.common.unit.Fuzziness;<br>import org.elasticsearch.index.query.BoolQueryBuilder;<br>import org.elasticsearch.index.query.QueryBuilders;<br>import org.elasticsearch.index.query.RangeQueryBuilder;<br>import org.elasticsearch.index.query.TermsQueryBuilder;<br>import org.elasticsearch.search.SearchHit;<br>import org.elasticsearch.search.SearchHits;<br>import org.elasticsearch.search.aggregations.AggregationBuilders;<br>import org.elasticsearch.search.builder.SearchSourceBuilder;<br>import org.elasticsearch.search.fetch.subphase.highlight.HighlightBuilder;<br>import org.elasticsearch.search.fetch.subphase.highlight.HighlightField;<br>import org.elasticsearch.search.sort.SortOrder;</p>
<p>import java.util.Map;</p>
<p>public class QueryDoc &#123;</p>
<pre><code>public static final ElasticsearchTask SEARCH_WITH_GROUP = client -&amp;gt; &#123;
    SearchRequest request = new SearchRequest().indices(&quot;user&quot;);
    SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
    sourceBuilder.aggregation(AggregationBuilders.terms(&quot;age_groupby&quot;).field(&quot;age&quot;));
    //设置请求体
    request.source(sourceBuilder);
    //3.客户端发送请求，获取响应对象
    SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    //4.打印响应结果
    SearchHits hits = response.getHits();
    System.out.println(response);
&#125;;

public static void main(String[] args) &#123;
    ConnectElasticsearch.connect(SEARCH_WITH_GROUP);
&#125;
</code></pre>
<p>}<br></code></pre><br> 后台打印<br> <pre><code class="language-java">&#123;"took":10,"timed_out":false,"_shards":&#123;"total":1,"successful":1,"skipped":0,"failed":0&#125;,"hits":&#123;"total":&#123;"value":6,"relation":"eq"&#125;,"max_score":1.0,"hits":[&#123;"_index":"user","_type":"_doc","_id":"1001","_score":1.0,"_source":&#123;"name":"zhangsan","age":"10","sex":"女"&#125;&#125;,&#123;"_index":"user","_type":"_doc","_id":"1002","_score":1.0,"_source":&#123;"name":"lisi","age":"30","sex":"女"&#125;&#125;,&#123;"_index":"user","_type":"_doc","_id":"1003","_score":1.0,"_source":&#123;"name":"wangwu1","age":"40","sex":"男"&#125;&#125;,&#123;"_index":"user","_type":"_doc","_id":"1004","_score":1.0,"_source":&#123;"name":"wangwu2","age":"20","sex":"女"&#125;&#125;,&#123;"_index":"user","_type":"_doc","_id":"1005","_score":1.0,"_source":&#123;"name":"wangwu3","age":"50","sex":"男"&#125;&#125;,&#123;"_index":"user","_type":"_doc","_id":"1006","_score":1.0,"_source":&#123;"name":"wangwu4","age":"20","sex":"男"&#125;&#125;]&#125;,"aggregations":&#123;"lterms#age_groupby":&#123;"doc_count_error_upper_bound":0,"sum_other_doc_count":0,"buckets":[&#123;"key":20,"doc_count":2&#125;,&#123;"key":10,"doc_count":1&#125;,&#123;"key":30,"doc_count":1&#125;,&#123;"key":40,"doc_count":1&#125;,&#123;"key":50,"doc_count":1&#125;]&#125;&#125;&#125;</p>
<p>Process finished with exit code 0<br></code></pre> 
   </p>
<p> </p>
<p> </p>
<p> </p>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>Elasticsearch入门之增删改查进阶</title>
    <url>/2021/07/18/Elasticsearch%E5%85%A5%E9%97%A8%E4%B9%8B%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5%E8%BF%9B%E9%98%B6/</url>
    <content><![CDATA[<p>title: Elasticsearch入门之增删改查进阶<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、条件查询 &amp; 分页查询 &amp; 查询排序</p>
<blockquote>
<p> 1.1、条件查询<br>         假设有以下文档内容，（在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search">http://127.0.0.1:9200/shopping/_search</a><br> <pre><code class="language-java">&#123;<br>    "took": 5,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 6,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 1,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "ANQqsHgBaKNfVnMbhZYU",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 3999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "A9R5sHgBaKNfVnMb25Ya",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BNR5sHgBaKNfVnMb7pal",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BtR6sHgBaKNfVnMbX5Y5",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "B9R6sHgBaKNfVnMbZpZ6",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "CdR7sHgBaKNfVnMbsJb9",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre><br> 1.2、URL带参查询<br>       <strong>查找category为小米的文档</strong>，在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search?q=category:%E5%B0%8F%E7%B1%B3%EF%BC%8C%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search?q=category:小米，返回结果如下：</a><br> <pre><code class="language-java">&#123;<br>    "took": 94,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 3,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 1.3862942,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "ANQqsHgBaKNfVnMbhZYU",<br>                "_score": 1.3862942,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 3999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "A9R5sHgBaKNfVnMb25Ya",<br>                "_score": 1.3862942,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BNR5sHgBaKNfVnMb7pal",<br>                "_score": 1.3862942,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre><br> 上述为URL带参数形式查询，这很容易让不善者心怀恶意，或者参数值出现中文会出现乱码情况。为了避免这些情况，我们可用使用带JSON请求体请求进行查询。 1.3、请求体带参查询<br>       接下带JSON请求体，还是<strong>查找category为小米的文档</strong>，在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a><br> <pre><code class="language-java">&#123;<br>    "query":&#123;<br>        "match":&#123;<br>            "category":"小米"<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 3,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 3,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 1.3862942,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "ANQqsHgBaKNfVnMbhZYU",<br>                "_score": 1.3862942,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 3999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "A9R5sHgBaKNfVnMb25Ya",<br>                "_score": 1.3862942,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BNR5sHgBaKNfVnMb7pal",<br>                "_score": 1.3862942,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre><br>  1.4、带请求体方式的查找所有内容<br>       <strong>查找所有文档内容</strong>，也可以这样，在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a><br> <pre><code class="language-java">&#123;<br>    "query":&#123;<br>        "match_all":&#123;&#125;<br>    &#125;<br>&#125;<br></code></pre><br> 则返回所有文档内容：<br> <pre><code class="language-java">&#123;<br>    "took": 2,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 6,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 1,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "ANQqsHgBaKNfVnMbhZYU",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 3999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "A9R5sHgBaKNfVnMb25Ya",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BNR5sHgBaKNfVnMb7pal",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BtR6sHgBaKNfVnMbX5Y5",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "B9R6sHgBaKNfVnMbZpZ6",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "CdR7sHgBaKNfVnMbsJb9",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre><br> 1.5、查询指定字段<br>        <strong>如果你想查询指定字段</strong>，在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a><br> <pre><code class="language-java">&#123;<br>    "query":&#123;<br>        "match_all":&#123;&#125;<br>    &#125;,<br>    "_source":["title"]<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 5,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 6,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 1,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "ANQqsHgBaKNfVnMbhZYU",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机"<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "A9R5sHgBaKNfVnMb25Ya",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机"<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BNR5sHgBaKNfVnMb7pal",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机"<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BtR6sHgBaKNfVnMbX5Y5",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "华为手机"<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "B9R6sHgBaKNfVnMbZpZ6",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "华为手机"<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "CdR7sHgBaKNfVnMbsJb9",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "华为手机"<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre><br> 1.6、分页查询<br>        在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a><br> <pre><code class="language-java">&#123;<br>    "query":&#123;<br>        "match_all":&#123;&#125;<br>    &#125;,<br>    "from":0,<br>    "size":2<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 1,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 6,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 1,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "ANQqsHgBaKNfVnMbhZYU",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 3999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "A9R5sHgBaKNfVnMb25Ya",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre><br> 1.7、查询排序<br> 如果你想通过排序查出价格最高的手机，在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a><br> <pre><code class="language-java">&#123;<br>    "query":&#123;<br>        "match_all":&#123;&#125;<br>    &#125;,<br>    "sort":&#123;<br>        "price":&#123;<br>            "order":"desc"<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 96,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 6,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": null,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "ANQqsHgBaKNfVnMbhZYU",<br>                "_score": null,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 3999<br>                &#125;,<br>                "sort": [<br>                    3999<br>                ]<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "A9R5sHgBaKNfVnMb25Ya",<br>                "_score": null,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;,<br>                "sort": [<br>                    1999<br>                ]<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BNR5sHgBaKNfVnMb7pal",<br>                "_score": null,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;,<br>                "sort": [<br>                    1999<br>                ]<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BtR6sHgBaKNfVnMbX5Y5",<br>                "_score": null,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;,<br>                "sort": [<br>                    1999<br>                ]<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "B9R6sHgBaKNfVnMbZpZ6",<br>                "_score": null,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;,<br>                "sort": [<br>                    1999<br>                ]<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "CdR7sHgBaKNfVnMbsJb9",<br>                "_score": null,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;,<br>                "sort": [<br>                    1999<br>                ]<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre> 
   </p>
</blockquote>
<h3 id="2、多条件查询-amp-范围查询"><a href="#2、多条件查询-amp-范围查询" class="headerlink" title="2、多条件查询 &amp; 范围查询"></a>2、多条件查询 &amp; 范围查询</h3><blockquote>
<p> 2.1、多条件查询<br>    假设想找出小米牌子，价格为3999元的。（must相当于数据库的&amp;&amp;）<br> 在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a><br> <pre><code class="language-java">&#123;<br>    "query":&#123;<br>        "bool":&#123;<br>            "must":[&#123;<br>                "match":&#123;<br>                    "category":"小米"<br>                &#125;<br>            &#125;,&#123;<br>                "match":&#123;<br>                    "price":3999.00<br>                &#125;<br>            &#125;]<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 134,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 1,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 2.3862944,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "ANQqsHgBaKNfVnMbhZYU",<br>                "_score": 2.3862944,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 3999<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre><br> 假设想找出小米和华为的牌子，价格大于2000元的手机。（should相当于数据库的||）<br> 在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a><br> <pre><code class="language-java">&#123;<br>    "query":&#123;<br>        "bool":&#123;<br>            "should":[&#123;<br>                "match":&#123;<br>                    "category":"小米"<br>                &#125;<br>            &#125;,&#123;<br>                "match":&#123;<br>                    "category":"华为"<br>                &#125;<br>            &#125;]<br>        &#125;,<br>        "filter":&#123;<br>            "range":&#123;<br>                "price":&#123;<br>                    "gt":2000<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 8,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 6,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 1.3862942,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "ANQqsHgBaKNfVnMbhZYU",<br>                "_score": 1.3862942,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 3999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "A9R5sHgBaKNfVnMb25Ya",<br>                "_score": 1.3862942,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BNR5sHgBaKNfVnMb7pal",<br>                "_score": 1.3862942,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BtR6sHgBaKNfVnMbX5Y5",<br>                "_score": 1.3862942,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "B9R6sHgBaKNfVnMbZpZ6",<br>                "_score": 1.3862942,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "CdR7sHgBaKNfVnMbsJb9",<br>                "_score": 1.3862942,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre> </p>
</blockquote>
<h3 id="3、全文检索-amp-完全匹配-amp-高亮查询"><a href="#3、全文检索-amp-完全匹配-amp-高亮查询" class="headerlink" title="3、全文检索 &amp; 完全匹配 &amp; 高亮查询"></a>3、全文检索 &amp; 完全匹配 &amp; 高亮查询</h3><blockquote>
<p> 3.1、全文检索<br>       这功能像搜索引擎那样，如品牌输入“小华”，返回结果带回品牌有“小米”和华为的。<br> 在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a><br> <pre><code class="language-java">&#123;<br>    "query":&#123;<br>        "match":&#123;<br>            "category" : "小华"<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 7,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 6,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 0.6931471,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "ANQqsHgBaKNfVnMbhZYU",<br>                "_score": 0.6931471,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 3999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "A9R5sHgBaKNfVnMb25Ya",<br>                "_score": 0.6931471,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BNR5sHgBaKNfVnMb7pal",<br>                "_score": 0.6931471,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BtR6sHgBaKNfVnMbX5Y5",<br>                "_score": 0.6931471,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "B9R6sHgBaKNfVnMbZpZ6",<br>                "_score": 0.6931471,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "CdR7sHgBaKNfVnMbsJb9",<br>                "_score": 0.6931471,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre><br> 3.2、完全匹配<br>     在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a><br> <pre><code class="language-java">&#123;<br>    "query":&#123;<br>        "match_phrase":&#123;<br>            "category" : "为"<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 2,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 3,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 0.6931471,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BtR6sHgBaKNfVnMbX5Y5",<br>                "_score": 0.6931471,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "B9R6sHgBaKNfVnMbZpZ6",<br>                "_score": 0.6931471,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "CdR7sHgBaKNfVnMbsJb9",<br>                "_score": 0.6931471,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre><br> 3.3、高亮查询<br> 在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a><br> <pre><code class="language-java">&#123;<br>    "query":&#123;<br>        "match_phrase":&#123;<br>            "category" : "为"<br>        &#125;<br>    &#125;,<br>    "highlight":&#123;<br>        "fields":&#123;<br>            "category":&#123;&#125;//&lt;----高亮这字段<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 100,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 3,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 0.6931471,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BtR6sHgBaKNfVnMbX5Y5",<br>                "_score": 0.6931471,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;,<br>                "highlight": &#123;<br>                    "category": [<br>                        "华&lt;em&gt;为&lt;/em&gt;"//&lt;------高亮一个为字。<br>                    ]<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "B9R6sHgBaKNfVnMbZpZ6",<br>                "_score": 0.6931471,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;,<br>                "highlight": &#123;<br>                    "category": [<br>                        "华&lt;em&gt;为&lt;/em&gt;"<br>                    ]<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "CdR7sHgBaKNfVnMbsJb9",<br>                "_score": 0.6931471,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;,<br>                "highlight": &#123;<br>                    "category": [<br>                        "华&lt;em&gt;为&lt;/em&gt;"<br>                    ]<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre> 
   </p>
</blockquote>
<h3 id="4、聚合查询"><a href="#4、聚合查询" class="headerlink" title="4、聚合查询"></a>4、聚合查询</h3><blockquote>
<p> 聚合允许使用者对 es 文档进行统计分析，类似与关系型数据库中的 group by，当然还有很多其他的聚合，例如取最大值max、平均值avg等等。<br> 接下来按price字段进行分组：<br> 在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a><br> <pre><code class="language-java">&#123;<br>    "aggs":&#123;//聚合操作<br>        "price_group":&#123;//名称，随意起名<br>            "terms":&#123;//分组<br>                "field":"price"//分组字段<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 63,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 6,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 1,<br>        "hits": [<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "ANQqsHgBaKNfVnMbhZYU",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 3999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "A9R5sHgBaKNfVnMb25Ya",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BNR5sHgBaKNfVnMb7pal",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "小米手机",<br>                    "category": "小米",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "BtR6sHgBaKNfVnMbX5Y5",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "B9R6sHgBaKNfVnMbZpZ6",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;,<br>            &#123;<br>                "_index": "shopping",<br>                "_type": "_doc",<br>                "_id": "CdR7sHgBaKNfVnMbsJb9",<br>                "_score": 1,<br>                "_source": &#123;<br>                    "title": "华为手机",<br>                    "category": "华为",<br>                    "images": "<a href="http://www.gulixueyuan.com/xm.jpg&quot;">http://www.gulixueyuan.com/xm.jpg&quot;</a>,<br>                    "price": 1999<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;,<br>    "aggregations": &#123;<br>        "price_group": &#123;<br>            "doc_count_error_upper_bound": 0,<br>            "sum_other_doc_count": 0,<br>            "buckets": [<br>                &#123;<br>                    "key": 1999,<br>                    "doc_count": 5<br>                &#125;,<br>                &#123;<br>                    "key": 3999,<br>                    "doc_count": 1<br>                &#125;<br>            ]<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 上面返回结果会附带原始数据的。若不想要不附带原始数据的结果，在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a><br> <pre><code class="language-java">&#123;<br>    "aggs":&#123;<br>        "price_group":&#123;<br>            "terms":&#123;<br>                "field":"price"<br>            &#125;<br>        &#125;<br>    &#125;,<br>    "size":0<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 60,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 6,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": null,<br>        "hits": []<br>    &#125;,<br>    "aggregations": &#123;<br>        "price_group": &#123;<br>            "doc_count_error_upper_bound": 0,<br>            "sum_other_doc_count": 0,<br>            "buckets": [<br>                &#123;<br>                    "key": 1999,<br>                    "doc_count": 5<br>                &#125;,<br>                &#123;<br>                    "key": 3999,<br>                    "doc_count": 1<br>                &#125;<br>            ]<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 若想对所有手机价格求<strong>平均值</strong>。<br> 在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a><br> <pre><code class="language-java">&#123;<br>    "aggs":&#123;<br>        "price_avg":&#123;//名称，随意起名<br>            "avg":&#123;//求平均<br>                "field":"price"<br>            &#125;<br>        &#125;<br>    &#125;,<br>    "size":0<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 14,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 6,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": null,<br>        "hits": []<br>    &#125;,<br>    "aggregations": &#123;<br>        "price_avg": &#123;<br>            "value": 2332.3333333333335<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre> 
   </p>
</blockquote>
<h3 id="5、映射关系"><a href="#5、映射关系" class="headerlink" title="5、映射关系"></a>5、映射关系</h3><blockquote>
<p> 有了索引库，等于有了数据库中的 database。<br> 接下来就需要建索引库(index)中的映射了，类似于数据库(database)中的表结构(table)。<br> 创建数据库表需要设置字段名称，类型，长度，约束等；索引库也一样，需要知道这个类型下有哪些字段，每个字段有哪些约束信息，这就叫做映射(mapping)。<br> 先创建一个索引：<br> <pre><code class="language-java"># PUT <a href="http://127.0.0.1:9200/user">http://127.0.0.1:9200/user</a><br></code></pre><br> 返回结果：<br> <pre><code class="language-java">&#123;<br>    "acknowledged": true,<br>    "shards_acknowledged": true,<br>    "index": "user"<br>&#125;<br></code></pre><br> <strong>创建映射</strong><br> <pre><code class="language-java"># PUT <a href="http://127.0.0.1:9200/user/_mapping">http://127.0.0.1:9200/user/_mapping</a></p>
</blockquote>
<p>&#123;<br>    “properties”: &#123;<br>        “name”:&#123;<br>            “type”: “text”,<br>            “index”: true<br>        &#125;,<br>        “sex”:&#123;<br>            “type”: “keyword”,<br>            “index”: true<br>        &#125;,<br>        “tel”:&#123;<br>            “type”: “keyword”,<br>            “index”: false<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "acknowledged": true<br>&#125;<br></code></pre><br> <strong>查询映射</strong><br> <pre><code class="language-java">#GET <a href="http://127.0.0.1:9200/user/_mapping">http://127.0.0.1:9200/user/_mapping</a><br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "user": &#123;<br>        "mappings": &#123;<br>            "properties": &#123;<br>                "name": &#123;<br>                    "type": "text"<br>                &#125;,<br>                "sex": &#123;<br>                    "type": "keyword"<br>                &#125;,<br>                "tel": &#123;<br>                    "type": "keyword",<br>                    "index": false<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 增加数据<br> <pre><code class="language-java">#PUT <a href="http://127.0.0.1:9200/user/_create/1001">http://127.0.0.1:9200/user/_create/1001</a><br>&#123;<br>    "name":"小米",<br>    "sex":"男的",<br>    "tel":"1111"<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "_index": "user",<br>    "_type": "_doc",<br>    "_id": "1001",<br>    "_version": 1,<br>    "result": "created",<br>    "_shards": &#123;<br>        "total": 2,<br>        "successful": 1,<br>        "failed": 0<br>    &#125;,<br>    "_seq_no": 0,<br>    "_primary_term": 1<br>&#125;<br></code></pre><br> 查找name含有”小“数据：<br> <pre><code class="language-java">#GET <a href="http://127.0.0.1:9200/user/_search">http://127.0.0.1:9200/user/_search</a><br>&#123;<br>    "query":&#123;<br>        "match":&#123;<br>            "name":"小"<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 495,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 1,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 0.2876821,<br>        "hits": [<br>            &#123;<br>                "_index": "user",<br>                "_type": "_doc",<br>                "_id": "1001",<br>                "_score": 0.2876821,<br>                "_source": &#123;<br>                    "name": "小米",<br>                    "sex": "男的",<br>                    "tel": "1111"<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre><br> 查找sex含有”男“数据：<br> <pre><code class="language-java">#GET <a href="http://127.0.0.1:9200/user/_search">http://127.0.0.1:9200/user/_search</a><br>&#123;<br>    "query":&#123;<br>        "match":&#123;<br>            "sex":"男"<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 1,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 0,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": null,<br>        "hits": []<br>    &#125;<br>&#125;<br></code></pre><br> 找不想要的结果，只因创建映射时”sex”的类型为”keyword”。<br> “sex”只能完全为”男的“，才能得出原数据。<br> <pre><code class="language-java">#GET <a href="http://127.0.0.1:9200/user/_search">http://127.0.0.1:9200/user/_search</a><br>&#123;<br>    "query":&#123;<br>        "match":&#123;<br>            "sex":"男的"<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "took": 2,<br>    "timed_out": false,<br>    "_shards": &#123;<br>        "total": 1,<br>        "successful": 1,<br>        "skipped": 0,<br>        "failed": 0<br>    &#125;,<br>    "hits": &#123;<br>        "total": &#123;<br>            "value": 1,<br>            "relation": "eq"<br>        &#125;,<br>        "max_score": 0.2876821,<br>        "hits": [<br>            &#123;<br>                "_index": "user",<br>                "_type": "_doc",<br>                "_id": "1001",<br>                "_score": 0.2876821,<br>                "_source": &#123;<br>                    "name": "小米",<br>                    "sex": "男的",<br>                    "tel": "1111"<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;<br>&#125;<br></code></pre><br> 查询电话<br> <pre><code class="language-java"># GET <a href="http://127.0.0.1:9200/user/_search">http://127.0.0.1:9200/user/_search</a><br>&#123;<br>    "query":&#123;<br>        "match":&#123;<br>            "tel":"11"<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "error": &#123;<br>        "root_cause": [<br>            &#123;<br>                "type": "query_shard_exception",<br>                "reason": "failed to create query: Cannot search on field [tel] since it is not indexed.",<br>                "index_uuid": "ivLnMfQKROS7Skb2MTFOew",<br>                "index": "user"<br>            &#125;<br>        ],<br>        "type": "search_phase_execution_exception",<br>        "reason": "all shards failed",<br>        "phase": "query",<br>        "grouped": true,<br>        "failed_shards": [<br>            &#123;<br>                "shard": 0,<br>                "index": "user",<br>                "node": "4P7dIRfXSbezE5JTiuylew",<br>                "reason": &#123;<br>                    "type": "query_shard_exception",<br>                    "reason": "failed to create query: Cannot search on field [tel] since it is not indexed.",<br>                    "index_uuid": "ivLnMfQKROS7Skb2MTFOew",<br>                    "index": "user",<br>                    "caused_by": &#123;<br>                        "type": "illegal_argument_exception",<br>                        "reason": "Cannot search on field [tel] since it is not indexed."<br>                    &#125;<br>                &#125;<br>            &#125;<br>        ]<br>    &#125;,<br>    "status": 400<br>&#125;<br></code></pre><br> 报错只因创建映射时”tel”的”index”为false。 </p>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>clickhouse,硬件管理与优化(cpu,内存,网络,存储,操作系统配置),profile管理，Quotas设置，约束管理，查询权限，用户管理配置等</title>
    <url>/2021/07/18/clickhouse,%E7%A1%AC%E4%BB%B6%E7%AE%A1%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96(cpu,%E5%86%85%E5%AD%98,%E7%BD%91%E7%BB%9C,%E5%AD%98%E5%82%A8,%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE),profile%E7%AE%A1%E7%90%86%EF%BC%8CQuotas%E8%AE%BE%E7%BD%AE%EF%BC%8C%E7%BA%A6%E6%9D%9F%E7%AE%A1%E7%90%86%EF%BC%8C%E6%9F%A5%E8%AF%A2%E6%9D%83%E9%99%90%EF%BC%8C%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86%E9%85%8D%E7%BD%AE%E7%AD%89/</url>
    <content><![CDATA[<p>title: clickhouse,硬件管理与优化(cpu,内存,网络,存储,操作系统配置),profile管理，Quotas设置，约束管理，查询权限，用户管理配置等<br>categories:</p>
<ul>
<li>clickhouse</li>
</ul>
<p>—### 1.运维管理与优化</p>
<blockquote>
<p> <strong>1.1)硬件管理与优化</strong><br>       1.1.1)CPU<br>                ClickHouse的并行数据处理机制，使得其能利用所有可用的硬件资源。在选择CPU处理器时，应选择更多核心数而不是更高频率的处理器。<br>                例如：频率为2600MHz的16核心处理器比3600MHz的8核心的处理器的效率更高。                           建议使用Turbo Boost和超线程技术，在高工作负载情况下能显著提高性能。<br>       1.1.2)内存<br>                ClickHouse的服务本身需要的RAM很少，但是ClickHouse需要内存来处理查询，建议至少使用4GB内存。                RAM的容量取决于：<br>                 a.查询的复杂性。<br>                 b.查询处理的数据量。<br>                 c.根据GROUP BY、DISTINCT、JOIN和其他操作产生的临时数据大小估算所需的RAM容量。<br>                对于少量数据，例如压缩后在200GB以下，使用数据量一样多的内存。                对于大量数据，以及交互式查询，热数据集缓存在操作系统的cache中，建议配置尽可能大的内存，例如128GB的内存性能明显比64GB高很多。<br>                如果内存不足， ClickHouse支持使用外部存储器处理数据，如外部聚合和外部排序等，当数据超过设置的阈值时使用外部存储器处理数据。<br>       1.1.3)网络<br>                推荐使用10GB或更高带宽的网络。<br>                ClickHouse在数据处理过程（数据导入、中间数据存储等）中会充分利用网络带宽。网络带宽对于处理具有大量中间数据的分布式查询至关重要。<br>                网络带宽会影响复制的过程。<br>       1.1.4)存储综合考虑安全性、性能和预算。                  如果使用RAID0，则需考虑使用副本机制。                  预算足够，使用SSD，然后HDD。                  RAID10的性能最佳，兼顾了安全性和性能，但是成本高，50%的磁盘利用率。                 主机的磁盘超过4块，可以考虑使用RAID6、RAID50、RAID5等。<br>                 优先使用具有多个本地磁盘的服务器，而不是具有附加磁盘架的服务器。<br>                 考虑压缩率、副本、磁盘存储容量、未来的数据增长估算存储资源。                 数据量：对数据进行采样，计算每行的平均大小，根据总行数估算数据量。                数据压缩系数：ClickHouse的数据通常被压缩5倍左右，根据原始数据大小和ClickHouse存储的表的数据目录占用空间进行比较。                副本：每份副本存储完整的数据。<br> <strong>1.2)操作系统的配置</strong><br>        1.2.1)CPU频率调整策略<br>              建议将CPU的电源管理策略调整为performance，即将CPU频率固定工作在其支持的最高运行频率上， 不动态调节，可以获取到最大的性能。              查看系统支持的策略：<br> <pre><code># cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_available_governors<br>performance powersave<br></code></pre><br>              查看生效的策略：<br> <pre><code># cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor<br>powersave<br></code></pre><br>               设置：<br> <pre><code>echo 'performance' | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor<br></code></pre><br>  <br>        1.2.2) 关闭透明大页                开启透明大页，操作系统的内存分配活动需要各种内存锁，直接影响程序的内存访问性能，对于ClickHouse而言，透明大页会严重干扰内存分配器的工作，从而导致性能显著下降。<br> <pre><code class="language-bash">echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag<br>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</p>
</blockquote>
<p>echo ‘echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag’&gt;&gt; /etc/rc.local<br>echo ‘echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled’&gt;&gt; /etc/rc.local<br></code></pre><br>        1.2.3)禁用swap文件<br>              避免将数据调度到swap上，影响性能。<br> <pre><code class="language-bash">dd if=/dev/zero of=/home/swap bs=1024 count=1048576<br>swapon /dev/dm-1</p>
<h1 id="swapon"><a href="#swapon" class="headerlink" title="swapon"></a>swapon</h1><p>NAME TYPE SIZE USED PRIO<br>/dev/dm-1 partition 16G 0B -3</p>
<p>swapoff   /dev/dm-1<br></code></pre><br>        1.2.4)内核分配策略<br>             overcommit_memory是一个内核对内存分配的一种策略。具体可见/proc/sys/vm/overcommit_memory下的值。             overcommit_memory取值有三种分别为0,1,2<br>             overcommit_memory=0，表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。             overcommit_memory=1，表示内核允许分配所有的物理内存，而不管当前的内存状态如何。             overcommit_memory=2，表示内核允许分配超过所有物理内存和交换空间总和的内存。<br>        1.2.5)彻底理解ClickHouse的配置文件<br>             ClickHouse支持多文件的配置管理，主配置文件为/etc/clickhouse-server/config.xml，其他的配置文件必须位于/etc/clickhouse-server/config.d目录中。<br>             所有配置文件必须为XML格式，每个文件具有相同的根元素，通常为.<br>            配置替换                  配置的元素可以指定incl属性，这个属性指定了一个”substitutions (替换)”。默认情况下，这个”替换”来自配置文件/etc/metrika.xml的元素，可以通过服务器的配置选项include_from修改”替换”文              件的路径。当指定了”替换”，将使用替换文件中相应元素的内容作为值。“替换”的值是引用”替换”文件的根节点（yarndex）下的子元素。如果incl中指定的”替换”不存在，则在服务器中记录日志，           如果不想记录日志，则为元素指定optional=”true”属性即可。            例如，”替换”文件/etc/metrika.xml中的部分内容：<br> <pre><code class="language-XML">&lt;yandex&gt;<br>...<br>&lt;zookeeper-servers&gt;<br>    &lt;host&gt;192.168.9.100&lt;/host&gt;<br>    &lt;port&gt;2181&lt;/port&gt;<br>&lt;/zookeeper-servers&gt;<br>...<br>&lt;/yandex&gt;<br></code></pre><br> ClickHouse的config.xml配置文件默认引用了这个文件的”替换”：zookeeper-servers，它是/etc/metrika.xml中根节点yandex下的子元素。如下： <br> <pre><code class="language-XML">&lt;zookeeper incl="zookeeper-servers" optional="true" /&gt;<br></code></pre><br> <strong>1.3)用户设置</strong><br>          在config.xml文件默认指定了一个单独的用户管理相关的配置文件，用于管理用户的权限、profiles、quotas等。这个配置文件由users_config元素指定文件路径，默认为users.xml。如果省略users_config元素，则直接在config.xml中指定用户管理相关的配置。<br> <pre><code class="language-XML">&lt;users_config&gt;users.xml&lt;/users_config&gt;<br></code></pre><br>      可以将用户配置拆分为多个配置文件，类似config.xml和config.d。用户配置的目录默认为users.d，目录名称的规则为：user_config设置的文件名去掉.xml后缀，并拼接上.d后缀。例如，如果user_config设置为abc.xml，则用户配置目录为：abc.d。 如下示例，为用户创建了一个单独的配置文件：<br> <pre><code class="language-XML">$ cat /etc/clickhouse-server/users.d/alice.xml<br>&lt;yandex&gt;<br>    &lt;users&gt;<br>      &lt;alice&gt;<br>          &lt;profile&gt;default&lt;/profile&gt;<br>          &lt;networks&gt;<br>              &lt;ip&gt;::/0&lt;/ip&gt;<br>          &lt;/networks&gt;<br>          &lt;password&gt;123&lt;/password&gt;<br>          &lt;quota&gt;default&lt;/quota&gt;<br>      &lt;/alice&gt;<br>    &lt;/users&gt;<br>&lt;/yandex&gt;<br></code></pre><br> <strong>1.4)重复设置项的处理</strong><br> **     **主配置文件的有些设置会被其他配置文件中的设置覆盖。      可以为这些配置文件的元素指定replace和remove属性。      如果replace和remove属性都不指定， ClickHouse将以递归的方式合并元素的内容，替换掉重复子元素的值。      如果指定了replace属性， 则使用当前的元素配置替换从其他配置文件引用的元素内容。      如果指定了remove属性， 则表示删除该元素。      例如下面的配置，它会替换networks元素（由incl指定）的整个配置，而保留当前定义的设置：<br> <pre><code class="language-XML">&lt;networks incl="networks" replace="replace"&gt;<br>    &lt;ip&gt;::/0&lt;/ip&gt;<br>&lt;/networks&gt;<br></code></pre><br>  <br> 1.5)预处理文件<br>      ClickHouse服务在启动时，会生成每类配置文件的预处理文件，这些文件包含了所有已完成的替换和重写，是ClickHouse最终应用的配置。<br>      ClickHouse会跟踪配置文件的更改，能动态加载变更的用户和集群设置。这意味着用户可以在线动态修改集群、用户等相关配置，而无需重新启动服务。<br>       预处理文件路径为/var/lib/clickhouse/preprocessed_configs，使用/etc/clickhouse-server/preprocessed软链接指向这个目录。<br> <pre><code class="language-bash"># ll /etc/clickhouse-server/preprocessed<br>lrwxrwxrwx 1 root root 41 3月   4 09:44 /etc/clickhouse-server/preprocessed -&gt; /var/lib/clickhouse//preprocessed_configs</p>
<h1 id="ls-etc-clickhouse-server-preprocessed"><a href="#ls-etc-clickhouse-server-preprocessed" class="headerlink" title="ls /etc/clickhouse-server/preprocessed/"></a>ls /etc/clickhouse-server/preprocessed/</h1><p>abc_dictionary.xml  config.xml  users.xml<br></code></pre> 
   </p>
<h3 id="2-ZooKeeper的关键优化点"><a href="#2-ZooKeeper的关键优化点" class="headerlink" title="2.ZooKeeper的关键优化点"></a>2.ZooKeeper的关键优化点</h3><blockquote>
 <ol>- **ZooKeeper节点数3个以上，奇数台。**- **与ClickHouse集群独立部署  **ZooKeeper对延迟非常敏感，ClickHouse可能会利用所有可用的系统资源。<li>**配置snapshot文件清理策略** <pre><code class="language-bash">autopurge.purgeInterval=1
</blockquote>
<p>autopurge.snapRetainCount=10<br></code></pre> autopurge.purgeInterval：开启清理事务日志和快照文件的功能，单位是小时。默认是0，表示不开启自动清理功能。 autopurge.snapRetainCount ： 指定了需要保留的文件数目。默认是保留3个。</li>- <strong>限制snapshot数量</strong> snapCount=3000000 每snapCount次事务日志输出后，触发一次快照(snapshot)。 ZooKeeper会生成一个snapshot文件和事务日志文件。 默认是100000。- <strong>log和data数据分磁盘存储</strong> dataDir：存储快照文件snapshot的目录。默认情况下，事务日志也会存储在这里。 dataLogDir：事务日志输出目录。尽量给事务日志的输出配置单独的磁盘或是挂载点，这将极大的提升ZK性能。- <strong>ZooKeeper的磁盘建议使用SSD</strong> 如果数据在TB级别以上，且复制表的数量比较多，超过100个，建议使用SSD磁盘。提升ZooKeeper的响应速度，避免ClickHouse副本间数据同步的延迟。<li>**调整JVM大小  *<em>ZooKeeper的JVM内存默认是根据操作系统本身内存大小的一个百分比预先分配的，所以这不是我们所需要的。 在./bin/zkEnv.sh文件中，有如下配置项： <pre><code class="language-bash">if [ -f "$ZOOCFGDIR/java.env" ]<br>then<br>    . "$ZOOCFGDIR/java.env"<br>fi<br></code></pre> 我们在./conf/java.env文件中配置JVM的内存，增加如下配置： <pre><code class="language-bash">export JAVA_HOME=/usr/local/java/jdk1.8.0_151<br>export JVMFLAGS="-Xms1024m -Xmx2048m $JVMFLAGS"<br></code></pre> 修改完成使用jmap -heap $pid来验证内存修改情况。 </li><li><strong>其它配置</strong> <strong>tickTime=2000</strong> ZK中的一个时间单元。ZK中所有时间都是以这个时间单元为基础，进行整数倍配置的。例如，session的最小超时时间是2</em>tickTime。 默认值2000，单位毫秒。 <strong>initLimit=10</strong> Follower在启动过程中，会从Leader同步所有最新数据，然后确定自己能够对外服务的起始状态。Leader允许F在 initLimit 时间内完成这个工作。通常情况下，我们不用太在意这个参数的设置。如果ZK集群的数据量确实很大了，F在启动的时候，从Leader上同步数据的时间也会相应变长，因此在这种情况下，有必要适当调大这个参数了。 initLimit=30000 <strong>syncLimit=5</strong> 在运行过程中，Leader负责与ZK集群中所有机器进行通信，例如通过一些心跳检测机制，来检测机器的存活状态。如果L发出心跳包在syncLimit之后，还没有从F那里收到响应，那么就认为这个F已经不在线了。注意：不要把这个参数设置得过大，否则可能会掩盖一些问题。 建议设置为10。 <strong>maxClientCnxns ：</strong> 单个客户端与单台服务器之间的连接数的限制，是ip级别的，默认是60，如果设置为0，那么表明不作任何限制。请注意这个限制的使用范围，仅仅是单台客户端机器与单台ZK服务器之间的连接数限制，不是针对指定客户端IP，也不是ZK集群的连接数限制，也不是单台ZK对所有客户端的连接数限制。 建议设置为2000 <strong>maxSessionTimeout=60000000</strong> Session超时时间限制，如果客户端设置的超时时间不在这个范围，那么会被强制设置为最大或最小时间。默认的Session超时时间是在2 * tickTime ~ 20 * tickTime 这个范围 <strong>preAllocSize=131072</strong> 预先开辟磁盘空间，用于后续写入事务日志。默认是64M，每个事务日志大小就是64M。如果ZK的快照频率较大的话，建议适当减小这个参数。单位kb。 <strong>配置：</strong> <pre><code class="language-bash">tickTime=2000</p>
<p>initLimit=30000<br>syncLimit=10</p>
<p>maxClientCnxns=2000<br>maxSessionTimeout=60000000</p>
<p>dataDir=/opt/zookeeper/&#123;<!-- -->&#123; cluster[‘name’] &#125;&#125;/data<br>dataLogDir=/opt/zookeeper/&#123;<!-- -->&#123; cluster[‘name’] &#125;&#125;/logs</p>
<p>autopurge.purgeInterval=1<br>autopurge.snapRetainCount=10</p>
<p>snapCount=3000000</p>
<p>preAllocSize=131072<br></code></pre>   </li>- <strong>建ClickHouse表配置元数据压缩</strong> 建表的时候设置use_minimalistic_part_header_in_zookeeper=1， 则ZooKeeper中会存储较少的数据，支持副本的表使用单个znode紧凑地存储数据片段的头信息。如果表包含很多列， 则此存储方法将大大减少Zookeeper中存储的数据量。</ol></p>
<h3 id="3-服务监控"><a href="#3-服务监控" class="headerlink" title="3.服务监控"></a>3.服务监控</h3><blockquote>
<p> ClickHouse内置了自我状态检测的功能， 可根据系统表、查询日志等监控服务器计算资源的不同度量以及查询处理的通用统计信息。<br> <ol><li> 系统表  ClickHouse提供了system.metrics、system.events和system.asynchronous_metrics表收集服务器的不同的运行度量。  1.1)system.metrics           这张表的数据实时更新， 用于查看正在运行的查询或当前副本的延迟信息等。           包含的列有：               •metric(String) ： 度量名称。               •value(Int64) ：指标值。               •description (String) ：度量描述。           <strong>示例:</strong> <pre><code class="language-sql">select * from system.metrics;</p>
</blockquote>
<p>┌─metric───────────────────────────────────────┬────value─┬─description─────────────────────────────────────────────┐<br>│ Query                                        │        1 │ Number of executing queries                             │<br>│ Merge                                        │        0 │ Number of executing background merges                   │<br>│ PartMutation                                 │        0 │ Number of mutations (ALTER DELETE/UPDATE)               │<br>│ GlobalThread                                 │       65 │ Number of threads in global thread pool.                │<br>│ GlobalThreadActive                           │       51 │ Number of threads in global thread pool running a task. │<br>└──────────────────────────────────────────────┴──────────┴─────────────────────────────────────────────────────────┘<br></code></pre>   1.2)<strong>system.events         用于收集系统中发生的事件数的信息。例如，可以查询自ClickHouse服务启动以来已处理的SELECT 查询数。         列信息如下：             •event (String) ： 事件名称。             •value (UInt64) ： 发生的事件数。             •description (String) ： 事件描述。         示例：</strong> <pre><code class="language-sql">clickhouse1 :) select * from system.events LIMIT 5;</p>
<p>SELECT *<br>FROM system.events<br>LIMIT 5</p>
<p>┌─event───────────────────────┬───value─┬─description────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐<br>│ Query                       │       7 │ Number of queries to be interpreted and potentially executed. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries. │<br>│ SelectQuery                 │       7 │ Same as Query, but only for SELECT queries.                                                                                                                                                                                                                │<br>│ QueryTimeMicroseconds       │  140616 │ Total time of all queries.                                                                                                                                                                                                                                 │<br>│ SelectQueryTimeMicroseconds │  140616 │ Total time of SELECT queries.                                                                                                                                                                                                                              │<br>│ FileOpen                    │ 3645730 │ Number of files opened.                                                                                                                                                                                                                                    │<br>└─────────────────────────────┴─────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘</p>
<p>5 rows in set. Elapsed: 0.002 sec. </p>
<p>clickhouse1 :)<br></code></pre>   1.3)<strong>system.asynchronous_metrics        <strong>用于实时监控后台定期计算的指标。例如，正在使用的RAM大小        列信息如下：</strong>             •metric (String)</strong> ： 事件名称。**             •value (Float64)** ：指标值。        **例如：        ** <pre><code class="language-sql">clickhouse1 :) SELECT * FROM system.asynchronous_metrics;</p>
<p>SELECT *<br>FROM system.asynchronous_metrics</p>
<p>┌─metric───────────────────────────────────┬──────value─┐<br>│ CPUFrequencyMHz_0                        │   2591.504 │<br>│ jemalloc.arenas.all.pmuzzy               │          0 │<br>│ jemalloc.arenas.all.pdirty               │       1311 │<br>│ jemalloc.background_thread.run_intervals │          0 │<br>│ jemalloc.background_thread.num_runs      │          0 │<br>│ jemalloc.retained                        │  894418944 │<br>│ jemalloc.mapped                          │  136331264 │<br>│ jemalloc.metadata                        │   13635904 │<br>│ jemalloc.resident                        │  126943232 │<br>│ jemalloc.allocated                       │  102341072 │<br>│ jemalloc.epoch                           │       1298 │<br>│ NumberOfTables                           │         73 │<br>│ jemalloc.active                          │  109989888 │<br>│ NumberOfDatabases                        │          3 │<br>│ MaxPartCountForPartition                 │          7 │<br>│ jemalloc.background_thread.num_threads   │          0 │<br>│ ReplicasSumQueueSize                     │          0 │<br>│ ReplicasMaxMergesInQueue                 │          0 │<br>│ MemoryShared                             │ 4238995456 │<br>│ MemoryCode                               │  432128000 │<br>│ ReplicasMaxAbsoluteDelay                 │          0 │<br>│ ReplicasMaxQueueSize                     │          0 │<br>│ jemalloc.arenas.all.muzzy_purged         │          0 │<br>│ MemoryVirtual                            │ 6097547264 │<br>│ MarkCacheBytes                           │          0 │<br>│ Uptime                                   │      77887 │<br>│ jemalloc.arenas.all.dirty_purged         │  379880169 │<br>│ ReplicasMaxRelativeDelay                 │          0 │<br>│ MemoryResident                           │ 4455157760 │<br>│ ReplicasMaxInsertsInQueue                │          0 │<br>│ jemalloc.metadata_thp                    │          0 │<br>│ UncompressedCacheCells                   │          0 │<br>│ CompiledExpressionCacheCount             │          0 │<br>│ ReplicasSumMergesInQueue                 │          0 │<br>│ UncompressedCacheBytes                   │          0 │<br>│ ReplicasSumInsertsInQueue                │          0 │<br>│ MarkCacheFiles                           │          0 │<br>│ MemoryDataAndStack                       │ 1824006144 │<br>│ jemalloc.arenas.all.pactive              │      26853 │<br>└──────────────────────────────────────────┴────────────┘</p>
<p>39 rows in set. Elapsed: 0.049 sec. </p>
<p>clickhouse1 :)<br></code></pre>   </li><li> 查询日志<strong>query_log</strong> 记录所有查询语句的开始时间、耗时、用户、资源占用等信息，包括SELECT、SET、ALTER等语句。 在ClickHouse的主配置文件config.xml配置了query_log日志的表、分区、数据刷新间隔等信息。 <pre><code class="language-XML">&lt;!-- Query log. Used only for queries with setting log_queries = 1. --&gt;<br>    &lt;query_log&gt;<br>        &lt;!-- What table to insert data. If table is not exist, it will be created.<br>             When query log structure is changed after system update,<br>              then old table will be renamed and new table will be created automatically.<br>        --&gt;<br>        &lt;database&gt;system&lt;/database&gt;<br>        &lt;table&gt;query_log&lt;/table&gt;<br>        &lt;!--<br>            PARTITION BY expr <a href="https://clickhouse.yandex/docs/en/table_engines/custom_partitioning_key/">https://clickhouse.yandex/docs/en/table_engines/custom_partitioning_key/</a><br>            Example:<br>                event_date<br>                toMonday(event_date)<br>                toYYYYMM(event_date)<br>                toStartOfHour(event_time)<br>        --&gt;<br>        &lt;partition_by&gt;toYYYYMM(event_date)&lt;/partition_by&gt;</p>
<pre><code>    &amp;lt;!-- Instead of partition_by, you can provide full engine expression (starting with ENGINE = ) with parameters,
         Example: &amp;lt;engine&amp;gt;ENGINE = MergeTree PARTITION BY toYYYYMM(event_date) ORDER BY (event_date, event_time) SETTINGS index_granularity = 1024&amp;lt;/engine&amp;gt;
      --&amp;gt;

    &amp;lt;!-- Interval of flushing data. --&amp;gt;
    &amp;lt;flush_interval_milliseconds&amp;gt;7500&amp;lt;/flush_interval_milliseconds&amp;gt;
&amp;lt;/query_log&amp;gt;
</code></pre>
<p></code></pre> ClickHouse默认不会收集查询的日志， 可通过设置log_queries = 1开启查询日志的功能,下面开启的命令要在服务器的黑窗口执行。 <pre><code class="language-bash">set log_queries = 1;<br>show tables;</p>
<p>SELECT * from <code>system</code>.query_log ql limit 1;<br></code></pre> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20201217003637697.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RvdG8xMjk3NDg4NTA0,size_16,color_FFFFFF,t_70#pic_center"><strong>trace_log</strong> 存储query profilers收集的堆栈跟踪日志。 堆栈日志根据计时器类型分为REAL和CPU，分别表示实际时钟计时器和CPU时钟计时器。 计时器相关的两个设置： <pre><code class="language-sql">query_profiler_real_time_period_ns：设置query profilers的实际计时器的周期，单位为纳秒，默认为1000000000（1秒）<br>query_profiler_cpu_time_period_ns：设置query profilers的CPU计时器的周期，单位为纳秒，默认为1000000000（1秒）。<br></code></pre> 在ClickHouse的主配置文件config.xml配置了trace_log日志的表、分区、数据刷新间隔等信息。 <pre><code class="language-XML">&lt;trace_log&gt;<br>    &lt;database&gt;system&lt;/database&gt;<br>    &lt;table&gt;trace_log&lt;/table&gt;</p>
<pre><code>&amp;lt;partition_by&amp;gt;toYYYYMM(event_date)&amp;lt;/partition_by&amp;gt;
&amp;lt;flush_interval_milliseconds&amp;gt;7500&amp;lt;/flush_interval_milliseconds&amp;gt;
</code></pre>
<p>&lt;/trace_log&gt;<br></code></pre> <strong>示例：</strong> <pre><code class="language-sql">SELECT * FROM system.trace_log ORDER BY event_date ASC LIMIT 2;<br></code></pre> <strong>query_thread_log</strong> 查询线程日志， 记录查询执行的所有线程的信息。 在ClickHouse的主配置文件config.xml配置了query_thread_log日志的表、分区、数据刷新间隔等信息。 <pre><code class="language-XML">&lt;query_thread_log&gt;<br>    &lt;database&gt;system&lt;/database&gt;<br>    &lt;table&gt;query_thread_log&lt;/table&gt;<br>    &lt;partition_by&gt;toYYYYMM(event_date)&lt;/partition_by&gt;<br>    &lt;flush_interval_milliseconds&gt;7500&lt;/flush_interval_milliseconds&gt;<br>&lt;/query_thread_log&gt;<br></code></pre> ClickHouse默认不会收集查询线程的日志， 可通过设置log_query_threads= 1开启查询日志的功能。 <pre><code class="language-sql">set log_query_threads = 1;</p>
<p>select * from system.query_thread_log limit 1;<br></code></pre> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20201217003929835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RvdG8xMjk3NDg4NTA0,size_16,color_FFFFFF,t_70#pic_center"><strong>part_log</strong> 用户监控MergeTree引擎表中针对数据片段所有操作（创建、删除、合并、下载等）的信息。 part_log默认是关闭， 在ClickHouse的主配置文件使用如下配置开启数据片段日志 <pre><code class="language-XML">&lt;part_log&gt;<br>    &lt;database&gt;system&lt;/database&gt;<br>    &lt;table&gt;part_log&lt;/table&gt;<br>    &lt;flush_interval_milliseconds&gt;7500&lt;/flush_interval_milliseconds&gt;<br>&lt;/part_log&gt;<br></code></pre> <strong>text_log</strong> text_log用于记录服务器的常规日志，但是以结构化和高效的方式存储在表中。 text_log默认是关闭的， 在ClickHouse的主配置文件使用如下配置开启日志。 <pre><code class="language-XML">&lt;text_log&gt;<br>    &lt;database&gt;system&lt;/database&gt;<br>    &lt;table&gt;text_log&lt;/table&gt;<br>    &lt;flush_interval_milliseconds&gt;7500&lt;/flush_interval_milliseconds&gt;<br>&lt;/text_log&gt;<br></code></pre> <strong>metric_log</strong> 用于存储来自表system.metrics和system.events指标值的历史记录。collect_interval_milliseconds用于设置采集的时间间隔。metric_log默认是关闭的， 在ClickHouse的主配置文件使用如下配置开启日志。</li></ol></p>
<h3 id="4-用户管理"><a href="#4-用户管理" class="headerlink" title="4.用户管理"></a>4.用户管理</h3><blockquote>
 <ol><li> profile管理 profile是一组设置的集合，类似于角色的概念，每个用户都有一个profile。 可以有两种方式使用profile： 在会话中应用profile的所有设置，例如：SET profile = ‘web’ 。 在users.xml的users部分为某个用户指定profile。**profiles在users.xml配置文件的profiles标签下配置：** <pre><code class="language-XML">&lt;!-- Settings profiles --&gt;
&lt;profiles&gt;
    &lt;!-- Default settings --&gt;
    &lt;default&gt;
        &lt;!-- The maximum number of threads when running a single query. --&gt;
        &lt;max_threads&gt;8&lt;/max_threads&gt;
    &lt;/default&gt;
​
    &lt;!-- Settings for quries from the user interface --&gt;
    &lt;web&gt;
        &lt;max_rows_to_read&gt;1000000000&lt;/max_rows_to_read&gt;
        &lt;max_bytes_to_read&gt;100000000000&lt;/max_bytes_to_read&gt;
​
        &lt;max_rows_to_group_by&gt;1000000&lt;/max_rows_to_group_by&gt;
        &lt;group_by_overflow_mode&gt;any&lt;/group_by_overflow_mode&gt;
​
        &lt;max_rows_to_sort&gt;1000000&lt;/max_rows_to_sort&gt;
        &lt;max_bytes_to_sort&gt;1000000000&lt;/max_bytes_to_sort&gt;
​
        &lt;max_result_rows&gt;100000&lt;/max_result_rows&gt;
        &lt;max_result_bytes&gt;100000000&lt;/max_result_bytes&gt;
        &lt;result_overflow_mode&gt;break&lt;/result_overflow_mode&gt;
​
        &lt;max_execution_time&gt;600&lt;/max_execution_time&gt;
        &lt;min_execution_speed&gt;1000000&lt;/min_execution_speed&gt;
        &lt;timeout_before_checking_execution_speed&gt;15&lt;/timeout_before_checking_execution_speed&gt;
​
        &lt;max_columns_to_read&gt;25&lt;/max_columns_to_read&gt;
        &lt;max_temporary_columns&gt;100&lt;/max_temporary_columns&gt;
        &lt;max_temporary_non_const_columns&gt;50&lt;/max_temporary_non_const_columns&gt;
​
        &lt;max_subquery_depth&gt;2&lt;/max_subquery_depth&gt;
        &lt;max_pipeline_depth&gt;25&lt;/max_pipeline_depth&gt;
        &lt;max_ast_depth&gt;50&lt;/max_ast_depth&gt;
        &lt;max_ast_elements&gt;100&lt;/max_ast_elements&gt;
​
        &lt;readonly&gt;1&lt;/readonly&gt;
    &lt;/web&gt;
&lt;/profiles&gt;
</code></pre> 上面的配置指定了两个profile：default和web。默认的default不能省略，它包含默认的设置，在服务器启动时应用。web是常规的profile，可以使用SET语句或HTTP查询中的URL参数进行设置。 profile设置可相互继承。如果使用继承，在配置文件中列出的其他设置之前， 先指定一个或多个profile。如果一个设置在不同的profile都定义了，则使用最新的设置。 </li><li> Quotas设置 Quotas用于在一段时间内跟踪资源的使用情况或限制资源的使用。quotas在user.xml配置文件的quotas标签下配置，在users标签下分配给用户。 注意：quota用于限制一组查询，并且将所有远程服务器上的分布式查询处理的资源纳入限制范围，而不是限制单个查询。**quotas的配置示例1:** <pre><code class="language-XML">&lt;!-- Quotas --&gt;
&lt;quotas&gt;
    &lt;!-- Quota name. --&gt;
    &lt;default&gt;
        &lt;!-- Restrictions for a time period. You can set many intervals with different restrictions. --&gt;
        &lt;interval&gt;
            &lt;!-- Length of the interval. --&gt;
            &lt;duration&gt;3600&lt;/duration&gt;
​
            &lt;!-- Unlimited. Just collect data for the specified time interval. --&gt;
            &lt;queries&gt;0&lt;/queries&gt;
            &lt;errors&gt;0&lt;/errors&gt;
            &lt;result_rows&gt;0&lt;/result_rows&gt;
            &lt;read_rows&gt;0&lt;/read_rows&gt;
            &lt;execution_time&gt;0&lt;/execution_time&gt;
        &lt;/interval&gt;
    &lt;/default&gt;
&lt;/quotas&gt;
</code></pre> 默认情况下，quota只跟踪一个小时内的资源使用情况，并不会限制资源的使用。每个时间间隔内的资源消耗在每次请求之后输出到服务器日志。**Quota配置示例2：** <pre><code class="language-XML">&lt;statbox&gt;
    &lt;!-- Restrictions for a time period. You can set many intervals with different restrictions. --&gt;
    &lt;interval&gt;
        &lt;!-- Length of the interval. --&gt;
        &lt;duration&gt;3600&lt;/duration&gt;
​
        &lt;queries&gt;1000&lt;/queries&gt;
        &lt;errors&gt;100&lt;/errors&gt;
        &lt;result_rows&gt;1000000000&lt;/result_rows&gt;
        &lt;read_rows&gt;100000000000&lt;/read_rows&gt;
        &lt;execution_time&gt;900&lt;/execution_time&gt;
    &lt;/interval&gt;
</blockquote>
<pre><code>&amp;lt;interval&amp;gt;
    &amp;lt;duration&amp;gt;86400&amp;lt;/duration&amp;gt;
</code></pre>
<p>​<br>        &lt;queries&gt;10000&lt;/queries&gt;<br>        &lt;errors&gt;1000&lt;/errors&gt;<br>        &lt;result_rows&gt;5000000000&lt;/result_rows&gt;<br>        &lt;read_rows&gt;500000000000&lt;/read_rows&gt;<br>        &lt;execution_time&gt;7200&lt;/execution_time&gt;<br>    &lt;/interval&gt;<br>&lt;/statbox&gt;<br></code></pre> 上面配置了一个名称为statbox的quota，在每小时（3600秒）和每24小时（86400秒）设置了对资源的限制。间隔结束时，将清除所有收集的值，在接下来的下一个时间区间，quota将重新开始计算。 可用于quota限制的资源如下： queries ： 请求总数。 errors ： 抛出异常的总数。 result_rows : 作为结果给出的总行数。 read_rows : 在所有远程服务器上，从表中读取用于运行查询的源总行数。 execution_time : 查询执行的总耗时，单位为秒。如果在至少一个时间间隔内超过了限制，则会引发异常，异常信息包括限制的类型、时间间隔以及新时间间隔的开始时间。 对于分布式查询处理， 资源的累积量存储在请求服务器上，因此，如果用户转到另一个服务器，则这个服务器的quota将重新开始累积。重启服务器后，quota将重置。 </li><li> 约束管理 在users.xml配置文件的profiles部分定义对设置的约束，可以禁止用户使用SET语句更改某些设置。 约束的定义模板如下： <pre><code class="language-XML">&lt;profiles&gt;<br>  &lt;profile_name&gt;<br>    &lt;constraints&gt;<br>      &lt;setting_name_1&gt;<br>        &lt;min&gt;lower_boundary&lt;/min&gt;<br>      &lt;/setting_name_1&gt;<br>      &lt;setting_name_2&gt;<br>        &lt;max&gt;upper_boundary&lt;/max&gt;<br>      &lt;/setting_name_2&gt;<br>      &lt;setting_name_3&gt;<br>        &lt;min&gt;lower_boundary&lt;/min&gt;<br>        &lt;max&gt;upper_boundary&lt;/max&gt;<br>      &lt;/setting_name_3&gt;<br>      &lt;setting_name_4&gt;<br>        &lt;readonly/&gt;<br>      &lt;/setting_name_4&gt;<br>    &lt;/constraints&gt;<br>  &lt;/profile_name&gt;<br>&lt;/profiles&gt;<br></code></pre> 如果用户尝试违法冲突，则会引发异常。 支持三种类型的约束：max、min和readonly。 max和min约束使用数值指定约束的上限和下限，这两个约束可以组合使用。 readonly约束指定了用户无法更改相应的设置。 使用示例： <pre><code class="language-XML">&lt;profiles&gt;<br>  &lt;default&gt;<br>    &lt;max_memory_usage&gt;10000000000&lt;/max_memory_usage&gt;<br>    &lt;force_index_by_date&gt;0&lt;/force_index_by_date&gt;<br>    ...<br>    &lt;constraints&gt;<br>      &lt;max_memory_usage&gt;<br>        &lt;min&gt;5000000000&lt;/min&gt;<br>        &lt;max&gt;20000000000&lt;/max&gt;<br>      &lt;/max_memory_usage&gt;<br>      &lt;force_index_by_date&gt;<br>        &lt;readonly/&gt;<br>      &lt;/force_index_by_date&gt;<br>    &lt;/constraints&gt;<br>  &lt;/default&gt;<br>&lt;/profiles&gt;<br></code></pre> 上面的约束配置限制了max_memory_usage的范围在20000000000和5000000000之间，force_index_by_date设置为只读。 使用下面的语句修改配置将引发异常： <pre><code class="language-sql">SET max_memory_usage=20000000001;<br>SET max_memory_usage=4999999999;<br>SET force_index_by_date=1;<br></code></pre> <strong>异常信息如下：</strong> <pre><code class="language-sql">Code: 452, e.displayText() = DB::Exception: Setting max_memory_usage should not be greater than 20000000000.<br>Code: 452, e.displayText() = DB::Exception: Setting max_memory_usage should not be less than 5000000000.<br>Code: 452, e.displayText() = DB::Exception: Setting force_index_by_date should not be changed.<br></code></pre> Note：在default的profile中定义的约束为默认的约束，这些约束会限制所有的用户，除非用户在自己的profile中显式覆盖这些设置。 force_index_by_date，如果表的主键包含日期列，则查询条件必须包含该该列。如果表的主键不包含日期列，则无需包含日期列。 仅适用于MergeTree引擎。 </li><li> 查询权限 ClickHouse中的查询可分为如下几种类型：<strong>读取数据查询</strong>：SELECT、SHOW、DESCRIBE、EXISTS。<strong>写数据查询</strong>：INSERT、OPTIMIZE。<strong>更改设置查询</strong>：SET、USE。<strong>DDL查询</strong>：CREATE、ALTER、RENAME、ATTACH、DETACH、 DROP、TRUNCATE。 KILL QUERY 下面的设置可用户配置用户的查询权限：<strong>readonly <strong>：限制读取、写入和更改三类查询的权限。</strong>allow_ddl</strong>：限制DDL查询的权限。<strong>KILL QUERY</strong>不受任何设置的限制。 <pre><code>1. readonly<br>用于限制读取、写入和更改三类查询的权限，默认值为0。<br>readonly的取值如下：<br>0 ： 允许执行所有查询。<br>1 ： 仅允许读取数据的查询。<br>2 ： 允许读取数据和更改设置。<br>在设置readonly=1后，用户将无法在当前会话中更改readonly和allow_ddl的设置。<br>在HTTP请求中使用GET方法时将自动设置readonly=1。如果在http请求中修改数据，则必须使用POST方法。</p>
<p>设置readonly=1将禁止用户更改所有的设置。如果要禁止用户修改某些特定的设置，可以在users.xml配置文件中配置profiles的约束。</p>
<ol start="2">
<li>allow_ddl<br>用于配置是否允许DDL操作的权限，默认值为1。<br>可设置的值如下：<br>0 ： 不允许DDL查询。<br>1 ： 允许DDL查询。<br>如果当前会话的allow_ddl=0，则无法执行： SET allow_ddl=0。</code></pre>   </li><li> 用户管理配置 xml文件的users标签的结构如下： <pre><code class="language-XML">&lt;users&gt;<br> &lt;!-- If user name was not specified, 'default' user is used. --&gt;<br> &lt;user_name&gt;<pre><code> &amp;lt;password&amp;gt;&amp;lt;/password&amp;gt;
 &amp;lt;!-- Or --&amp;gt;
 &amp;lt;password_sha256_hex&amp;gt;&amp;lt;/password_sha256_hex&amp;gt;
</code></pre>
​<pre><code> &amp;lt;networks incl=&quot;networks&quot; replace=&quot;replace&quot;&amp;gt;
 &amp;lt;/networks&amp;gt;
</code></pre>
​<pre><code> &amp;lt;profile&amp;gt;profile_name&amp;lt;/profile&amp;gt;
</code></pre>
​<pre><code> &amp;lt;quota&amp;gt;default&amp;lt;/quota&amp;gt;
</code></pre>
​<pre><code> &amp;lt;databases&amp;gt;
     &amp;lt;database_name&amp;gt;
         &amp;lt;table_name&amp;gt;
             &amp;lt;filter&amp;gt;expression&amp;lt;/filter&amp;gt;
         &amp;lt;table_name&amp;gt;
     &amp;lt;/database_name&amp;gt;
 &amp;lt;/databases&amp;gt;
</code></pre>
​<pre><code>&amp;lt;allow_databases&amp;gt;
    &amp;lt;database&amp;gt;test&amp;lt;/database&amp;gt;
 &amp;lt;/allow_databases&amp;gt;
 &amp;lt;allow_dictionaries&amp;gt;
    &amp;lt;dictionary&amp;gt;test&amp;lt;/dictionary&amp;gt;
 &amp;lt;/allow_dictionaries&amp;gt;
</code></pre>
 &lt;/user_name&gt;<br> &lt;!– Other users settings –&gt;</li>
</ol>
<p>&lt;/users&gt;<br></code></pre> 在上面的配置中，定义了一个user_name的用户，该用户的所有其他配置都通过该标签的子标签配置。下面详细介绍每个具体子标签的配置信息。 1）**user_name/password       **密码可以使用明文、SHA256或SHA1指定。       明文形式的密码通过password标签指定。       <strong>例如:</strong> <pre><code class="language-XML">&lt;password&gt;qwerty&lt;/password&gt;<br></code></pre>    密码可以为空。    SHA256散列密码通过password_sha256_hex标签指定。    示例： <pre><code class="language-XML">&lt;password_sha256_hex&gt;65e84be33532fb784c48129675f9eff3a682b27168c0ea744b2cf58ee02337c5&lt;/password_sha256_hex&gt;<br></code></pre> **   <strong>可通过如下shell命令生成SHA256散列： <pre><code class="language-bash">PASSWORD=$(base64 &lt; /dev/urandom | head -c8); echo "$PASSWORD"; echo -n "$PASSWORD" | sha256sum | tr -d '-'<br></code></pre> **  <strong>命令的输出如下： <pre><code class="language-bash">pmpjaK2V<br>21c4185b8155e532ca5a1eb0d4ca74ecde83eddee4ca55af393007f7c29f7eb7<br></code></pre> 第一行是明文的密码，第二行对应的SHA256加密散列。 SHA1散列密码通过password_double_sha1_hex标签指定。 SHA1密码是为了兼容MySQL客户端。 使用示例： <pre><code class="language-XML">&lt;password_double_sha1_hex&gt;08b4a0f1de6ad37da17359e592c8d74788a83eb0&lt;/password_double_sha1_hex&gt;<br></code></pre> 可通过如下shell命令生成SHA1散列： <pre><code class="language-bash">PASSWORD=$(base64 &lt; /dev/urandom | head -c8); echo "$PASSWORD"; echo -n "$PASSWORD" | sha1sum | tr -d '-' | xxd -r -p | sha1sum | tr -d '-'<br></code></pre> 命令的输出如下： <pre><code class="language-bash">KCXM95It<br>de4bbcb9bbb35e3e497fcbebafc0f04b3dcef383<br></code></pre> 第一行是明文的密码，第二行对应的SHA1加密散列。</strong>2）user_name/networks      <strong>networks用于配置网络列表，只有网络列表范围内的用户可以连接到ClickHouse。     列表中的元素可以使用如下形式定义：     ： IP地址或带掩码的IP地址。     例如： <pre><code class="language-bash">213.180.204.3, 10.0.0.1/8, 10.0.0.1/255.255.255.0, 2a02:6b8::3, 2a02:6b8::3/64, 2a02:6b8::3/ffff:ffff:ffff:ffff::<br></code></pre> ： 主机名。 例如： <pre><code class="language-bash">example01.host.ru<br></code></pre> &lt;host_regexp&gt; ： 主机名的正则表达式。</strong>例如：</strong> <pre><code class="language-bash">^example\d\d-\d\d-\d.host.ru$<br></code></pre> 使用这种方式指定网络列表，强烈建议regexp以$结尾。 示例1：用户可以从任意网络访问，指定： <pre><code class="language-XML">&lt;ip&gt;::/0&lt;/ip&gt;<br></code></pre> <strong>示例2：仅限本地网络访问，指定：</strong>   <pre><code class="language-XML">&lt;ip&gt;::1&lt;/ip&gt;<br>&lt;ip&gt;127.0.0.1&lt;/ip&gt;<br></code></pre> **3）user_name/profile        <strong>profile用于给用户分配一个配置好的profile，这个profile是在users.xml配置文件的profiles标签下配置的。</strong>4）user_name/quota      <strong>用于给用户分配quota，这里quota是在users.xml配置文件的quotas标签下配置的。quota用于在一定时间内跟踪或限制资源的使用。</strong>5）user_name/databases      <strong>用于限制当前用户的SELECT查询返回的行，可实现基本的行级安全性。     <strong>示例：</strong>      以下的配置将限制用户user1只能查询table1表中id=1000的行，其他记录对用户不可见，就好像表中不存在其他行一样。 <pre><code class="language-XML">&lt;user1&gt;<br>    &lt;databases&gt;<br>        &lt;database_name&gt;<br>            &lt;table1&gt;<br>                &lt;filter&gt;id = 1000&lt;/filter&gt;<br>            &lt;/table1&gt;<br>        &lt;/database_name&gt;<br>    &lt;/databases&gt;<br>&lt;/user1&gt;<br></code></pre> 使用这种方式需要注意WHERE子句的查询谓词不会下推，即禁用了WHERE移动到PREWHERE的优化。</strong>6）user_name/allow_databases      **用于指定用户可以访问的数据库列表。默认情况下，用户可以访问所有数据库。      Note： 用户对system数据库的访问始终是有权限的，因为用户需要根据此数据库处理查询。      配置示例，配置用户可访问test1和test2数据库： <pre><code class="language-XML">&lt;allow_databases&gt;<br>  &lt;database&gt;test1&lt;/database&gt;<br>  &lt;database&gt;test2&lt;/database&gt;<br>&lt;/allow_databases&gt;<br></code></pre> **7）user_name/allow_dictionaries       **配置可以访问的字典列表。默认情况下，用户可访问所有字典。      示例， 配置用户可访问test1和test2字典： <pre><code class="language-XML">&lt;allow_dictionaries&gt;<br>  &lt;dictionary&gt;test1&lt;/dictionary&gt;<br>  &lt;dictionary&gt;test2&lt;/dictionary&gt;<br>&lt;/allow_dictionaries&gt;<br></code></pre>   </li></ol></p>
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
  </entry>
  <entry>
    <title>Elasticsearch进阶之故障转移、水平扩容，倒排索引，分析器等</title>
    <url>/2021/07/18/Elasticsearch%E8%BF%9B%E9%98%B6%E4%B9%8B%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E3%80%81%E6%B0%B4%E5%B9%B3%E6%89%A9%E5%AE%B9%EF%BC%8C%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%EF%BC%8C%E5%88%86%E6%9E%90%E5%99%A8%E7%AD%89/</url>
    <content><![CDATA[<p>title: Elasticsearch进阶之故障转移、水平扩容，倒排索引，分析器等<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、单节点集群</p>
<blockquote>
<p> 我们在包含一个空节点的集群内创建名为 users 的索引，为了演示目的，我们将分配 3个主分片和一份副本（每个主分片拥有一个副本分片）。<br> <pre><code class="language-java">#PUT <a href="http://127.0.0.1:1001/users">http://127.0.0.1:1001/users</a><br>&#123;<br>    "settings" : &#123;<br>        "number_of_shards" : 3,<br>        "number_of_replicas" : 1<br>    &#125;<br>&#125;<br></code></pre><br> 集群现在是拥有一个索引的单节点集群。所有 3 个主分片都被分配在 node-1 。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/54ee6753be248cc7d345b38a0eae7d96.png"><br> 通过 elasticsearch-head 插件（一个Chrome插件）查看集群情况 。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/e8b15d0b243d486e91f478a220da63bf.png"> </p>
</blockquote>
<ul>
<li>集群健康值:yellow( 3 of 6 )：表示当前集群的全部主分片都正常运行，但是副本分片没有全部处在正常状态。3 个主分片正常<img alt="" src="https://img-blog.csdnimg.cn/img_convert/489b6de480112879a00067b793bde685.png">- 3 个副本分片都是 Unassigned，它们都没有被分配到任何节点。 在同 一个节点上既保存原始数据又保存副本是没有意义的，因为一旦失去了那个节点，我们也将丢失该节点 上的所有副本数据。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/3ce9a78d26ee762f0a7a8abf7817a58e.png">- 当前集群是正常运行的，但存在丢失数据的风险。</li>
</ul>
<h3 id="2、故障转移"><a href="#2、故障转移" class="headerlink" title="2、故障转移"></a>2、故障转移</h3><blockquote>
<p> 当集群中只有一个节点在运行时，意味着会有一个单点故障问题——没有冗余。 幸运的是，我们只需再启动一个节点即可防止数据丢失。当你在同一台机器上启动了第二个节点时，只要它和第一个节点有同样的 cluster.name 配置，它就会自动发现集群并加入到其中。但是在不同机器上启动节点的时候，为了加入到同一集群，你需要配置一个可连接到的单播主机列表。之所以配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上 运行的节点才会自动组成集群。<br> 如果启动了第二个节点，集群将会拥有两个节点 : 所有主分片和副本分片都已被分配 。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/bf76cb1bfbdf07555918d9055817ab44.png"><br> 通过 elasticsearch-head 插件查看集群情况<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/18db400822b83e727d6206f486b7b2ea.png"> </p>
</blockquote>
<ul>
<li>集群健康值:green( 3 of 6 )：表示所有 6 个分片（包括 3 个主分片和 3 个副本分片）都在正常运行。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/e485d8263a4aa3a94af0be951bd5a241.png">- 3 个主分片正常。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/e485d8263a4aa3a94af0be951bd5a241.png">- 第二个节点加入到集群后， 3 个副本分片将会分配到这个节点上——每 个主分片对应一个副本分片。这意味着当集群内任何一个节点出现问题时，我们的数据都完好无损。所 有新近被索引的文档都将会保存在主分片上，然后被并行的复制到对应的副本分片上。这就保证了我们 既可以从主分片又可以从副本分片上获得文档。</li>
</ul>
<h3 id="3、水平扩容"><a href="#3、水平扩容" class="headerlink" title="3、水平扩容"></a>3、水平扩容</h3><blockquote>
<p> 怎样为我们的正在增长中的应用程序按需扩容呢？当启动了第三个节点，我们的集群将会拥有三个节点的集群 : 为了分散负载而对分片进行重新分配 。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/d527e26aa2bccdf54b11410024eadc92.png"><br> 通过 elasticsearch-head 插件查看集群情况。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/6985fe14454c1269204478320d089bd7.png"> </p>
</blockquote>
<ul>
<li>集群健康值:green( 3 of 6 )：表示所有 6 个分片（包括 3 个主分片和 3 个副本分片）都在正常运行。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/9494419153adb44bedb395ac5d7bc488.png">- Node 1 和 Node 2 上各有一个分片被迁移到了新的 Node 3 节点，现在每个节点上都拥有 2 个分片， 而不是之前的 3 个。 这表示每个节点的硬件资源（CPU, RAM, I/O）将被更少的分片所共享，每个分片 的性能将会得到提升。<br>分片是一个功能完整的搜索引擎，它拥有使用一个节点上的所有资源的能力。 我们这个拥有 6 个分 片（3 个主分片和 3 个副本分片）的索引可以最大扩容到 6 个节点，每个节点上存在一个分片，并且每个 分片拥有所在节点的全部资源。 </li>
</ul>
<p> <strong>但是如果我们想要扩容超过 6 个节点怎么办呢？</strong><br> 主分片的数目在索引创建时就已经确定了下来。实际上，这个数目定义了这个索引能够 存储 的最大数据量。（实际大小取决于你的数据、硬件和使用场景。） 但是，读操作—— 搜索和返回数据——可以同时被主分片 或 副本分片所处理，所以当你拥有越多的副本分片 时，也将拥有越高的吞吐量。<br> 在运行中的集群上是可以动态调整副本分片数目的，我们可以按需伸缩集群。让我们把 副本数从默认的 1 增加到 2。<br> <pre><code class="language-java">#PUT <a href="http://127.0.0.1:1001/users/_settings">http://127.0.0.1:1001/users/_settings</a></p>
<p>&#123;<br>    “number_of_replicas” : 2<br>&#125;<br></code></pre><br> users 索引现在拥有 9 个分片： 3 个主分片和 6 个副本分片。 这意味着我们可以将集群 扩容到 9 个节点，每个节点上一个分片。相比原来 3 个节点时，集群搜索性能可以提升 3 倍。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/97fd01e34e5d8df23d226c4fef157801.png"><br> 通过 elasticsearch-head 插件查看集群情况：<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/8bf9dbf0cec5b7875bf8aa9d17a9a67c.png"><br> 当然，如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每 个分片从节点上获得的资源会变少。 你需要增加更多的硬件资源来提升吞吐量。<br> 但是更多的副本分片数提高了数据冗余量：按照上面的节点配置，我们可以在失去 2 个节点 的情况下不丢失任何数据。 </p>
<h3 id="4、应对故障"><a href="#4、应对故障" class="headerlink" title="4、应对故障"></a>4、应对故障</h3><blockquote>
<p> 我们关闭第一个节点，这时集群的状态为:关闭了一个节点后的集群。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/44e841004be934e6bce08187ca3852bb.png"><br> 我们关闭的节点是一个主节点。而集群必须拥有一个主节点来保证正常工作，所以发生 的第一件事情就是选举一个新的主节点： Node 2 。在我们关闭 Node 1 的同时也失去了主 分片 1 和 2 ，并且在缺失主分片的时候索引也不能正常工作。 如果此时来检查集群的状况，我们看到的状态将会为 red ：不是所有主分片都在正常工作。<br> 幸运的是，在其它节点上存在着这两个主分片的完整副本， 所以新的主节点立即将这些分片在 Node 2 和 Node 3 上对应的副本分片提升为主分片， 此时集群的状态将会为yellow。这个提升主分片的过程是瞬间发生的，如同按下一个开关一般。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/e956bda7e0d005699e27760d4193d101.png"><br> <strong>为什么我们集群状态是 yellow 而不是 green 呢？</strong><br> 虽然我们拥有所有的三个主分片，但是同时设置了每个主分片需要对应 2 份副本分片，而此 时只存在一份副本分片。 所以集群不能为 green 的状态，不过我们不必过于担心：如果我 们同样关闭了 Node 2 ，我们的程序 依然 可以保持在不丢任何数据的情况下运行，因为 Node 3 为每一个分片都保留着一份副本。<br> 如果想回复原来的样子，要确保Node-1的配置文件有如下配置：<br> <pre><code class="language-bash">discovery.seed_hosts: ["localhost:9302", "localhost:9303"]<br></code></pre><br> 集群可以将缺失的副本分片再次进行分配，那么集群的状态也将恢复成之前的状态。 如果 Node 1 依然拥有着之前的分片，它将尝试去重用它们，同时仅从主分片复制发生了修改的数据文件。和之前的集群相比，只是 Master 节点切换了。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/37eea6a8dae7ba908312f2ebf0eced11.png"> </p>
</blockquote>
<h3 id="5、路由计算-amp-分片控制"><a href="#5、路由计算-amp-分片控制" class="headerlink" title="5、路由计算 &amp; 分片控制"></a>5、路由计算 &amp; 分片控制</h3><blockquote>
 <h3>路由计算：</h3> 
 当索引一个文档的时候，文档会被存储到一个主分片中。 Elasticsearch 如何知道一个 文档应该存放到哪个分片中呢？当我们创建文档时，它如何决定这个文档应当被存储在分片 1 还是分片 2 中呢？首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的： 
 <pre><code class="language-java">shard = hash(routing) % number_of_primary_shards
</code></pre> 
 routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。 
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/9c34e8603887c2bed475416e3b67cd9a.png"> 
 这就解释了为什么我们要在创建索引的时候就确定好主分片的数量并且永远不会改变这个数量:因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。 
 所有的文档API ( get . index . delete 、 bulk , update以及 mget ）都接受一个叫做routing 的路由参数，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路由参数可以用来确保所有相关的文档—一例如所有属于同一个用户的文档——都被存储到同一个分片中。 
 <h3>分片控制</h3> 
 我们可以发送请求到集群中的任一节点。每个节点都有能力处理任意请求。每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。在下面的例子中，如果将所有的请求发送到Node 1001，我们将其称为协调节点**coordinating node**。 
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/3940d6cdb197259368542b86384911a4.png"> 
 当发送请求的时候， 为了扩展负载，更好的做法是轮询集群中所有的节点。 
</blockquote>
<h3 id="分片控制"><a href="#分片控制" class="headerlink" title="分片控制"></a>分片控制</h3><h3 id="6、数据写流程"><a href="#6、数据写流程" class="headerlink" title="6、数据写流程"></a>6、数据写流程</h3><blockquote>
<p> 新建、索引和删除请求都是写操作， 必须在主分片上面完成之后才能被复制到相关的副本分片。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/418356a32516c222a8d366df021276c2.png"><br> 在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。有一些可选的<strong>请求参数</strong>允许您影响这个过程，可能以数据安全为代价提升性能。这些选项很少使用，因为 Elasticsearch 已经很快，但是为了完整起见， 请参考下文：<br> <strong>1、consistency：</strong> </p>
</blockquote>
<ul>
<li>      即一致性。在默认设置下，即使仅仅是在试图执行一个写操作之前，主分片都会要求必须要有规定数量quorum（或者换种说法，也即必须要有大多数）的分片副本处于活跃可用状态，才会去执行写操作（其中分片副本 可以是主分片或者副本分片）。这是为了避免在发生网络分区故障（network partition）的时候进行写操作，进而导致数据不一致。 规定数量即： int((primary + number_of_replicas) / 2 ) + 1- consistency 参数的值可以设为：   one ：只要主分片状态 ok 就允许执行写操作。   all：必须要主分片和所有副本分片的状态没问题才允许执行写操作。   quorum：默认值为quorum , 即大多数的分片副本状态没问题就允许执行写操作。- 注意，规定数量的计算公式中number_of_replicas指的是在索引设置中的设定副本分片数，而不是指当前处理活动状态的副本分片数。如果你的索引设置中指定了当前索引拥有3个副本分片，那规定数量的计算结果即：int((1 primary + 3 replicas) / 2) + 1 = 3，如果此时你只启动两个节点，那么处于活跃状态的分片副本数量就达不到规定数量，也因此您将无法索引和删除任何文档。</li>
</ul>
<p> <strong>2、timeout</strong> </p>
<ul>
<li>如果没有足够的副本分片会发生什么？Elasticsearch 会等待，希望更多的分片出现。默认情况下，它最多等待 1 分钟。 如果你需要，你可以使用timeout参数使它更早终止：100是100 毫秒，30s是30秒。<br>新索引默认有1个副本分片，这意味着为满足规定数量应该需要两个活动的分片副本。 但是，这些默认的设置会阻止我们在单一节点上做任何事情。为了避免这个问题，要求只有当number_of_replicas 大于1的时候，规定数量才会执行。 </li>
</ul>
<h3 id="7、数据读流程"><a href="#7、数据读流程" class="headerlink" title="7、数据读流程"></a>7、数据读流程</h3><blockquote>
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/7139df83ee6f7a59c5d3252d34cc8762.png"> 
 在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡。在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。 在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。 
</blockquote>
<h3 id="8、更新流程-amp-批量操作流程"><a href="#8、更新流程-amp-批量操作流程" class="headerlink" title="8、更新流程 &amp; 批量操作流程"></a>8、更新流程 &amp; 批量操作流程</h3><blockquote>
 <h3>更新流程：</h3> 
 部分更新一个文档结合了先前说明的读取和写入流程： 
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/ca41993144aee98311671278725437cd.png"> 
 部分更新一个文档的步骤如下： 
</blockquote>
<ul>
<li>客户端向Node 1发送更新请求。- 它将请求转发到主分片所在的Node 3 。- Node 3从主分片检索文档，修改_source字段中的JSON，并且尝试重新索引主分片的文档。如果文档已经被另一个进程修改,它会重试步骤3 ,超过retry_on_conflict次后放弃。- 如果 Node 3成功地更新文档，它将新版本的文档并行转发到Node 1和 Node 2上的副本分片，重新建立索引。一旦所有副本分片都返回成功，Node 3向协调节点也返回成功，协调节点向客户端返回成功。<br>当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。请记住，这些更改将会异步转发到副本分片，并且不能保证它们以发送它们相同的顺序到达。 如果 Elasticsearch 仅转发更改请求，则可能以错误的顺序应用更改，导致得到损坏的文档。 <h3>批量操作流程：</h3> </li>
</ul>
<p> <strong>mget和 bulk API的模式类似于单文档模式。</strong>区别在于协调节点知道每个文档存在于哪个分片中。它将整个多文档请求分解成每个分片的多文档请求，并且将这些请求并行转发到每个参与节点。<br> 协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/b90ea9c79138d8361ca339cff205fdb0.png"><br> <strong>用单个 mget 请求取回多个文档所需的步骤顺序:</strong> </p>
<ul>
<li>客户端向 Node 1 发送 mget 请求。- Node 1为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复，Node 1 构建响应并将其返回给客户端。<br>可以对docs数组中每个文档设置routing参数。<br>bulk API， 允许在单个批量请求中执行多个创建、索引、删除和更新请求。 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/83499315a7b8ab81471a88f3e142f0a8.png"> </li>
</ul>
<p> <strong>bulk API 按如下步骤顺序执行：</strong> </p>
<ul>
<li>客户端向Node 1 发送 bulk请求。- Node 1为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。- 主分片一个接一个按顺序执行每个操作。当每个操作成功时,主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。</li>
</ul>
<h3 id="批量操作流程："><a href="#批量操作流程：" class="headerlink" title="批量操作流程："></a>批量操作流程：</h3><h3 id="9、倒排索引"><a href="#9、倒排索引" class="headerlink" title="9、倒排索引"></a>9、倒排索引</h3><blockquote>
<p> 分片是Elasticsearch最小的工作单元。但是究竟什么是一个分片，它是如何工作的？<br> 传统的数据库每个字段存储单个值，但这对全文检索并不够。文本字段中的每个单词需要被搜索，对数据库意味着需要单个字段有索引多值的能力。最好的支持是一个字段多个值需求的数据结构是<strong>倒排索引</strong>。<br> <h3>倒排索引原理</h3><br> Elasticsearch使用一种称为倒排索引的结构，它适用于快速的全文搜索。<br> 见其名，知其意，有倒排索引，肯定会对应有正向索引。正向索引（forward index），反向索引（inverted index）更熟悉的名字是<strong>倒排索引</strong>。<br> 所谓的<strong>正向索引</strong>，就是搜索引擎会将待搜索的文件都对应一个文件ID，搜索时将这个ID和搜索关键字进行对应，形成K-V对，然后对关键字进行统计计数。（统计？？下文有解释）<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/cba02cc6d7c5f054dfe5d58fafac9a6a.png"><br> 但是互联网上收录在搜索引擎中的文档的数目是个天文数字，这样的索引结构根本无法满足实时返回排名结果的要求。所以，搜索引擎会将正向索引重新构建为倒排索引，即把文件ID对应到关键词的映射转换为关键词到文件ID的映射，每个关键词都对应着一系列的文件，这些文件中都出现这个关键词。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/a1f52e96e0ac218b5024d708202afba4.png"><br> <h3>倒排索引的例子</h3><br> 一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。例如，假设我们有两个文档，每个文档的content域包含如下内容： </p>
</blockquote>
<ul>
<li>The quick brown fox jumped over the lazy dog- Quick brown foxes leap over lazy dogs in summer<br>为了创建倒排索引，我们首先将每个文档的content域拆分成单独的词（我们称它为词条或tokens )，创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。结果如下所示： <img alt="" src="https://img-blog.csdnimg.cn/img_convert/3cc642e9bae776c3e617f9d117d41e21.png"> 
现在，如果我们想搜索 `quick` `brown` ，我们只需要查找包含每个词条的文档： 
<img alt="" src="https://img-blog.csdnimg.cn/img_convert/f26aaa01e011edfa68736956b2f1ddea.png"> 
两个文档都匹配，但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单相似性算法，那么我们可以说，对于我们查询的相关性来讲，第一个文档比第二个文档更佳。 
但是，我们目前的倒排索引有一些问题： </li>
<li><code>Quick</code>和<code>quick</code>以独立的词条出现，然而用户可能认为它们是相同的词。 -  <code>fox</code>和<code>foxes</code>非常相似，就像<code>dog</code>和<code>dogs</code>；他们有相同的词根。 -  <code>jumped</code>和<code>leap</code>，尽管没有相同的词根，但他们的意思很相近。他们是同义词。<br>使用前面的索引搜索+Quick +fox不会得到任何匹配文档。(记住，＋前缀表明这个词必须存在）。<br>只有同时出现Quick和fox 的文档才满足这个查询条件，但是第一个文档包含quick fox ，第二个文档包含Quick foxes 。<br>我们的用户可以合理的期望两个文档与查询匹配。我们可以做的更好。<br>如果我们将词条规范为标准模式，那么我们可以找到与用户搜索的词条不完全一致，但具有足够相关性的文档。例如： </li>
<li><code>Quick</code>可以小写化为<code>quick</code>。- <code>foxes</code>可以词干提取变为词根的格式为<code>fox</code>。类似的，<code>dogs</code>可以为提取为<code>dog</code>。- <code>jumped</code>和<code>leap</code>是同义词，可以索引为相同的单词<code>jump</code> 。<br>现在索引看上去像这样： <img alt="" src="https://img-blog.csdnimg.cn/img_convert/19813d1918c89461303377444cf85c8c.png"> 
这还远远不够。我们搜索+Quick +fox 仍然会失败，因为在我们的索引中，已经没有Quick了。但是，如果我们对搜索的字符串使用与content域相同的标准化规则，会变成查询+quick +fox，这样两个文档都会匹配！分词和标准化的过程称为分析，这非常重要。你只能搜索在索引中出现的词条，所以索引文本和查询字符串必须标准化为相同的格式。 </li>
</ul>
<h3 id="倒排索引的例子"><a href="#倒排索引的例子" class="headerlink" title="倒排索引的例子"></a>倒排索引的例子</h3><h3 id="10、文档搜索"><a href="#10、文档搜索" class="headerlink" title="10、文档搜索"></a>10、文档搜索</h3><blockquote>
 <h3>不可改变的倒排索引</h3> 
 早期的全文检索会为整个文档集合建立一个很大的倒排索引并将其写入到磁盘。 一旦新的索引就绪，旧的就会被其替换，这样最近的变化便可以被检索到。 
 倒排索引被写入磁盘后是不可改变的：它永远不会修改。 
</blockquote>
<ul>
<li>不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。- 一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。- 其它缓存(像filter缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。- 写入单个大的倒排索引允许数据被压缩，减少磁盘IO和需要被缓存到内存的索引的使用量<br>当然，一个不变的索引也有不好的地方。主要事实是它是不可变的! 你不能修改它。如果你需要让一个新的文档可被搜索，你需要重建整个索引。这要么对一个索引所能包含的数据量造成了很大的限制，要么对索引可被更新的频率造成了很大的限制。 <h3>动态更新索引</h3> 
如何在保留不变性的前提下实现倒排索引的更新？ 
答案是：用更多的索引。通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到,从最早的开始查询完后再对结果进行合并。 
Elasticsearch基于Lucene，这个java库引入了按段搜索的概念。每一段本身都是一个倒排索引，但索引在 Lucene 中除表示所有段的集合外，还增加了提交点的概念—一个列出了所有已知段的文件。 
<img alt="" src="https://img-blog.csdnimg.cn/img_convert/9ee1adbb2d55e710257e01b812a6d8cf.png"> 
按段搜索会以如下流程执行： 
一、新文档被收集到内存索引缓存。 
<img alt="" src="https://img-blog.csdnimg.cn/img_convert/9d499fde966ee9825fa5a424d8357489.png"> 
二、不时地, 缓存被提交。 </li>
<li>一个新的段，一个追加的倒排索引，被写入磁盘。- 一个新的包含新段名字的提交点被写入磁盘。- 磁盘进行同步，所有在文件系统缓存中等待的写入都刷新到磁盘，以确保它们被写入物理文件<br>三、新的段被开启，让它包含的文档可见以被搜索。<br>四、内存缓存被清空，等待接收新的文档。 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/f74828ff58cc4635a97e88706a221e50.png"> 
当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。这种方式可以用相对较低的成本将新文档添加到索引。 
段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。取而代之的是，每个提交点会包含一个.del 文件，文件中会列出这些被删除文档的段信息。 
当一个**文档被“删除”**时，它实际上只是在 .del 文件中被标记删除。一个被标记删除的文档仍然可以被查询匹配到，但它会在最终结果被返回前从结果集中移除。 
文档更新也是类似的操作方式:当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。 </li>
</ul>
<h3 id="动态更新索引"><a href="#动态更新索引" class="headerlink" title="动态更新索引"></a>动态更新索引</h3><h3 id="11、文档刷新-amp-文档刷写-amp-文档合并"><a href="#11、文档刷新-amp-文档刷写-amp-文档合并" class="headerlink" title="11、文档刷新 &amp; 文档刷写 &amp; 文档合并"></a>11、文档刷新 &amp; 文档刷写 &amp; 文档合并</h3><blockquote>
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/b3b31c1e592d5aa794e7c9fcb259c924.png"> 
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/521c25f0f16247240234d1b8eb3c5f25.png"> 
 <h3>近实时搜索</h3> 
 随着按段（per-segment）搜索的发展，一个新的文档从索引到可被搜索的延迟显著降低了。新文档在几分钟之内即可被检索，但这样还是不够快。磁盘在这里成为了瓶颈。提交（Commiting）一个新的段到磁盘需要一个fsync来确保段被物理性地写入磁盘，这样在断电的时候就不会丢失数据。但是fsync操作代价很大；如果每次索引一个文档都去执行一次的话会造成很大的性能问题。 
 我们需要的是一个更轻量的方式来使一个文档可被搜索，这意味着fsync要从整个过程中被移除。在Elasticsearch和磁盘之间是文件系统缓存。像之前描述的一样，在内存索引缓冲区中的文档会被写入到一个新的段中。但是这里新段会被先写入到文件系统缓存—这一步代价会比较低，稍后再被刷新到磁盘—这一步代价比较高。不过只要文件已经在缓存中，就可以像其它文件一样被打开和读取了。 
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/a679d4f5f4bfa6913a53316251beef2a.png"> 
 Lucene允许新段被写入和打开，使其包含的文档在未进行一次完整提交时便对搜索可见。这种方式比进行一次提交代价要小得多，并且在不影响性能的前提下可以被频繁地执行。 
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/673d3a77e254fa3a5a6f5293ffb125ab.png"> 
 在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做refresh。默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch是近实时搜索：文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。 
 这些行为可能会对新用户造成困惑：他们索引了一个文档然后尝试搜索它，但却没有搜到。这个问题的解决办法是用refresh API执行一次手动刷新：/usersl_refresh 
 尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候，手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。相反，你的应用需要意识到Elasticsearch 的近实时的性质，并接受它的不足。 
 并不是所有的情况都需要每秒刷新。可能你正在使用Elasticsearch索引大量的日志文件，你可能想优化索引速度而不是近实时搜索，可以通过设置refresh_interval ，降低每个索引的刷新频率 
 <pre><code class="language-java">&#123;
    "settings": &#123;
        "refresh_interval": "30s"
    &#125;
&#125;
</code></pre> 
 refresh_interval可以在既存索引上进行动态更新。在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来。 
 <pre><code class="language-java"># 关闭自动刷新
PUT /users/_settings
&#123; "refresh_interval": -1 &#125;
</blockquote>
<h1 id="每一秒刷新"><a href="#每一秒刷新" class="headerlink" title="每一秒刷新"></a>每一秒刷新</h1><p>PUT /users/_settings<br>&#123; “refresh_interval”: “1s” &#125;<br></code></pre><br> <h3>持久化变更</h3><br> 如果没有用fsync把数据从文件系统缓存刷（flush）到硬盘，我们不能保证数据在断电甚至是程序正常退出之后依然存在。为了保证Elasticsearch 的可靠性，需要确保数据变化被持久化到磁盘。在动态更新索引，我们说一次完整的提交会将段刷到磁盘，并写入一个包含所有段列表的提交点。Elasticsearch 在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片。<br> 即使通过每秒刷新(refresh）实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。但在两次提交之间发生变化的文档怎么办?我们也不希望丢失掉这些数据。Elasticsearch 增加了一个translog ，或者叫事务日志，在每一次对Elasticsearch进行操作时均进行了日志记录。<br> 整个流程如下:<br> 一、一个文档被索引之后，就会被添加到内存缓冲区，并且追加到了 translog<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/baeab48c8d6b87660ac4fb954e9c9731.png"><br> 二、刷新（refresh）使分片每秒被刷新（refresh）一次： </p>
<ul>
<li>这些在内存缓冲区的文档被写入到一个新的段中，且没有进行fsync操作。- 这个段被打开，使其可被搜索。- 内存缓冲区被清空。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/17be4247e6b23f31b1e589c70d61e817.png"> 
三、这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志。 
<img alt="" src="https://img-blog.csdnimg.cn/img_convert/4b5c4a3a3ffb4c84625bb283f6a67018.png"> 
四、每隔一段时间—例如translog变得越来越大，索引被刷新（flush）；一个新的translog被创建，并且一个全量提交被执行。 </li>
<li>所有在内存缓冲区的文档都被写入一个新的段。 -  缓冲区被清空。 -  一个提交点被写入硬盘。 -  文件系统缓存通过fsync被刷新（flush） 。 -  老的translog被删除。<br>translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当Elasticsearch启动的时候，它会从磁盘中使用最后一个提交点去恢复己知的段，并且会重放translog 中所有在最后一次提交后发生的变更操作。<br>translog 也被用来提供实时CRUD。当你试着通过ID查询、更新、删除一个文档，它会在尝试从相应的段中检索之前，首先检查 translog任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/11c7d2cc05244e669eb8402dd8049de9.png"> 
执行一个提交并且截断translog 的行为在 Elasticsearch被称作一次flush。分片每30分钟被自动刷新（flush)，或者在 translog 太大的时候也会刷新。 
你很少需要自己手动执行flush操作，通常情况下，自动刷新就足够了。这就是说，在重启节点或关闭索引之前执行 flush有益于你的索引。当Elasticsearch尝试恢复或重新打开一个索引，它需要重放translog中所有的操作，所以如果日志越短，恢复越快。 
translog 的目的是保证操作不会丢失，在文件被fsync到磁盘前，被写入的文件在重启之后就会丢失。默认translog是每5秒被fsync刷新到硬盘，或者在每次写请求完成之后执行（e.g. index, delete, update, bulk）。这个过程在主分片和复制分片都会发生。最终，基本上，这意味着在整个请求被fsync到主分片和复制分片的translog之前，你的客户端不会得到一个200 OK响应。 
在每次请求后都执行一个fsync会带来一些性能损失，尽管实践表明这种损失相对较小（特别是 bulk 导入，它在一次请求中平摊了大量文档的开销）。 
但是对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync还是比较有益的。比如，写入的数据被缓存到内存中，再每5秒执行一次 fsync 。如果你决定使用异步translog 的话，你需要保证在发生 crash 时，丢失掉 sync_interval时间段的数据也无所谓。请在决定前知晓这个特性。如果你不确定这个行为的后果，最好是使用默认的参数{“index.translog.durability”: “request”}来避免数据丢失。 
<h3>段合并</h3> 
由于自动刷新流程每秒会创建一个新的段，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。每一个段都会消耗文件句柄、内存和 cpu运行周期。更重要的是，每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。 
Elasticsearch通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。 
段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。 
启动段合并不需要你做任何事。进行索引和搜索时会自动进行。 
一、当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。 
二、合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。 
<img alt="" src="https://img-blog.csdnimg.cn/img_convert/c907ca35bd7c0393d46aec2c7038af19.png"> 
三、一旦合并结束，老的段被删除 </li>
<li>新的段被刷新(flush)到了磁盘。- 写入一个包含新段且排除旧的和较小的段的新提交点。- 新的段被打开用来搜索。老的段被删除。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/a00cc1c19652c47fcfb663aaf337a41b.png"> 
合并大的段需要消耗大量的 I/O 和 CPU 资源，如果任其发展会影响搜索性能。 Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然有足够的资源很好地执行。 </li>
</ul>
<h3 id="持久化变更"><a href="#持久化变更" class="headerlink" title="持久化变更"></a>持久化变更</h3><h3 id="12、文档分析"><a href="#12、文档分析" class="headerlink" title="12、文档分析"></a>12、文档分析</h3><blockquote>
<p> 分析包含下面的过程： </p>
</blockquote>
<ul>
<li>将一块文本分成适合于倒排索引的独立的词条。- 将这些词条统一化为标准格式以提高它们的“可搜索性”，或者recall。<br>分析器执行上面的工作。分析器实际上是将三个功能封装到了一个包里： </li>
<li>字符过滤器：首先，字符串按顺序通过每个 字符过滤器 。他们的任务是在分词前整理字符串。一个字符过滤器可以用来去掉 HTML，或者将 &amp; 转化成 and。- 分词器：其次，字符串被分词器分为单个的词条。一个简单的分词器遇到空格和标点的时候，可能会将文本拆分成词条。- Token 过滤器：最后，词条按顺序通过每个 token 过滤器 。这个过程可能会改变词条（例如，小写化Quick ），删除词条（例如， 像 a， and， the 等无用词），或者增加词条（例如，像jump和leap这种同义词）</li>
</ul>
<h3 id="13、内置分析器"><a href="#13、内置分析器" class="headerlink" title="13、内置分析器"></a>13、内置分析器</h3><blockquote>
<p> Elasticsearch还附带了可以直接使用的预包装的分析器。接下来我们会列出最重要的分析器。为了证明它们的差异，我们看看每个分析器会从下面的字符串得到哪些词条：<br> <pre><code class="language-java">"Set the shape to semi-transparent by calling set_trans(5)"<br></code></pre><br> <ul><li>标准分析器 标准分析器是Elasticsearch 默认使用的分析器。它是分析各种语言文本最常用的选择。它根据Unicode 联盟定义的单词边界划分文本。删除绝大部分标点。最后，将词条小写。它会产生： <pre><code class="language-java">set, the, shape, to, semi, transparent, by, calling, set_trans, 5<br></code></pre> </li><li>简单分析器 简单分析器在任何不是字母的地方分隔文本，将词条小写。它会产生： <pre><code class="language-java">set, the, shape, to, semi, transparent, by, calling, set, trans<br></code></pre> </li><li>空格分析器 空格分析器在空格的地方划分文本。它会产生: <pre><code class="language-java">Set, the, shape, to, semi-transparent, by, calling, set_trans(5)<br></code></pre> </li><li>语言分析器 特定语言分析器可用于很多语言。它们可以考虑指定语言的特点。例如，英语分析器附带了一组英语无用词（常用单词，例如and或者the ,它们对相关性没有多少影响），它们会被删除。由于理解英语语法的规则，这个分词器可以提取英语单词的词干。 英语分词器会产生下面的词条： <pre><code class="language-java">set, shape, semi, transpar, call, set_tran, 5<br></code></pre> 注意看transparent、calling和 set_trans已经变为词根格式。 </li></ul></p>
</blockquote>
<h3 id="14、分析器使用场景"><a href="#14、分析器使用场景" class="headerlink" title="14、分析器使用场景"></a>14、分析器使用场景</h3><blockquote>
<p> 当我们索引一个文档，它的全文域被分析成词条以用来创建倒排索引。但是，当我们在全文域搜索的时候，我们需要将查询字符串通过相同的分析过程，以保证我们搜索的词条格式与索引中的词条格式一致。<br> 全文查询，理解每个域是如何定义的，因此它们可以做正确的事： </p>
</blockquote>
<ul>
<li> 当你查询一个全文域时，会对查询字符串应用相同的分析器，以产生正确的搜索词条列表。 -  当你查询一个精确值域时，不会分析查询字符串，而是搜索你指定的精确值。 </li>
</ul>
<h3 id="15、测试分析器"><a href="#15、测试分析器" class="headerlink" title="15、测试分析器"></a>15、测试分析器</h3><blockquote>
<p> 有些时候很难理解分词的过程和实际被存储到索引中的词条，特别是你刚接触Elasticsearch。为了理解发生了什么，你可以使用analyze API来看文本是如何被分析的。在消息体里，指定分析器和要分析的文本。<br> <pre><code class="language-java">#GET <a href="http://localhost:9200/_analyze">http://localhost:9200/_analyze</a><br>&#123;<br>    "analyzer": "standard",<br>    "text": "Text to analyze"<br>&#125;<br></code></pre><br> 结果中每个元素代表一个单独的词条：<br> <pre><code class="language-java">&#123;<br>    "tokens": [<br>        &#123;<br>            "token": "text",<br>            "start_offset": 0,<br>            "end_offset": 4,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 1<br>        &#125;,<br>        &#123;<br>            "token": "to",<br>            "start_offset": 5,<br>            "end_offset": 7,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 2<br>        &#125;,<br>        &#123;<br>            "token": "analyze",<br>            "start_offset": 8,<br>            "end_offset": 15,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 3<br>        &#125;<br>    ]<br>&#125;<br></code></pre> </p>
</blockquote>
<ul>
<li>token是实际存储到索引中的词条。- start_ offset 和end_ offset指明字符在原始字符串中的位置。- position指明词条在原始文本中出现的位置。</li>
</ul>
<h3 id="16、指定分析器"><a href="#16、指定分析器" class="headerlink" title="16、指定分析器"></a>16、指定分析器</h3><blockquote>
<p> 当Elasticsearch在你的文档中检测到一个新的字符串域，它会自动设置其为一个全文字符串域，使用 标准 分析器对它进行分析。你不希望总是这样。可能你想使用一个不同的分析器，适用于你的数据使用的语言。有时候你想要一个字符串域就是一个字符串域，不使用分析，直接索引你传入的精确值，例如用户 ID 或者一个内部的状态域或标签。要做到这一点，我们必须手动指定这些域的映射。<br> （细粒度指定分析器）<br> <h3>IK分词器</h3><br> 首先通过 Postman 发送 GET 请求查询分词效果<br> <pre><code class="language-java"># GET <a href="http://localhost:9200/_analyze">http://localhost:9200/_analyze</a><br>&#123;<br>    "text":"测试单词"<br>&#125;<br></code></pre><br> ES 的默认分词器无法识别中文中测试、 单词这样的词汇，而是简单的将每个字拆完分为一个词。<br> <pre><code class="language-java">&#123;<br>    "tokens": [<br>        &#123;<br>            "token": "测",<br>            "start_offset": 0,<br>            "end_offset": 1,<br>            "type": "&lt;IDEOGRAPHIC&gt;",<br>            "position": 0<br>        &#125;,<br>        &#123;<br>            "token": "试",<br>            "start_offset": 1,<br>            "end_offset": 2,<br>            "type": "&lt;IDEOGRAPHIC&gt;",<br>            "position": 1<br>        &#125;,<br>        &#123;<br>            "token": "单",<br>            "start_offset": 2,<br>            "end_offset": 3,<br>            "type": "&lt;IDEOGRAPHIC&gt;",<br>            "position": 2<br>        &#125;,<br>        &#123;<br>            "token": "词",<br>            "start_offset": 3,<br>            "end_offset": 4,<br>            "type": "&lt;IDEOGRAPHIC&gt;",<br>            "position": 3<br>        &#125;<br>    ]<br>&#125;<br></code></pre><br> 这样的结果显然不符合我们的使用要求，所以我们需要下载 ES 对应版本的中文分词器。<br> 将解压后的后的文件夹放入 ES 根目录下的 plugins 目录下，重启 ES 即可使用。<br> 我们这次加入新的查询参数”analyzer”:“ik_max_word”。<br> <pre><code class="language-java"># GET <a href="http://localhost:9200/_analyze">http://localhost:9200/_analyze</a><br>&#123;<br>    "text":"测试单词",<br>    "analyzer":"ik_max_word"<br>&#125;<br></code></pre> </p>
</blockquote>
<ul>
<li>ik_max_word：会将文本做最细粒度的拆分。- ik_smart：会将文本做最粗粒度的拆分。<br>使用中文分词后的结果为： <pre><code class="language-java">&#123;
 "tokens": [
     &#123;
         "token": "测试", 
         "start_offset": 0, 
         "end_offset": 2, 
         "type": "CN_WORD", 
         "position": 0
     &#125;, 
     &#123;
         "token": "单词", 
         "start_offset": 2, 
         "end_offset": 4, 
         "type": "CN_WORD", 
         "position": 1
     &#125;
 ]
&#125;
</code></pre> 
ES 中也可以进行扩展词汇，首先查询 <pre><code class="language-java">#GET http://localhost:9200/_analyze</li>
</ul>
<p>&#123;<br>    “text”:”弗雷尔卓德”,<br>    “analyzer”:”ik_max_word”<br>&#125;<br></code></pre><br> 仅仅可以得到每个字的分词结果，我们需要做的就是使分词器识别到弗雷尔卓德也是一个词语。<br> <pre><code class="language-java">&#123;<br>    "tokens": [<br>        &#123;<br>            "token": "弗",<br>            "start_offset": 0,<br>            "end_offset": 1,<br>            "type": "CN_CHAR",<br>            "position": 0<br>        &#125;,<br>        &#123;<br>            "token": "雷",<br>            "start_offset": 1,<br>            "end_offset": 2,<br>            "type": "CN_CHAR",<br>            "position": 1<br>        &#125;,<br>        &#123;<br>            "token": "尔",<br>            "start_offset": 2,<br>            "end_offset": 3,<br>            "type": "CN_CHAR",<br>            "position": 2<br>        &#125;,<br>        &#123;<br>            "token": "卓",<br>            "start_offset": 3,<br>            "end_offset": 4,<br>            "type": "CN_CHAR",<br>            "position": 3<br>        &#125;,<br>        &#123;<br>            "token": "德",<br>            "start_offset": 4,<br>            "end_offset": 5,<br>            "type": "CN_CHAR",<br>            "position": 4<br>        &#125;<br>    ]<br>&#125;<br></code></pre> </p>
<ul>
<li>首先进入 ES 根目录中的 plugins 文件夹下的 ik 文件夹，进入 config 目录，创建 custom.dic文件，写入“弗雷尔卓德”。- 同时打开 IKAnalyzer.cfg.xml 文件，将新建的 custom.dic 配置其中。- 重启 ES 服务器 。<pre><code class="language-XML">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd"&gt;
&lt;properties&gt;
 &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt;
 &lt;!--用户可以在这里配置自己的扩展字典 --&gt;
 &lt;entry key="ext_dict"&gt;custom.dic&lt;/entry&gt;
  &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;
 &lt;entry key="ext_stopwords"&gt;&lt;/entry&gt;
 &lt;!--用户可以在这里配置远程扩展字典 --&gt;
 &lt;!-- &lt;entry key="remote_ext_dict"&gt;words_location&lt;/entry&gt; --&gt;
 &lt;!--用户可以在这里配置远程扩展停止词字典--&gt;
 &lt;!-- &lt;entry key="remote_ext_stopwords"&gt;words_location&lt;/entry&gt; --&gt;
&lt;/properties&gt;
</code></pre> 
扩展后再次查询 <pre><code class="language-java">#GET http://localhost:9200/_analyze</li>
</ul>
<p>&#123;<br>    “text”:”弗雷尔卓德”,<br>    “analyzer”:”ik_max_word”<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "tokens": [<br>        &#123;<br>            "token": "弗雷尔卓德",<br>            "start_offset": 0,<br>            "end_offset": 5,<br>            "type": "CN_WORD",<br>            "position": 0<br>        &#125;<br>    ]<br>&#125;<br></code></pre><br> <h3>自定义分析器</h3><br> 虽然Elasticsearch带有一些现成的分析器，然而在分析器上Elasticsearch真正的强大之处在于，你可以通过在一个适合你的特定数据的设置之中组合字符过滤器、分词器、词汇单元过滤器来创建自定义的分析器。在分析与分析器我们说过，一个分析器就是在一个包里面组合了三种函数的一个包装器，三种函数按照顺序被执行：<br> 1、字符过滤器<br> 字符过滤器用来整理一个尚未被分词的字符串。例如，如果我们的文本是HTML格式的，它会包含像<br> 或者</p>
<p>  这样的HTML标签，这些标签是我们不想索引的。我们可以使用html清除字符过滤器来移除掉所有的HTML标签，并且像把Á转换为相对应的Unicode字符Á 这样，转换HTML实体。一个分析器可能有0个或者多个字符过滤器。<br>  2、分词器<br>  一个分析器必须有一个唯一的分词器。分词器把字符串分解成单个词条或者词汇单元。标准分析器里使用的标准分词器把一个字符串根据单词边界分解成单个词条，并且移除掉大部分的标点符号，然而还有其他不同行为的分词器存在。<br>  例如，关键词分词器完整地输出接收到的同样的字符串，并不做任何分词。空格分词器只根据空格分割文本。正则分词器根据匹配正则表达式来分割文本。<br>  3、词单元过滤器<br>  经过分词，作为结果的词单元流会按照指定的顺序通过指定的词单元过滤器。词单元过滤器可以修改、添加或者移除词单元。我们已经提到过lowercase和stop词过滤器，但是在Elasticsearch 里面还有很多可供选择的词单元过滤器。词干过滤器把单词遏制为词干。ascii_folding过滤器移除变音符，把一个像”très”这样的词转换为“tres”。<br>  ngram和 edge_ngram词单元过滤器可以产生适合用于部分匹配或者自动补全的词单元。<br>  <strong>自定义分析器例子</strong><br>  接下来，我们看看如何创建自定义的分析器：<br>  <pre><code class="language-java">#PUT <a href="http://localhost:9200/my_index">http://localhost:9200/my_index</a></p>
<p>&#123;<br>    “settings”: &#123;<br>        “analysis”: &#123;<br>            “char_filter”: &#123;<br>                “&amp;_to_and”: &#123;<br>                    “type”: “mapping”,<br>                    “mappings”: [<br>                        “&amp;=&gt; and “<br>                    ]<br>                &#125;<br>            &#125;,<br>            “filter”: &#123;<br>                “my_stopwords”: &#123;<br>                    “type”: “stop”,<br>                    “stopwords”: [<br>                        “the”,<br>                        “a”<br>                    ]<br>                &#125;<br>            &#125;,<br>            “analyzer”: &#123;<br>                “my_analyzer”: &#123;<br>                    “type”: “custom”,<br>                    “char_filter”: [<br>                        “html_strip”,<br>                        “&amp;_to_and”<br>                    ],<br>                    “tokenizer”: “standard”,<br>                    “filter”: [<br>                        “lowercase”,<br>                        “my_stopwords”<br>                    ]<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br>  索引被创建以后，使用 analyze API 来 测试这个新的分析器：<br>  <pre><code class="language-java"># GET <a href="http://127.0.0.1:9200/my_index/_analyze">http://127.0.0.1:9200/my_index/_analyze</a><br>&#123;<br>    "text":"The quick &amp; brown fox",<br>    "analyzer": "my_analyzer"<br>&#125;<br></code></pre><br>  返回结果为：<br>  <pre><code class="language-java">&#123;<br>    "tokens": [<br>        &#123;<br>            "token": "quick",<br>            "start_offset": 4,<br>            "end_offset": 9,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 1<br>        &#125;,<br>        &#123;<br>            "token": "and",<br>            "start_offset": 10,<br>            "end_offset": 11,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 2<br>        &#125;,<br>        &#123;<br>            "token": "brown",<br>            "start_offset": 12,<br>            "end_offset": 17,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 3<br>        &#125;,<br>        &#123;<br>            "token": "fox",<br>            "start_offset": 18,<br>            "end_offset": 21,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 4<br>        &#125;<br>    ]<br>&#125;<br></code></pre> </p>
<h3 id="自定义分析器"><a href="#自定义分析器" class="headerlink" title="自定义分析器"></a>自定义分析器</h3>]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
  </entry>
</search>
