<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>Elasticsearch进阶之故障转移、水平扩容，倒排索引，分析器等 |  爱上口袋的天空</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/image1.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
      />
      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
       
 

      <!-- mermaid -->
      
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-Elasticsearch进阶之故障转移、水平扩容，倒排索引，分析器等"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Elasticsearch进阶之故障转移、水平扩容，倒排索引，分析器等
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/07/18/Elasticsearch%E8%BF%9B%E9%98%B6%E4%B9%8B%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E3%80%81%E6%B0%B4%E5%B9%B3%E6%89%A9%E5%AE%B9%EF%BC%8C%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%EF%BC%8C%E5%88%86%E6%9E%90%E5%99%A8%E7%AD%89/" class="article-date">
  <time datetime="2021-07-18T14:21:56.432Z" itemprop="datePublished">2021-07-18</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Elasticsearch/">Elasticsearch</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">11.2k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">40 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <p>title: Elasticsearch进阶之故障转移、水平扩容，倒排索引，分析器等<br>categories:</p>
<ul>
<li>elasticsearch</li>
</ul>
<p>—### 1、单节点集群</p>
<blockquote>
<p> 我们在包含一个空节点的集群内创建名为 users 的索引，为了演示目的，我们将分配 3个主分片和一份副本（每个主分片拥有一个副本分片）。<br> <pre><code class="language-java">#PUT <a target="_blank" rel="noopener" href="http://127.0.0.1:1001/users">http://127.0.0.1:1001/users</a><br>&#123;<br>    "settings" : &#123;<br>        "number_of_shards" : 3,<br>        "number_of_replicas" : 1<br>    &#125;<br>&#125;<br></code></pre><br> 集群现在是拥有一个索引的单节点集群。所有 3 个主分片都被分配在 node-1 。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/54ee6753be248cc7d345b38a0eae7d96.png"><br> 通过 elasticsearch-head 插件（一个Chrome插件）查看集群情况 。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/e8b15d0b243d486e91f478a220da63bf.png"> </p>
</blockquote>
<ul>
<li>集群健康值:yellow( 3 of 6 )：表示当前集群的全部主分片都正常运行，但是副本分片没有全部处在正常状态。3 个主分片正常<img alt="" src="https://img-blog.csdnimg.cn/img_convert/489b6de480112879a00067b793bde685.png">- 3 个副本分片都是 Unassigned，它们都没有被分配到任何节点。 在同 一个节点上既保存原始数据又保存副本是没有意义的，因为一旦失去了那个节点，我们也将丢失该节点 上的所有副本数据。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/3ce9a78d26ee762f0a7a8abf7817a58e.png">- 当前集群是正常运行的，但存在丢失数据的风险。</li>
</ul>
<h3 id="2、故障转移"><a href="#2、故障转移" class="headerlink" title="2、故障转移"></a>2、故障转移</h3><blockquote>
<p> 当集群中只有一个节点在运行时，意味着会有一个单点故障问题——没有冗余。 幸运的是，我们只需再启动一个节点即可防止数据丢失。当你在同一台机器上启动了第二个节点时，只要它和第一个节点有同样的 cluster.name 配置，它就会自动发现集群并加入到其中。但是在不同机器上启动节点的时候，为了加入到同一集群，你需要配置一个可连接到的单播主机列表。之所以配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上 运行的节点才会自动组成集群。<br> 如果启动了第二个节点，集群将会拥有两个节点 : 所有主分片和副本分片都已被分配 。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/bf76cb1bfbdf07555918d9055817ab44.png"><br> 通过 elasticsearch-head 插件查看集群情况<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/18db400822b83e727d6206f486b7b2ea.png"> </p>
</blockquote>
<ul>
<li>集群健康值:green( 3 of 6 )：表示所有 6 个分片（包括 3 个主分片和 3 个副本分片）都在正常运行。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/e485d8263a4aa3a94af0be951bd5a241.png">- 3 个主分片正常。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/e485d8263a4aa3a94af0be951bd5a241.png">- 第二个节点加入到集群后， 3 个副本分片将会分配到这个节点上——每 个主分片对应一个副本分片。这意味着当集群内任何一个节点出现问题时，我们的数据都完好无损。所 有新近被索引的文档都将会保存在主分片上，然后被并行的复制到对应的副本分片上。这就保证了我们 既可以从主分片又可以从副本分片上获得文档。</li>
</ul>
<h3 id="3、水平扩容"><a href="#3、水平扩容" class="headerlink" title="3、水平扩容"></a>3、水平扩容</h3><blockquote>
<p> 怎样为我们的正在增长中的应用程序按需扩容呢？当启动了第三个节点，我们的集群将会拥有三个节点的集群 : 为了分散负载而对分片进行重新分配 。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/d527e26aa2bccdf54b11410024eadc92.png"><br> 通过 elasticsearch-head 插件查看集群情况。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/6985fe14454c1269204478320d089bd7.png"> </p>
</blockquote>
<ul>
<li>集群健康值:green( 3 of 6 )：表示所有 6 个分片（包括 3 个主分片和 3 个副本分片）都在正常运行。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/9494419153adb44bedb395ac5d7bc488.png">- Node 1 和 Node 2 上各有一个分片被迁移到了新的 Node 3 节点，现在每个节点上都拥有 2 个分片， 而不是之前的 3 个。 这表示每个节点的硬件资源（CPU, RAM, I/O）将被更少的分片所共享，每个分片 的性能将会得到提升。<br>分片是一个功能完整的搜索引擎，它拥有使用一个节点上的所有资源的能力。 我们这个拥有 6 个分 片（3 个主分片和 3 个副本分片）的索引可以最大扩容到 6 个节点，每个节点上存在一个分片，并且每个 分片拥有所在节点的全部资源。 </li>
</ul>
<p> <strong>但是如果我们想要扩容超过 6 个节点怎么办呢？</strong><br> 主分片的数目在索引创建时就已经确定了下来。实际上，这个数目定义了这个索引能够 存储 的最大数据量。（实际大小取决于你的数据、硬件和使用场景。） 但是，读操作—— 搜索和返回数据——可以同时被主分片 或 副本分片所处理，所以当你拥有越多的副本分片 时，也将拥有越高的吞吐量。<br> 在运行中的集群上是可以动态调整副本分片数目的，我们可以按需伸缩集群。让我们把 副本数从默认的 1 增加到 2。<br> <pre><code class="language-java">#PUT <a target="_blank" rel="noopener" href="http://127.0.0.1:1001/users/_settings">http://127.0.0.1:1001/users/_settings</a></p>
<p>&#123;<br>    “number_of_replicas” : 2<br>&#125;<br></code></pre><br> users 索引现在拥有 9 个分片： 3 个主分片和 6 个副本分片。 这意味着我们可以将集群 扩容到 9 个节点，每个节点上一个分片。相比原来 3 个节点时，集群搜索性能可以提升 3 倍。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/97fd01e34e5d8df23d226c4fef157801.png"><br> 通过 elasticsearch-head 插件查看集群情况：<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/8bf9dbf0cec5b7875bf8aa9d17a9a67c.png"><br> 当然，如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每 个分片从节点上获得的资源会变少。 你需要增加更多的硬件资源来提升吞吐量。<br> 但是更多的副本分片数提高了数据冗余量：按照上面的节点配置，我们可以在失去 2 个节点 的情况下不丢失任何数据。 </p>
<h3 id="4、应对故障"><a href="#4、应对故障" class="headerlink" title="4、应对故障"></a>4、应对故障</h3><blockquote>
<p> 我们关闭第一个节点，这时集群的状态为:关闭了一个节点后的集群。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/44e841004be934e6bce08187ca3852bb.png"><br> 我们关闭的节点是一个主节点。而集群必须拥有一个主节点来保证正常工作，所以发生 的第一件事情就是选举一个新的主节点： Node 2 。在我们关闭 Node 1 的同时也失去了主 分片 1 和 2 ，并且在缺失主分片的时候索引也不能正常工作。 如果此时来检查集群的状况，我们看到的状态将会为 red ：不是所有主分片都在正常工作。<br> 幸运的是，在其它节点上存在着这两个主分片的完整副本， 所以新的主节点立即将这些分片在 Node 2 和 Node 3 上对应的副本分片提升为主分片， 此时集群的状态将会为yellow。这个提升主分片的过程是瞬间发生的，如同按下一个开关一般。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/e956bda7e0d005699e27760d4193d101.png"><br> <strong>为什么我们集群状态是 yellow 而不是 green 呢？</strong><br> 虽然我们拥有所有的三个主分片，但是同时设置了每个主分片需要对应 2 份副本分片，而此 时只存在一份副本分片。 所以集群不能为 green 的状态，不过我们不必过于担心：如果我 们同样关闭了 Node 2 ，我们的程序 依然 可以保持在不丢任何数据的情况下运行，因为 Node 3 为每一个分片都保留着一份副本。<br> 如果想回复原来的样子，要确保Node-1的配置文件有如下配置：<br> <pre><code class="language-bash">discovery.seed_hosts: ["localhost:9302", "localhost:9303"]<br></code></pre><br> 集群可以将缺失的副本分片再次进行分配，那么集群的状态也将恢复成之前的状态。 如果 Node 1 依然拥有着之前的分片，它将尝试去重用它们，同时仅从主分片复制发生了修改的数据文件。和之前的集群相比，只是 Master 节点切换了。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/37eea6a8dae7ba908312f2ebf0eced11.png"> </p>
</blockquote>
<h3 id="5、路由计算-amp-分片控制"><a href="#5、路由计算-amp-分片控制" class="headerlink" title="5、路由计算 &amp; 分片控制"></a>5、路由计算 &amp; 分片控制</h3><blockquote>
 <h3>路由计算：</h3> 
 当索引一个文档的时候，文档会被存储到一个主分片中。 Elasticsearch 如何知道一个 文档应该存放到哪个分片中呢？当我们创建文档时，它如何决定这个文档应当被存储在分片 1 还是分片 2 中呢？首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的： 
 <pre><code class="language-java">shard = hash(routing) % number_of_primary_shards
</code></pre> 
 routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。 
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/9c34e8603887c2bed475416e3b67cd9a.png"> 
 这就解释了为什么我们要在创建索引的时候就确定好主分片的数量并且永远不会改变这个数量:因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。 
 所有的文档API ( get . index . delete 、 bulk , update以及 mget ）都接受一个叫做routing 的路由参数，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路由参数可以用来确保所有相关的文档—一例如所有属于同一个用户的文档——都被存储到同一个分片中。 
 <h3>分片控制</h3> 
 我们可以发送请求到集群中的任一节点。每个节点都有能力处理任意请求。每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。在下面的例子中，如果将所有的请求发送到Node 1001，我们将其称为协调节点**coordinating node**。 
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/3940d6cdb197259368542b86384911a4.png"> 
 当发送请求的时候， 为了扩展负载，更好的做法是轮询集群中所有的节点。 
</blockquote>
<h3 id="分片控制"><a href="#分片控制" class="headerlink" title="分片控制"></a>分片控制</h3><h3 id="6、数据写流程"><a href="#6、数据写流程" class="headerlink" title="6、数据写流程"></a>6、数据写流程</h3><blockquote>
<p> 新建、索引和删除请求都是写操作， 必须在主分片上面完成之后才能被复制到相关的副本分片。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/418356a32516c222a8d366df021276c2.png"><br> 在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。有一些可选的<strong>请求参数</strong>允许您影响这个过程，可能以数据安全为代价提升性能。这些选项很少使用，因为 Elasticsearch 已经很快，但是为了完整起见， 请参考下文：<br> <strong>1、consistency：</strong> </p>
</blockquote>
<ul>
<li>      即一致性。在默认设置下，即使仅仅是在试图执行一个写操作之前，主分片都会要求必须要有规定数量quorum（或者换种说法，也即必须要有大多数）的分片副本处于活跃可用状态，才会去执行写操作（其中分片副本 可以是主分片或者副本分片）。这是为了避免在发生网络分区故障（network partition）的时候进行写操作，进而导致数据不一致。 规定数量即： int((primary + number_of_replicas) / 2 ) + 1- consistency 参数的值可以设为：   one ：只要主分片状态 ok 就允许执行写操作。   all：必须要主分片和所有副本分片的状态没问题才允许执行写操作。   quorum：默认值为quorum , 即大多数的分片副本状态没问题就允许执行写操作。- 注意，规定数量的计算公式中number_of_replicas指的是在索引设置中的设定副本分片数，而不是指当前处理活动状态的副本分片数。如果你的索引设置中指定了当前索引拥有3个副本分片，那规定数量的计算结果即：int((1 primary + 3 replicas) / 2) + 1 = 3，如果此时你只启动两个节点，那么处于活跃状态的分片副本数量就达不到规定数量，也因此您将无法索引和删除任何文档。</li>
</ul>
<p> <strong>2、timeout</strong> </p>
<ul>
<li>如果没有足够的副本分片会发生什么？Elasticsearch 会等待，希望更多的分片出现。默认情况下，它最多等待 1 分钟。 如果你需要，你可以使用timeout参数使它更早终止：100是100 毫秒，30s是30秒。<br>新索引默认有1个副本分片，这意味着为满足规定数量应该需要两个活动的分片副本。 但是，这些默认的设置会阻止我们在单一节点上做任何事情。为了避免这个问题，要求只有当number_of_replicas 大于1的时候，规定数量才会执行。 </li>
</ul>
<h3 id="7、数据读流程"><a href="#7、数据读流程" class="headerlink" title="7、数据读流程"></a>7、数据读流程</h3><blockquote>
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/7139df83ee6f7a59c5d3252d34cc8762.png"> 
 在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡。在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。 在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。 
</blockquote>
<h3 id="8、更新流程-amp-批量操作流程"><a href="#8、更新流程-amp-批量操作流程" class="headerlink" title="8、更新流程 &amp; 批量操作流程"></a>8、更新流程 &amp; 批量操作流程</h3><blockquote>
 <h3>更新流程：</h3> 
 部分更新一个文档结合了先前说明的读取和写入流程： 
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/ca41993144aee98311671278725437cd.png"> 
 部分更新一个文档的步骤如下： 
</blockquote>
<ul>
<li>客户端向Node 1发送更新请求。- 它将请求转发到主分片所在的Node 3 。- Node 3从主分片检索文档，修改_source字段中的JSON，并且尝试重新索引主分片的文档。如果文档已经被另一个进程修改,它会重试步骤3 ,超过retry_on_conflict次后放弃。- 如果 Node 3成功地更新文档，它将新版本的文档并行转发到Node 1和 Node 2上的副本分片，重新建立索引。一旦所有副本分片都返回成功，Node 3向协调节点也返回成功，协调节点向客户端返回成功。<br>当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。请记住，这些更改将会异步转发到副本分片，并且不能保证它们以发送它们相同的顺序到达。 如果 Elasticsearch 仅转发更改请求，则可能以错误的顺序应用更改，导致得到损坏的文档。 <h3>批量操作流程：</h3> </li>
</ul>
<p> <strong>mget和 bulk API的模式类似于单文档模式。</strong>区别在于协调节点知道每个文档存在于哪个分片中。它将整个多文档请求分解成每个分片的多文档请求，并且将这些请求并行转发到每个参与节点。<br> 协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/b90ea9c79138d8361ca339cff205fdb0.png"><br> <strong>用单个 mget 请求取回多个文档所需的步骤顺序:</strong> </p>
<ul>
<li>客户端向 Node 1 发送 mget 请求。- Node 1为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复，Node 1 构建响应并将其返回给客户端。<br>可以对docs数组中每个文档设置routing参数。<br>bulk API， 允许在单个批量请求中执行多个创建、索引、删除和更新请求。 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/83499315a7b8ab81471a88f3e142f0a8.png"> </li>
</ul>
<p> <strong>bulk API 按如下步骤顺序执行：</strong> </p>
<ul>
<li>客户端向Node 1 发送 bulk请求。- Node 1为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。- 主分片一个接一个按顺序执行每个操作。当每个操作成功时,主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。</li>
</ul>
<h3 id="批量操作流程："><a href="#批量操作流程：" class="headerlink" title="批量操作流程："></a>批量操作流程：</h3><h3 id="9、倒排索引"><a href="#9、倒排索引" class="headerlink" title="9、倒排索引"></a>9、倒排索引</h3><blockquote>
<p> 分片是Elasticsearch最小的工作单元。但是究竟什么是一个分片，它是如何工作的？<br> 传统的数据库每个字段存储单个值，但这对全文检索并不够。文本字段中的每个单词需要被搜索，对数据库意味着需要单个字段有索引多值的能力。最好的支持是一个字段多个值需求的数据结构是<strong>倒排索引</strong>。<br> <h3>倒排索引原理</h3><br> Elasticsearch使用一种称为倒排索引的结构，它适用于快速的全文搜索。<br> 见其名，知其意，有倒排索引，肯定会对应有正向索引。正向索引（forward index），反向索引（inverted index）更熟悉的名字是<strong>倒排索引</strong>。<br> 所谓的<strong>正向索引</strong>，就是搜索引擎会将待搜索的文件都对应一个文件ID，搜索时将这个ID和搜索关键字进行对应，形成K-V对，然后对关键字进行统计计数。（统计？？下文有解释）<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/cba02cc6d7c5f054dfe5d58fafac9a6a.png"><br> 但是互联网上收录在搜索引擎中的文档的数目是个天文数字，这样的索引结构根本无法满足实时返回排名结果的要求。所以，搜索引擎会将正向索引重新构建为倒排索引，即把文件ID对应到关键词的映射转换为关键词到文件ID的映射，每个关键词都对应着一系列的文件，这些文件中都出现这个关键词。<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/a1f52e96e0ac218b5024d708202afba4.png"><br> <h3>倒排索引的例子</h3><br> 一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。例如，假设我们有两个文档，每个文档的content域包含如下内容： </p>
</blockquote>
<ul>
<li>The quick brown fox jumped over the lazy dog- Quick brown foxes leap over lazy dogs in summer<br>为了创建倒排索引，我们首先将每个文档的content域拆分成单独的词（我们称它为词条或tokens )，创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。结果如下所示： <img alt="" src="https://img-blog.csdnimg.cn/img_convert/3cc642e9bae776c3e617f9d117d41e21.png"> 
现在，如果我们想搜索 `quick` `brown` ，我们只需要查找包含每个词条的文档： 
<img alt="" src="https://img-blog.csdnimg.cn/img_convert/f26aaa01e011edfa68736956b2f1ddea.png"> 
两个文档都匹配，但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单相似性算法，那么我们可以说，对于我们查询的相关性来讲，第一个文档比第二个文档更佳。 
但是，我们目前的倒排索引有一些问题： </li>
<li><code>Quick</code>和<code>quick</code>以独立的词条出现，然而用户可能认为它们是相同的词。 -  <code>fox</code>和<code>foxes</code>非常相似，就像<code>dog</code>和<code>dogs</code>；他们有相同的词根。 -  <code>jumped</code>和<code>leap</code>，尽管没有相同的词根，但他们的意思很相近。他们是同义词。<br>使用前面的索引搜索+Quick +fox不会得到任何匹配文档。(记住，＋前缀表明这个词必须存在）。<br>只有同时出现Quick和fox 的文档才满足这个查询条件，但是第一个文档包含quick fox ，第二个文档包含Quick foxes 。<br>我们的用户可以合理的期望两个文档与查询匹配。我们可以做的更好。<br>如果我们将词条规范为标准模式，那么我们可以找到与用户搜索的词条不完全一致，但具有足够相关性的文档。例如： </li>
<li><code>Quick</code>可以小写化为<code>quick</code>。- <code>foxes</code>可以词干提取变为词根的格式为<code>fox</code>。类似的，<code>dogs</code>可以为提取为<code>dog</code>。- <code>jumped</code>和<code>leap</code>是同义词，可以索引为相同的单词<code>jump</code> 。<br>现在索引看上去像这样： <img alt="" src="https://img-blog.csdnimg.cn/img_convert/19813d1918c89461303377444cf85c8c.png"> 
这还远远不够。我们搜索+Quick +fox 仍然会失败，因为在我们的索引中，已经没有Quick了。但是，如果我们对搜索的字符串使用与content域相同的标准化规则，会变成查询+quick +fox，这样两个文档都会匹配！分词和标准化的过程称为分析，这非常重要。你只能搜索在索引中出现的词条，所以索引文本和查询字符串必须标准化为相同的格式。 </li>
</ul>
<h3 id="倒排索引的例子"><a href="#倒排索引的例子" class="headerlink" title="倒排索引的例子"></a>倒排索引的例子</h3><h3 id="10、文档搜索"><a href="#10、文档搜索" class="headerlink" title="10、文档搜索"></a>10、文档搜索</h3><blockquote>
 <h3>不可改变的倒排索引</h3> 
 早期的全文检索会为整个文档集合建立一个很大的倒排索引并将其写入到磁盘。 一旦新的索引就绪，旧的就会被其替换，这样最近的变化便可以被检索到。 
 倒排索引被写入磁盘后是不可改变的：它永远不会修改。 
</blockquote>
<ul>
<li>不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。- 一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。- 其它缓存(像filter缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。- 写入单个大的倒排索引允许数据被压缩，减少磁盘IO和需要被缓存到内存的索引的使用量<br>当然，一个不变的索引也有不好的地方。主要事实是它是不可变的! 你不能修改它。如果你需要让一个新的文档可被搜索，你需要重建整个索引。这要么对一个索引所能包含的数据量造成了很大的限制，要么对索引可被更新的频率造成了很大的限制。 <h3>动态更新索引</h3> 
如何在保留不变性的前提下实现倒排索引的更新？ 
答案是：用更多的索引。通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到,从最早的开始查询完后再对结果进行合并。 
Elasticsearch基于Lucene，这个java库引入了按段搜索的概念。每一段本身都是一个倒排索引，但索引在 Lucene 中除表示所有段的集合外，还增加了提交点的概念—一个列出了所有已知段的文件。 
<img alt="" src="https://img-blog.csdnimg.cn/img_convert/9ee1adbb2d55e710257e01b812a6d8cf.png"> 
按段搜索会以如下流程执行： 
一、新文档被收集到内存索引缓存。 
<img alt="" src="https://img-blog.csdnimg.cn/img_convert/9d499fde966ee9825fa5a424d8357489.png"> 
二、不时地, 缓存被提交。 </li>
<li>一个新的段，一个追加的倒排索引，被写入磁盘。- 一个新的包含新段名字的提交点被写入磁盘。- 磁盘进行同步，所有在文件系统缓存中等待的写入都刷新到磁盘，以确保它们被写入物理文件<br>三、新的段被开启，让它包含的文档可见以被搜索。<br>四、内存缓存被清空，等待接收新的文档。 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/f74828ff58cc4635a97e88706a221e50.png"> 
当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。这种方式可以用相对较低的成本将新文档添加到索引。 
段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。取而代之的是，每个提交点会包含一个.del 文件，文件中会列出这些被删除文档的段信息。 
当一个**文档被“删除”**时，它实际上只是在 .del 文件中被标记删除。一个被标记删除的文档仍然可以被查询匹配到，但它会在最终结果被返回前从结果集中移除。 
文档更新也是类似的操作方式:当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。 </li>
</ul>
<h3 id="动态更新索引"><a href="#动态更新索引" class="headerlink" title="动态更新索引"></a>动态更新索引</h3><h3 id="11、文档刷新-amp-文档刷写-amp-文档合并"><a href="#11、文档刷新-amp-文档刷写-amp-文档合并" class="headerlink" title="11、文档刷新 &amp; 文档刷写 &amp; 文档合并"></a>11、文档刷新 &amp; 文档刷写 &amp; 文档合并</h3><blockquote>
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/b3b31c1e592d5aa794e7c9fcb259c924.png"> 
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/521c25f0f16247240234d1b8eb3c5f25.png"> 
 <h3>近实时搜索</h3> 
 随着按段（per-segment）搜索的发展，一个新的文档从索引到可被搜索的延迟显著降低了。新文档在几分钟之内即可被检索，但这样还是不够快。磁盘在这里成为了瓶颈。提交（Commiting）一个新的段到磁盘需要一个fsync来确保段被物理性地写入磁盘，这样在断电的时候就不会丢失数据。但是fsync操作代价很大；如果每次索引一个文档都去执行一次的话会造成很大的性能问题。 
 我们需要的是一个更轻量的方式来使一个文档可被搜索，这意味着fsync要从整个过程中被移除。在Elasticsearch和磁盘之间是文件系统缓存。像之前描述的一样，在内存索引缓冲区中的文档会被写入到一个新的段中。但是这里新段会被先写入到文件系统缓存—这一步代价会比较低，稍后再被刷新到磁盘—这一步代价比较高。不过只要文件已经在缓存中，就可以像其它文件一样被打开和读取了。 
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/a679d4f5f4bfa6913a53316251beef2a.png"> 
 Lucene允许新段被写入和打开，使其包含的文档在未进行一次完整提交时便对搜索可见。这种方式比进行一次提交代价要小得多，并且在不影响性能的前提下可以被频繁地执行。 
 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/673d3a77e254fa3a5a6f5293ffb125ab.png"> 
 在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做refresh。默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch是近实时搜索：文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。 
 这些行为可能会对新用户造成困惑：他们索引了一个文档然后尝试搜索它，但却没有搜到。这个问题的解决办法是用refresh API执行一次手动刷新：/usersl_refresh 
 尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候，手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。相反，你的应用需要意识到Elasticsearch 的近实时的性质，并接受它的不足。 
 并不是所有的情况都需要每秒刷新。可能你正在使用Elasticsearch索引大量的日志文件，你可能想优化索引速度而不是近实时搜索，可以通过设置refresh_interval ，降低每个索引的刷新频率 
 <pre><code class="language-java">&#123;
    "settings": &#123;
        "refresh_interval": "30s"
    &#125;
&#125;
</code></pre> 
 refresh_interval可以在既存索引上进行动态更新。在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来。 
 <pre><code class="language-java"># 关闭自动刷新
PUT /users/_settings
&#123; "refresh_interval": -1 &#125;
</blockquote>
<h1 id="每一秒刷新"><a href="#每一秒刷新" class="headerlink" title="每一秒刷新"></a>每一秒刷新</h1><p>PUT /users/_settings<br>&#123; “refresh_interval”: “1s” &#125;<br></code></pre><br> <h3>持久化变更</h3><br> 如果没有用fsync把数据从文件系统缓存刷（flush）到硬盘，我们不能保证数据在断电甚至是程序正常退出之后依然存在。为了保证Elasticsearch 的可靠性，需要确保数据变化被持久化到磁盘。在动态更新索引，我们说一次完整的提交会将段刷到磁盘，并写入一个包含所有段列表的提交点。Elasticsearch 在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片。<br> 即使通过每秒刷新(refresh）实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。但在两次提交之间发生变化的文档怎么办?我们也不希望丢失掉这些数据。Elasticsearch 增加了一个translog ，或者叫事务日志，在每一次对Elasticsearch进行操作时均进行了日志记录。<br> 整个流程如下:<br> 一、一个文档被索引之后，就会被添加到内存缓冲区，并且追加到了 translog<br> <img alt="" src="https://img-blog.csdnimg.cn/img_convert/baeab48c8d6b87660ac4fb954e9c9731.png"><br> 二、刷新（refresh）使分片每秒被刷新（refresh）一次： </p>
<ul>
<li>这些在内存缓冲区的文档被写入到一个新的段中，且没有进行fsync操作。- 这个段被打开，使其可被搜索。- 内存缓冲区被清空。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/17be4247e6b23f31b1e589c70d61e817.png"> 
三、这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志。 
<img alt="" src="https://img-blog.csdnimg.cn/img_convert/4b5c4a3a3ffb4c84625bb283f6a67018.png"> 
四、每隔一段时间—例如translog变得越来越大，索引被刷新（flush）；一个新的translog被创建，并且一个全量提交被执行。 </li>
<li>所有在内存缓冲区的文档都被写入一个新的段。 -  缓冲区被清空。 -  一个提交点被写入硬盘。 -  文件系统缓存通过fsync被刷新（flush） 。 -  老的translog被删除。<br>translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当Elasticsearch启动的时候，它会从磁盘中使用最后一个提交点去恢复己知的段，并且会重放translog 中所有在最后一次提交后发生的变更操作。<br>translog 也被用来提供实时CRUD。当你试着通过ID查询、更新、删除一个文档，它会在尝试从相应的段中检索之前，首先检查 translog任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。 <img alt="" src="https://img-blog.csdnimg.cn/img_convert/11c7d2cc05244e669eb8402dd8049de9.png"> 
执行一个提交并且截断translog 的行为在 Elasticsearch被称作一次flush。分片每30分钟被自动刷新（flush)，或者在 translog 太大的时候也会刷新。 
你很少需要自己手动执行flush操作，通常情况下，自动刷新就足够了。这就是说，在重启节点或关闭索引之前执行 flush有益于你的索引。当Elasticsearch尝试恢复或重新打开一个索引，它需要重放translog中所有的操作，所以如果日志越短，恢复越快。 
translog 的目的是保证操作不会丢失，在文件被fsync到磁盘前，被写入的文件在重启之后就会丢失。默认translog是每5秒被fsync刷新到硬盘，或者在每次写请求完成之后执行（e.g. index, delete, update, bulk）。这个过程在主分片和复制分片都会发生。最终，基本上，这意味着在整个请求被fsync到主分片和复制分片的translog之前，你的客户端不会得到一个200 OK响应。 
在每次请求后都执行一个fsync会带来一些性能损失，尽管实践表明这种损失相对较小（特别是 bulk 导入，它在一次请求中平摊了大量文档的开销）。 
但是对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync还是比较有益的。比如，写入的数据被缓存到内存中，再每5秒执行一次 fsync 。如果你决定使用异步translog 的话，你需要保证在发生 crash 时，丢失掉 sync_interval时间段的数据也无所谓。请在决定前知晓这个特性。如果你不确定这个行为的后果，最好是使用默认的参数{“index.translog.durability”: “request”}来避免数据丢失。 
<h3>段合并</h3> 
由于自动刷新流程每秒会创建一个新的段，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。每一个段都会消耗文件句柄、内存和 cpu运行周期。更重要的是，每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。 
Elasticsearch通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。 
段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。 
启动段合并不需要你做任何事。进行索引和搜索时会自动进行。 
一、当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。 
二、合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。 
<img alt="" src="https://img-blog.csdnimg.cn/img_convert/c907ca35bd7c0393d46aec2c7038af19.png"> 
三、一旦合并结束，老的段被删除 </li>
<li>新的段被刷新(flush)到了磁盘。- 写入一个包含新段且排除旧的和较小的段的新提交点。- 新的段被打开用来搜索。老的段被删除。<img alt="" src="https://img-blog.csdnimg.cn/img_convert/a00cc1c19652c47fcfb663aaf337a41b.png"> 
合并大的段需要消耗大量的 I/O 和 CPU 资源，如果任其发展会影响搜索性能。 Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然有足够的资源很好地执行。 </li>
</ul>
<h3 id="持久化变更"><a href="#持久化变更" class="headerlink" title="持久化变更"></a>持久化变更</h3><h3 id="12、文档分析"><a href="#12、文档分析" class="headerlink" title="12、文档分析"></a>12、文档分析</h3><blockquote>
<p> 分析包含下面的过程： </p>
</blockquote>
<ul>
<li>将一块文本分成适合于倒排索引的独立的词条。- 将这些词条统一化为标准格式以提高它们的“可搜索性”，或者recall。<br>分析器执行上面的工作。分析器实际上是将三个功能封装到了一个包里： </li>
<li>字符过滤器：首先，字符串按顺序通过每个 字符过滤器 。他们的任务是在分词前整理字符串。一个字符过滤器可以用来去掉 HTML，或者将 &amp; 转化成 and。- 分词器：其次，字符串被分词器分为单个的词条。一个简单的分词器遇到空格和标点的时候，可能会将文本拆分成词条。- Token 过滤器：最后，词条按顺序通过每个 token 过滤器 。这个过程可能会改变词条（例如，小写化Quick ），删除词条（例如， 像 a， and， the 等无用词），或者增加词条（例如，像jump和leap这种同义词）</li>
</ul>
<h3 id="13、内置分析器"><a href="#13、内置分析器" class="headerlink" title="13、内置分析器"></a>13、内置分析器</h3><blockquote>
<p> Elasticsearch还附带了可以直接使用的预包装的分析器。接下来我们会列出最重要的分析器。为了证明它们的差异，我们看看每个分析器会从下面的字符串得到哪些词条：<br> <pre><code class="language-java">"Set the shape to semi-transparent by calling set_trans(5)"<br></code></pre><br> <ul><li>标准分析器 标准分析器是Elasticsearch 默认使用的分析器。它是分析各种语言文本最常用的选择。它根据Unicode 联盟定义的单词边界划分文本。删除绝大部分标点。最后，将词条小写。它会产生： <pre><code class="language-java">set, the, shape, to, semi, transparent, by, calling, set_trans, 5<br></code></pre> </li><li>简单分析器 简单分析器在任何不是字母的地方分隔文本，将词条小写。它会产生： <pre><code class="language-java">set, the, shape, to, semi, transparent, by, calling, set, trans<br></code></pre> </li><li>空格分析器 空格分析器在空格的地方划分文本。它会产生: <pre><code class="language-java">Set, the, shape, to, semi-transparent, by, calling, set_trans(5)<br></code></pre> </li><li>语言分析器 特定语言分析器可用于很多语言。它们可以考虑指定语言的特点。例如，英语分析器附带了一组英语无用词（常用单词，例如and或者the ,它们对相关性没有多少影响），它们会被删除。由于理解英语语法的规则，这个分词器可以提取英语单词的词干。 英语分词器会产生下面的词条： <pre><code class="language-java">set, shape, semi, transpar, call, set_tran, 5<br></code></pre> 注意看transparent、calling和 set_trans已经变为词根格式。 </li></ul></p>
</blockquote>
<h3 id="14、分析器使用场景"><a href="#14、分析器使用场景" class="headerlink" title="14、分析器使用场景"></a>14、分析器使用场景</h3><blockquote>
<p> 当我们索引一个文档，它的全文域被分析成词条以用来创建倒排索引。但是，当我们在全文域搜索的时候，我们需要将查询字符串通过相同的分析过程，以保证我们搜索的词条格式与索引中的词条格式一致。<br> 全文查询，理解每个域是如何定义的，因此它们可以做正确的事： </p>
</blockquote>
<ul>
<li> 当你查询一个全文域时，会对查询字符串应用相同的分析器，以产生正确的搜索词条列表。 -  当你查询一个精确值域时，不会分析查询字符串，而是搜索你指定的精确值。 </li>
</ul>
<h3 id="15、测试分析器"><a href="#15、测试分析器" class="headerlink" title="15、测试分析器"></a>15、测试分析器</h3><blockquote>
<p> 有些时候很难理解分词的过程和实际被存储到索引中的词条，特别是你刚接触Elasticsearch。为了理解发生了什么，你可以使用analyze API来看文本是如何被分析的。在消息体里，指定分析器和要分析的文本。<br> <pre><code class="language-java">#GET <a target="_blank" rel="noopener" href="http://localhost:9200/_analyze">http://localhost:9200/_analyze</a><br>&#123;<br>    "analyzer": "standard",<br>    "text": "Text to analyze"<br>&#125;<br></code></pre><br> 结果中每个元素代表一个单独的词条：<br> <pre><code class="language-java">&#123;<br>    "tokens": [<br>        &#123;<br>            "token": "text",<br>            "start_offset": 0,<br>            "end_offset": 4,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 1<br>        &#125;,<br>        &#123;<br>            "token": "to",<br>            "start_offset": 5,<br>            "end_offset": 7,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 2<br>        &#125;,<br>        &#123;<br>            "token": "analyze",<br>            "start_offset": 8,<br>            "end_offset": 15,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 3<br>        &#125;<br>    ]<br>&#125;<br></code></pre> </p>
</blockquote>
<ul>
<li>token是实际存储到索引中的词条。- start_ offset 和end_ offset指明字符在原始字符串中的位置。- position指明词条在原始文本中出现的位置。</li>
</ul>
<h3 id="16、指定分析器"><a href="#16、指定分析器" class="headerlink" title="16、指定分析器"></a>16、指定分析器</h3><blockquote>
<p> 当Elasticsearch在你的文档中检测到一个新的字符串域，它会自动设置其为一个全文字符串域，使用 标准 分析器对它进行分析。你不希望总是这样。可能你想使用一个不同的分析器，适用于你的数据使用的语言。有时候你想要一个字符串域就是一个字符串域，不使用分析，直接索引你传入的精确值，例如用户 ID 或者一个内部的状态域或标签。要做到这一点，我们必须手动指定这些域的映射。<br> （细粒度指定分析器）<br> <h3>IK分词器</h3><br> 首先通过 Postman 发送 GET 请求查询分词效果<br> <pre><code class="language-java"># GET <a target="_blank" rel="noopener" href="http://localhost:9200/_analyze">http://localhost:9200/_analyze</a><br>&#123;<br>    "text":"测试单词"<br>&#125;<br></code></pre><br> ES 的默认分词器无法识别中文中测试、 单词这样的词汇，而是简单的将每个字拆完分为一个词。<br> <pre><code class="language-java">&#123;<br>    "tokens": [<br>        &#123;<br>            "token": "测",<br>            "start_offset": 0,<br>            "end_offset": 1,<br>            "type": "&lt;IDEOGRAPHIC&gt;",<br>            "position": 0<br>        &#125;,<br>        &#123;<br>            "token": "试",<br>            "start_offset": 1,<br>            "end_offset": 2,<br>            "type": "&lt;IDEOGRAPHIC&gt;",<br>            "position": 1<br>        &#125;,<br>        &#123;<br>            "token": "单",<br>            "start_offset": 2,<br>            "end_offset": 3,<br>            "type": "&lt;IDEOGRAPHIC&gt;",<br>            "position": 2<br>        &#125;,<br>        &#123;<br>            "token": "词",<br>            "start_offset": 3,<br>            "end_offset": 4,<br>            "type": "&lt;IDEOGRAPHIC&gt;",<br>            "position": 3<br>        &#125;<br>    ]<br>&#125;<br></code></pre><br> 这样的结果显然不符合我们的使用要求，所以我们需要下载 ES 对应版本的中文分词器。<br> 将解压后的后的文件夹放入 ES 根目录下的 plugins 目录下，重启 ES 即可使用。<br> 我们这次加入新的查询参数”analyzer”:“ik_max_word”。<br> <pre><code class="language-java"># GET <a target="_blank" rel="noopener" href="http://localhost:9200/_analyze">http://localhost:9200/_analyze</a><br>&#123;<br>    "text":"测试单词",<br>    "analyzer":"ik_max_word"<br>&#125;<br></code></pre> </p>
</blockquote>
<ul>
<li>ik_max_word：会将文本做最细粒度的拆分。- ik_smart：会将文本做最粗粒度的拆分。<br>使用中文分词后的结果为： <pre><code class="language-java">&#123;
 "tokens": [
     &#123;
         "token": "测试", 
         "start_offset": 0, 
         "end_offset": 2, 
         "type": "CN_WORD", 
         "position": 0
     &#125;, 
     &#123;
         "token": "单词", 
         "start_offset": 2, 
         "end_offset": 4, 
         "type": "CN_WORD", 
         "position": 1
     &#125;
 ]
&#125;
</code></pre> 
ES 中也可以进行扩展词汇，首先查询 <pre><code class="language-java">#GET http://localhost:9200/_analyze</li>
</ul>
<p>&#123;<br>    “text”:”弗雷尔卓德”,<br>    “analyzer”:”ik_max_word”<br>&#125;<br></code></pre><br> 仅仅可以得到每个字的分词结果，我们需要做的就是使分词器识别到弗雷尔卓德也是一个词语。<br> <pre><code class="language-java">&#123;<br>    "tokens": [<br>        &#123;<br>            "token": "弗",<br>            "start_offset": 0,<br>            "end_offset": 1,<br>            "type": "CN_CHAR",<br>            "position": 0<br>        &#125;,<br>        &#123;<br>            "token": "雷",<br>            "start_offset": 1,<br>            "end_offset": 2,<br>            "type": "CN_CHAR",<br>            "position": 1<br>        &#125;,<br>        &#123;<br>            "token": "尔",<br>            "start_offset": 2,<br>            "end_offset": 3,<br>            "type": "CN_CHAR",<br>            "position": 2<br>        &#125;,<br>        &#123;<br>            "token": "卓",<br>            "start_offset": 3,<br>            "end_offset": 4,<br>            "type": "CN_CHAR",<br>            "position": 3<br>        &#125;,<br>        &#123;<br>            "token": "德",<br>            "start_offset": 4,<br>            "end_offset": 5,<br>            "type": "CN_CHAR",<br>            "position": 4<br>        &#125;<br>    ]<br>&#125;<br></code></pre> </p>
<ul>
<li>首先进入 ES 根目录中的 plugins 文件夹下的 ik 文件夹，进入 config 目录，创建 custom.dic文件，写入“弗雷尔卓德”。- 同时打开 IKAnalyzer.cfg.xml 文件，将新建的 custom.dic 配置其中。- 重启 ES 服务器 。<pre><code class="language-XML">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd"&gt;
&lt;properties&gt;
 &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt;
 &lt;!--用户可以在这里配置自己的扩展字典 --&gt;
 &lt;entry key="ext_dict"&gt;custom.dic&lt;/entry&gt;
  &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;
 &lt;entry key="ext_stopwords"&gt;&lt;/entry&gt;
 &lt;!--用户可以在这里配置远程扩展字典 --&gt;
 &lt;!-- &lt;entry key="remote_ext_dict"&gt;words_location&lt;/entry&gt; --&gt;
 &lt;!--用户可以在这里配置远程扩展停止词字典--&gt;
 &lt;!-- &lt;entry key="remote_ext_stopwords"&gt;words_location&lt;/entry&gt; --&gt;
&lt;/properties&gt;
</code></pre> 
扩展后再次查询 <pre><code class="language-java">#GET http://localhost:9200/_analyze</li>
</ul>
<p>&#123;<br>    “text”:”弗雷尔卓德”,<br>    “analyzer”:”ik_max_word”<br>&#125;<br></code></pre><br> 返回结果如下：<br> <pre><code class="language-java">&#123;<br>    "tokens": [<br>        &#123;<br>            "token": "弗雷尔卓德",<br>            "start_offset": 0,<br>            "end_offset": 5,<br>            "type": "CN_WORD",<br>            "position": 0<br>        &#125;<br>    ]<br>&#125;<br></code></pre><br> <h3>自定义分析器</h3><br> 虽然Elasticsearch带有一些现成的分析器，然而在分析器上Elasticsearch真正的强大之处在于，你可以通过在一个适合你的特定数据的设置之中组合字符过滤器、分词器、词汇单元过滤器来创建自定义的分析器。在分析与分析器我们说过，一个分析器就是在一个包里面组合了三种函数的一个包装器，三种函数按照顺序被执行：<br> 1、字符过滤器<br> 字符过滤器用来整理一个尚未被分词的字符串。例如，如果我们的文本是HTML格式的，它会包含像<br> 或者</p>
<p>  这样的HTML标签，这些标签是我们不想索引的。我们可以使用html清除字符过滤器来移除掉所有的HTML标签，并且像把Á转换为相对应的Unicode字符Á 这样，转换HTML实体。一个分析器可能有0个或者多个字符过滤器。<br>  2、分词器<br>  一个分析器必须有一个唯一的分词器。分词器把字符串分解成单个词条或者词汇单元。标准分析器里使用的标准分词器把一个字符串根据单词边界分解成单个词条，并且移除掉大部分的标点符号，然而还有其他不同行为的分词器存在。<br>  例如，关键词分词器完整地输出接收到的同样的字符串，并不做任何分词。空格分词器只根据空格分割文本。正则分词器根据匹配正则表达式来分割文本。<br>  3、词单元过滤器<br>  经过分词，作为结果的词单元流会按照指定的顺序通过指定的词单元过滤器。词单元过滤器可以修改、添加或者移除词单元。我们已经提到过lowercase和stop词过滤器，但是在Elasticsearch 里面还有很多可供选择的词单元过滤器。词干过滤器把单词遏制为词干。ascii_folding过滤器移除变音符，把一个像”très”这样的词转换为“tres”。<br>  ngram和 edge_ngram词单元过滤器可以产生适合用于部分匹配或者自动补全的词单元。<br>  <strong>自定义分析器例子</strong><br>  接下来，我们看看如何创建自定义的分析器：<br>  <pre><code class="language-java">#PUT <a target="_blank" rel="noopener" href="http://localhost:9200/my_index">http://localhost:9200/my_index</a></p>
<p>&#123;<br>    “settings”: &#123;<br>        “analysis”: &#123;<br>            “char_filter”: &#123;<br>                “&amp;_to_and”: &#123;<br>                    “type”: “mapping”,<br>                    “mappings”: [<br>                        “&amp;=&gt; and “<br>                    ]<br>                &#125;<br>            &#125;,<br>            “filter”: &#123;<br>                “my_stopwords”: &#123;<br>                    “type”: “stop”,<br>                    “stopwords”: [<br>                        “the”,<br>                        “a”<br>                    ]<br>                &#125;<br>            &#125;,<br>            “analyzer”: &#123;<br>                “my_analyzer”: &#123;<br>                    “type”: “custom”,<br>                    “char_filter”: [<br>                        “html_strip”,<br>                        “&amp;_to_and”<br>                    ],<br>                    “tokenizer”: “standard”,<br>                    “filter”: [<br>                        “lowercase”,<br>                        “my_stopwords”<br>                    ]<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre><br>  索引被创建以后，使用 analyze API 来 测试这个新的分析器：<br>  <pre><code class="language-java"># GET <a target="_blank" rel="noopener" href="http://127.0.0.1:9200/my_index/_analyze">http://127.0.0.1:9200/my_index/_analyze</a><br>&#123;<br>    "text":"The quick &amp; brown fox",<br>    "analyzer": "my_analyzer"<br>&#125;<br></code></pre><br>  返回结果为：<br>  <pre><code class="language-java">&#123;<br>    "tokens": [<br>        &#123;<br>            "token": "quick",<br>            "start_offset": 4,<br>            "end_offset": 9,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 1<br>        &#125;,<br>        &#123;<br>            "token": "and",<br>            "start_offset": 10,<br>            "end_offset": 11,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 2<br>        &#125;,<br>        &#123;<br>            "token": "brown",<br>            "start_offset": 12,<br>            "end_offset": 17,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 3<br>        &#125;,<br>        &#123;<br>            "token": "fox",<br>            "start_offset": 18,<br>            "end_offset": 21,<br>            "type": "&lt;ALPHANUM&gt;",<br>            "position": 4<br>        &#125;<br>    ]<br>&#125;<br></code></pre> </p>
<h3 id="自定义分析器"><a href="#自定义分析器" class="headerlink" title="自定义分析器"></a>自定义分析器</h3> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://example.com/2021/07/18/Elasticsearch%E8%BF%9B%E9%98%B6%E4%B9%8B%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E3%80%81%E6%B0%B4%E5%B9%B3%E6%89%A9%E5%AE%B9%EF%BC%8C%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%EF%BC%8C%E5%88%86%E6%9E%90%E5%99%A8%E7%AD%89/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2021/07/18/Elasticsearch%E5%85%A5%E9%97%A8%E4%B9%8B%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5%E8%BF%9B%E9%98%B6/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            Elasticsearch入门之增删改查进阶
          
        </div>
      </a>
    
    
      <a href="/2021/07/18/Elasticsearch%E7%AE%80%E4%BB%8B%E4%BB%A5%E5%8F%8A%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5%E5%85%A5%E9%97%A8(%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0)/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Elasticsearch简介以及增删改查入门(学习笔记)</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "",
    app_key: "",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2015-2021
        <i class="ri-heart-fill heart_icon"></i> kgf
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        由 <a href="https://hexo.io" target="_blank">Hexo</a> 强力驱动
        <span class="division">|</span>
        主题 - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/image1.ico" alt="爱上口袋的天空"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/%20%7C%7C%20fa%20fa-home">首页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives/%20%7C%7C%20fa%20fa-archive">时间轴</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%20%7C%7C%20fa%20fa-tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories/%20%7C%7C%20fa%20fa-folder-open">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/%E9%9F%B3%E4%B9%90%20%7C%7C%20/music/%20%7C%7C%20fa%20fa-music,%E7%85%A7%E7%89%87%20%7C%7C%20/Gallery/%20%7C%7C%20fa%20fa-picture-o,%E7%94%B5%E5%BD%B1%20%7C%7C%20/movies/%20%7C%7C%20fa%20fa-film">清单||fa fa-heartbeat</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/link/%20%7C%7C%20fa%20fa-link">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about/%20%7C%7C%20fa%20fa-heart">关于</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/messageboard/%20%7C%7C%20fa%20fa-link">留言板</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
  </div>
</body>

</html>